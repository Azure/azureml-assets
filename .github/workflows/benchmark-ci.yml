name: benchmark-ci
on:
  pull_request:
    branches:
      - main
    paths:
      - benchmark/**
  pull_request_target:
    branches:
      - main
    paths:
      - benchmark/**
    types:
      - opened
      - labeled
      - synchronize
      - reopened
  workflow_dispatch:
    inputs:
      test_run:
        description: 'Run canary e2e (approx 10 mins) ? (y/n)'
        required: true
        default: 'n'

jobs:
  check-execution-context:
    uses: Azure/azureml-assets/.github/workflows/check-execution-context.yaml@main

  test:
    name: Run all pytest unit tests
    if: fromJSON(needs.check-execution-context.outputs.continue)
    runs-on: ubuntu-latest
    needs: check-execution-context
    
    permissions:
      # Required to clone repo
      contents: read
      # Required for EnricoMi/publish-unit-test-result-action
      checks: write
      issues: read
      pull-requests: write
      # Required for marocchino/sticky-pull-request-comment
      discussions: write

    defaults:
      run:
        working-directory: benchmark/

    steps:
    - name: Clone branch
      uses: Azure/azureml-assets/.github/actions/clone-repo@main
      with:
        forked-pr: ${{ needs.check-execution-context.outputs.forked_pr }}

    - name: Set up Python 3.8
      uses: actions/setup-python@v2
      with:
        python-version: 3.8

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip==21.3.1
        pip install flake8==3.9.1 pytest~=6.2 pytest-cov~=2.11
        pip install -r requirements.txt

        # Fix: force protobuf downgrade to avoid exception
        pip install protobuf==3.19.4

    - name: Test with pytest
      run: >-
        python -m pytest tests/ -v
        --junitxml=test-build-result.xml
        --cov=src/ --cov-report xml:coverage.xml --cov-report term-missing

    - name: Publish test results
      uses: EnricoMi/publish-unit-test-result-action@v2
      with:
        check_name: Test Results for ${{ github.workflow }}
        files: benchmark/test-build-result.xml

    - name: Code Coverage Summary Report
      uses: irongut/CodeCoverageSummary@v1.0.2
      with:
        filename: benchmark/coverage.xml
        badge: true
        format: markdown
        output: both

    - name: Add Coverage PR Comment
      uses: marocchino/sticky-pull-request-comment@v2
      if: github.event_name == 'pull_request'
      with:
        recreate: true
        path: code-coverage-results.md

  canary:
    # Tests running a sample pipeline end-to-end and wait for completion
    name: Run canary pipeline e2e
    if: fromJSON(needs.check-execution-context.outputs.continue) && (github.ref == 'refs/heads/main' || github.event.inputs.test_run == 'y')
    runs-on: ubuntu-latest
    needs: check-execution-context
    environment: Testing

    permissions:
      # Required to clone repo
      contents: read
      # Required for OIDC login to Azure
      id-token: write
      
    defaults:
      run:
        working-directory: benchmark/

    env:
      scripts_setup_dir: scripts/setup

    # timeout-minutes: 30 # TBD
    steps:
    - name: Clone branch
      uses: Azure/azureml-assets/.github/actions/clone-repo@main
      with:
        forked-pr: ${{ needs.check-execution-context.outputs.forked_pr }}
    
    - name: Log in to Azure and create resources
      uses: ./.github/actions/create-azure-resources
      with:
        client-id: ${{ secrets.AZURE_CLIENT_ID }}
        tenant-id: ${{ secrets.AZURE_TENANT_ID }}
        subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
        scripts-setup-dir: ${{ env.scripts_setup_dir }}

    - name: Install AzureML CLI v2
      run: |
        az extension remove --name ml
        az extension add --source https://azuremlsdktestpypi.blob.core.windows.net/wheels/sdk-cli-v2/ml-0.0.59687177-py3-none-any.whl --yes

    - name : Run canary pipeline e2e [classification_random]
      run: |
        az ml environment create -f ./src/environments/nvidia_pytorch/env.yml
        az ml job create -f ./src/pipelines/canary/classification_random.yml --stream
