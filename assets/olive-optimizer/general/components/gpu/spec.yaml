$schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json
type: command

version: 0.0.10
name: olive_optimizer_gpu
display_name: Olive Optimizer - GPU
is_deterministic: false

code: ../../src

description: An GPU version optimizer based on "Olive". "Olive" is an easy-to-use hardware-aware model optimization tool that composes industry-leading techniques across model compression, optimization, and compilation. For detailed info please refer to https://github.com/microsoft/Olive

inputs:
  config:
    type: uri_file
    optional: False
    description: "A JSON file that provides detailed Olive configurations."
  code_path:
    type: uri_folder
    optional: True
    description: "A code folder that contains all the files that is needed for Olive."
  data:
    type: uri_folder
    optional: True
    description: "A folder that contains the data directory that is needed for Olive."
  model:
    type: uri_folder
    optional: True
    description: "A folder that contains the model that is needed for Olive."

outputs:
  optimized_parameters:
    type: uri_folder
    description: "A folder that contains the inference parameters file(s) for corresponding optimized model(s)."
  optimized_model:
    type: uri_folder
    description: "A folder that contains the optimized model(s)."

environment: azureml:olive-optimizer-gpu@latest

command: >
    python -m olive_optimizer.run
    --config_path ${{inputs.config}}
    $[[--code ${{inputs.code_path}}]]
    $[[--data_path ${{inputs.data}}]]
    $[[--model_path ${{inputs.model}}]]
    --optimized_parameters_path ${{outputs.optimized_parameters}}
    --optimized_model_path ${{outputs.optimized_model}}
