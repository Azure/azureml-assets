$schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json
type: command

tags:
    Preview: ""

version: 0.0.24
name: llm_autoprompt_qna
display_name: LLM - Auto Prompt for QnA
is_deterministic: true

description: A command component for Zero/Few Shot Learning with GPT based models for Question Answering tasks.

inputs:
  data_file_name:
    type: string
    optional: True
    default: "QAGenerationData.jsonl"
    description: "Name of the dataset to use to tune the prompts."
  dev_data:
    type: uri_file
    optional: False
    description: "Train Data (should contain label_key and premise_key)."
  test_data:
    type: uri_file
    optional: False
    description: "Validation Data (should contain label_key and premise_key)."
  meta_prompts:
    type: uri_file
    optional: True
    description: "A sample prompt to pass it to the model. Add your text as {key name} and {labels}."
  top_k:
    type: integer
    optional: True
    default: 3
    description: "Number of best prompts to return"
  llm_config:
    type: string
    optional: False
    default: '{"type": "azure_open_ai", "model_name": "text-davinci-002", "deployment_name": "text-davinci-002"}'
    description: "JSON Configuration for generative model to use for completion. Must contain following keys: 'type' (value must be 'azure_open_ai' or 'azure'), 'model_name' (name of model to use for summary), 'deployment_name' (name of deployment for model)."
  openai_api_version:
    type: string
    optional: False
    default: "2023-03-15-preview"
    description: "Version of OpenAI API to use for communicating with LLM."
  openai_api_type:
    type: string
    optional: False
    default: azure
    description: "Type of OpenAI endpoint hosting model. Defaults to azure for AOAI endpoints."
  task_type:
    type: string
    optional: False
    enum:
    - arithmetic
    - multiple_choice
    - abstractive
    description: "Task type for the prompt generation. Options: arithmetic, multiple_choice, abstractive"
  text_keys:
    type: string
    optional: False
    default: "question"
    description: "Name of key(s) for Input texts in dev and test data. (Pass comma separated key names in case of multiple keys)."
  answer_key:
    type: string
    optional: False
    default: "answer"
    description: "Name of key for labels in dev and test data."
  context_key:
    type: string
    optional: True
    default: "context"
    description: "Required only in case of Multiple choice QnA Data."
  primary_metric:
    type: string
    optional: False
    default: bert_f1
    enum:
    - f1_score
    - bert_f1
    - bert_precision
    - bert_recall
    - exact_match
    - gpt_similarity
    - gpt_consistency
    - gpt_relevance
    - gpt_fluency
    - gpt_coherence
    description: "The primary metric used to pick top-k best prompts."
  prediction_temperature:
    type: number
    optional: True
    default: 0.0
    description: "Degree of randomness for responses from LLM. Value is a float from 0-1."
  prediction_max_tokens:
    type: integer
    optional: True
    default: 500
    description: "Number of tokens to reserve for response from LLM."
  prediction_logprobs:
    type: integer
    optional: True
    default: 1
    description: "Maximum number of most likely tokens to return from LLM."
  n_prompts:
    type: integer
    optional: True
    default: 10
    description: "Number of prompts to generate for each meta prompt."
  best_of:
    type: integer
    optional: True
    default: 100
    description: "Number of candidate completions to generated from LLM."

outputs:
  best_prompt:
    type: uri_file
    description: "JSON file containing keys of 'best_prompt_{metric}' and values of lists of top k prompts for each metric."

environment: azureml:llm-auto-prompt@latest
code: ../src
command: >-
  python zero_shot.py
  $[[--data_file_name ${{inputs.data_file_name}}]]
  --dev_data ${{inputs.dev_data}}
  --test_data ${{inputs.test_data}}
  --task_type ${{inputs.task_type}}
  --text_keys ${{inputs.text_keys}}
  --label_key ${{inputs.answer_key}}
  --predictions ${{outputs.best_prompt}}
  --learning_type zero_shot
  --llm_config '${{inputs.llm_config}}'
  --openai_api_version '${{inputs.openai_api_version}}'
  --openai_api_type '${{inputs.openai_api_type}}'
  --primary_metric ${{inputs.primary_metric}}
  $[[--prompt ${{inputs.meta_prompts}}]]
  $[[--temperature ${{inputs.prediction_temperature}}]]
  $[[--max_tokens ${{inputs.prediction_max_tokens}}]]
  $[[--logprobs ${{inputs.prediction_logprobs}}]]
  $[[--choices_key ${{inputs.context_key}}]]
  $[[--n_prompts ${{inputs.n_prompts}}]]
  $[[--best_of ${{inputs.best_of}}]]
  $[[--top_k ${{inputs.top_k}}]]
