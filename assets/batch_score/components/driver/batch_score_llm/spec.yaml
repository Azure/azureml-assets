$schema: http://azureml/sdk-2-0/ParallelComponent.json
type: parallel

name: batch_score_llm
version: 1.1.4
display_name: Batch Score Large Language Models
is_deterministic: False

inputs:
  # Predefined arguments for parallel job:
  # https://learn.microsoft.com/en-us/azure/machine-learning/reference-yaml-job-parallel?source=recommendations#predefined-arguments-for-parallel-job
  resume_from:
    type: string
    optional: True
    description: The pipeline run id to resume from

  # PRS preview feature
  async_mode:
    type: boolean
    optional: True
    default: False
    description: Whether to use PRS mini-batch streaming feature, which allows each PRS processor to process multiple mini-batches at a time.

  # Custom arguments
  configuration_file:
    type: uri_file
    optional: False
    description: Configures the behavior of batch scoring.
  data_input_table:
    type: mltable
    optional: False
    description: The data to be split and scored in parallel.

outputs:
  job_output_path:
    type: uri_file
  mini_batch_results_output_directory:
    type: uri_folder

max_concurrency_per_instance: 1
resources:
  instance_count: 1
mini_batch_size: 3kb
mini_batch_error_threshold: 5
logging_level: "DEBUG"
retry_settings:
  max_retries: 2
  timeout: 60

input_data: ${{inputs.data_input_table}}

task:
  code: ../src
  type: run_function
  entry_script: batch_score.main
  # Enable PRS safe append row configuration that is needed when dealing with large outputs with Unicode characters.
  # Using --append_row_safe_output true
  program_arguments: >-
    $[[--amlbi_async_mode ${{inputs.async_mode}}]]
    --append_row_safe_output true
    --configuration_file ${{inputs.configuration_file}}
    --partitioned_scoring_results ${{outputs.mini_batch_results_output_directory}}
    $[[--resume_from ${{inputs.resume_from}}]]
  environment: azureml://registries/azureml/environments/model-evaluation/versions/15
  append_row_to: ${{outputs.job_output_path}}
