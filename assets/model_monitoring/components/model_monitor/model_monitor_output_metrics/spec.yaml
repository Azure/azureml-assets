$schema: http://azureml/sdk-2-0/SparkComponent.json
type: spark

name: model_monitor_output_metrics
display_name: Model Monitor - Output Metrics
description: Output the computed model monitor metrics to the default datastore.
version: 0.3.9
is_deterministic: true

code: ../../src/
entry:
  file: ./model_monitor_output_metrics/run.py

inputs:
  signal_metrics: 
    type: mltable
    mode: direct
  monitor_name:
    type: string
  signal_name:
    type: string
  signal_type: 
    type: string
  metric_timestamp:
    type: string
  target_histogram:
    type: mltable
    mode: direct
    optional: true
  baseline_histogram:
    type: mltable
    mode: direct
    optional: true
  feature_importance_all:
    type: mltable
    mode: direct
    optional: true
outputs:
  signal_output:
    type: uri_folder
    mode: direct
conf:
  spark.hadoop.aml.enable_cache : "true"
  spark.driver.cores: 1
  spark.driver.memory: 2g
  spark.executor.cores: 2
  spark.executor.memory: 2g
  spark.executor.instances: 1
  spark.dynamicAllocation.enabled: True
  spark.dynamicAllocation.minExecutors: 1
  spark.dynamicAllocation.maxExecutors: 4
  spark.synapse.library.python.env: |
    channels:
      - conda-forge
    dependencies:
      - python=3.8
      - pip:
        - scipy~=1.10.0
        - numpy~=1.21.0
        - pandas~=1.4.3
        - azureml-mlflow~=1.49.0
        - azure-storage-file-datalake~=12.8.0
        - mltable~=1.3.0
        - azureml-fsspec
        - fsspec~=2023.4.0
    name: momo-base-spark
args: >-
  --signal_name ${{inputs.signal_name}} 
  --monitor_name ${{inputs.monitor_name}} 
  --signal_type ${{inputs.signal_type}} 
  --signal_metrics ${{inputs.signal_metrics}} 
  --metric_timestamp ${{inputs.metric_timestamp}} 
  --signal_output ${{outputs.signal_output}} 
  $[[--target_histogram ${{inputs.target_histogram}}]] 
  $[[--baseline_histogram ${{inputs.baseline_histogram}}]]
  $[[--feature_importance_all ${{inputs.feature_importance_all}}]]
