$schema: http://azureml/sdk-2-0/SparkComponent.json
type: spark

name: model_monitor_feature_selector
display_name: Model Monitor - Feature Selector
description: Selects features to compute signal metrics on.
version: 0.3.4
is_deterministic: true

code: ../../src
entry:
  file: ./model_monitor_feature_selector/run.py

inputs:
  input_data_1:
    type: mltable
    mode: direct
  input_data_2:
    type: mltable
    mode: direct
    optional: true
  filter_type:
    type: string
  filter_value:
    type: string
  feature_importance:
    type: mltable
    mode: direct
    optional: true
outputs:
  feature_names:
    type: mltable
    mode: direct
conf:
  spark.hadoop.aml.enable_cache : "true"
  spark.driver.cores: 1
  spark.driver.memory: 2g
  spark.executor.cores: 2
  spark.executor.memory: 2g
  spark.executor.instances: 1
  spark.dynamicAllocation.enabled: True
  spark.dynamicAllocation.minExecutors: 1
  spark.dynamicAllocation.maxExecutors: 4
  spark.synapse.library.python.env: |
    channels:
      - conda-forge
    dependencies:
      - python=3.8
      - pip:
        - scipy~=1.10.0
        - numpy~=1.21.0
        - pandas~=1.4.3
        - azureml-mlflow~=1.49.0
        - azure-storage-file-datalake~=12.8.0
        - mltable~=1.3.0
        - azureml-fsspec
        - fsspec~=2023.4.0
    name: momo-base-spark
args: >-
  --input_data_1 ${{inputs.input_data_1}}
  $[[--input_data_2 ${{inputs.input_data_2}}]]
  --filter_type ${{inputs.filter_type}}
  --filter_value ${{inputs.filter_value}}
  $[[--feature_importance ${{inputs.feature_importance}}]]
  --feature_names ${{outputs.feature_names}}
