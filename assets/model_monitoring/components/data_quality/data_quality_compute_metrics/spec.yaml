$schema: http://azureml/sdk-2-0/SparkComponent.json
type: spark

name: data_quality_compute_metrics
display_name:  Data Quality - Compute Metrics
description: Compute data quality metrics leveraged by the data quality monitor.
version: 0.3.4
is_deterministic: true

inputs:
  input_data: 
    type: mltable
    mode: direct
  data_statistics:
    type: mltable
    mode: direct
  feature_names:
    type: mltable
    mode: direct
  categorical_metrics:
    type: string
    default: "DataTypeErrorRate,NullValueRate,OutOfBoundsRate"
  numerical_metrics:
    type: string
    default: "DataTypeErrorRate,NullValueRate,OutOfBoundsRate"
outputs:
  signal_metrics:
    type: mltable
    mode: direct

code: ../../src/
entry:
  file: ./data_quality_compute_metrics/run.py
conf:
  spark.driver.cores: 1
  spark.driver.memory: 2g
  spark.executor.cores: 2
  spark.executor.memory: 2g
  spark.executor.instances: 1
  spark.dynamicAllocation.enabled: True
  spark.dynamicAllocation.minExecutors: 1
  spark.dynamicAllocation.maxExecutors: 4
  spark.synapse.library.python.env: |
    channels:
      - conda-forge
    dependencies:
      - python=3.8
      - pip:
        - scipy~=1.10.0
        - numpy~=1.21.0
        - pandas~=1.4.3
        - azureml-mlflow~=1.49.0
        - mltable~=1.3.0
        - azureml-fsspec
        - fsspec~=2023.4.0
    name: momo-base-spark
args: >-
  --input_data ${{inputs.input_data}}
  --data_statistics ${{inputs.data_statistics}}
  --categorical_metrics ${{inputs.categorical_metrics}}
  --numerical_metrics ${{inputs.numerical_metrics}}
  --signal_metrics ${{outputs.signal_metrics}}
