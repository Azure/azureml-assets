$schema: http://azureml/sdk-2-0/SparkComponent.json
type: spark

name: data_quality_metrics_joiner
display_name:  Data Quality - Metrics Joiner
description: Join baseline and target data quality metrics into a single output.
version: 0.3.5
is_deterministic: true

inputs:
  baseline_metrics: 
    type: mltable
    mode: direct
  target_metrics: 
    type: mltable
    mode: direct
  categorical_threshold:
    type: number
  numerical_threshold:
    type: number
outputs:
  signal_metrics:
    type: mltable
    mode: direct

code: ../../src/
entry:
  file: ./data_quality_metrics_joiner/run.py
conf:
  spark.hadoop.aml.enable_cache : "true"
  spark.driver.cores: 4
  spark.driver.memory: 28g
  spark.executor.cores: 4
  spark.executor.memory: 28g
  spark.executor.instances: 1
  spark.dynamicAllocation.enabled: True
  spark.dynamicAllocation.minExecutors: 1
  spark.dynamicAllocation.maxExecutors: 4
  spark.synapse.library.python.env: |
    channels:
      - defaults
    dependencies:
      - python=3.8
      - pip:
        - azure-storage-file-datalake~=12.8.0
        - mltable~=1.3.0
        - azureml-fsspec~=1.0.0
        - fsspec~=2023.4.0
    name: momo-base-spark
args: >-
  --baseline_metrics ${{inputs.baseline_metrics}}
  --target_metrics ${{inputs.target_metrics}}
  --numerical_threshold ${{inputs.numerical_threshold}}
  --categorical_threshold ${{inputs.categorical_threshold}}
  --signal_metrics ${{outputs.signal_metrics}}
