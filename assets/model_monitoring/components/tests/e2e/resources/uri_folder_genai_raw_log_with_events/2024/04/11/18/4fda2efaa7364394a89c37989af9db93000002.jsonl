{"specversion":"1.0","id":"85dda57a-62e3-4094-9fe3-fe59f3c4bae9","source":"/subscriptions/1aefdc5e-3a7c-4d71-a9f9-f5d3b03be19a/resourceGroups/yuachengtestrg/providers/Microsoft.MachineLearningServices/workspaces/ai-proj-eastus/onlineEndpoints/clone-vivi-log-test/deployments/clone-vivi-log-test-1","type":"azureml.inference.app_traces","datacontenttype":"application/json","time":"2024-04-11T18:07:31Z","data":[{"name":"openai_chat","context":{"trace_id":"0xa2f3f4f8267a482fa3bb96ad3e1f7f35","span_id":"0xe0e44f82233e81c6","trace_state":"[]"},"kind":"SpanKind.INTERNAL","parent_id":"0xb63bc7b18406dd64","start_time":"2024-04-11T18:07:26.697869Z","end_time":"2024-04-11T18:07:28.349388Z","status":{"status_code":"OK"},"attributes":{"framework":"promptflow","span_type":"LLM","function":"openai.resources.chat.completions.Completions.create","node_name":"modify_query_with_history","request_id":"ee2f5c78-77c1-4766-802d-49aa4b354ec3","line_run_id":"ee2f5c78-77c1-4766-802d-49aa4b354ec3","inputs":"{\n  \"model\": \"gpt-4-32k\",\n  \"messages\": [\n    {\n      \"role\": \"system\",\n      \"content\": \"Given the following conversation history and the users next question,rephrase the question to be a stand alone question.\\nIf the conversation is irrelevant or empty, just restate the original question.\\nDo not add more details than necessary to the question.\\nconversation:\\n\\n chat history:\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"what is aml?\"\n    },\n    {\n      \"role\": \"assistant\",\n      \"content\": \"\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"Follow up Input: how to create a spark job? \\nStandalone Question:\"\n    }\n  ],\n  \"temperature\": 1.0,\n  \"top_p\": 1.0,\n  \"n\": 1,\n  \"stream\": false,\n  \"presence_penalty\": 0.0,\n  \"frequency_penalty\": 0.0,\n  \"user\": \"\",\n  \"max_tokens\": 16\n}","llm.response.model":"gpt-4-32k","llm.generated_message":"{\n  \"content\": \"What are the steps to create a Spark job?\",\n  \"role\": \"assistant\",\n  \"function_call\": null,\n  \"tool_calls\": null\n}","__computed__.cumulative_token_count.completion":10,"__computed__.cumulative_token_count.prompt":92,"__computed__.cumulative_token_count.total":102,"llm.usage.completion_tokens":10,"llm.usage.prompt_tokens":92,"llm.usage.total_tokens":102,"output":"{\n  \"id\": \"chatcmpl-9Ct7XOLFacAQObzL32meHlThDLioG\",\n  \"choices\": [\n    {\n      \"finish_reason\": \"stop\",\n      \"index\": 0,\n      \"logprobs\": null,\n      \"message\": {\n        \"content\": \"What are the steps to create a Spark job?\",\n        \"role\": \"assistant\",\n        \"function_call\": null,\n        \"tool_calls\": null\n      },\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ],\n  \"created\": 1712858847,\n  \"model\": \"gpt-4-32k\",\n  \"object\": \"chat.completion\",\n  \"system_fingerprint\": null,\n  \"usage\": {\n    \"completion_tokens\": 10,\n    \"prompt_tokens\": 92,\n    \"total_tokens\": 102\n  },\n  \"prompt_filter_results\": [\n    {\n      \"prompt_index\": 0,\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ]\n}"},"events":[{"name":"promptflow.function.inputs","timestamp":"2024-04-11T18:07:26.700022Z","attributes":{"payload":"{\n  \"model\": \"gpt-4-32k\",\n  \"messages\": [\n    {\n      \"role\": \"system\",\n      \"content\": \"Given the following conversation history and the users next question,rephrase the question to be a stand alone question.\\nIf the conversation is irrelevant or empty, just restate the original question.\\nDo not add more details than necessary to the question.\\nconversation:\\n\\n chat history:\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"what is aml?\"\n    },\n    {\n      \"role\": \"assistant\",\n      \"content\": \"\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"Follow up Input: how to create a spark job? \\nStandalone Question:\"\n    }\n  ],\n  \"temperature\": 1.0,\n  \"top_p\": 1.0,\n  \"n\": 1,\n  \"stream\": false,\n  \"presence_penalty\": 0.0,\n  \"frequency_penalty\": 0.0,\n  \"user\": \"\",\n  \"max_tokens\": 16\n}"}},{"name":"promptflow.llm.generated_message","timestamp":"2024-04-11T18:07:28.347843Z","attributes":{"payload":"{\n  \"content\": \"What are the steps to create a Spark job?\",\n  \"role\": \"assistant\",\n  \"function_call\": null,\n  \"tool_calls\": null\n}"}},{"name":"promptflow.function.output","timestamp":"2024-04-11T18:07:28.349215Z","attributes":{"payload":"{\n  \"id\": \"chatcmpl-9Ct7XOLFacAQObzL32meHlThDLioG\",\n  \"choices\": [\n    {\n      \"finish_reason\": \"stop\",\n      \"index\": 0,\n      \"logprobs\": null,\n      \"message\": {\n        \"content\": \"What are the steps to create a Spark job?\",\n        \"role\": \"assistant\",\n        \"function_call\": null,\n        \"tool_calls\": null\n      },\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ],\n  \"created\": 1712858847,\n  \"model\": \"gpt-4-32k\",\n  \"object\": \"chat.completion\",\n  \"system_fingerprint\": null,\n  \"usage\": {\n    \"completion_tokens\": 10,\n    \"prompt_tokens\": 92,\n    \"total_tokens\": 102\n  },\n  \"prompt_filter_results\": [\n    {\n      \"prompt_index\": 0,\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ]\n}"}}],"links":[],"resource":{"attributes":{"service.name":"promptflow"},"schema_url":""}}],"collectdatatype":"pandas.core.frame.DataFrame","agent":"azureml-ai-monitoring/0.1.0b4","contentrange":"bytes 0-6589/6590","correlationid":"03eb9c0f-6dc4-47d2-b971-00528d5cf805","xrequestid":"03eb9c0f-6dc4-47d2-b971-00528d5cf805","modelversion":"default"}
{"specversion":"1.0","id":"8ad9292a-5ebc-4fa8-b613-58645b477659","source":"/subscriptions/1aefdc5e-3a7c-4d71-a9f9-f5d3b03be19a/resourceGroups/yuachengtestrg/providers/Microsoft.MachineLearningServices/workspaces/ai-proj-eastus/onlineEndpoints/clone-vivi-log-test/deployments/clone-vivi-log-test-1","type":"azureml.inference.app_traces","datacontenttype":"application/json","time":"2024-04-11T18:07:31Z","data":[{"name":"lookup","context":{"trace_id":"0xa2f3f4f8267a482fa3bb96ad3e1f7f35","span_id":"0x74dcae90ed4c9542","trace_state":"[]"},"kind":"SpanKind.INTERNAL","parent_id":"0xc2bb84e37668431d","start_time":"2024-04-11T18:07:28.353927Z","end_time":"2024-04-11T18:07:30.254128Z","status":{"status_code":"OK"},"attributes":{"framework":"promptflow","span_type":"Function","function":"search","node_name":"lookup","request_id":"ee2f5c78-77c1-4766-802d-49aa4b354ec3","line_run_id":"ee2f5c78-77c1-4766-802d-49aa4b354ec3","inputs":"{\n  \"mlindex_content\": \"embeddings:\\n  api_base: https:\/\/azureml-rag-auseast.openai.azure.com\/\\n  api_type: Azure\\n  api_version: 2023-07-01-preview\\n  batch_size: '16'\\n  connection:\\n    id: \\n      \/subscriptions\/1aefdc5e-3a7c-4d71-a9f9-f5d3b03be19a\/resourceGroups\/yuachengtestrg\/providers\/Microsoft.MachineLearningServices\/workspaces\/ai-proj-eastus\/connections\/Default_AzureOpenAI\\n  connection_type: workspace_connection\\n  deployment: text-embedding-ada-002\\n  dimension: 1536\\n  file_format_version: '2'\\n  kind: open_ai\\n  model: text-embedding-ada-002\\n  schema_version: '2'\\nindex:\\n  api_version: 2023-07-01-preview\\n  connection:\\n    id: \\n      \/subscriptions\/1aefdc5e-3a7c-4d71-a9f9-f5d3b03be19a\/resourceGroups\/yuachengtestrg\/providers\/Microsoft.MachineLearningServices\/workspaces\/ai-proj-eastus\/connections\/AzureAISearch\\n  connection_type: workspace_connection\\n  endpoint: https:\/\/yuacheng-aisearch-eastus.search.windows.net\\n  engine: azure-sdk\\n  field_mapping:\\n    content: content\\n    embedding: contentVector\\n    filename: filepath\\n    metadata: meta_json_string\\n    title: title\\n    url: url\\n  index: aml-rag-doc\\n  kind: acs\\n  semantic_configuration_name: azureml-default\\nself:\\n  path: \\n    azureml:\/\/subscriptions\/1aefdc5e-3a7c-4d71-a9f9-f5d3b03be19a\/resourcegroups\/yuachengtestrg\/workspaces\/ai-proj-eastus\/datastores\/workspaceblobstore\/paths\/azureml\/c258bd68-edde-4fbb-8333-d53f35698512\/index\/\\n  asset_id: \\n    azureml:\/\/locations\/eastus\/workspaces\/38bb01fe-e2e1-4e40-9af9-a9ff97fdcd6d\/data\/aml-rag-doc\/versions\/1\\n\",\n  \"queries\": \"What are the steps to create a Spark job?\",\n  \"query_type\": \"Hybrid (vector + keyword)\",\n  \"top_k\": 3\n}","output":"[\n  {\n    \"text\": \"# Configure Apache Spark jobs in Azure Machine Learning\\n\\n3. Under **Add tags**, provide **Name** and **Value**, then select **Add**. Adding tags is optional.\\n    4. Under the **Code** section:\\n        1. Select **Azure Machine Learning workspace default blob storage** from **Choose code location** dropdown.\\n        2. Under **Path to code file to upload**, select **Browse**.\\n        3. In the pop-up screen titled **Path selection**, select the path of code file `titanic.py` on the workspace default datastore `workspaceblobstore`.\\n        4. Select **Save**.\\n        5. Input `titanic.py` as the name of **Entry file** for the standalone job.\\n        6. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter **Input name** as `titanic_data`. The input should refer to this name later in the **Arguments**.\\n            2. Select **Input type** as **Data**.\\n            3. Select **Data type** as **File**.\\n            4. Select **Data source** as **URI**.\\n            5. Enter an Azure Data Lake Storage (ADLS) Gen 2 data URI for `titanic.csv` file in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here, `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        7.  To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter **Output name** as `wrangled_data`. The output should refer to this name later in the **Arguments**.\\n            2. Select **Output type** as **Folder**.\\n            3. For **Output URI destination**, enter an Azure Data Lake Storage (ADLS) Gen 2 folder URI in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        8.  Enter **Arguments**  as `--titanic_data ${{inputs.titanic_data}} --wrangled_data ${{outputs.wrangled_data}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** as 2 and executor **Memory (GB)** as 2.\\n            2. For **Dynamically allocated executors**, select **Disabled**.\\n            3. Enter the number of **Executor instances** as 2.\\n        2. For **Driver size**, enter number of driver **Cores** as 1 and driver **Memory (GB)** as 2.\\n    6. Select **Next**.\\n6. On the **Review** screen:\\n    1. Review the job specification before submitting it.\\n    2. Select **Create** to submit the standalone Spark job.\\n\\n\u003e [!NOTE]\\n\u003e A standalone job submitted from the Studio UI using an Azure Machine Learning serverless Spark compute defaults to user identity passthrough for data access.\\n\\n\\n---\\n\\n\u003e [!TIP]\\n\u003e You might have an existing Synapse Spark pool in your Azure Synapse workspace. To use an existing Synapse Spark pool, please follow the instructions to [attach a Synapse Spark pool in Azure Machine Learning workspace](.\/how-to-manage-synapse-spark-pool.md).\\n\\n## Next steps\\n- [Apache Spark in Azure Machine Learning](.\/apache-spark-azure-ml-concepts.md)\\n- [Quickstart: Interactive Data Wrangling with Apache Spark](.\/apache-spark-environment-configuration.md)\\n- [Attach and manage a Synapse Spark pool in Azure Machine Learning](.\/how-to-manage-synapse-spark-pool.md)\\n- [Interactive Data Wrangling with Apache Spark in Azure Machine Learning](.\/interactive-data-wrangling-with-apache-spark-azure-ml.md)\\n- [Submit Spark jobs in Azure Machine Learning](.\/how-to-submit-spark-jobs.md)\\n- [Code samples for Spark jobs using Azure Machine Learning CLI](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/cli\/jobs\/spark)\",\n    \"metadata\": {\n      \"id\": \"cXVpY2tzdGFydC1zcGFyay1qb2JzLm1kNA==\",\n      \"source\": {\n        \"title\": \"Configure Apache Spark jobs in Azure Machine Learning\",\n        \"filename\": \"quickstart-spark-jobs.md\",\n        \"url\": \"quickstart-spark-jobs.md\",\n        \"mtime\": 1710206171.0\n      },\n      \"stats\": {\n        \"tiktokens\": 901,\n        \"chars\": 3569,\n        \"lines\": 47\n      },\n      \"content_hash\": \"180236985807e2fb8630996332b1ac47df8c1aa7eda985ecb895df59c6ad2ec7\"\n    },\n    \"score\": 0.030751174315810204\n  },\n  {\n    \"text\": \"# Submit Spark jobs in Azure Machine Learning\\n\\n6. To add any Jar file(s) that the standalone job requires at runtime, select **+ Add file** under **Jars** and input the name of the `.jar` file to be included in the Spark driver. Also, add the executor `CLASSPATH` for successful job execution. Multiple files can be added.\\n        7. To add archive(s) that should be extracted into the working directory of each executor for successful job execution, select **+ Add file** under **Archives**, and input the name of the archive. Multiple archives can be added.\\n        8. Adding **Py files**, **Jars**, and **Archives** is optional.\\n        9. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter an **Input name**. The input should refer to this name later in the **Arguments**.\\n            2. Select an **Input type**.\\n            3. For type **Data**:\\n                1. Select **Data type** as **File** or **Folder**.\\n                2. Select **Data source** as **Upload from local**, **URI**, or **Datastore**.\\n                    - For **Upload from local**, select **Browse** under **Path to upload**, to choose the input file or folder.\\n                    - For **URI**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI), or enter a data asset `azureml:\/\/`.\\n                    - For **Datastore**:\\n                        1. **Select a datastore** from the dropdown menu.\\n                        2. Under **Path to data**, select **Browse**.\\n                        3. In the pop-up screen titled **Path selection**, select the path of the code files on the workspace default blob storage.\\n                        4. Select **Save**.\\n            4. For type **Integer**, enter an integer value as **Input value**.\\n            5. For type **Number**, enter a numeric value as **Input value**.\\n            6. For type **Boolean**, select **True** or **False** as **Input value**.\\n            7. For type **String**, enter a string as **Input value**.\\n        10. To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter an **Output name**. The output should refer to this name later to in the **Arguments**.\\n            2. Select **Output type** as **File** or **Folder**.\\n            3. For **Output URI destination**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI) or enter a data asset `azureml:\/\/`.\\n        11. Enter **Arguments** by using the names defined in the **Input name** and **Output name** fields in the earlier steps, and the names of input and output arguments used in the Python script **Entry file**. For example, if the **Input name** and **Output name** are defined as `job_input` and `job_output`, and the arguments are added in the **Entry file** as shown here\\n\\n            ``` python\\n            import argparse\\n\\n            parser = argparse.ArgumentParser()\\n            parser.add_argument(\\\"--input_param\\\")\\n            parser.add_argument(\\\"--output_param\\\")\\n            ```\\n\\n    then enter **Arguments** as `--input_param ${{inputs.job_input}} --output_param ${{outputs.job_output}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** and executor **Memory (GB)**, in gigabytes.\\n            2. For **Dynamically allocated executors**, select the **Disabled** or **Enabled** option.\\n        - If dynamic allocation of executors is **Disabled**, enter the number of **Executor instances**.\\n        - If dynamic allocation of executors is **Enabled**, use the slider to select the minimum and maximum number of executors.\\n        1. For **Driver size**:\\n            1. Enter number of driver **Cores** and driver **Memory (GB)**, in gigabytes.\\n            2. Enter **Name** and **Value** pairs for any **Additional configurations**, then select **Add**. Providing **Additional configurations** is optional.\\n    6. Select **Next**.\\n7. On the **Review** screen:\",\n    \"metadata\": {\n      \"id\": \"aG93LXRvLXN1Ym1pdC1zcGFyay1qb2JzLm1kNw==\",\n      \"source\": {\n        \"title\": \"Submit Spark jobs in Azure Machine Learning\",\n        \"filename\": \"how-to-submit-spark-jobs.md\",\n        \"url\": \"how-to-submit-spark-jobs.md\",\n        \"mtime\": 1710206154.0\n      },\n      \"stats\": {\n        \"tiktokens\": 933,\n        \"chars\": 3974,\n        \"lines\": 48\n      },\n      \"content_hash\": \"4d20509f3e7b887d13bf41c0ef760f486cc1b45615c33bca6825cd23643bd058\"\n    },\n    \"score\": 0.025739235803484917\n  },\n  {\n    \"text\": \"# Configure Apache Spark jobs in Azure Machine Learning\\n\\n- [Code samples for Spark jobs using Azure Machine Learning Python SDK](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/sdk\/python\/jobs\/spark)\",\n    \"metadata\": {\n      \"id\": \"cXVpY2tzdGFydC1zcGFyay1qb2JzLm1kNQ==\",\n      \"source\": {\n        \"title\": \"Configure Apache Spark jobs in Azure Machine Learning\",\n        \"filename\": \"quickstart-spark-jobs.md\",\n        \"url\": \"quickstart-spark-jobs.md\",\n        \"mtime\": 1710206171.0\n      },\n      \"stats\": {\n        \"tiktokens\": 44,\n        \"chars\": 203,\n        \"lines\": 3\n      },\n      \"content_hash\": \"9c6e5e25028d10af22f711dfc932d1c762f186375243340e341c3fe22463cf50\"\n    },\n    \"score\": 0.02253928780555725\n  }\n]"},"events":[{"name":"promptflow.function.inputs","timestamp":"2024-04-11T18:07:28.354625Z","attributes":{"payload":"{\n  \"mlindex_content\": \"embeddings:\\n  api_base: https:\/\/azureml-rag-auseast.openai.azure.com\/\\n  api_type: Azure\\n  api_version: 2023-07-01-preview\\n  batch_size: '16'\\n  connection:\\n    id: \\n      \/subscriptions\/1aefdc5e-3a7c-4d71-a9f9-f5d3b03be19a\/resourceGroups\/yuachengtestrg\/providers\/Microsoft.MachineLearningServices\/workspaces\/ai-proj-eastus\/connections\/Default_AzureOpenAI\\n  connection_type: workspace_connection\\n  deployment: text-embedding-ada-002\\n  dimension: 1536\\n  file_format_version: '2'\\n  kind: open_ai\\n  model: text-embedding-ada-002\\n  schema_version: '2'\\nindex:\\n  api_version: 2023-07-01-preview\\n  connection:\\n    id: \\n      \/subscriptions\/1aefdc5e-3a7c-4d71-a9f9-f5d3b03be19a\/resourceGroups\/yuachengtestrg\/providers\/Microsoft.MachineLearningServices\/workspaces\/ai-proj-eastus\/connections\/AzureAISearch\\n  connection_type: workspace_connection\\n  endpoint: https:\/\/yuacheng-aisearch-eastus.search.windows.net\\n  engine: azure-sdk\\n  field_mapping:\\n    content: content\\n    embedding: contentVector\\n    filename: filepath\\n    metadata: meta_json_string\\n    title: title\\n    url: url\\n  index: aml-rag-doc\\n  kind: acs\\n  semantic_configuration_name: azureml-default\\nself:\\n  path: \\n    azureml:\/\/subscriptions\/1aefdc5e-3a7c-4d71-a9f9-f5d3b03be19a\/resourcegroups\/yuachengtestrg\/workspaces\/ai-proj-eastus\/datastores\/workspaceblobstore\/paths\/azureml\/c258bd68-edde-4fbb-8333-d53f35698512\/index\/\\n  asset_id: \\n    azureml:\/\/locations\/eastus\/workspaces\/38bb01fe-e2e1-4e40-9af9-a9ff97fdcd6d\/data\/aml-rag-doc\/versions\/1\\n\",\n  \"queries\": \"What are the steps to create a Spark job?\",\n  \"query_type\": \"Hybrid (vector + keyword)\",\n  \"top_k\": 3\n}"}},{"name":"promptflow.function.output","timestamp":"2024-04-11T18:07:30.252883Z","attributes":{"payload":"[\n  {\n    \"text\": \"# Configure Apache Spark jobs in Azure Machine Learning\\n\\n3. Under **Add tags**, provide **Name** and **Value**, then select **Add**. Adding tags is optional.\\n    4. Under the **Code** section:\\n        1. Select **Azure Machine Learning workspace default blob storage** from **Choose code location** dropdown.\\n        2. Under **Path to code file to upload**, select **Browse**.\\n        3. In the pop-up screen titled **Path selection**, select the path of code file `titanic.py` on the workspace default datastore `workspaceblobstore`.\\n        4. Select **Save**.\\n        5. Input `titanic.py` as the name of **Entry file** for the standalone job.\\n        6. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter **Input name** as `titanic_data`. The input should refer to this name later in the **Arguments**.\\n            2. Select **Input type** as **Data**.\\n            3. Select **Data type** as **File**.\\n            4. Select **Data source** as **URI**.\\n            5. Enter an Azure Data Lake Storage (ADLS) Gen 2 data URI for `titanic.csv` file in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here, `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        7.  To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter **Output name** as `wrangled_data`. The output should refer to this name later in the **Arguments**.\\n            2. Select **Output type** as **Folder**.\\n            3. For **Output URI destination**, enter an Azure Data Lake Storage (ADLS) Gen 2 folder URI in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        8.  Enter **Arguments**  as `--titanic_data ${{inputs.titanic_data}} --wrangled_data ${{outputs.wrangled_data}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** as 2 and executor **Memory (GB)** as 2.\\n            2. For **Dynamically allocated executors**, select **Disabled**.\\n            3. Enter the number of **Executor instances** as 2.\\n        2. For **Driver size**, enter number of driver **Cores** as 1 and driver **Memory (GB)** as 2.\\n    6. Select **Next**.\\n6. On the **Review** screen:\\n    1. Review the job specification before submitting it.\\n    2. Select **Create** to submit the standalone Spark job.\\n\\n\u003e [!NOTE]\\n\u003e A standalone job submitted from the Studio UI using an Azure Machine Learning serverless Spark compute defaults to user identity passthrough for data access.\\n\\n\\n---\\n\\n\u003e [!TIP]\\n\u003e You might have an existing Synapse Spark pool in your Azure Synapse workspace. To use an existing Synapse Spark pool, please follow the instructions to [attach a Synapse Spark pool in Azure Machine Learning workspace](.\/how-to-manage-synapse-spark-pool.md).\\n\\n## Next steps\\n- [Apache Spark in Azure Machine Learning](.\/apache-spark-azure-ml-concepts.md)\\n- [Quickstart: Interactive Data Wrangling with Apache Spark](.\/apache-spark-environment-configuration.md)\\n- [Attach and manage a Synapse Spark pool in Azure Machine Learning](.\/how-to-manage-synapse-spark-pool.md)\\n- [Interactive Data Wrangling with Apache Spark in Azure Machine Learning](.\/interactive-data-wrangling-with-apache-spark-azure-ml.md)\\n- [Submit Spark jobs in Azure Machine Learning](.\/how-to-submit-spark-jobs.md)\\n- [Code samples for Spark jobs using Azure Machine Learning CLI](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/cli\/jobs\/spark)\",\n    \"metadata\": {\n      \"id\": \"cXVpY2tzdGFydC1zcGFyay1qb2JzLm1kNA==\",\n      \"source\": {\n        \"title\": \"Configure Apache Spark jobs in Azure Machine Learning\",\n        \"filename\": \"quickstart-spark-jobs.md\",\n        \"url\": \"quickstart-spark-jobs.md\",\n        \"mtime\": 1710206171.0\n      },\n      \"stats\": {\n        \"tiktokens\": 901,\n        \"chars\": 3569,\n        \"lines\": 47\n      },\n      \"content_hash\": \"180236985807e2fb8630996332b1ac47df8c1aa7eda985ecb895df59c6ad2ec7\"\n    },\n    \"score\": 0.030751174315810204\n  },\n  {\n    \"text\": \"# Submit Spark jobs in Azure Machine Learning\\n\\n6. To add any Jar file(s) that the standalone job requires at runtime, select **+ Add file** under **Jars** and input the name of the `.jar` file to be included in the Spark driver. Also, add the executor `CLASSPATH` for successful job execution. Multiple files can be added.\\n        7. To add archive(s) that should be extracted into the working directory of each executor for successful job execution, select **+ Add file** under **Archives**, and input the name of the archive. Multiple archives can be added.\\n        8. Adding **Py files**, **Jars**, and **Archives** is optional.\\n        9. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter an **Input name**. The input should refer to this name later in the **Arguments**.\\n            2. Select an **Input type**.\\n            3. For type **Data**:\\n                1. Select **Data type** as **File** or **Folder**.\\n                2. Select **Data source** as **Upload from local**, **URI**, or **Datastore**.\\n                    - For **Upload from local**, select **Browse** under **Path to upload**, to choose the input file or folder.\\n                    - For **URI**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI), or enter a data asset `azureml:\/\/`.\\n                    - For **Datastore**:\\n                        1. **Select a datastore** from the dropdown menu.\\n                        2. Under **Path to data**, select **Browse**.\\n                        3. In the pop-up screen titled **Path selection**, select the path of the code files on the workspace default blob storage.\\n                        4. Select **Save**.\\n            4. For type **Integer**, enter an integer value as **Input value**.\\n            5. For type **Number**, enter a numeric value as **Input value**.\\n            6. For type **Boolean**, select **True** or **False** as **Input value**.\\n            7. For type **String**, enter a string as **Input value**.\\n        10. To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter an **Output name**. The output should refer to this name later to in the **Arguments**.\\n            2. Select **Output type** as **File** or **Folder**.\\n            3. For **Output URI destination**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI) or enter a data asset `azureml:\/\/`.\\n        11. Enter **Arguments** by using the names defined in the **Input name** and **Output name** fields in the earlier steps, and the names of input and output arguments used in the Python script **Entry file**. For example, if the **Input name** and **Output name** are defined as `job_input` and `job_output`, and the arguments are added in the **Entry file** as shown here\\n\\n            ``` python\\n            import argparse\\n\\n            parser = argparse.ArgumentParser()\\n            parser.add_argument(\\\"--input_param\\\")\\n            parser.add_argument(\\\"--output_param\\\")\\n            ```\\n\\n    then enter **Arguments** as `--input_param ${{inputs.job_input}} --output_param ${{outputs.job_output}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** and executor **Memory (GB)**, in gigabytes.\\n            2. For **Dynamically allocated executors**, select the **Disabled** or **Enabled** option.\\n        - If dynamic allocation of executors is **Disabled**, enter the number of **Executor instances**.\\n        - If dynamic allocation of executors is **Enabled**, use the slider to select the minimum and maximum number of executors.\\n        1. For **Driver size**:\\n            1. Enter number of driver **Cores** and driver **Memory (GB)**, in gigabytes.\\n            2. Enter **Name** and **Value** pairs for any **Additional configurations**, then select **Add**. Providing **Additional configurations** is optional.\\n    6. Select **Next**.\\n7. On the **Review** screen:\",\n    \"metadata\": {\n      \"id\": \"aG93LXRvLXN1Ym1pdC1zcGFyay1qb2JzLm1kNw==\",\n      \"source\": {\n        \"title\": \"Submit Spark jobs in Azure Machine Learning\",\n        \"filename\": \"how-to-submit-spark-jobs.md\",\n        \"url\": \"how-to-submit-spark-jobs.md\",\n        \"mtime\": 1710206154.0\n      },\n      \"stats\": {\n        \"tiktokens\": 933,\n        \"chars\": 3974,\n        \"lines\": 48\n      },\n      \"content_hash\": \"4d20509f3e7b887d13bf41c0ef760f486cc1b45615c33bca6825cd23643bd058\"\n    },\n    \"score\": 0.025739235803484917\n  },\n  {\n    \"text\": \"# Configure Apache Spark jobs in Azure Machine Learning\\n\\n- [Code samples for Spark jobs using Azure Machine Learning Python SDK](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/sdk\/python\/jobs\/spark)\",\n    \"metadata\": {\n      \"id\": \"cXVpY2tzdGFydC1zcGFyay1qb2JzLm1kNQ==\",\n      \"source\": {\n        \"title\": \"Configure Apache Spark jobs in Azure Machine Learning\",\n        \"filename\": \"quickstart-spark-jobs.md\",\n        \"url\": \"quickstart-spark-jobs.md\",\n        \"mtime\": 1710206171.0\n      },\n      \"stats\": {\n        \"tiktokens\": 44,\n        \"chars\": 203,\n        \"lines\": 3\n      },\n      \"content_hash\": \"9c6e5e25028d10af22f711dfc932d1c762f186375243340e341c3fe22463cf50\"\n    },\n    \"score\": 0.02253928780555725\n  }\n]"}}],"links":[],"resource":{"attributes":{"service.name":"promptflow"},"schema_url":""}}],"agent":"azureml-ai-monitoring/0.1.0b4","contentrange":"bytes 0-23991/23992","correlationid":"d359727e-5787-44e1-bfeb-c0af0a9b112c","xrequestid":"d359727e-5787-44e1-bfeb-c0af0a9b112c","modelversion":"default","collectdatatype":"pandas.core.frame.DataFrame"}
{"specversion":"1.0","id":"87746605-0aaf-4633-99ad-2828d3a25ab9","source":"/subscriptions/1aefdc5e-3a7c-4d71-a9f9-f5d3b03be19a/resourceGroups/yuachengtestrg/providers/Microsoft.MachineLearningServices/workspaces/ai-proj-eastus/onlineEndpoints/clone-vivi-log-test/deployments/clone-vivi-log-test-1","type":"azureml.inference.app_traces","datacontenttype":"application/json","time":"2024-04-11T18:07:31Z","data":[{"name":"modify_query_with_history","context":{"trace_id":"0xa2f3f4f8267a482fa3bb96ad3e1f7f35","span_id":"0xb63bc7b18406dd64","trace_state":"[]"},"kind":"SpanKind.INTERNAL","parent_id":"0xc2bb84e37668431d","start_time":"2024-04-11T18:07:26.691748Z","end_time":"2024-04-11T18:07:28.349643Z","status":{"status_code":"OK"},"attributes":{"framework":"promptflow","span_type":"Function","function":"AzureOpenAI.chat","node_name":"modify_query_with_history","request_id":"ee2f5c78-77c1-4766-802d-49aa4b354ec3","line_run_id":"ee2f5c78-77c1-4766-802d-49aa4b354ec3","prompt.template":"system: \nGiven the following conversation history and the users next question,rephrase the question to be a stand alone question.\nIf the conversation is irrelevant or empty, just restate the original question.\nDo not add more details than necessary to the question.\nconversation:\n\n chat history: \n{% for item in chat_history %} user: \n{{ item.inputs.question }} \nassistant: \n{{ item.outputs.output }} \n{% endfor %}\n\nuser:\nFollow up Input: {{question}} \nStandalone Question:","prompt.variables":"{\n  \"question\": \"how to create a spark job?\",\n  \"chat_history\": [\n    {\n      \"inputs\": {\n        \"question\": \"what is aml?\"\n      },\n      \"outputs\": {\n        \"answer\": \"Azure Machine Learning (AML) is a cloud service used for accelerating and managing the machine learning project lifecycle. It is designed for ML professionals, data scientists, and engineers to facilitate their daily workflows in training and deploying models and managing machine learning operations (MLOps). You can create models in AML or use models built from open-source platforms like PyTorch, TensorFlow, or scikit-learn. Furthermore, Azure Machine Learning provides tools for monitoring, retraining, and redeploying models(Source: overview-what-is-azure-machine-learning.md).\"\n      }\n    }\n  ]\n}","inputs":"{\n  \"prompt\": \"system: \\nGiven the following conversation history and the users next question,rephrase the question to be a stand alone question.\\nIf the conversation is irrelevant or empty, just restate the original question.\\nDo not add more details than necessary to the question.\\nconversation:\\n\\n chat history: \\n{% for item in chat_history %} user: \\n{{ item.inputs.question }} \\nassistant: \\n{{ item.outputs.output }} \\n{% endfor %}\\n\\nuser:\\nFollow up Input: {{question}} \\nStandalone Question:\",\n  \"deployment_name\": \"gpt-4-32k\",\n  \"temperature\": 1.0,\n  \"top_p\": 1.0,\n  \"max_tokens\": 16,\n  \"presence_penalty\": 0.0,\n  \"frequency_penalty\": 0.0,\n  \"chat_history\": [\n    {\n      \"inputs\": {\n        \"question\": \"what is aml?\"\n      },\n      \"outputs\": {\n        \"answer\": \"Azure Machine Learning (AML) is a cloud service used for accelerating and managing the machine learning project lifecycle. It is designed for ML professionals, data scientists, and engineers to facilitate their daily workflows in training and deploying models and managing machine learning operations (MLOps). You can create models in AML or use models built from open-source platforms like PyTorch, TensorFlow, or scikit-learn. Furthermore, Azure Machine Learning provides tools for monitoring, retraining, and redeploying models(Source: overview-what-is-azure-machine-learning.md).\"\n      }\n    }\n  ],\n  \"question\": \"how to create a spark job?\"\n}","__computed__.cumulative_token_count.completion":10,"__computed__.cumulative_token_count.prompt":92,"__computed__.cumulative_token_count.total":102,"output":"\"What are the steps to create a Spark job?\""},"events":[{"name":"promptflow.prompt.template","timestamp":"2024-04-11T18:07:26.694109Z","attributes":{"payload":"{\n  \"prompt.template\": \"system: \\nGiven the following conversation history and the users next question,rephrase the question to be a stand alone question.\\nIf the conversation is irrelevant or empty, just restate the original question.\\nDo not add more details than necessary to the question.\\nconversation:\\n\\n chat history: \\n{% for item in chat_history %} user: \\n{{ item.inputs.question }} \\nassistant: \\n{{ item.outputs.output }} \\n{% endfor %}\\n\\nuser:\\nFollow up Input: {{question}} \\nStandalone Question:\",\n  \"prompt.variables\": \"{\\n  \\\"question\\\": \\\"how to create a spark job?\\\",\\n  \\\"chat_history\\\": [\\n    {\\n      \\\"inputs\\\": {\\n        \\\"question\\\": \\\"what is aml?\\\"\\n      },\\n      \\\"outputs\\\": {\\n        \\\"answer\\\": \\\"Azure Machine Learning (AML) is a cloud service used for accelerating and managing the machine learning project lifecycle. It is designed for ML professionals, data scientists, and engineers to facilitate their daily workflows in training and deploying models and managing machine learning operations (MLOps). You can create models in AML or use models built from open-source platforms like PyTorch, TensorFlow, or scikit-learn. Furthermore, Azure Machine Learning provides tools for monitoring, retraining, and redeploying models(Source: overview-what-is-azure-machine-learning.md).\\\"\\n      }\\n    }\\n  ]\\n}\"\n}"}},{"name":"promptflow.function.inputs","timestamp":"2024-04-11T18:07:26.695653Z","attributes":{"payload":"{\n  \"prompt\": \"system: \\nGiven the following conversation history and the users next question,rephrase the question to be a stand alone question.\\nIf the conversation is irrelevant or empty, just restate the original question.\\nDo not add more details than necessary to the question.\\nconversation:\\n\\n chat history: \\n{% for item in chat_history %} user: \\n{{ item.inputs.question }} \\nassistant: \\n{{ item.outputs.output }} \\n{% endfor %}\\n\\nuser:\\nFollow up Input: {{question}} \\nStandalone Question:\",\n  \"deployment_name\": \"gpt-4-32k\",\n  \"temperature\": 1.0,\n  \"top_p\": 1.0,\n  \"max_tokens\": 16,\n  \"presence_penalty\": 0.0,\n  \"frequency_penalty\": 0.0,\n  \"chat_history\": [\n    {\n      \"inputs\": {\n        \"question\": \"what is aml?\"\n      },\n      \"outputs\": {\n        \"answer\": \"Azure Machine Learning (AML) is a cloud service used for accelerating and managing the machine learning project lifecycle. It is designed for ML professionals, data scientists, and engineers to facilitate their daily workflows in training and deploying models and managing machine learning operations (MLOps). You can create models in AML or use models built from open-source platforms like PyTorch, TensorFlow, or scikit-learn. Furthermore, Azure Machine Learning provides tools for monitoring, retraining, and redeploying models(Source: overview-what-is-azure-machine-learning.md).\"\n      }\n    }\n  ],\n  \"question\": \"how to create a spark job?\"\n}"}},{"name":"promptflow.function.output","timestamp":"2024-04-11T18:07:28.349577Z","attributes":{"payload":"\"What are the steps to create a Spark job?\""}}],"links":[],"resource":{"attributes":{"service.name":"promptflow"},"schema_url":""}}],"collectdatatype":"pandas.core.frame.DataFrame","contentrange":"bytes 0-6991/6992","correlationid":"527eebd6-3dcd-428b-adf7-589250ffc263","xrequestid":"527eebd6-3dcd-428b-adf7-589250ffc263","agent":"azureml-ai-monitoring/0.1.0b4","modelversion":"default"}
{"specversion":"1.0","id":"5d471e45-bf34-486d-8c7d-3c9108f6b152","source":"/subscriptions/1aefdc5e-3a7c-4d71-a9f9-f5d3b03be19a/resourceGroups/yuachengtestrg/providers/Microsoft.MachineLearningServices/workspaces/ai-proj-eastus/onlineEndpoints/clone-vivi-log-test/deployments/clone-vivi-log-test-1","type":"azureml.inference.app_traces","datacontenttype":"application/json","time":"2024-04-11T18:07:31Z","data":[{"name":"generate_prompt_context","context":{"trace_id":"0xa2f3f4f8267a482fa3bb96ad3e1f7f35","span_id":"0x405e673e1b6a33c9","trace_state":"[]"},"kind":"SpanKind.INTERNAL","parent_id":"0xc2bb84e37668431d","start_time":"2024-04-11T18:07:30.324234Z","end_time":"2024-04-11T18:07:30.328375Z","status":{"status_code":"OK"},"attributes":{"framework":"promptflow","span_type":"Function","function":"generate_prompt_context","node_name":"generate_prompt_context","request_id":"ee2f5c78-77c1-4766-802d-49aa4b354ec3","line_run_id":"ee2f5c78-77c1-4766-802d-49aa4b354ec3","inputs":"{\n  \"search_result\": [\n    {\n      \"text\": \"# Configure Apache Spark jobs in Azure Machine Learning\\n\\n3. Under **Add tags**, provide **Name** and **Value**, then select **Add**. Adding tags is optional.\\n    4. Under the **Code** section:\\n        1. Select **Azure Machine Learning workspace default blob storage** from **Choose code location** dropdown.\\n        2. Under **Path to code file to upload**, select **Browse**.\\n        3. In the pop-up screen titled **Path selection**, select the path of code file `titanic.py` on the workspace default datastore `workspaceblobstore`.\\n        4. Select **Save**.\\n        5. Input `titanic.py` as the name of **Entry file** for the standalone job.\\n        6. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter **Input name** as `titanic_data`. The input should refer to this name later in the **Arguments**.\\n            2. Select **Input type** as **Data**.\\n            3. Select **Data type** as **File**.\\n            4. Select **Data source** as **URI**.\\n            5. Enter an Azure Data Lake Storage (ADLS) Gen 2 data URI for `titanic.csv` file in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here, `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        7.  To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter **Output name** as `wrangled_data`. The output should refer to this name later in the **Arguments**.\\n            2. Select **Output type** as **Folder**.\\n            3. For **Output URI destination**, enter an Azure Data Lake Storage (ADLS) Gen 2 folder URI in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        8.  Enter **Arguments**  as `--titanic_data ${{inputs.titanic_data}} --wrangled_data ${{outputs.wrangled_data}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** as 2 and executor **Memory (GB)** as 2.\\n            2. For **Dynamically allocated executors**, select **Disabled**.\\n            3. Enter the number of **Executor instances** as 2.\\n        2. For **Driver size**, enter number of driver **Cores** as 1 and driver **Memory (GB)** as 2.\\n    6. Select **Next**.\\n6. On the **Review** screen:\\n    1. Review the job specification before submitting it.\\n    2. Select **Create** to submit the standalone Spark job.\\n\\n\u003e [!NOTE]\\n\u003e A standalone job submitted from the Studio UI using an Azure Machine Learning serverless Spark compute defaults to user identity passthrough for data access.\\n\\n\\n---\\n\\n\u003e [!TIP]\\n\u003e You might have an existing Synapse Spark pool in your Azure Synapse workspace. To use an existing Synapse Spark pool, please follow the instructions to [attach a Synapse Spark pool in Azure Machine Learning workspace](.\/how-to-manage-synapse-spark-pool.md).\\n\\n## Next steps\\n- [Apache Spark in Azure Machine Learning](.\/apache-spark-azure-ml-concepts.md)\\n- [Quickstart: Interactive Data Wrangling with Apache Spark](.\/apache-spark-environment-configuration.md)\\n- [Attach and manage a Synapse Spark pool in Azure Machine Learning](.\/how-to-manage-synapse-spark-pool.md)\\n- [Interactive Data Wrangling with Apache Spark in Azure Machine Learning](.\/interactive-data-wrangling-with-apache-spark-azure-ml.md)\\n- [Submit Spark jobs in Azure Machine Learning](.\/how-to-submit-spark-jobs.md)\\n- [Code samples for Spark jobs using Azure Machine Learning CLI](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/cli\/jobs\/spark)\",\n      \"metadata\": {\n        \"id\": \"cXVpY2tzdGFydC1zcGFyay1qb2JzLm1kNA==\",\n        \"source\": {\n          \"title\": \"Configure Apache Spark jobs in Azure Machine Learning\",\n          \"filename\": \"quickstart-spark-jobs.md\",\n          \"url\": \"quickstart-spark-jobs.md\",\n          \"mtime\": 1710206171.0\n        },\n        \"stats\": {\n          \"tiktokens\": 901,\n          \"chars\": 3569,\n          \"lines\": 47\n        },\n        \"content_hash\": \"180236985807e2fb8630996332b1ac47df8c1aa7eda985ecb895df59c6ad2ec7\"\n      },\n      \"score\": 0.030751174315810204\n    },\n    {\n      \"text\": \"# Submit Spark jobs in Azure Machine Learning\\n\\n6. To add any Jar file(s) that the standalone job requires at runtime, select **+ Add file** under **Jars** and input the name of the `.jar` file to be included in the Spark driver. Also, add the executor `CLASSPATH` for successful job execution. Multiple files can be added.\\n        7. To add archive(s) that should be extracted into the working directory of each executor for successful job execution, select **+ Add file** under **Archives**, and input the name of the archive. Multiple archives can be added.\\n        8. Adding **Py files**, **Jars**, and **Archives** is optional.\\n        9. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter an **Input name**. The input should refer to this name later in the **Arguments**.\\n            2. Select an **Input type**.\\n            3. For type **Data**:\\n                1. Select **Data type** as **File** or **Folder**.\\n                2. Select **Data source** as **Upload from local**, **URI**, or **Datastore**.\\n                    - For **Upload from local**, select **Browse** under **Path to upload**, to choose the input file or folder.\\n                    - For **URI**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI), or enter a data asset `azureml:\/\/`.\\n                    - For **Datastore**:\\n                        1. **Select a datastore** from the dropdown menu.\\n                        2. Under **Path to data**, select **Browse**.\\n                        3. In the pop-up screen titled **Path selection**, select the path of the code files on the workspace default blob storage.\\n                        4. Select **Save**.\\n            4. For type **Integer**, enter an integer value as **Input value**.\\n            5. For type **Number**, enter a numeric value as **Input value**.\\n            6. For type **Boolean**, select **True** or **False** as **Input value**.\\n            7. For type **String**, enter a string as **Input value**.\\n        10. To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter an **Output name**. The output should refer to this name later to in the **Arguments**.\\n            2. Select **Output type** as **File** or **Folder**.\\n            3. For **Output URI destination**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI) or enter a data asset `azureml:\/\/`.\\n        11. Enter **Arguments** by using the names defined in the **Input name** and **Output name** fields in the earlier steps, and the names of input and output arguments used in the Python script **Entry file**. For example, if the **Input name** and **Output name** are defined as `job_input` and `job_output`, and the arguments are added in the **Entry file** as shown here\\n\\n            ``` python\\n            import argparse\\n\\n            parser = argparse.ArgumentParser()\\n            parser.add_argument(\\\"--input_param\\\")\\n            parser.add_argument(\\\"--output_param\\\")\\n            ```\\n\\n    then enter **Arguments** as `--input_param ${{inputs.job_input}} --output_param ${{outputs.job_output}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** and executor **Memory (GB)**, in gigabytes.\\n            2. For **Dynamically allocated executors**, select the **Disabled** or **Enabled** option.\\n        - If dynamic allocation of executors is **Disabled**, enter the number of **Executor instances**.\\n        - If dynamic allocation of executors is **Enabled**, use the slider to select the minimum and maximum number of executors.\\n        1. For **Driver size**:\\n            1. Enter number of driver **Cores** and driver **Memory (GB)**, in gigabytes.\\n            2. Enter **Name** and **Value** pairs for any **Additional configurations**, then select **Add**. Providing **Additional configurations** is optional.\\n    6. Select **Next**.\\n7. On the **Review** screen:\",\n      \"metadata\": {\n        \"id\": \"aG93LXRvLXN1Ym1pdC1zcGFyay1qb2JzLm1kNw==\",\n        \"source\": {\n          \"title\": \"Submit Spark jobs in Azure Machine Learning\",\n          \"filename\": \"how-to-submit-spark-jobs.md\",\n          \"url\": \"how-to-submit-spark-jobs.md\",\n          \"mtime\": 1710206154.0\n        },\n        \"stats\": {\n          \"tiktokens\": 933,\n          \"chars\": 3974,\n          \"lines\": 48\n        },\n        \"content_hash\": \"4d20509f3e7b887d13bf41c0ef760f486cc1b45615c33bca6825cd23643bd058\"\n      },\n      \"score\": 0.025739235803484917\n    },\n    {\n      \"text\": \"# Configure Apache Spark jobs in Azure Machine Learning\\n\\n- [Code samples for Spark jobs using Azure Machine Learning Python SDK](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/sdk\/python\/jobs\/spark)\",\n      \"metadata\": {\n        \"id\": \"cXVpY2tzdGFydC1zcGFyay1qb2JzLm1kNQ==\",\n        \"source\": {\n          \"title\": \"Configure Apache Spark jobs in Azure Machine Learning\",\n          \"filename\": \"quickstart-spark-jobs.md\",\n          \"url\": \"quickstart-spark-jobs.md\",\n          \"mtime\": 1710206171.0\n        },\n        \"stats\": {\n          \"tiktokens\": 44,\n          \"chars\": 203,\n          \"lines\": 3\n        },\n        \"content_hash\": \"9c6e5e25028d10af22f711dfc932d1c762f186375243340e341c3fe22463cf50\"\n      },\n      \"score\": 0.02253928780555725\n    }\n  ]\n}","output":"\"Content: # Configure Apache Spark jobs in Azure Machine Learning\\n\\n3. Under **Add tags**, provide **Name** and **Value**, then select **Add**. Adding tags is optional.\\n    4. Under the **Code** section:\\n        1. Select **Azure Machine Learning workspace default blob storage** from **Choose code location** dropdown.\\n        2. Under **Path to code file to upload**, select **Browse**.\\n        3. In the pop-up screen titled **Path selection**, select the path of code file `titanic.py` on the workspace default datastore `workspaceblobstore`.\\n        4. Select **Save**.\\n        5. Input `titanic.py` as the name of **Entry file** for the standalone job.\\n        6. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter **Input name** as `titanic_data`. The input should refer to this name later in the **Arguments**.\\n            2. Select **Input type** as **Data**.\\n            3. Select **Data type** as **File**.\\n            4. Select **Data source** as **URI**.\\n            5. Enter an Azure Data Lake Storage (ADLS) Gen 2 data URI for `titanic.csv` file in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here, `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        7.  To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter **Output name** as `wrangled_data`. The output should refer to this name later in the **Arguments**.\\n            2. Select **Output type** as **Folder**.\\n            3. For **Output URI destination**, enter an Azure Data Lake Storage (ADLS) Gen 2 folder URI in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        8.  Enter **Arguments**  as `--titanic_data ${{inputs.titanic_data}} --wrangled_data ${{outputs.wrangled_data}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** as 2 and executor **Memory (GB)** as 2.\\n            2. For **Dynamically allocated executors**, select **Disabled**.\\n            3. Enter the number of **Executor instances** as 2.\\n        2. For **Driver size**, enter number of driver **Cores** as 1 and driver **Memory (GB)** as 2.\\n    6. Select **Next**.\\n6. On the **Review** screen:\\n    1. Review the job specification before submitting it.\\n    2. Select **Create** to submit the standalone Spark job.\\n\\n\u003e [!NOTE]\\n\u003e A standalone job submitted from the Studio UI using an Azure Machine Learning serverless Spark compute defaults to user identity passthrough for data access.\\n\\n\\n---\\n\\n\u003e [!TIP]\\n\u003e You might have an existing Synapse Spark pool in your Azure Synapse workspace. To use an existing Synapse Spark pool, please follow the instructions to [attach a Synapse Spark pool in Azure Machine Learning workspace](.\/how-to-manage-synapse-spark-pool.md).\\n\\n## Next steps\\n- [Apache Spark in Azure Machine Learning](.\/apache-spark-azure-ml-concepts.md)\\n- [Quickstart: Interactive Data Wrangling with Apache Spark](.\/apache-spark-environment-configuration.md)\\n- [Attach and manage a Synapse Spark pool in Azure Machine Learning](.\/how-to-manage-synapse-spark-pool.md)\\n- [Interactive Data Wrangling with Apache Spark in Azure Machine Learning](.\/interactive-data-wrangling-with-apache-spark-azure-ml.md)\\n- [Submit Spark jobs in Azure Machine Learning](.\/how-to-submit-spark-jobs.md)\\n- [Code samples for Spark jobs using Azure Machine Learning CLI](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/cli\/jobs\/spark)\\nSource: quickstart-spark-jobs.md\\n\\nContent: # Submit Spark jobs in Azure Machine Learning\\n\\n6. To add any Jar file(s) that the standalone job requires at runtime, select **+ Add file** under **Jars** and input the name of the `.jar` file to be included in the Spark driver. Also, add the executor `CLASSPATH` for successful job execution. Multiple files can be added.\\n        7. To add archive(s) that should be extracted into the working directory of each executor for successful job execution, select **+ Add file** under **Archives**, and input the name of the archive. Multiple archives can be added.\\n        8. Adding **Py files**, **Jars**, and **Archives** is optional.\\n        9. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter an **Input name**. The input should refer to this name later in the **Arguments**.\\n            2. Select an **Input type**.\\n            3. For type **Data**:\\n                1. Select **Data type** as **File** or **Folder**.\\n                2. Select **Data source** as **Upload from local**, **URI**, or **Datastore**.\\n                    - For **Upload from local**, select **Browse** under **Path to upload**, to choose the input file or folder.\\n                    - For **URI**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI), or enter a data asset `azureml:\/\/`.\\n                    - For **Datastore**:\\n                        1. **Select a datastore** from the dropdown menu.\\n                        2. Under **Path to data**, select **Browse**.\\n                        3. In the pop-up screen titled **Path selection**, select the path of the code files on the workspace default blob storage.\\n                        4. Select **Save**.\\n            4. For type **Integer**, enter an integer value as **Input value**.\\n            5. For type **Number**, enter a numeric value as **Input value**.\\n            6. For type **Boolean**, select **True** or **False** as **Input value**.\\n            7. For type **String**, enter a string as **Input value**.\\n        10. To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter an **Output name**. The output should refer to this name later to in the **Arguments**.\\n            2. Select **Output type** as **File** or **Folder**.\\n            3. For **Output URI destination**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI) or enter a data asset `azureml:\/\/`.\\n        11. Enter **Arguments** by using the names defined in the **Input name** and **Output name** fields in the earlier steps, and the names of input and output arguments used in the Python script **Entry file**. For example, if the **Input name** and **Output name** are defined as `job_input` and `job_output`, and the arguments are added in the **Entry file** as shown here\\n\\n            ``` python\\n            import argparse\\n\\n            parser = argparse.ArgumentParser()\\n            parser.add_argument(\\\"--input_param\\\")\\n            parser.add_argument(\\\"--output_param\\\")\\n            ```\\n\\n    then enter **Arguments** as `--input_param ${{inputs.job_input}} --output_param ${{outputs.job_output}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** and executor **Memory (GB)**, in gigabytes.\\n            2. For **Dynamically allocated executors**, select the **Disabled** or **Enabled** option.\\n        - If dynamic allocation of executors is **Disabled**, enter the number of **Executor instances**.\\n        - If dynamic allocation of executors is **Enabled**, use the slider to select the minimum and maximum number of executors.\\n        1. For **Driver size**:\\n            1. Enter number of driver **Cores** and driver **Memory (GB)**, in gigabytes.\\n            2. Enter **Name** and **Value** pairs for any **Additional configurations**, then select **Add**. Providing **Additional configurations** is optional.\\n    6. Select **Next**.\\n7. On the **Review** screen:\\nSource: how-to-submit-spark-jobs.md\\n\\nContent: # Configure Apache Spark jobs in Azure Machine Learning\\n\\n- [Code samples for Spark jobs using Azure Machine Learning Python SDK](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/sdk\/python\/jobs\/spark)\\nSource: quickstart-spark-jobs.md\""},"events":[{"name":"promptflow.function.inputs","timestamp":"2024-04-11T18:07:30.328011Z","attributes":{"payload":"{\n  \"search_result\": [\n    {\n      \"text\": \"# Configure Apache Spark jobs in Azure Machine Learning\\n\\n3. Under **Add tags**, provide **Name** and **Value**, then select **Add**. Adding tags is optional.\\n    4. Under the **Code** section:\\n        1. Select **Azure Machine Learning workspace default blob storage** from **Choose code location** dropdown.\\n        2. Under **Path to code file to upload**, select **Browse**.\\n        3. In the pop-up screen titled **Path selection**, select the path of code file `titanic.py` on the workspace default datastore `workspaceblobstore`.\\n        4. Select **Save**.\\n        5. Input `titanic.py` as the name of **Entry file** for the standalone job.\\n        6. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter **Input name** as `titanic_data`. The input should refer to this name later in the **Arguments**.\\n            2. Select **Input type** as **Data**.\\n            3. Select **Data type** as **File**.\\n            4. Select **Data source** as **URI**.\\n            5. Enter an Azure Data Lake Storage (ADLS) Gen 2 data URI for `titanic.csv` file in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here, `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        7.  To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter **Output name** as `wrangled_data`. The output should refer to this name later in the **Arguments**.\\n            2. Select **Output type** as **Folder**.\\n            3. For **Output URI destination**, enter an Azure Data Lake Storage (ADLS) Gen 2 folder URI in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        8.  Enter **Arguments**  as `--titanic_data ${{inputs.titanic_data}} --wrangled_data ${{outputs.wrangled_data}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** as 2 and executor **Memory (GB)** as 2.\\n            2. For **Dynamically allocated executors**, select **Disabled**.\\n            3. Enter the number of **Executor instances** as 2.\\n        2. For **Driver size**, enter number of driver **Cores** as 1 and driver **Memory (GB)** as 2.\\n    6. Select **Next**.\\n6. On the **Review** screen:\\n    1. Review the job specification before submitting it.\\n    2. Select **Create** to submit the standalone Spark job.\\n\\n\u003e [!NOTE]\\n\u003e A standalone job submitted from the Studio UI using an Azure Machine Learning serverless Spark compute defaults to user identity passthrough for data access.\\n\\n\\n---\\n\\n\u003e [!TIP]\\n\u003e You might have an existing Synapse Spark pool in your Azure Synapse workspace. To use an existing Synapse Spark pool, please follow the instructions to [attach a Synapse Spark pool in Azure Machine Learning workspace](.\/how-to-manage-synapse-spark-pool.md).\\n\\n## Next steps\\n- [Apache Spark in Azure Machine Learning](.\/apache-spark-azure-ml-concepts.md)\\n- [Quickstart: Interactive Data Wrangling with Apache Spark](.\/apache-spark-environment-configuration.md)\\n- [Attach and manage a Synapse Spark pool in Azure Machine Learning](.\/how-to-manage-synapse-spark-pool.md)\\n- [Interactive Data Wrangling with Apache Spark in Azure Machine Learning](.\/interactive-data-wrangling-with-apache-spark-azure-ml.md)\\n- [Submit Spark jobs in Azure Machine Learning](.\/how-to-submit-spark-jobs.md)\\n- [Code samples for Spark jobs using Azure Machine Learning CLI](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/cli\/jobs\/spark)\",\n      \"metadata\": {\n        \"id\": \"cXVpY2tzdGFydC1zcGFyay1qb2JzLm1kNA==\",\n        \"source\": {\n          \"title\": \"Configure Apache Spark jobs in Azure Machine Learning\",\n          \"filename\": \"quickstart-spark-jobs.md\",\n          \"url\": \"quickstart-spark-jobs.md\",\n          \"mtime\": 1710206171.0\n        },\n        \"stats\": {\n          \"tiktokens\": 901,\n          \"chars\": 3569,\n          \"lines\": 47\n        },\n        \"content_hash\": \"180236985807e2fb8630996332b1ac47df8c1aa7eda985ecb895df59c6ad2ec7\"\n      },\n      \"score\": 0.030751174315810204\n    },\n    {\n      \"text\": \"# Submit Spark jobs in Azure Machine Learning\\n\\n6. To add any Jar file(s) that the standalone job requires at runtime, select **+ Add file** under **Jars** and input the name of the `.jar` file to be included in the Spark driver. Also, add the executor `CLASSPATH` for successful job execution. Multiple files can be added.\\n        7. To add archive(s) that should be extracted into the working directory of each executor for successful job execution, select **+ Add file** under **Archives**, and input the name of the archive. Multiple archives can be added.\\n        8. Adding **Py files**, **Jars**, and **Archives** is optional.\\n        9. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter an **Input name**. The input should refer to this name later in the **Arguments**.\\n            2. Select an **Input type**.\\n            3. For type **Data**:\\n                1. Select **Data type** as **File** or **Folder**.\\n                2. Select **Data source** as **Upload from local**, **URI**, or **Datastore**.\\n                    - For **Upload from local**, select **Browse** under **Path to upload**, to choose the input file or folder.\\n                    - For **URI**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI), or enter a data asset `azureml:\/\/`.\\n                    - For **Datastore**:\\n                        1. **Select a datastore** from the dropdown menu.\\n                        2. Under **Path to data**, select **Browse**.\\n                        3. In the pop-up screen titled **Path selection**, select the path of the code files on the workspace default blob storage.\\n                        4. Select **Save**.\\n            4. For type **Integer**, enter an integer value as **Input value**.\\n            5. For type **Number**, enter a numeric value as **Input value**.\\n            6. For type **Boolean**, select **True** or **False** as **Input value**.\\n            7. For type **String**, enter a string as **Input value**.\\n        10. To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter an **Output name**. The output should refer to this name later to in the **Arguments**.\\n            2. Select **Output type** as **File** or **Folder**.\\n            3. For **Output URI destination**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI) or enter a data asset `azureml:\/\/`.\\n        11. Enter **Arguments** by using the names defined in the **Input name** and **Output name** fields in the earlier steps, and the names of input and output arguments used in the Python script **Entry file**. For example, if the **Input name** and **Output name** are defined as `job_input` and `job_output`, and the arguments are added in the **Entry file** as shown here\\n\\n            ``` python\\n            import argparse\\n\\n            parser = argparse.ArgumentParser()\\n            parser.add_argument(\\\"--input_param\\\")\\n            parser.add_argument(\\\"--output_param\\\")\\n            ```\\n\\n    then enter **Arguments** as `--input_param ${{inputs.job_input}} --output_param ${{outputs.job_output}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** and executor **Memory (GB)**, in gigabytes.\\n            2. For **Dynamically allocated executors**, select the **Disabled** or **Enabled** option.\\n        - If dynamic allocation of executors is **Disabled**, enter the number of **Executor instances**.\\n        - If dynamic allocation of executors is **Enabled**, use the slider to select the minimum and maximum number of executors.\\n        1. For **Driver size**:\\n            1. Enter number of driver **Cores** and driver **Memory (GB)**, in gigabytes.\\n            2. Enter **Name** and **Value** pairs for any **Additional configurations**, then select **Add**. Providing **Additional configurations** is optional.\\n    6. Select **Next**.\\n7. On the **Review** screen:\",\n      \"metadata\": {\n        \"id\": \"aG93LXRvLXN1Ym1pdC1zcGFyay1qb2JzLm1kNw==\",\n        \"source\": {\n          \"title\": \"Submit Spark jobs in Azure Machine Learning\",\n          \"filename\": \"how-to-submit-spark-jobs.md\",\n          \"url\": \"how-to-submit-spark-jobs.md\",\n          \"mtime\": 1710206154.0\n        },\n        \"stats\": {\n          \"tiktokens\": 933,\n          \"chars\": 3974,\n          \"lines\": 48\n        },\n        \"content_hash\": \"4d20509f3e7b887d13bf41c0ef760f486cc1b45615c33bca6825cd23643bd058\"\n      },\n      \"score\": 0.025739235803484917\n    },\n    {\n      \"text\": \"# Configure Apache Spark jobs in Azure Machine Learning\\n\\n- [Code samples for Spark jobs using Azure Machine Learning Python SDK](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/sdk\/python\/jobs\/spark)\",\n      \"metadata\": {\n        \"id\": \"cXVpY2tzdGFydC1zcGFyay1qb2JzLm1kNQ==\",\n        \"source\": {\n          \"title\": \"Configure Apache Spark jobs in Azure Machine Learning\",\n          \"filename\": \"quickstart-spark-jobs.md\",\n          \"url\": \"quickstart-spark-jobs.md\",\n          \"mtime\": 1710206171.0\n        },\n        \"stats\": {\n          \"tiktokens\": 44,\n          \"chars\": 203,\n          \"lines\": 3\n        },\n        \"content_hash\": \"9c6e5e25028d10af22f711dfc932d1c762f186375243340e341c3fe22463cf50\"\n      },\n      \"score\": 0.02253928780555725\n    }\n  ]\n}"}},{"name":"promptflow.function.output","timestamp":"2024-04-11T18:07:30.328223Z","attributes":{"payload":"\"Content: # Configure Apache Spark jobs in Azure Machine Learning\\n\\n3. Under **Add tags**, provide **Name** and **Value**, then select **Add**. Adding tags is optional.\\n    4. Under the **Code** section:\\n        1. Select **Azure Machine Learning workspace default blob storage** from **Choose code location** dropdown.\\n        2. Under **Path to code file to upload**, select **Browse**.\\n        3. In the pop-up screen titled **Path selection**, select the path of code file `titanic.py` on the workspace default datastore `workspaceblobstore`.\\n        4. Select **Save**.\\n        5. Input `titanic.py` as the name of **Entry file** for the standalone job.\\n        6. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter **Input name** as `titanic_data`. The input should refer to this name later in the **Arguments**.\\n            2. Select **Input type** as **Data**.\\n            3. Select **Data type** as **File**.\\n            4. Select **Data source** as **URI**.\\n            5. Enter an Azure Data Lake Storage (ADLS) Gen 2 data URI for `titanic.csv` file in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here, `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        7.  To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter **Output name** as `wrangled_data`. The output should refer to this name later in the **Arguments**.\\n            2. Select **Output type** as **Folder**.\\n            3. For **Output URI destination**, enter an Azure Data Lake Storage (ADLS) Gen 2 folder URI in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        8.  Enter **Arguments**  as `--titanic_data ${{inputs.titanic_data}} --wrangled_data ${{outputs.wrangled_data}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** as 2 and executor **Memory (GB)** as 2.\\n            2. For **Dynamically allocated executors**, select **Disabled**.\\n            3. Enter the number of **Executor instances** as 2.\\n        2. For **Driver size**, enter number of driver **Cores** as 1 and driver **Memory (GB)** as 2.\\n    6. Select **Next**.\\n6. On the **Review** screen:\\n    1. Review the job specification before submitting it.\\n    2. Select **Create** to submit the standalone Spark job.\\n\\n\u003e [!NOTE]\\n\u003e A standalone job submitted from the Studio UI using an Azure Machine Learning serverless Spark compute defaults to user identity passthrough for data access.\\n\\n\\n---\\n\\n\u003e [!TIP]\\n\u003e You might have an existing Synapse Spark pool in your Azure Synapse workspace. To use an existing Synapse Spark pool, please follow the instructions to [attach a Synapse Spark pool in Azure Machine Learning workspace](.\/how-to-manage-synapse-spark-pool.md).\\n\\n## Next steps\\n- [Apache Spark in Azure Machine Learning](.\/apache-spark-azure-ml-concepts.md)\\n- [Quickstart: Interactive Data Wrangling with Apache Spark](.\/apache-spark-environment-configuration.md)\\n- [Attach and manage a Synapse Spark pool in Azure Machine Learning](.\/how-to-manage-synapse-spark-pool.md)\\n- [Interactive Data Wrangling with Apache Spark in Azure Machine Learning](.\/interactive-data-wrangling-with-apache-spark-azure-ml.md)\\n- [Submit Spark jobs in Azure Machine Learning](.\/how-to-submit-spark-jobs.md)\\n- [Code samples for Spark jobs using Azure Machine Learning CLI](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/cli\/jobs\/spark)\\nSource: quickstart-spark-jobs.md\\n\\nContent: # Submit Spark jobs in Azure Machine Learning\\n\\n6. To add any Jar file(s) that the standalone job requires at runtime, select **+ Add file** under **Jars** and input the name of the `.jar` file to be included in the Spark driver. Also, add the executor `CLASSPATH` for successful job execution. Multiple files can be added.\\n        7. To add archive(s) that should be extracted into the working directory of each executor for successful job execution, select **+ Add file** under **Archives**, and input the name of the archive. Multiple archives can be added.\\n        8. Adding **Py files**, **Jars**, and **Archives** is optional.\\n        9. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter an **Input name**. The input should refer to this name later in the **Arguments**.\\n            2. Select an **Input type**.\\n            3. For type **Data**:\\n                1. Select **Data type** as **File** or **Folder**.\\n                2. Select **Data source** as **Upload from local**, **URI**, or **Datastore**.\\n                    - For **Upload from local**, select **Browse** under **Path to upload**, to choose the input file or folder.\\n                    - For **URI**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI), or enter a data asset `azureml:\/\/`.\\n                    - For **Datastore**:\\n                        1. **Select a datastore** from the dropdown menu.\\n                        2. Under **Path to data**, select **Browse**.\\n                        3. In the pop-up screen titled **Path selection**, select the path of the code files on the workspace default blob storage.\\n                        4. Select **Save**.\\n            4. For type **Integer**, enter an integer value as **Input value**.\\n            5. For type **Number**, enter a numeric value as **Input value**.\\n            6. For type **Boolean**, select **True** or **False** as **Input value**.\\n            7. For type **String**, enter a string as **Input value**.\\n        10. To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter an **Output name**. The output should refer to this name later to in the **Arguments**.\\n            2. Select **Output type** as **File** or **Folder**.\\n            3. For **Output URI destination**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI) or enter a data asset `azureml:\/\/`.\\n        11. Enter **Arguments** by using the names defined in the **Input name** and **Output name** fields in the earlier steps, and the names of input and output arguments used in the Python script **Entry file**. For example, if the **Input name** and **Output name** are defined as `job_input` and `job_output`, and the arguments are added in the **Entry file** as shown here\\n\\n            ``` python\\n            import argparse\\n\\n            parser = argparse.ArgumentParser()\\n            parser.add_argument(\\\"--input_param\\\")\\n            parser.add_argument(\\\"--output_param\\\")\\n            ```\\n\\n    then enter **Arguments** as `--input_param ${{inputs.job_input}} --output_param ${{outputs.job_output}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** and executor **Memory (GB)**, in gigabytes.\\n            2. For **Dynamically allocated executors**, select the **Disabled** or **Enabled** option.\\n        - If dynamic allocation of executors is **Disabled**, enter the number of **Executor instances**.\\n        - If dynamic allocation of executors is **Enabled**, use the slider to select the minimum and maximum number of executors.\\n        1. For **Driver size**:\\n            1. Enter number of driver **Cores** and driver **Memory (GB)**, in gigabytes.\\n            2. Enter **Name** and **Value** pairs for any **Additional configurations**, then select **Add**. Providing **Additional configurations** is optional.\\n    6. Select **Next**.\\n7. On the **Review** screen:\\nSource: how-to-submit-spark-jobs.md\\n\\nContent: # Configure Apache Spark jobs in Azure Machine Learning\\n\\n- [Code samples for Spark jobs using Azure Machine Learning Python SDK](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/sdk\/python\/jobs\/spark)\\nSource: quickstart-spark-jobs.md\""}}],"links":[],"resource":{"attributes":{"service.name":"promptflow"},"schema_url":""}}],"contentrange":"bytes 0-37052/37053","correlationid":"b89d4b81-bfc0-4f21-800e-e597201b2ec4","xrequestid":"b89d4b81-bfc0-4f21-800e-e597201b2ec4","modelversion":"default","collectdatatype":"pandas.core.frame.DataFrame","agent":"azureml-ai-monitoring/0.1.0b4"}
{"specversion":"1.0","id":"69b0c887-80aa-4a85-99c9-d6680209bae9","source":"/subscriptions/1aefdc5e-3a7c-4d71-a9f9-f5d3b03be19a/resourceGroups/yuachengtestrg/providers/Microsoft.MachineLearningServices/workspaces/ai-proj-eastus/onlineEndpoints/clone-vivi-log-test/deployments/clone-vivi-log-test-1","type":"azureml.inference.app_traces","datacontenttype":"application/json","time":"2024-04-11T18:07:31Z","data":[{"name":"openai_embeddings","context":{"trace_id":"0xa2f3f4f8267a482fa3bb96ad3e1f7f35","span_id":"0x56af9148c62e7cb3","trace_state":"[]"},"kind":"SpanKind.INTERNAL","parent_id":"0x25f14e486ecbdcb7","start_time":"2024-04-11T18:07:28.356403Z","end_time":"2024-04-11T18:07:29.822491Z","status":{"status_code":"OK"},"attributes":{"framework":"promptflow","span_type":"Embedding","function":"openai.resources.embeddings.Embeddings.create","node_name":"lookup","request_id":"ee2f5c78-77c1-4766-802d-49aa4b354ec3","line_run_id":"ee2f5c78-77c1-4766-802d-49aa4b354ec3","inputs":"{\n  \"input\": [\n    [\n      3923,\n      527,\n      279,\n      7504,\n      311,\n      1893,\n      264,\n      27565,\n      2683,\n      30\n    ]\n  ],\n  \"model\": \"text-embedding-ada-002\"\n}","llm.response.model":"ada","embedding.embeddings":"[\n  {\n    \"embedding.vector\": \"\u003c1536 dimensional vector\u003e\",\n    \"embedding.text\": \"\u003c10 dimensional token\u003e\"\n  }\n]","__computed__.cumulative_token_count.prompt":10,"__computed__.cumulative_token_count.total":10,"llm.usage.prompt_tokens":10,"llm.usage.total_tokens":10,"output":"{\n  \"data\": [\n    {\n      \"embedding\": [\n        -0.0094194570556283,\n        -0.016255056485533714,\n        -0.021914932876825333,\n        -0.019823240116238594,\n        -0.010615686886012554,\n        0.005359110422432423,\n        -0.013637022115290165,\n        -0.02038375847041607,\n        -0.02170986495912075,\n        -0.017047986388206482,\n        -0.0013269608607515693,\n        0.005205309484153986,\n        -0.015762893483042717,\n        -0.005882033612579107,\n        -0.0031101980712264776,\n        -0.001731970114633441,\n        0.008312089368700981,\n        -0.02667251043021679,\n        0.012809914536774158,\n        -0.018497133627533913,\n        -0.039537109434604645,\n        0.012864599004387856,\n        0.014477800577878952,\n        -0.002741075586527586,\n        0.005157459992915392,\n        0.009105019271373749,\n        0.01611834391951561,\n        0.008749567903578281,\n        -0.0019344747997820377,\n        3.212198134860955e-05,\n        0.005427466239780188,\n        -0.01030808500945568,\n        -0.012816749513149261,\n        -0.026385415345430374,\n        -0.03606462478637695,\n        0.01669253595173359,\n        -0.00877007469534874,\n        -0.005174549296498299,\n        -0.0033374817576259375,\n        -0.026084650307893753,\n        0.0278208926320076,\n        0.0127894077450037,\n        -0.008093350566923618,\n        -0.0069347163662314415,\n        -0.0062409029342234135,\n        0.021778222173452377,\n        -0.023596491664648056,\n        -0.01566719450056553,\n        0.008004487492144108,\n        0.0067125591449439526,\n        0.0035784365609288216,\n        -0.002146378392353654,\n        -0.056653451174497604,\n        0.012536490336060524,\n        0.017430780455470085,\n        -0.006452806293964386,\n        0.004624283406883478,\n        0.03322101756930351,\n        -0.009774908423423767,\n        -0.003163173794746399,\n        0.003626285819336772,\n        -0.0057555753737688065,\n        -0.01699330098927021,\n        0.014327417127788067,\n        -0.0010219222167506814,\n        -0.013821583241224289,\n        0.0069107916206121445,\n        0.008817924186587334,\n        -0.02210633084177971,\n        -0.008359938859939575,\n        0.06168445572257042,\n        0.003275961382314563,\n        -0.006247738376259804,\n        0.008975142613053322,\n        0.0013286697212606668,\n        -0.001356012187898159,\n        -0.006480148993432522,\n        -0.024061311036348343,\n        0.012242559343576431,\n        0.014792238362133503,\n        0.002252330305054784,\n        0.013794240541756153,\n        -0.04175184294581413,\n        0.020916935056447983,\n        0.002252330305054784,\n        0.006497237831354141,\n        -0.005010494962334633,\n        0.0016619052039459348,\n        -0.01236560009419918,\n        -0.001225281273946166,\n        0.002394168870523572,\n        -0.00019342612358741462,\n        0.02016502059996128,\n        0.0030025371816009283,\n        0.006257991772145033,\n        0.014354759827256203,\n        0.010041496716439724,\n        -0.013226886279881,\n        0.017403436824679375,\n        -0.033275701105594635,\n        -0.013281570747494698,\n        0.00011342823563609272,\n        -0.03551777824759483,\n        -0.010014154016971588,\n        -0.02195594646036625,\n        -0.0015781691763550043,\n        0.0037048952654004097,\n        -0.0110394936054945,\n        0.01844244822859764,\n        0.00933059398084879,\n        0.0059025404043495655,\n        0.009214389137923717,\n        -0.019180692732334137,\n        -0.04084954410791397,\n        -0.017047986388206482,\n        -0.009139196947216988,\n        0.00798398070037365,\n        -0.023596491664648056,\n        -0.011155699379742146,\n        -0.026070978492498398,\n        0.03059614636003971,\n        0.033248357474803925,\n        0.036666158586740494,\n        -0.02510032244026661,\n        0.021819235756993294,\n        -0.015229716897010803,\n        -0.010096181184053421,\n        -0.020602498203516006,\n        0.014915279112756252,\n        -0.023350410163402557,\n        0.017676861956715584,\n        0.015120347030460835,\n        0.003964648116379976,\n        0.00618280004709959,\n        -0.03461547940969467,\n        0.013117516413331032,\n        0.0026932263281196356,\n        -0.0001705695758573711,\n        -0.0288188885897398,\n        -0.013671199791133404,\n        0.028408752754330635,\n        0.023719532415270805,\n        0.008414623327553272,\n        -0.016337083652615547,\n        0.02996727079153061,\n        -0.00538303516805172,\n        0.012481805868446827,\n        -0.01326106395572424,\n        -0.015475798398256302,\n        -0.021819235756993294,\n        -0.00028410463710315526,\n        -0.005646205507218838,\n        0.016460124403238297,\n        -0.013917281292378902,\n        -0.0011603430612012744,\n        0.014983635395765305,\n        0.0008706845692358911,\n        0.013247393071651459,\n        -0.0053249322809278965,\n        0.00040351401548832655,\n        0.03800593689084053,\n        0.04199792444705963,\n        0.03190857917070389,\n        -0.008387281559407711,\n        -0.011374438181519508,\n        0.029064971953630447,\n        0.01913967914879322,\n        -0.013172200880944729,\n        -0.008079678751528263,\n        -0.00330672156997025,\n        -0.010075674392282963,\n        -0.01445045880973339,\n        -0.03806062042713165,\n        0.03313899040222168,\n        -0.010615686886012554,\n        0.014942621812224388,\n        0.003619450144469738,\n        -0.002723986515775323,\n        0.00213954271748662,\n        -0.006681798957288265,\n        0.020930606871843338,\n        -0.005468479823321104,\n        0.005099357571452856,\n        0.009480977430939674,\n        -0.014874265529215336,\n        -0.011333424597978592,\n        -0.010663536377251148,\n        -0.020342744886875153,\n        0.00956983957439661,\n        -0.009378443472087383,\n        0.010718220844864845,\n        0.013650692999362946,\n        -0.01654215157032013,\n        0.01315169408917427,\n        -0.6430932283401489,\n        -0.024471448734402657,\n        0.012256231158971786,\n        -0.034396737813949585,\n        -0.013637022115290165,\n        -0.008202720433473587,\n        -0.0019566905684769154,\n        -0.03341241180896759,\n        -0.0052702478133141994,\n        0.015380100347101688,\n        0.01134026050567627,\n        0.02228405512869358,\n        0.03226403146982193,\n        -0.002007957547903061,\n        -0.00907084159553051,\n        -0.009884277358651161,\n        0.02527804858982563,\n        -0.021696195006370544,\n        -0.02140909992158413,\n        0.02879154682159424,\n        -0.026180347427725792,\n        -0.013903610408306122,\n        -0.0034297623205929995,\n        -0.017253054305911064,\n        0.0035579297691583633,\n        -0.009597182273864746,\n        -0.0021703029051423073,\n        -0.014218048192560673,\n        0.003463940229266882,\n        -0.017512807622551918,\n        -0.0017242800677195191,\n        0.00011823451495729387,\n        0.019823240116238594,\n        0.0026795552112162113,\n        0.031225020065903664,\n        0.004996823612600565,\n        -0.03598259761929512,\n        0.022762548178434372,\n        -0.008359938859939575,\n        0.06742636114358902,\n        -0.03516232594847679,\n        -0.016227714717388153,\n        0.018073325976729393,\n        -0.016514809802174568,\n        0.0014423115644603968,\n        -0.003453686833381653,\n        -0.00470972852781415,\n        -0.004159462638199329,\n        -0.0008224081248044968,\n        0.018251052126288414,\n        0.019331077113747597,\n        -0.011114685796201229,\n        -0.00037189936847425997,\n        0.010178208351135254,\n        0.007799419574439526,\n        -0.007115859538316727,\n        0.017006972804665565,\n        0.0005036982474848628,\n        -0.00652458006516099,\n        0.02315901219844818,\n        0.003892874112352729,\n        -0.0023429018910974264,\n        -0.013404611498117447,\n        -0.030896911397576332,\n        -0.009392114356160164,\n        0.006292169913649559,\n        -0.013117516413331032,\n        -0.016309741884469986,\n        0.009891113266348839,\n        -0.03456079214811325,\n        0.00696205860003829,\n        -0.0010424290085211396,\n        0.0011201839661225677,\n        -0.012427120469510555,\n        -0.006531415972858667,\n        0.0033050125930458307,\n        0.0003601506759878248,\n        -0.004402126185595989,\n        0.006647620815783739,\n        -0.007525995373725891,\n        0.006592936348170042,\n        -0.008079678751528263,\n        -0.03535372391343117,\n        -0.003137540305033326,\n        -0.010465303435921669,\n        0.008243734017014503,\n        -0.02283090353012085,\n        -0.04109562560915947,\n        0.015051990747451782,\n        0.013404611498117447,\n        0.02890091761946678,\n        0.015448455698788166,\n        -0.005051508545875549,\n        -0.045579779893159866,\n        -0.008462472818791866,\n        0.013671199791133404,\n        0.027164673432707787,\n        -0.004361112602055073,\n        -0.004323516972362995,\n        -0.007778912782669067,\n        -0.023637505248188972,\n        0.007833597250282764,\n        -0.0028487362433224916,\n        -0.0006797149544581771,\n        0.037295032292604446,\n        -0.009617689065635204,\n        -0.028408752754330635,\n        -0.009269073605537415,\n        0.029283709824085236,\n        -0.017704203724861145,\n        -0.005984567571431398,\n        0.01656949520111084,\n        -0.021149346604943275,\n        -0.0014670906821265817,\n        -0.012721051461994648,\n        -0.033877234905958176,\n        0.030732857063412666,\n        -0.008606020361185074,\n        0.017225712537765503,\n        -0.014532485976815224,\n        -0.001320979674346745,\n        0.0050241658464074135,\n        0.008318925276398659,\n        -0.0049318852834403515,\n        -0.010383276268839836,\n        0.026918591931462288,\n        0.007908789440989494,\n        -0.004532002843916416,\n        0.007874610833823681,\n        -0.02437574975192547,\n        -0.012639024294912815,\n        0.010164537467062473,\n        0.015940619632601738,\n        0.008776910603046417,\n        0.017198368906974792,\n        -0.0014371848665177822,\n        -0.006545086856931448,\n        0.006924462970346212,\n        -0.0058341845870018005,\n        -0.023336738348007202,\n        -0.01893461123108864,\n        0.011572671122848988,\n        -0.005899122916162014,\n        -0.012057998217642307,\n        -0.01055416651070118,\n        0.0012039199937134981,\n        -0.02031540311872959,\n        -0.0036946418695151806,\n        -0.00784726906567812,\n        -0.006093937437981367,\n        -0.013507145456969738,\n        -0.004559345077723265,\n        -0.013199543580412865,\n        0.020370088517665863,\n        0.008749567903578281,\n        -0.007744734641164541,\n        0.005328350234776735,\n        -0.019303733482956886,\n        -0.00683218240737915,\n        -0.03513498231768608,\n        0.006292169913649559,\n        0.0356818325817585,\n        -0.019631844013929367,\n        0.006391285918653011,\n        -0.026139333844184875,\n        -0.015790235251188278,\n        -0.01056783739477396,\n        -0.013855760917067528,\n        0.003091400023549795,\n        -0.032072633504867554,\n        0.02258482202887535,\n        -0.025592485442757607,\n        -0.007102188188582659,\n        0.02742442674934864,\n        -0.012064834125339985,\n        0.014327417127788067,\n        -0.014682868495583534,\n        -0.0035852722357958555,\n        0.013548159040510654,\n        0.0030435509979724884,\n        -0.008353102952241898,\n        0.019344747066497803,\n        -0.01689760386943817,\n        0.002274545840919018,\n        0.01099164504557848,\n        0.030076639726758003,\n        0.0068048397079110146,\n        0.005550506990402937,\n        -0.035271696746349335,\n        0.0048396047204732895,\n        -0.009241730906069279,\n        0.03587322682142258,\n        0.035545118153095245,\n        0.010226057842373848,\n        0.011183041147887707,\n        0.02437574975192547,\n        -0.00952199101448059,\n        -0.021327072754502296,\n        -0.016049988567829132,\n        0.006220396142452955,\n        0.032072633504867554,\n        0.011764067225158215,\n        -0.006654456723481417,\n        -0.00427908543497324,\n        0.013336255215108395,\n        -0.02942042239010334,\n        0.019057651981711388,\n        -0.018086997792124748,\n        0.002341192914173007,\n        0.006066595204174519,\n        0.009166539646685123,\n        -0.02138175629079342,\n        -0.015079333446919918,\n        0.002199354348704219,\n        0.01669253595173359,\n        0.0165968369692564,\n        -0.009228060021996498,\n        0.02173720858991146,\n        -0.039263688027858734,\n        0.019358418881893158,\n        0.012509147636592388,\n        -0.0010167955188080668,\n        0.02939308062195778,\n        -0.006866360083222389,\n        -0.01853814721107483,\n        0.01226306613534689,\n        -8.272143895737827e-05,\n        0.0006327202427200973,\n        0.006353690288960934,\n        -0.00964503176510334,\n        0.00808651465922594,\n        -0.01134026050567627,\n        0.0032349477987736464,\n        -0.0017379513010382652,\n        0.04358378425240517,\n        0.014026651158928871,\n        -0.00987060647457838,\n        -0.011723053641617298,\n        0.013637022115290165,\n        0.009446798823773861,\n        -0.007177379913628101,\n        -0.006114444229751825,\n        0.030623488128185272,\n        -0.004436304327100515,\n        0.023719532415270805,\n        0.018797900527715683,\n        0.04946240037679672,\n        0.001576460199430585,\n        0.0019464370561763644,\n        0.03628336638212204,\n        -0.007990816608071327,\n        -0.024485118687152863,\n        -0.018633846193552017,\n        0.026904921978712082,\n        0.005820513237267733,\n        -0.025537801906466484,\n        -0.0026863908860832453,\n        -0.007929296232759953,\n        -0.0063878679648041725,\n        0.03313899040222168,\n        0.006924462970346212,\n        0.01916702277958393,\n        0.03313899040222168,\n        -0.010697714053094387,\n        -0.0002670156245585531,\n        -0.012085340917110443,\n        -0.009036662988364697,\n        -0.011969135142862797,\n        0.0026539217215031385,\n        -0.020342744886875153,\n        6.798217509640381e-05,\n        0.002503538504242897,\n        -0.017335081472992897,\n        -0.029338395223021507,\n        0.020670853555202484,\n        0.021504797041416168,\n        -0.0029102566186338663,\n        0.017376095056533813,\n        0.007539666723459959,\n        0.030650829896330833,\n        -0.029037628322839737,\n        -0.015120347030460835,\n        0.022844575345516205,\n        0.0078609399497509,\n        -0.022776219993829727,\n        -0.019057651981711388,\n        0.011893943883478642,\n        0.00151579431258142,\n        0.010349098592996597,\n        0.020998962223529816,\n        0.013076502829790115,\n        0.002612908137962222,\n        0.0015969669912010431,\n        0.011251397430896759,\n        0.003134122584015131,\n        -0.0008386426488868892,\n        0.02887357398867607,\n        -0.020397430285811424,\n        0.0094194570556283,\n        -0.0017516225343570113,\n        -0.010513152927160263,\n        0.01754014939069748,\n        0.002876078709959984,\n        -0.02475854381918907,\n        0.038416072726249695,\n        -0.002645377302542329,\n        -0.000711756874807179,\n        -0.02016502059996128,\n        -0.0038860386703163385,\n        -0.03595525771379471,\n        -0.004477317910641432,\n        -0.014874265529215336,\n        0.003903127508237958,\n        -0.003091400023549795,\n        0.013630186207592487,\n        -0.01348663866519928,\n        -0.02155948244035244,\n        -0.007785748224705458,\n        0.013336255215108395,\n        0.01759483478963375,\n        0.005003659054636955,\n        -0.023637505248188972,\n        -0.005160877946764231,\n        0.024321064352989197,\n        0.040439408272504807,\n        0.04134170711040497,\n        -0.0044465577229857445,\n        0.009815922006964684,\n        -0.037240348756313324,\n        0.00436794850975275,\n        0.003971483558416367,\n        -0.010096181184053421,\n        -0.0072115580551326275,\n        -0.0008484688587486744,\n        -0.004371365997940302,\n        -0.006257991772145033,\n        0.006422046106308699,\n        -0.012099011801183224,\n        0.000281541288131848,\n        -0.008729061111807823,\n        -0.004405544139444828,\n        -0.010588344186544418,\n        0.01741710864007473,\n        -0.019276391714811325,\n        0.0026402506045997143,\n        -0.002209607744589448,\n        0.018456120043992996,\n        -0.003451978089287877,\n        0.018428778275847435,\n        0.03174452483654022,\n        0.011497478932142258,\n        -0.008291582576930523,\n        -0.0112308906391263,\n        -0.007232064846903086,\n        0.001767002628184855,\n        0.009125526063144207,\n        0.009337429888546467,\n        0.01624138467013836,\n        0.007655872032046318,\n        0.05104826018214226,\n        0.009351100772619247,\n        0.023596491664648056,\n        0.011750396341085434,\n        0.017403436824679375,\n        -0.01126506831496954,\n        0.0027034797240048647,\n        0.007649036590009928,\n        0.015489469282329082,\n        0.0152844013646245,\n        -0.009877442382276058,\n        -0.002595819067209959,\n        0.013930953107774258,\n        0.027643166482448578,\n        -0.004969481378793716,\n        0.020000966265797615,\n        0.003739073174074292,\n        -0.0031683004926890135,\n        0.010622522793710232,\n        -0.004156044684350491,\n        0.03111565113067627,\n        -0.022653179243206978,\n        -0.005188220180571079,\n        0.012591174803674221,\n        -0.03576385974884033,\n        -0.04604460299015045,\n        0.008011323399841785,\n        0.004350859206169844,\n        0.00763536524027586,\n        -0.009713387116789818,\n        -0.014641854912042618,\n        0.0034724848810583353,\n        -0.0038826207164674997,\n        -0.023145342245697975,\n        -0.008318925276398659,\n        -0.01626872830092907,\n        -0.0056256987154483795,\n        -0.044677481055259705,\n        0.015776565298438072,\n        0.025988951325416565,\n        0.016938617452979088,\n        0.0032708346843719482,\n        -0.018155353143811226,\n        -0.0035408406984061003,\n        -0.018797900527715683,\n        -0.018975624814629555,\n        -0.02373320236802101,\n        0.008523993194103241,\n        -0.0053249322809278965,\n        0.0017413691384717822,\n        0.002021628664806485,\n        -0.005923047196120024,\n        0.008920458145439625,\n        0.009891113266348839,\n        0.01926271989941597,\n        -0.021545810624957085,\n        0.024867912754416466,\n        -0.01540744211524725,\n        -0.022502794861793518,\n        0.006914209574460983,\n        0.027014290913939476,\n        0.02237975411117077,\n        0.021477455273270607,\n        -0.00630584079772234,\n        -7.802196341799572e-05,\n        -0.016255056485533714,\n        -0.04232603684067726,\n        0.00459694117307663,\n        -0.014026651158928871,\n        -0.020274389535188675,\n        0.007744734641164541,\n        0.013377268798649311,\n        0.0045388382859528065,\n        -0.016528481617569923,\n        -0.020520471036434174,\n        0.012078505009412766,\n        0.005769246257841587,\n        0.029584476724267006,\n        0.001083442592062056,\n        0.014778567478060722,\n        0.01445045880973339,\n        0.00572139723226428,\n        0.017335081472992897,\n        -0.012468134053051472,\n        0.014026651158928871,\n        0.016309741884469986,\n        -0.020821237936615944,\n        0.04429468885064125,\n        0.04369315505027771,\n        -0.036119312047958374,\n        0.030760200694203377,\n        0.004672132432460785,\n        -0.02567451260983944,\n        -0.006880031432956457,\n        -0.001044992357492447,\n        -0.004576434381306171,\n        0.044376716017723083,\n        0.0008664123015478253,\n        -0.017034314572811127,\n        -0.022994957864284515,\n        -0.008428295142948627,\n        0.0028282294515520334,\n        0.015913276001811028,\n        -0.01168887596577406,\n        -0.01723938249051571,\n        -0.009392114356160164,\n        -0.006668127607554197,\n        0.0070953527465462685,\n        -0.0037493265699595213,\n        0.021942276507616043,\n        -0.01893461123108864,\n        -0.031853895634412766,\n        0.007977144792675972,\n        -0.008899951353669167,\n        0.017950285226106644,\n        -0.02198329009115696,\n        0.00196181726641953,\n        -0.0511576309800148,\n        -0.02702796272933483,\n        0.009829592891037464,\n        -0.015598839148879051,\n        0.005536836106330156,\n        -0.014682868495583534,\n        0.02829938381910324,\n        0.025592485442757607,\n        0.02198329009115696,\n        0.014983635395765305,\n        0.013978801667690277,\n        -0.010075674392282963,\n        0.0015559534076601267,\n        -0.007710556965321302,\n        0.0006451097433455288,\n        0.003180262865498662,\n        0.002283090492710471,\n        0.007519159931689501,\n        0.02031540311872959,\n        -0.013479802757501602,\n        -0.00763536524027586,\n        0.007252571638673544,\n        0.006230649538338184,\n        0.011237726546823978,\n        -0.013069666922092438,\n        -0.023200025781989098,\n        0.0030298796482384205,\n        -0.04577117785811424,\n        -0.0057384860701859,\n        0.011613684706389904,\n        -0.014928949996829033,\n        0.017854586243629456,\n        -0.039564453065395355,\n        -0.011900779791176319,\n        0.02370586059987545,\n        0.013671199791133404,\n        0.017731545493006706,\n        0.02031540311872959,\n        0.023897256702184677,\n        0.0007980563095770776,\n        0.009610853157937527,\n        -0.004405544139444828,\n        0.011620519682765007,\n        -0.01472388207912445,\n        -0.017772559076547623,\n        -0.014983635395765305,\n        0.006770661566406488,\n        0.002457398222759366,\n        0.02824469842016697,\n        -0.0010791703825816512,\n        -0.009747565723955631,\n        0.015557825565338135,\n        0.013930953107774258,\n        0.018674859777092934,\n        -0.015858592465519905,\n        0.00515404250472784,\n        0.011285575106739998,\n        -0.03251011297106743,\n        -0.012891941703855991,\n        -0.031033623963594437,\n        0.020096663385629654,\n        0.019877925515174866,\n        0.005328350234776735,\n        -0.0018063073512166739,\n        0.002823102753609419,\n        0.011490643955767155,\n        -0.012693708762526512,\n        -0.017157355323433876,\n        0.009474141523241997,\n        -0.012310915626585484,\n        0.026959605515003204,\n        0.025715526193380356,\n        0.028463438153266907,\n        0.003434889018535614,\n        0.009029828011989594,\n        0.00425516115501523,\n        -0.018797900527715683,\n        -0.002659048419445753,\n        -0.005854691378772259,\n        0.011470137163996696,\n        0.012167368084192276,\n        0.002900003222748637,\n        -0.016938617452979088,\n        0.0018370675388723612,\n        0.0012731305323541164,\n        -0.004573016427457333,\n        -0.010793412104249,\n        0.03423268347978592,\n        -0.0024898673873394728,\n        -0.0008061736007221043,\n        -0.001030466752126813,\n        -0.008346267975866795,\n        0.002942725783213973,\n        0.020821237936615944,\n        0.010178208351135254,\n        0.009576675482094288,\n        0.007737899199128151,\n        -0.007614858448505402,\n        -0.002404422266408801,\n        0.015462127514183521,\n        -0.011422287672758102,\n        0.037295032292604446,\n        -0.006059759296476841,\n        -0.012119518592953682,\n        0.004251743201166391,\n        0.012010148726403713,\n        -0.025072980672121048,\n        -0.00034647947177290916,\n        0.0012261357624083757,\n        0.006839017849415541,\n        0.0014525649603456259,\n        0.013739556074142456,\n        -0.0009159704204648733,\n        0.007587515749037266,\n        -0.019604500383138657,\n        -0.009897949174046516,\n        0.019084995612502098,\n        0.03562714532017708,\n        -0.029338395223021507,\n        0.00035865537938661873,\n        -0.0040535107254981995,\n        -0.00641862815245986,\n        0.01816902495920658,\n        -0.0058581093326210976,\n        0.0008792290464043617,\n        0.007881446741521358,\n        0.0024078399874269962,\n        0.008400952443480492,\n        0.0391816608607769,\n        -0.002368535380810499,\n        -0.004303010180592537,\n        -0.005813677795231342,\n        0.0033238104078918695,\n        -0.005273665301501751,\n        0.029857899993658066,\n        0.011422287672758102,\n        -0.0005968332989141345,\n        -0.0255788154900074,\n        -0.004549091681838036,\n        -0.014819581061601639,\n        0.013896774500608444,\n        0.016077330335974693,\n        0.014682868495583534,\n        0.011524821631610394,\n        0.018073325976729393,\n        0.02155948244035244,\n        -0.002741075586527586,\n        -0.02352813445031643,\n        0.023241039365530014,\n        -0.014436786994338036,\n        -0.021217701956629753,\n        -0.00020506800501607358,\n        -0.015106676146388054,\n        -0.005290754605084658,\n        0.038689494132995605,\n        -0.010526823811233044,\n        -0.01784091629087925,\n        -0.034670162945985794,\n        0.03026803582906723,\n        -0.0037117307074368,\n        -0.013315748423337936,\n        -0.020342744886875153,\n        -0.016077330335974693,\n        0.0033802040852606297,\n        0.0037971758283674717,\n        0.011538492515683174,\n        0.016883932054042816,\n        0.013842090032994747,\n        -0.027315057814121246,\n        0.008414623327553272,\n        0.006815093103796244,\n        -0.003940723370760679,\n        0.007054339163005352,\n        -0.03283822163939476,\n        -0.0001453633012715727,\n        0.018524475395679474,\n        -0.0331936739385128,\n        -0.02412966825067997,\n        0.015434784814715385,\n        0.019208036363124847,\n        -0.021340742707252502,\n        0.011586342006921768,\n        0.007355105597525835,\n        -0.012406613677740097,\n        -0.013452460989356041,\n        0.021053647622466087,\n        -0.018784228712320328,\n        -0.0056496234610676765,\n        -0.015079333446919918,\n        0.024539804086089134,\n        0.010547330603003502,\n        0.016255056485533714,\n        -0.009357936680316925,\n        -0.010827590711414814,\n        -0.005960643291473389,\n        -0.024908926337957382,\n        -0.03251011297106743,\n        -0.026262374594807625,\n        0.00833259616047144,\n        0.02525070682168007,\n        -0.0029769036918878555,\n        -0.015393771231174469,\n        -0.02400662750005722,\n        -0.02113567478954792,\n        -0.010526823811233044,\n        0.009515155106782913,\n        -0.004904543049633503,\n        0.008817924186587334,\n        0.016378097236156464,\n        -0.0037527442909777164,\n        0.016227714717388153,\n        0.007307256571948528,\n        0.01759483478963375,\n        0.007724227849394083,\n        -0.0034041288308799267,\n        -0.0019959951750934124,\n        -0.010137194767594337,\n        0.007676378823816776,\n        0.0013158529764041305,\n        -0.020903265103697777,\n        -0.047794513404369354,\n        0.009412621147930622,\n        0.005577849689871073,\n        0.01602264679968357,\n        0.012844092212617397,\n        0.008004487492144108,\n        -0.015298073180019855,\n        -0.0170889999717474,\n        -0.004477317910641432,\n        -0.004002243746072054,\n        0.022270385175943375,\n        0.030213352292776108,\n        0.020930606871843338,\n        -0.030705515295267105,\n        -0.011490643955767155,\n        0.014997306279838085,\n        -0.024922598153352737,\n        -0.003260581288486719,\n        -0.01362335029989481,\n        0.007874610833823681,\n        -0.019946280866861343,\n        0.005451390985399485,\n        -0.016132015734910965,\n        -0.009624524973332882,\n        -0.013869432732462883,\n        0.0012175912270322442,\n        0.022926602512598038,\n        0.0018832078203558922,\n        0.019522473216056824,\n        0.014600841328501701,\n        -0.00887260865420103,\n        0.00460377661511302,\n        -0.004019332583993673,\n        -0.01257750391960144,\n        -0.026945935562253,\n        -0.016227714717388153,\n        0.016104673966765404,\n        -0.03808796405792236,\n        -0.028162671253085136,\n        -0.005037837196141481,\n        -0.012345093302428722,\n        -0.015926947817206383,\n        -0.005817095749080181,\n        -0.007109024096280336,\n        0.005092522129416466,\n        2.7475907700136304e-05,\n        0.016063660383224487,\n        0.004832769278436899,\n        -0.02996727079153061,\n        -0.013650692999362946,\n        -0.01425906177610159,\n        -0.027492783963680267,\n        -0.001508958637714386,\n        0.00427224999293685,\n        0.0024727783165872097,\n        -0.007443968206644058,\n        0.007621693890541792,\n        -0.02887357398867607,\n        -0.03190857917070389,\n        -0.005331768188625574,\n        0.012536490336060524,\n        0.01956348679959774,\n        0.02061617001891136,\n        0.011962300166487694,\n        0.23164480924606323,\n        -0.007601187098771334,\n        0.0009928708896040916,\n        0.03510764241218567,\n        0.01584492065012455,\n        -0.0009424583404324949,\n        0.009241730906069279,\n        0.007854104042053223,\n        0.0017131722997874022,\n        0.008161705918610096,\n        -0.008202720433473587,\n        -0.013944623991847038,\n        -0.003308430314064026,\n        0.008756403811275959,\n        0.013390940614044666,\n        -0.03292024880647659,\n        -0.03406862914562225,\n        0.007573844864964485,\n        -0.014177034609019756,\n        -0.03595525771379471,\n        0.006985983345657587,\n        -0.008763238787651062,\n        -0.037295032292604446,\n        -0.016924945637583733,\n        0.04084954410791397,\n        0.010267071425914764,\n        -0.012290408834815025,\n        0.015134017914533615,\n        0.015913276001811028,\n        0.018633846193552017,\n        -0.019549816846847534,\n        0.021094661206007004,\n        0.010581509210169315,\n        0.010164537467062473,\n        0.014341088943183422,\n        -0.014819581061601639,\n        0.010759234428405762,\n        -0.01226306613534689,\n        0.01413602102547884,\n        0.01629607006907463,\n        0.019002968445420265,\n        0.0017892182804644108,\n        -0.011531657539308071,\n        -0.03620133921504021,\n        -0.003592107677832246,\n        0.0042859213426709175,\n        -0.028381410986185074,\n        -0.009528825990855694,\n        0.007840433157980442,\n        0.011627355590462685,\n        -0.022871917113661766,\n        -0.020452115684747696,\n        0.0321820043027401,\n        0.011367603205144405,\n        0.014040322043001652,\n        0.009843263775110245,\n        0.00572139723226428,\n        -0.001030466752126813,\n        0.023664847016334534,\n        0.014245389960706234,\n        -0.017786230891942978,\n        0.03786922246217728,\n        -0.008066007867455482,\n        0.012857763096690178,\n        0.004484153352677822,\n        -0.006145204417407513,\n        -0.016801904886960983,\n        0.014300075359642506,\n        0.023965613916516304,\n        0.02300862967967987,\n        -0.02403396926820278,\n        -0.008462472818791866,\n        0.0011406907578930259,\n        -0.017102671787142754,\n        -0.011880272999405861,\n        -0.025483116507530212,\n        0.018497133627533913,\n        0.015161360614001751,\n        0.03426002711057663,\n        0.03395926207304001,\n        -0.010506317019462585,\n        -0.010171372443437576,\n        -0.00060580502031371,\n        -0.0255788154900074,\n        0.008667540736496449,\n        -0.017909271642565727,\n        0.002712024375796318,\n        -0.006903956178575754,\n        -0.032400742173194885,\n        0.01868852972984314,\n        -0.001696083229035139,\n        0.0026111991610378027,\n        -0.014464129693806171,\n        -0.017458122223615646,\n        0.017786230891942978,\n        0.00887260865420103,\n        0.010889111086726189,\n        0.01959083043038845,\n        0.001661050831899047,\n        -0.0021908096969127655,\n        -0.04883352667093277,\n        0.043665811419487,\n        0.008066007867455482,\n        0.00551974680274725,\n        -0.02228405512869358,\n        -0.005639370065182447,\n        -0.004873782861977816,\n        0.00877007469534874,\n        0.036146651953458786,\n        -0.01896195486187935,\n        0.0021412516944110394,\n        -0.03978319093585014,\n        0.023869914934039116,\n        -0.0070816813968122005,\n        -0.019153350964188576,\n        0.009439963847398758,\n        -0.01401298027485609,\n        -0.010451632551848888,\n        -0.0013337964192032814,\n        -0.011634191498160362,\n        0.009098183363676071,\n        0.004309845622628927,\n        -0.008373609744012356,\n        0.010684043169021606,\n        -0.0029581058770418167,\n        -0.036173995584249496,\n        0.007177379913628101,\n        -0.005147206597030163,\n        -0.020903265103697777,\n        -0.03633804991841316,\n        0.020082993432879448,\n        0.012871434912085533,\n        -0.005577849689871073,\n        -0.002971776993945241,\n        -0.006944969762116671,\n        -0.01179140992462635,\n        -0.017676861956715584,\n        0.019700199365615845,\n        0.011941793374717236,\n        -0.01179140992462635,\n        0.008038665167987347,\n        -0.007273078430444002,\n        0.016760891303420067,\n        0.017047986388206482,\n        -0.011873437091708183,\n        -0.02639908716082573,\n        0.02123137377202511,\n        -0.02542843110859394,\n        -0.007143201772123575,\n        -0.03084222786128521,\n        -0.018770556896924973,\n        0.005666712298989296,\n        -0.01248864084482193,\n        -0.03450610861182213,\n        0.02428005076944828,\n        -0.018579160794615746,\n        -0.0011526530142873526,\n        -0.024608159437775612,\n        -0.008776910603046417,\n        -0.01200331375002861,\n        -0.03680286929011345,\n        0.004224400967359543,\n        0.014245389960706234,\n        -0.0037595799658447504,\n        -0.017772559076547623,\n        -0.024799557402729988,\n        -0.17531946301460266,\n        -0.015161360614001751,\n        0.03822467476129532,\n        -0.023664847016334534,\n        0.022147344425320625,\n        0.021450113505125046,\n        0.021149346604943275,\n        -0.002840191824361682,\n        -0.031006282195448875,\n        0.023637505248188972,\n        0.014327417127788067,\n        -0.010663536377251148,\n        -0.042380720376968384,\n        -0.0035579297691583633,\n        0.0025086652021855116,\n        -0.002946143504232168,\n        0.01077974122017622,\n        0.0316898413002491,\n        0.04943506047129631,\n        0.01756749115884304,\n        0.015940619632601738,\n        -0.01953614503145218,\n        -0.018223710358142853,\n        0.010226057842373848,\n        -0.0168429184705019,\n        0.0009005902684293687,\n        -0.021723536774516106,\n        0.005229233764111996,\n        0.014778567478060722,\n        -0.02627604641020298,\n        -0.00023283762857317924,\n        0.007785748224705458,\n        0.0036878061946481466,\n        -0.006985983345657587,\n        -0.0039373054169118404,\n        -0.03229137510061264,\n        0.0012731305323541164,\n        -0.02080756612122059,\n        -0.005406959448009729,\n        0.0031888072844594717,\n        0.018251052126288414,\n        0.01669253595173359,\n        0.0030538043938577175,\n        -0.0021327072754502296,\n        0.017034314572811127,\n        0.022940274327993393,\n        0.0037869224324822426,\n        0.0015004142187535763,\n        0.0037629976868629456,\n        0.0003041841846425086,\n        0.03311164677143097,\n        -0.004528584890067577,\n        -0.019754884764552116,\n        -0.006640785373747349,\n        0.00235828198492527,\n        -0.025961609557271004,\n        -0.013158529996871948,\n        0.027287714183330536,\n        0.0010484101949259639,\n        -0.02860015071928501,\n        0.010301249101758003,\n        -0.027561139315366745,\n        0.00029478524811565876,\n        -0.029584476724267006,\n        -0.02827204205095768,\n        -0.011196712963283062,\n        0.005420630797743797,\n        0.01674721948802471,\n        -0.03590057045221329,\n        0.005639370065182447,\n        0.006927880458533764,\n        -0.0010210677282884717,\n        -0.013596008531749249,\n        0.0036809705197811127,\n        -0.0034468513913452625,\n        0.000853595556691289,\n        -0.00920755323022604,\n        0.035818543285131454,\n        0.0016302906442433596,\n        0.001154361991211772,\n        0.007129530888050795,\n        0.06502022594213486,\n        -0.004644790198653936,\n        0.016651522368192673,\n        0.015393771231174469,\n        0.00843513011932373,\n        -0.002067768946290016,\n        0.0029017121996730566,\n        -0.0341779999434948,\n        -0.028053302317857742,\n        0.0027889248449355364,\n        0.005594938527792692,\n        -0.02467651665210724,\n        0.004884036257863045,\n        0.0007305547478608787,\n        0.007245736196637154,\n        0.016514809802174568,\n        -0.0069347163662314415,\n        0.019098665565252304,\n        0.0062409029342234135,\n        0.005782917607575655,\n        0.015708208084106445,\n        -0.04306428134441376,\n        0.019782226532697678,\n        0.03797859326004982,\n        0.006811675149947405,\n        0.009460470639169216,\n        0.02328205294907093,\n        0.03281088173389435,\n        -0.00685610668733716,\n        -0.010820754803717136,\n        0.019358418881893158,\n        0.005987985525280237,\n        0.034095972776412964,\n        -0.0001542282261652872,\n        0.02403396926820278,\n        -0.013520816341042519,\n        -0.026166677474975586,\n        0.008230062201619148,\n        0.0032657079864293337,\n        0.020301731303334236,\n        -0.008599184453487396,\n        -0.017102671787142754,\n        0.023774215951561928,\n        -0.028326725587248802,\n        -0.010390112176537514,\n        -0.1020418331027031,\n        -0.00406034616753459,\n        0.0007040667696855962,\n        0.03199060633778572,\n        0.009173375554382801,\n        0.015393771231174469,\n        -0.0013363597681745887,\n        0.02545577473938465,\n        -0.018128011375665665,\n        0.0074234614148736,\n        0.0031016534194350243,\n        -0.016952287405729294,\n        0.010882275179028511,\n        -0.011162534356117249,\n        -0.009884277358651161,\n        -0.013513981364667416,\n        -0.001104803872294724,\n        -0.0027256954926997423,\n        0.012222052551805973,\n        0.0258248969912529,\n        -0.022967616096138954,\n        -0.01868852972984314,\n        -0.013876267708837986,\n        -0.008701718412339687,\n        0.0054411375895142555,\n        0.00022044809884391725,\n        -0.006876613479107618,\n        0.0036741350777447224,\n        0.012105847708880901,\n        -0.004620865453034639,\n        0.004648208152502775,\n        -0.017006972804665565,\n        -0.0018080162117257714,\n        -0.0009834719821810722,\n        -0.017950285226106644,\n        0.0006788605242036283,\n        -0.02123137377202511,\n        -0.03379520773887634,\n        0.0144094442948699,\n        -0.033002275973558426,\n        0.0074644749984145164,\n        0.01428640354424715,\n        0.02403396926820278,\n        -0.009911620058119297,\n        -0.009474141523241997,\n        0.013637022115290165,\n        -0.0288188885897398,\n        0.036693502217531204,\n        0.002474487293511629,\n        -0.017553821206092834,\n        -0.006678381003439426,\n        0.014231719076633453,\n        -0.03573651611804962,\n        -0.014860594645142555,\n        0.0057384860701859,\n        -0.007977144792675972,\n        0.00470972852781415,\n        0.024567145854234695,\n        -0.01844244822859764,\n        -0.005789753049612045,\n        0.01953614503145218,\n        0.011060000397264957,\n        -0.004607194568961859,\n        0.004853276070207357,\n        0.012604846619069576,\n        -0.01617302931845188,\n        -0.0294477641582489,\n        -0.020301731303334236,\n        -0.004959227982908487,\n        -0.023117998614907265,\n        -0.033029619604349136,\n        -0.0020848580170422792,\n        -0.026344401761889458,\n        0.016255056485533714,\n        -0.010178208351135254,\n        -0.01527073048055172,\n        -0.005413795355707407,\n        -0.010889111086726189,\n        0.020028308033943176,\n        -0.008674376644194126,\n        -0.0165968369692564,\n        -0.013103845529258251,\n        0.011312917806208134,\n        -0.023323066532611847,\n        0.022338740527629852,\n        0.00041697159758768976,\n        -0.007669543381780386,\n        -0.002595819067209959,\n        0.010813918896019459,\n        -0.026440100744366646,\n        0.0014363304944708943,\n        0.028436096385121346,\n        -0.007238900288939476,\n        0.0006609170814044774,\n        -0.019098665565252304,\n        -0.010472139343619347,\n        -0.014915279112756252,\n        0.013062831945717335,\n        0.011811916716396809,\n        0.026891250163316727,\n        0.006709141191095114,\n        -0.00143034930806607,\n        -0.06053607165813446,\n        0.023965613916516304,\n        -0.007457639556378126,\n        -0.013213214464485645,\n        -0.011114685796201229,\n        -0.0015106676146388054,\n        0.00890678633004427,\n        0.0031101980712264776,\n        -0.009152868762612343,\n        0.010048331692814827,\n        -0.007649036590009928,\n        0.016774563118815422,\n        -0.02201063185930252,\n        0.0012799660908058286,\n        0.0031324136070907116,\n        -0.001912259147502482,\n        0.022639507427811623,\n        -0.01280307862907648,\n        -0.010772905312478542,\n        -0.005328350234776735,\n        -0.03275619447231293,\n        0.0006498091970570385,\n        0.003385330783203244,\n        0.020971620455384254,\n        0.003296468174085021,\n        -0.009446798823773861,\n        0.0005887160659767687,\n        0.0394277423620224,\n        -0.0039475588127970695,\n        -0.03491624444723129,\n        0.01100531592965126,\n        -0.015803907066583633,\n        0.009843263775110245,\n        0.027287714183330536,\n        0.009282744489610195,\n        -0.019249049946665764,\n        0.01581757888197899,\n        0.016952287405729294,\n        0.008660704828798771,\n        0.018647516146302223,\n        -0.005591520573943853,\n        -0.014792238362133503,\n        0.0019686527084559202,\n        -0.014327417127788067,\n        0.007690050173550844,\n        -0.003487864974886179,\n        0.012317751534283161,\n        -0.005393288563936949,\n        0.005622280761599541,\n        0.005991403479129076,\n        0.02073921076953411,\n        0.016501137986779213,\n        -0.009474141523241997,\n        -0.021750878542661667,\n        -0.014067664742469788,\n        -0.008694883435964584,\n        0.02283090353012085,\n        -0.018524475395679474,\n        -0.010089345276355743,\n        -0.033248357474803925,\n        0.05547773092985153,\n        0.011504314839839935,\n        0.002816267078742385,\n        -0.002638541627675295,\n        -0.0019447281956672668,\n        -0.006903956178575754,\n        0.0012440792052075267,\n        0.0021327072754502296,\n        0.012885105796158314,\n        -0.03024069406092167,\n        -0.002129289321601391,\n        -0.005813677795231342,\n        0.0018080162117257714,\n        0.00595722533762455,\n        -0.007341434247791767,\n        -0.0030623488128185272,\n        -0.008414623327553272,\n        -0.001274839392863214,\n        -0.008824759162962437,\n        0.013842090032994747,\n        0.01439577341079712,\n        -0.011333424597978592,\n        -0.015065662562847137,\n        0.009672373533248901,\n        0.041287023574113846,\n        0.03174452483654022,\n        -0.0035647654440253973,\n        0.003626285819336772,\n        -0.017376095056533813,\n        -0.016132015734910965,\n        0.0003838616539724171,\n        -0.0067945863120257854,\n        0.0037835044786334038,\n        0.001703773275949061,\n        0.023992955684661865,\n        0.035435751080513,\n        -0.015010977163910866,\n        0.0024061312433332205,\n        -0.01086860429495573,\n        -0.0027718357741832733,\n        -0.006729647982865572,\n        0.011729889549314976,\n        0.00763536524027586,\n        -0.02525070682168007,\n        -0.01723938249051571,\n        -0.0031119068153202534,\n        -0.0025342986918985844,\n        -0.009740729816257954,\n        0.015093004330992699,\n        0.02325471118092537,\n        -0.003105071373283863,\n        -0.01076607033610344,\n        0.006927880458533764,\n        0.012591174803674221,\n        -0.012105847708880901,\n        -0.012310915626585484,\n        -0.007232064846903086,\n        -0.029803216457366943,\n        -0.023774215951561928,\n        0.028627492487430573,\n        0.0159679614007473,\n        0.0015371555928140879,\n        0.007532831281423569,\n        -0.00964503176510334,\n        0.036693502217531204,\n        0.002694935305044055,\n        0.020424772053956985,\n        -0.018223710358142853,\n        0.014177034609019756,\n        -0.009911620058119297,\n        0.005222398322075605,\n        0.02587958239018917,\n        -0.0053488570265471935,\n        -0.004323516972362995,\n        -0.008004487492144108,\n        -0.014518814161419868,\n        -0.020780224353075027,\n        0.0011731598060578108,\n        0.011545328423380852,\n        0.09061271697282791,\n        0.040931571274995804,\n        -0.0016191827598959208,\n        0.015134017914533615,\n        0.007806255016475916,\n        0.03374052047729492,\n        0.015202374197542667,\n        -0.023774215951561928,\n        -0.024567145854234695,\n        -0.01641911081969738,\n        0.02917434088885784,\n        0.01099164504557848,\n        -0.01901663839817047,\n        -0.03311164677143097,\n        -0.0005280501209199429,\n        -0.02443043515086174,\n        0.006948387250304222,\n        0.019454117864370346,\n        -0.00039710564306005836,\n        0.014095007441937923,\n        0.03234605863690376,\n        0.03461547940969467,\n        0.03349443897604942,\n        0.027369743213057518,\n        -0.036420077085494995,\n        -0.02050679922103882,\n        0.045880548655986786,\n        -0.01801864244043827,\n        0.0014875974738970399,\n        -0.035435751080513,\n        0.02083490788936615,\n        -0.0001317989081144333,\n        -0.01929006353020668,\n        -0.017758889123797417,\n        -0.000527622876688838,\n        0.01717102713882923,\n        -0.002383915474638343,\n        -0.014368430711328983,\n        0.02572919800877571,\n        0.00013350781227927655,\n        -0.0074644749984145164,\n        -0.008565006777644157,\n        -0.03863481059670448,\n        -0.038935575634241104,\n        -0.021901262924075127,\n        0.019946280866861343,\n        0.007970309816300869,\n        -0.00807284377515316,\n        0.0011201839661225677\n      ],\n      \"index\": 0,\n      \"object\": \"embedding\"\n    }\n  ],\n  \"model\": \"ada\",\n  \"object\": \"list\",\n  \"usage\": {\n    \"prompt_tokens\": 10,\n    \"total_tokens\": 10\n  }\n}"},"events":[{"name":"promptflow.function.inputs","timestamp":"2024-04-11T18:07:28.357701Z","attributes":{"payload":"{\n  \"input\": [\n    [\n      3923,\n      527,\n      279,\n      7504,\n      311,\n      1893,\n      264,\n      27565,\n      2683,\n      30\n    ]\n  ],\n  \"model\": \"text-embedding-ada-002\"\n}"}},{"name":"promptflow.embedding.embeddings","timestamp":"2024-04-11T18:07:29.756695Z","attributes":{"payload":"[\n  {\n    \"embedding.vector\": \"\u003c1536 dimensional vector\u003e\",\n    \"embedding.text\": \"\u003c10 dimensional token\u003e\"\n  }\n]"}},{"name":"promptflow.function.output","timestamp":"2024-04-11T18:07:29.820902Z","attributes":{"payload":"{\n  \"data\": [\n    {\n      \"embedding\": [\n        -0.0094194570556283,\n        -0.016255056485533714,\n        -0.021914932876825333,\n        -0.019823240116238594,\n        -0.010615686886012554,\n        0.005359110422432423,\n        -0.013637022115290165,\n        -0.02038375847041607,\n        -0.02170986495912075,\n        -0.017047986388206482,\n        -0.0013269608607515693,\n        0.005205309484153986,\n        -0.015762893483042717,\n        -0.005882033612579107,\n        -0.0031101980712264776,\n        -0.001731970114633441,\n        0.008312089368700981,\n        -0.02667251043021679,\n        0.012809914536774158,\n        -0.018497133627533913,\n        -0.039537109434604645,\n        0.012864599004387856,\n        0.014477800577878952,\n        -0.002741075586527586,\n        0.005157459992915392,\n        0.009105019271373749,\n        0.01611834391951561,\n        0.008749567903578281,\n        -0.0019344747997820377,\n        3.212198134860955e-05,\n        0.005427466239780188,\n        -0.01030808500945568,\n        -0.012816749513149261,\n        -0.026385415345430374,\n        -0.03606462478637695,\n        0.01669253595173359,\n        -0.00877007469534874,\n        -0.005174549296498299,\n        -0.0033374817576259375,\n        -0.026084650307893753,\n        0.0278208926320076,\n        0.0127894077450037,\n        -0.008093350566923618,\n        -0.0069347163662314415,\n        -0.0062409029342234135,\n        0.021778222173452377,\n        -0.023596491664648056,\n        -0.01566719450056553,\n        0.008004487492144108,\n        0.0067125591449439526,\n        0.0035784365609288216,\n        -0.002146378392353654,\n        -0.056653451174497604,\n        0.012536490336060524,\n        0.017430780455470085,\n        -0.006452806293964386,\n        0.004624283406883478,\n        0.03322101756930351,\n        -0.009774908423423767,\n        -0.003163173794746399,\n        0.003626285819336772,\n        -0.0057555753737688065,\n        -0.01699330098927021,\n        0.014327417127788067,\n        -0.0010219222167506814,\n        -0.013821583241224289,\n        0.0069107916206121445,\n        0.008817924186587334,\n        -0.02210633084177971,\n        -0.008359938859939575,\n        0.06168445572257042,\n        0.003275961382314563,\n        -0.006247738376259804,\n        0.008975142613053322,\n        0.0013286697212606668,\n        -0.001356012187898159,\n        -0.006480148993432522,\n        -0.024061311036348343,\n        0.012242559343576431,\n        0.014792238362133503,\n        0.002252330305054784,\n        0.013794240541756153,\n        -0.04175184294581413,\n        0.020916935056447983,\n        0.002252330305054784,\n        0.006497237831354141,\n        -0.005010494962334633,\n        0.0016619052039459348,\n        -0.01236560009419918,\n        -0.001225281273946166,\n        0.002394168870523572,\n        -0.00019342612358741462,\n        0.02016502059996128,\n        0.0030025371816009283,\n        0.006257991772145033,\n        0.014354759827256203,\n        0.010041496716439724,\n        -0.013226886279881,\n        0.017403436824679375,\n        -0.033275701105594635,\n        -0.013281570747494698,\n        0.00011342823563609272,\n        -0.03551777824759483,\n        -0.010014154016971588,\n        -0.02195594646036625,\n        -0.0015781691763550043,\n        0.0037048952654004097,\n        -0.0110394936054945,\n        0.01844244822859764,\n        0.00933059398084879,\n        0.0059025404043495655,\n        0.009214389137923717,\n        -0.019180692732334137,\n        -0.04084954410791397,\n        -0.017047986388206482,\n        -0.009139196947216988,\n        0.00798398070037365,\n        -0.023596491664648056,\n        -0.011155699379742146,\n        -0.026070978492498398,\n        0.03059614636003971,\n        0.033248357474803925,\n        0.036666158586740494,\n        -0.02510032244026661,\n        0.021819235756993294,\n        -0.015229716897010803,\n        -0.010096181184053421,\n        -0.020602498203516006,\n        0.014915279112756252,\n        -0.023350410163402557,\n        0.017676861956715584,\n        0.015120347030460835,\n        0.003964648116379976,\n        0.00618280004709959,\n        -0.03461547940969467,\n        0.013117516413331032,\n        0.0026932263281196356,\n        -0.0001705695758573711,\n        -0.0288188885897398,\n        -0.013671199791133404,\n        0.028408752754330635,\n        0.023719532415270805,\n        0.008414623327553272,\n        -0.016337083652615547,\n        0.02996727079153061,\n        -0.00538303516805172,\n        0.012481805868446827,\n        -0.01326106395572424,\n        -0.015475798398256302,\n        -0.021819235756993294,\n        -0.00028410463710315526,\n        -0.005646205507218838,\n        0.016460124403238297,\n        -0.013917281292378902,\n        -0.0011603430612012744,\n        0.014983635395765305,\n        0.0008706845692358911,\n        0.013247393071651459,\n        -0.0053249322809278965,\n        0.00040351401548832655,\n        0.03800593689084053,\n        0.04199792444705963,\n        0.03190857917070389,\n        -0.008387281559407711,\n        -0.011374438181519508,\n        0.029064971953630447,\n        0.01913967914879322,\n        -0.013172200880944729,\n        -0.008079678751528263,\n        -0.00330672156997025,\n        -0.010075674392282963,\n        -0.01445045880973339,\n        -0.03806062042713165,\n        0.03313899040222168,\n        -0.010615686886012554,\n        0.014942621812224388,\n        0.003619450144469738,\n        -0.002723986515775323,\n        0.00213954271748662,\n        -0.006681798957288265,\n        0.020930606871843338,\n        -0.005468479823321104,\n        0.005099357571452856,\n        0.009480977430939674,\n        -0.014874265529215336,\n        -0.011333424597978592,\n        -0.010663536377251148,\n        -0.020342744886875153,\n        0.00956983957439661,\n        -0.009378443472087383,\n        0.010718220844864845,\n        0.013650692999362946,\n        -0.01654215157032013,\n        0.01315169408917427,\n        -0.6430932283401489,\n        -0.024471448734402657,\n        0.012256231158971786,\n        -0.034396737813949585,\n        -0.013637022115290165,\n        -0.008202720433473587,\n        -0.0019566905684769154,\n        -0.03341241180896759,\n        -0.0052702478133141994,\n        0.015380100347101688,\n        0.01134026050567627,\n        0.02228405512869358,\n        0.03226403146982193,\n        -0.002007957547903061,\n        -0.00907084159553051,\n        -0.009884277358651161,\n        0.02527804858982563,\n        -0.021696195006370544,\n        -0.02140909992158413,\n        0.02879154682159424,\n        -0.026180347427725792,\n        -0.013903610408306122,\n        -0.0034297623205929995,\n        -0.017253054305911064,\n        0.0035579297691583633,\n        -0.009597182273864746,\n        -0.0021703029051423073,\n        -0.014218048192560673,\n        0.003463940229266882,\n        -0.017512807622551918,\n        -0.0017242800677195191,\n        0.00011823451495729387,\n        0.019823240116238594,\n        0.0026795552112162113,\n        0.031225020065903664,\n        0.004996823612600565,\n        -0.03598259761929512,\n        0.022762548178434372,\n        -0.008359938859939575,\n        0.06742636114358902,\n        -0.03516232594847679,\n        -0.016227714717388153,\n        0.018073325976729393,\n        -0.016514809802174568,\n        0.0014423115644603968,\n        -0.003453686833381653,\n        -0.00470972852781415,\n        -0.004159462638199329,\n        -0.0008224081248044968,\n        0.018251052126288414,\n        0.019331077113747597,\n        -0.011114685796201229,\n        -0.00037189936847425997,\n        0.010178208351135254,\n        0.007799419574439526,\n        -0.007115859538316727,\n        0.017006972804665565,\n        0.0005036982474848628,\n        -0.00652458006516099,\n        0.02315901219844818,\n        0.003892874112352729,\n        -0.0023429018910974264,\n        -0.013404611498117447,\n        -0.030896911397576332,\n        -0.009392114356160164,\n        0.006292169913649559,\n        -0.013117516413331032,\n        -0.016309741884469986,\n        0.009891113266348839,\n        -0.03456079214811325,\n        0.00696205860003829,\n        -0.0010424290085211396,\n        0.0011201839661225677,\n        -0.012427120469510555,\n        -0.006531415972858667,\n        0.0033050125930458307,\n        0.0003601506759878248,\n        -0.004402126185595989,\n        0.006647620815783739,\n        -0.007525995373725891,\n        0.006592936348170042,\n        -0.008079678751528263,\n        -0.03535372391343117,\n        -0.003137540305033326,\n        -0.010465303435921669,\n        0.008243734017014503,\n        -0.02283090353012085,\n        -0.04109562560915947,\n        0.015051990747451782,\n        0.013404611498117447,\n        0.02890091761946678,\n        0.015448455698788166,\n        -0.005051508545875549,\n        -0.045579779893159866,\n        -0.008462472818791866,\n        0.013671199791133404,\n        0.027164673432707787,\n        -0.004361112602055073,\n        -0.004323516972362995,\n        -0.007778912782669067,\n        -0.023637505248188972,\n        0.007833597250282764,\n        -0.0028487362433224916,\n        -0.0006797149544581771,\n        0.037295032292604446,\n        -0.009617689065635204,\n        -0.028408752754330635,\n        -0.009269073605537415,\n        0.029283709824085236,\n        -0.017704203724861145,\n        -0.005984567571431398,\n        0.01656949520111084,\n        -0.021149346604943275,\n        -0.0014670906821265817,\n        -0.012721051461994648,\n        -0.033877234905958176,\n        0.030732857063412666,\n        -0.008606020361185074,\n        0.017225712537765503,\n        -0.014532485976815224,\n        -0.001320979674346745,\n        0.0050241658464074135,\n        0.008318925276398659,\n        -0.0049318852834403515,\n        -0.010383276268839836,\n        0.026918591931462288,\n        0.007908789440989494,\n        -0.004532002843916416,\n        0.007874610833823681,\n        -0.02437574975192547,\n        -0.012639024294912815,\n        0.010164537467062473,\n        0.015940619632601738,\n        0.008776910603046417,\n        0.017198368906974792,\n        -0.0014371848665177822,\n        -0.006545086856931448,\n        0.006924462970346212,\n        -0.0058341845870018005,\n        -0.023336738348007202,\n        -0.01893461123108864,\n        0.011572671122848988,\n        -0.005899122916162014,\n        -0.012057998217642307,\n        -0.01055416651070118,\n        0.0012039199937134981,\n        -0.02031540311872959,\n        -0.0036946418695151806,\n        -0.00784726906567812,\n        -0.006093937437981367,\n        -0.013507145456969738,\n        -0.004559345077723265,\n        -0.013199543580412865,\n        0.020370088517665863,\n        0.008749567903578281,\n        -0.007744734641164541,\n        0.005328350234776735,\n        -0.019303733482956886,\n        -0.00683218240737915,\n        -0.03513498231768608,\n        0.006292169913649559,\n        0.0356818325817585,\n        -0.019631844013929367,\n        0.006391285918653011,\n        -0.026139333844184875,\n        -0.015790235251188278,\n        -0.01056783739477396,\n        -0.013855760917067528,\n        0.003091400023549795,\n        -0.032072633504867554,\n        0.02258482202887535,\n        -0.025592485442757607,\n        -0.007102188188582659,\n        0.02742442674934864,\n        -0.012064834125339985,\n        0.014327417127788067,\n        -0.014682868495583534,\n        -0.0035852722357958555,\n        0.013548159040510654,\n        0.0030435509979724884,\n        -0.008353102952241898,\n        0.019344747066497803,\n        -0.01689760386943817,\n        0.002274545840919018,\n        0.01099164504557848,\n        0.030076639726758003,\n        0.0068048397079110146,\n        0.005550506990402937,\n        -0.035271696746349335,\n        0.0048396047204732895,\n        -0.009241730906069279,\n        0.03587322682142258,\n        0.035545118153095245,\n        0.010226057842373848,\n        0.011183041147887707,\n        0.02437574975192547,\n        -0.00952199101448059,\n        -0.021327072754502296,\n        -0.016049988567829132,\n        0.006220396142452955,\n        0.032072633504867554,\n        0.011764067225158215,\n        -0.006654456723481417,\n        -0.00427908543497324,\n        0.013336255215108395,\n        -0.02942042239010334,\n        0.019057651981711388,\n        -0.018086997792124748,\n        0.002341192914173007,\n        0.006066595204174519,\n        0.009166539646685123,\n        -0.02138175629079342,\n        -0.015079333446919918,\n        0.002199354348704219,\n        0.01669253595173359,\n        0.0165968369692564,\n        -0.009228060021996498,\n        0.02173720858991146,\n        -0.039263688027858734,\n        0.019358418881893158,\n        0.012509147636592388,\n        -0.0010167955188080668,\n        0.02939308062195778,\n        -0.006866360083222389,\n        -0.01853814721107483,\n        0.01226306613534689,\n        -8.272143895737827e-05,\n        0.0006327202427200973,\n        0.006353690288960934,\n        -0.00964503176510334,\n        0.00808651465922594,\n        -0.01134026050567627,\n        0.0032349477987736464,\n        -0.0017379513010382652,\n        0.04358378425240517,\n        0.014026651158928871,\n        -0.00987060647457838,\n        -0.011723053641617298,\n        0.013637022115290165,\n        0.009446798823773861,\n        -0.007177379913628101,\n        -0.006114444229751825,\n        0.030623488128185272,\n        -0.004436304327100515,\n        0.023719532415270805,\n        0.018797900527715683,\n        0.04946240037679672,\n        0.001576460199430585,\n        0.0019464370561763644,\n        0.03628336638212204,\n        -0.007990816608071327,\n        -0.024485118687152863,\n        -0.018633846193552017,\n        0.026904921978712082,\n        0.005820513237267733,\n        -0.025537801906466484,\n        -0.0026863908860832453,\n        -0.007929296232759953,\n        -0.0063878679648041725,\n        0.03313899040222168,\n        0.006924462970346212,\n        0.01916702277958393,\n        0.03313899040222168,\n        -0.010697714053094387,\n        -0.0002670156245585531,\n        -0.012085340917110443,\n        -0.009036662988364697,\n        -0.011969135142862797,\n        0.0026539217215031385,\n        -0.020342744886875153,\n        6.798217509640381e-05,\n        0.002503538504242897,\n        -0.017335081472992897,\n        -0.029338395223021507,\n        0.020670853555202484,\n        0.021504797041416168,\n        -0.0029102566186338663,\n        0.017376095056533813,\n        0.007539666723459959,\n        0.030650829896330833,\n        -0.029037628322839737,\n        -0.015120347030460835,\n        0.022844575345516205,\n        0.0078609399497509,\n        -0.022776219993829727,\n        -0.019057651981711388,\n        0.011893943883478642,\n        0.00151579431258142,\n        0.010349098592996597,\n        0.020998962223529816,\n        0.013076502829790115,\n        0.002612908137962222,\n        0.0015969669912010431,\n        0.011251397430896759,\n        0.003134122584015131,\n        -0.0008386426488868892,\n        0.02887357398867607,\n        -0.020397430285811424,\n        0.0094194570556283,\n        -0.0017516225343570113,\n        -0.010513152927160263,\n        0.01754014939069748,\n        0.002876078709959984,\n        -0.02475854381918907,\n        0.038416072726249695,\n        -0.002645377302542329,\n        -0.000711756874807179,\n        -0.02016502059996128,\n        -0.0038860386703163385,\n        -0.03595525771379471,\n        -0.004477317910641432,\n        -0.014874265529215336,\n        0.003903127508237958,\n        -0.003091400023549795,\n        0.013630186207592487,\n        -0.01348663866519928,\n        -0.02155948244035244,\n        -0.007785748224705458,\n        0.013336255215108395,\n        0.01759483478963375,\n        0.005003659054636955,\n        -0.023637505248188972,\n        -0.005160877946764231,\n        0.024321064352989197,\n        0.040439408272504807,\n        0.04134170711040497,\n        -0.0044465577229857445,\n        0.009815922006964684,\n        -0.037240348756313324,\n        0.00436794850975275,\n        0.003971483558416367,\n        -0.010096181184053421,\n        -0.0072115580551326275,\n        -0.0008484688587486744,\n        -0.004371365997940302,\n        -0.006257991772145033,\n        0.006422046106308699,\n        -0.012099011801183224,\n        0.000281541288131848,\n        -0.008729061111807823,\n        -0.004405544139444828,\n        -0.010588344186544418,\n        0.01741710864007473,\n        -0.019276391714811325,\n        0.0026402506045997143,\n        -0.002209607744589448,\n        0.018456120043992996,\n        -0.003451978089287877,\n        0.018428778275847435,\n        0.03174452483654022,\n        0.011497478932142258,\n        -0.008291582576930523,\n        -0.0112308906391263,\n        -0.007232064846903086,\n        0.001767002628184855,\n        0.009125526063144207,\n        0.009337429888546467,\n        0.01624138467013836,\n        0.007655872032046318,\n        0.05104826018214226,\n        0.009351100772619247,\n        0.023596491664648056,\n        0.011750396341085434,\n        0.017403436824679375,\n        -0.01126506831496954,\n        0.0027034797240048647,\n        0.007649036590009928,\n        0.015489469282329082,\n        0.0152844013646245,\n        -0.009877442382276058,\n        -0.002595819067209959,\n        0.013930953107774258,\n        0.027643166482448578,\n        -0.004969481378793716,\n        0.020000966265797615,\n        0.003739073174074292,\n        -0.0031683004926890135,\n        0.010622522793710232,\n        -0.004156044684350491,\n        0.03111565113067627,\n        -0.022653179243206978,\n        -0.005188220180571079,\n        0.012591174803674221,\n        -0.03576385974884033,\n        -0.04604460299015045,\n        0.008011323399841785,\n        0.004350859206169844,\n        0.00763536524027586,\n        -0.009713387116789818,\n        -0.014641854912042618,\n        0.0034724848810583353,\n        -0.0038826207164674997,\n        -0.023145342245697975,\n        -0.008318925276398659,\n        -0.01626872830092907,\n        -0.0056256987154483795,\n        -0.044677481055259705,\n        0.015776565298438072,\n        0.025988951325416565,\n        0.016938617452979088,\n        0.0032708346843719482,\n        -0.018155353143811226,\n        -0.0035408406984061003,\n        -0.018797900527715683,\n        -0.018975624814629555,\n        -0.02373320236802101,\n        0.008523993194103241,\n        -0.0053249322809278965,\n        0.0017413691384717822,\n        0.002021628664806485,\n        -0.005923047196120024,\n        0.008920458145439625,\n        0.009891113266348839,\n        0.01926271989941597,\n        -0.021545810624957085,\n        0.024867912754416466,\n        -0.01540744211524725,\n        -0.022502794861793518,\n        0.006914209574460983,\n        0.027014290913939476,\n        0.02237975411117077,\n        0.021477455273270607,\n        -0.00630584079772234,\n        -7.802196341799572e-05,\n        -0.016255056485533714,\n        -0.04232603684067726,\n        0.00459694117307663,\n        -0.014026651158928871,\n        -0.020274389535188675,\n        0.007744734641164541,\n        0.013377268798649311,\n        0.0045388382859528065,\n        -0.016528481617569923,\n        -0.020520471036434174,\n        0.012078505009412766,\n        0.005769246257841587,\n        0.029584476724267006,\n        0.001083442592062056,\n        0.014778567478060722,\n        0.01445045880973339,\n        0.00572139723226428,\n        0.017335081472992897,\n        -0.012468134053051472,\n        0.014026651158928871,\n        0.016309741884469986,\n        -0.020821237936615944,\n        0.04429468885064125,\n        0.04369315505027771,\n        -0.036119312047958374,\n        0.030760200694203377,\n        0.004672132432460785,\n        -0.02567451260983944,\n        -0.006880031432956457,\n        -0.001044992357492447,\n        -0.004576434381306171,\n        0.044376716017723083,\n        0.0008664123015478253,\n        -0.017034314572811127,\n        -0.022994957864284515,\n        -0.008428295142948627,\n        0.0028282294515520334,\n        0.015913276001811028,\n        -0.01168887596577406,\n        -0.01723938249051571,\n        -0.009392114356160164,\n        -0.006668127607554197,\n        0.0070953527465462685,\n        -0.0037493265699595213,\n        0.021942276507616043,\n        -0.01893461123108864,\n        -0.031853895634412766,\n        0.007977144792675972,\n        -0.008899951353669167,\n        0.017950285226106644,\n        -0.02198329009115696,\n        0.00196181726641953,\n        -0.0511576309800148,\n        -0.02702796272933483,\n        0.009829592891037464,\n        -0.015598839148879051,\n        0.005536836106330156,\n        -0.014682868495583534,\n        0.02829938381910324,\n        0.025592485442757607,\n        0.02198329009115696,\n        0.014983635395765305,\n        0.013978801667690277,\n        -0.010075674392282963,\n        0.0015559534076601267,\n        -0.007710556965321302,\n        0.0006451097433455288,\n        0.003180262865498662,\n        0.002283090492710471,\n        0.007519159931689501,\n        0.02031540311872959,\n        -0.013479802757501602,\n        -0.00763536524027586,\n        0.007252571638673544,\n        0.006230649538338184,\n        0.011237726546823978,\n        -0.013069666922092438,\n        -0.023200025781989098,\n        0.0030298796482384205,\n        -0.04577117785811424,\n        -0.0057384860701859,\n        0.011613684706389904,\n        -0.014928949996829033,\n        0.017854586243629456,\n        -0.039564453065395355,\n        -0.011900779791176319,\n        0.02370586059987545,\n        0.013671199791133404,\n        0.017731545493006706,\n        0.02031540311872959,\n        0.023897256702184677,\n        0.0007980563095770776,\n        0.009610853157937527,\n        -0.004405544139444828,\n        0.011620519682765007,\n        -0.01472388207912445,\n        -0.017772559076547623,\n        -0.014983635395765305,\n        0.006770661566406488,\n        0.002457398222759366,\n        0.02824469842016697,\n        -0.0010791703825816512,\n        -0.009747565723955631,\n        0.015557825565338135,\n        0.013930953107774258,\n        0.018674859777092934,\n        -0.015858592465519905,\n        0.00515404250472784,\n        0.011285575106739998,\n        -0.03251011297106743,\n        -0.012891941703855991,\n        -0.031033623963594437,\n        0.020096663385629654,\n        0.019877925515174866,\n        0.005328350234776735,\n        -0.0018063073512166739,\n        0.002823102753609419,\n        0.011490643955767155,\n        -0.012693708762526512,\n        -0.017157355323433876,\n        0.009474141523241997,\n        -0.012310915626585484,\n        0.026959605515003204,\n        0.025715526193380356,\n        0.028463438153266907,\n        0.003434889018535614,\n        0.009029828011989594,\n        0.00425516115501523,\n        -0.018797900527715683,\n        -0.002659048419445753,\n        -0.005854691378772259,\n        0.011470137163996696,\n        0.012167368084192276,\n        0.002900003222748637,\n        -0.016938617452979088,\n        0.0018370675388723612,\n        0.0012731305323541164,\n        -0.004573016427457333,\n        -0.010793412104249,\n        0.03423268347978592,\n        -0.0024898673873394728,\n        -0.0008061736007221043,\n        -0.001030466752126813,\n        -0.008346267975866795,\n        0.002942725783213973,\n        0.020821237936615944,\n        0.010178208351135254,\n        0.009576675482094288,\n        0.007737899199128151,\n        -0.007614858448505402,\n        -0.002404422266408801,\n        0.015462127514183521,\n        -0.011422287672758102,\n        0.037295032292604446,\n        -0.006059759296476841,\n        -0.012119518592953682,\n        0.004251743201166391,\n        0.012010148726403713,\n        -0.025072980672121048,\n        -0.00034647947177290916,\n        0.0012261357624083757,\n        0.006839017849415541,\n        0.0014525649603456259,\n        0.013739556074142456,\n        -0.0009159704204648733,\n        0.007587515749037266,\n        -0.019604500383138657,\n        -0.009897949174046516,\n        0.019084995612502098,\n        0.03562714532017708,\n        -0.029338395223021507,\n        0.00035865537938661873,\n        -0.0040535107254981995,\n        -0.00641862815245986,\n        0.01816902495920658,\n        -0.0058581093326210976,\n        0.0008792290464043617,\n        0.007881446741521358,\n        0.0024078399874269962,\n        0.008400952443480492,\n        0.0391816608607769,\n        -0.002368535380810499,\n        -0.004303010180592537,\n        -0.005813677795231342,\n        0.0033238104078918695,\n        -0.005273665301501751,\n        0.029857899993658066,\n        0.011422287672758102,\n        -0.0005968332989141345,\n        -0.0255788154900074,\n        -0.004549091681838036,\n        -0.014819581061601639,\n        0.013896774500608444,\n        0.016077330335974693,\n        0.014682868495583534,\n        0.011524821631610394,\n        0.018073325976729393,\n        0.02155948244035244,\n        -0.002741075586527586,\n        -0.02352813445031643,\n        0.023241039365530014,\n        -0.014436786994338036,\n        -0.021217701956629753,\n        -0.00020506800501607358,\n        -0.015106676146388054,\n        -0.005290754605084658,\n        0.038689494132995605,\n        -0.010526823811233044,\n        -0.01784091629087925,\n        -0.034670162945985794,\n        0.03026803582906723,\n        -0.0037117307074368,\n        -0.013315748423337936,\n        -0.020342744886875153,\n        -0.016077330335974693,\n        0.0033802040852606297,\n        0.0037971758283674717,\n        0.011538492515683174,\n        0.016883932054042816,\n        0.013842090032994747,\n        -0.027315057814121246,\n        0.008414623327553272,\n        0.006815093103796244,\n        -0.003940723370760679,\n        0.007054339163005352,\n        -0.03283822163939476,\n        -0.0001453633012715727,\n        0.018524475395679474,\n        -0.0331936739385128,\n        -0.02412966825067997,\n        0.015434784814715385,\n        0.019208036363124847,\n        -0.021340742707252502,\n        0.011586342006921768,\n        0.007355105597525835,\n        -0.012406613677740097,\n        -0.013452460989356041,\n        0.021053647622466087,\n        -0.018784228712320328,\n        -0.0056496234610676765,\n        -0.015079333446919918,\n        0.024539804086089134,\n        0.010547330603003502,\n        0.016255056485533714,\n        -0.009357936680316925,\n        -0.010827590711414814,\n        -0.005960643291473389,\n        -0.024908926337957382,\n        -0.03251011297106743,\n        -0.026262374594807625,\n        0.00833259616047144,\n        0.02525070682168007,\n        -0.0029769036918878555,\n        -0.015393771231174469,\n        -0.02400662750005722,\n        -0.02113567478954792,\n        -0.010526823811233044,\n        0.009515155106782913,\n        -0.004904543049633503,\n        0.008817924186587334,\n        0.016378097236156464,\n        -0.0037527442909777164,\n        0.016227714717388153,\n        0.007307256571948528,\n        0.01759483478963375,\n        0.007724227849394083,\n        -0.0034041288308799267,\n        -0.0019959951750934124,\n        -0.010137194767594337,\n        0.007676378823816776,\n        0.0013158529764041305,\n        -0.020903265103697777,\n        -0.047794513404369354,\n        0.009412621147930622,\n        0.005577849689871073,\n        0.01602264679968357,\n        0.012844092212617397,\n        0.008004487492144108,\n        -0.015298073180019855,\n        -0.0170889999717474,\n        -0.004477317910641432,\n        -0.004002243746072054,\n        0.022270385175943375,\n        0.030213352292776108,\n        0.020930606871843338,\n        -0.030705515295267105,\n        -0.011490643955767155,\n        0.014997306279838085,\n        -0.024922598153352737,\n        -0.003260581288486719,\n        -0.01362335029989481,\n        0.007874610833823681,\n        -0.019946280866861343,\n        0.005451390985399485,\n        -0.016132015734910965,\n        -0.009624524973332882,\n        -0.013869432732462883,\n        0.0012175912270322442,\n        0.022926602512598038,\n        0.0018832078203558922,\n        0.019522473216056824,\n        0.014600841328501701,\n        -0.00887260865420103,\n        0.00460377661511302,\n        -0.004019332583993673,\n        -0.01257750391960144,\n        -0.026945935562253,\n        -0.016227714717388153,\n        0.016104673966765404,\n        -0.03808796405792236,\n        -0.028162671253085136,\n        -0.005037837196141481,\n        -0.012345093302428722,\n        -0.015926947817206383,\n        -0.005817095749080181,\n        -0.007109024096280336,\n        0.005092522129416466,\n        2.7475907700136304e-05,\n        0.016063660383224487,\n        0.004832769278436899,\n        -0.02996727079153061,\n        -0.013650692999362946,\n        -0.01425906177610159,\n        -0.027492783963680267,\n        -0.001508958637714386,\n        0.00427224999293685,\n        0.0024727783165872097,\n        -0.007443968206644058,\n        0.007621693890541792,\n        -0.02887357398867607,\n        -0.03190857917070389,\n        -0.005331768188625574,\n        0.012536490336060524,\n        0.01956348679959774,\n        0.02061617001891136,\n        0.011962300166487694,\n        0.23164480924606323,\n        -0.007601187098771334,\n        0.0009928708896040916,\n        0.03510764241218567,\n        0.01584492065012455,\n        -0.0009424583404324949,\n        0.009241730906069279,\n        0.007854104042053223,\n        0.0017131722997874022,\n        0.008161705918610096,\n        -0.008202720433473587,\n        -0.013944623991847038,\n        -0.003308430314064026,\n        0.008756403811275959,\n        0.013390940614044666,\n        -0.03292024880647659,\n        -0.03406862914562225,\n        0.007573844864964485,\n        -0.014177034609019756,\n        -0.03595525771379471,\n        0.006985983345657587,\n        -0.008763238787651062,\n        -0.037295032292604446,\n        -0.016924945637583733,\n        0.04084954410791397,\n        0.010267071425914764,\n        -0.012290408834815025,\n        0.015134017914533615,\n        0.015913276001811028,\n        0.018633846193552017,\n        -0.019549816846847534,\n        0.021094661206007004,\n        0.010581509210169315,\n        0.010164537467062473,\n        0.014341088943183422,\n        -0.014819581061601639,\n        0.010759234428405762,\n        -0.01226306613534689,\n        0.01413602102547884,\n        0.01629607006907463,\n        0.019002968445420265,\n        0.0017892182804644108,\n        -0.011531657539308071,\n        -0.03620133921504021,\n        -0.003592107677832246,\n        0.0042859213426709175,\n        -0.028381410986185074,\n        -0.009528825990855694,\n        0.007840433157980442,\n        0.011627355590462685,\n        -0.022871917113661766,\n        -0.020452115684747696,\n        0.0321820043027401,\n        0.011367603205144405,\n        0.014040322043001652,\n        0.009843263775110245,\n        0.00572139723226428,\n        -0.001030466752126813,\n        0.023664847016334534,\n        0.014245389960706234,\n        -0.017786230891942978,\n        0.03786922246217728,\n        -0.008066007867455482,\n        0.012857763096690178,\n        0.004484153352677822,\n        -0.006145204417407513,\n        -0.016801904886960983,\n        0.014300075359642506,\n        0.023965613916516304,\n        0.02300862967967987,\n        -0.02403396926820278,\n        -0.008462472818791866,\n        0.0011406907578930259,\n        -0.017102671787142754,\n        -0.011880272999405861,\n        -0.025483116507530212,\n        0.018497133627533913,\n        0.015161360614001751,\n        0.03426002711057663,\n        0.03395926207304001,\n        -0.010506317019462585,\n        -0.010171372443437576,\n        -0.00060580502031371,\n        -0.0255788154900074,\n        0.008667540736496449,\n        -0.017909271642565727,\n        0.002712024375796318,\n        -0.006903956178575754,\n        -0.032400742173194885,\n        0.01868852972984314,\n        -0.001696083229035139,\n        0.0026111991610378027,\n        -0.014464129693806171,\n        -0.017458122223615646,\n        0.017786230891942978,\n        0.00887260865420103,\n        0.010889111086726189,\n        0.01959083043038845,\n        0.001661050831899047,\n        -0.0021908096969127655,\n        -0.04883352667093277,\n        0.043665811419487,\n        0.008066007867455482,\n        0.00551974680274725,\n        -0.02228405512869358,\n        -0.005639370065182447,\n        -0.004873782861977816,\n        0.00877007469534874,\n        0.036146651953458786,\n        -0.01896195486187935,\n        0.0021412516944110394,\n        -0.03978319093585014,\n        0.023869914934039116,\n        -0.0070816813968122005,\n        -0.019153350964188576,\n        0.009439963847398758,\n        -0.01401298027485609,\n        -0.010451632551848888,\n        -0.0013337964192032814,\n        -0.011634191498160362,\n        0.009098183363676071,\n        0.004309845622628927,\n        -0.008373609744012356,\n        0.010684043169021606,\n        -0.0029581058770418167,\n        -0.036173995584249496,\n        0.007177379913628101,\n        -0.005147206597030163,\n        -0.020903265103697777,\n        -0.03633804991841316,\n        0.020082993432879448,\n        0.012871434912085533,\n        -0.005577849689871073,\n        -0.002971776993945241,\n        -0.006944969762116671,\n        -0.01179140992462635,\n        -0.017676861956715584,\n        0.019700199365615845,\n        0.011941793374717236,\n        -0.01179140992462635,\n        0.008038665167987347,\n        -0.007273078430444002,\n        0.016760891303420067,\n        0.017047986388206482,\n        -0.011873437091708183,\n        -0.02639908716082573,\n        0.02123137377202511,\n        -0.02542843110859394,\n        -0.007143201772123575,\n        -0.03084222786128521,\n        -0.018770556896924973,\n        0.005666712298989296,\n        -0.01248864084482193,\n        -0.03450610861182213,\n        0.02428005076944828,\n        -0.018579160794615746,\n        -0.0011526530142873526,\n        -0.024608159437775612,\n        -0.008776910603046417,\n        -0.01200331375002861,\n        -0.03680286929011345,\n        0.004224400967359543,\n        0.014245389960706234,\n        -0.0037595799658447504,\n        -0.017772559076547623,\n        -0.024799557402729988,\n        -0.17531946301460266,\n        -0.015161360614001751,\n        0.03822467476129532,\n        -0.023664847016334534,\n        0.022147344425320625,\n        0.021450113505125046,\n        0.021149346604943275,\n        -0.002840191824361682,\n        -0.031006282195448875,\n        0.023637505248188972,\n        0.014327417127788067,\n        -0.010663536377251148,\n        -0.042380720376968384,\n        -0.0035579297691583633,\n        0.0025086652021855116,\n        -0.002946143504232168,\n        0.01077974122017622,\n        0.0316898413002491,\n        0.04943506047129631,\n        0.01756749115884304,\n        0.015940619632601738,\n        -0.01953614503145218,\n        -0.018223710358142853,\n        0.010226057842373848,\n        -0.0168429184705019,\n        0.0009005902684293687,\n        -0.021723536774516106,\n        0.005229233764111996,\n        0.014778567478060722,\n        -0.02627604641020298,\n        -0.00023283762857317924,\n        0.007785748224705458,\n        0.0036878061946481466,\n        -0.006985983345657587,\n        -0.0039373054169118404,\n        -0.03229137510061264,\n        0.0012731305323541164,\n        -0.02080756612122059,\n        -0.005406959448009729,\n        0.0031888072844594717,\n        0.018251052126288414,\n        0.01669253595173359,\n        0.0030538043938577175,\n        -0.0021327072754502296,\n        0.017034314572811127,\n        0.022940274327993393,\n        0.0037869224324822426,\n        0.0015004142187535763,\n        0.0037629976868629456,\n        0.0003041841846425086,\n        0.03311164677143097,\n        -0.004528584890067577,\n        -0.019754884764552116,\n        -0.006640785373747349,\n        0.00235828198492527,\n        -0.025961609557271004,\n        -0.013158529996871948,\n        0.027287714183330536,\n        0.0010484101949259639,\n        -0.02860015071928501,\n        0.010301249101758003,\n        -0.027561139315366745,\n        0.00029478524811565876,\n        -0.029584476724267006,\n        -0.02827204205095768,\n        -0.011196712963283062,\n        0.005420630797743797,\n        0.01674721948802471,\n        -0.03590057045221329,\n        0.005639370065182447,\n        0.006927880458533764,\n        -0.0010210677282884717,\n        -0.013596008531749249,\n        0.0036809705197811127,\n        -0.0034468513913452625,\n        0.000853595556691289,\n        -0.00920755323022604,\n        0.035818543285131454,\n        0.0016302906442433596,\n        0.001154361991211772,\n        0.007129530888050795,\n        0.06502022594213486,\n        -0.004644790198653936,\n        0.016651522368192673,\n        0.015393771231174469,\n        0.00843513011932373,\n        -0.002067768946290016,\n        0.0029017121996730566,\n        -0.0341779999434948,\n        -0.028053302317857742,\n        0.0027889248449355364,\n        0.005594938527792692,\n        -0.02467651665210724,\n        0.004884036257863045,\n        0.0007305547478608787,\n        0.007245736196637154,\n        0.016514809802174568,\n        -0.0069347163662314415,\n        0.019098665565252304,\n        0.0062409029342234135,\n        0.005782917607575655,\n        0.015708208084106445,\n        -0.04306428134441376,\n        0.019782226532697678,\n        0.03797859326004982,\n        0.006811675149947405,\n        0.009460470639169216,\n        0.02328205294907093,\n        0.03281088173389435,\n        -0.00685610668733716,\n        -0.010820754803717136,\n        0.019358418881893158,\n        0.005987985525280237,\n        0.034095972776412964,\n        -0.0001542282261652872,\n        0.02403396926820278,\n        -0.013520816341042519,\n        -0.026166677474975586,\n        0.008230062201619148,\n        0.0032657079864293337,\n        0.020301731303334236,\n        -0.008599184453487396,\n        -0.017102671787142754,\n        0.023774215951561928,\n        -0.028326725587248802,\n        -0.010390112176537514,\n        -0.1020418331027031,\n        -0.00406034616753459,\n        0.0007040667696855962,\n        0.03199060633778572,\n        0.009173375554382801,\n        0.015393771231174469,\n        -0.0013363597681745887,\n        0.02545577473938465,\n        -0.018128011375665665,\n        0.0074234614148736,\n        0.0031016534194350243,\n        -0.016952287405729294,\n        0.010882275179028511,\n        -0.011162534356117249,\n        -0.009884277358651161,\n        -0.013513981364667416,\n        -0.001104803872294724,\n        -0.0027256954926997423,\n        0.012222052551805973,\n        0.0258248969912529,\n        -0.022967616096138954,\n        -0.01868852972984314,\n        -0.013876267708837986,\n        -0.008701718412339687,\n        0.0054411375895142555,\n        0.00022044809884391725,\n        -0.006876613479107618,\n        0.0036741350777447224,\n        0.012105847708880901,\n        -0.004620865453034639,\n        0.004648208152502775,\n        -0.017006972804665565,\n        -0.0018080162117257714,\n        -0.0009834719821810722,\n        -0.017950285226106644,\n        0.0006788605242036283,\n        -0.02123137377202511,\n        -0.03379520773887634,\n        0.0144094442948699,\n        -0.033002275973558426,\n        0.0074644749984145164,\n        0.01428640354424715,\n        0.02403396926820278,\n        -0.009911620058119297,\n        -0.009474141523241997,\n        0.013637022115290165,\n        -0.0288188885897398,\n        0.036693502217531204,\n        0.002474487293511629,\n        -0.017553821206092834,\n        -0.006678381003439426,\n        0.014231719076633453,\n        -0.03573651611804962,\n        -0.014860594645142555,\n        0.0057384860701859,\n        -0.007977144792675972,\n        0.00470972852781415,\n        0.024567145854234695,\n        -0.01844244822859764,\n        -0.005789753049612045,\n        0.01953614503145218,\n        0.011060000397264957,\n        -0.004607194568961859,\n        0.004853276070207357,\n        0.012604846619069576,\n        -0.01617302931845188,\n        -0.0294477641582489,\n        -0.020301731303334236,\n        -0.004959227982908487,\n        -0.023117998614907265,\n        -0.033029619604349136,\n        -0.0020848580170422792,\n        -0.026344401761889458,\n        0.016255056485533714,\n        -0.010178208351135254,\n        -0.01527073048055172,\n        -0.005413795355707407,\n        -0.010889111086726189,\n        0.020028308033943176,\n        -0.008674376644194126,\n        -0.0165968369692564,\n        -0.013103845529258251,\n        0.011312917806208134,\n        -0.023323066532611847,\n        0.022338740527629852,\n        0.00041697159758768976,\n        -0.007669543381780386,\n        -0.002595819067209959,\n        0.010813918896019459,\n        -0.026440100744366646,\n        0.0014363304944708943,\n        0.028436096385121346,\n        -0.007238900288939476,\n        0.0006609170814044774,\n        -0.019098665565252304,\n        -0.010472139343619347,\n        -0.014915279112756252,\n        0.013062831945717335,\n        0.011811916716396809,\n        0.026891250163316727,\n        0.006709141191095114,\n        -0.00143034930806607,\n        -0.06053607165813446,\n        0.023965613916516304,\n        -0.007457639556378126,\n        -0.013213214464485645,\n        -0.011114685796201229,\n        -0.0015106676146388054,\n        0.00890678633004427,\n        0.0031101980712264776,\n        -0.009152868762612343,\n        0.010048331692814827,\n        -0.007649036590009928,\n        0.016774563118815422,\n        -0.02201063185930252,\n        0.0012799660908058286,\n        0.0031324136070907116,\n        -0.001912259147502482,\n        0.022639507427811623,\n        -0.01280307862907648,\n        -0.010772905312478542,\n        -0.005328350234776735,\n        -0.03275619447231293,\n        0.0006498091970570385,\n        0.003385330783203244,\n        0.020971620455384254,\n        0.003296468174085021,\n        -0.009446798823773861,\n        0.0005887160659767687,\n        0.0394277423620224,\n        -0.0039475588127970695,\n        -0.03491624444723129,\n        0.01100531592965126,\n        -0.015803907066583633,\n        0.009843263775110245,\n        0.027287714183330536,\n        0.009282744489610195,\n        -0.019249049946665764,\n        0.01581757888197899,\n        0.016952287405729294,\n        0.008660704828798771,\n        0.018647516146302223,\n        -0.005591520573943853,\n        -0.014792238362133503,\n        0.0019686527084559202,\n        -0.014327417127788067,\n        0.007690050173550844,\n        -0.003487864974886179,\n        0.012317751534283161,\n        -0.005393288563936949,\n        0.005622280761599541,\n        0.005991403479129076,\n        0.02073921076953411,\n        0.016501137986779213,\n        -0.009474141523241997,\n        -0.021750878542661667,\n        -0.014067664742469788,\n        -0.008694883435964584,\n        0.02283090353012085,\n        -0.018524475395679474,\n        -0.010089345276355743,\n        -0.033248357474803925,\n        0.05547773092985153,\n        0.011504314839839935,\n        0.002816267078742385,\n        -0.002638541627675295,\n        -0.0019447281956672668,\n        -0.006903956178575754,\n        0.0012440792052075267,\n        0.0021327072754502296,\n        0.012885105796158314,\n        -0.03024069406092167,\n        -0.002129289321601391,\n        -0.005813677795231342,\n        0.0018080162117257714,\n        0.00595722533762455,\n        -0.007341434247791767,\n        -0.0030623488128185272,\n        -0.008414623327553272,\n        -0.001274839392863214,\n        -0.008824759162962437,\n        0.013842090032994747,\n        0.01439577341079712,\n        -0.011333424597978592,\n        -0.015065662562847137,\n        0.009672373533248901,\n        0.041287023574113846,\n        0.03174452483654022,\n        -0.0035647654440253973,\n        0.003626285819336772,\n        -0.017376095056533813,\n        -0.016132015734910965,\n        0.0003838616539724171,\n        -0.0067945863120257854,\n        0.0037835044786334038,\n        0.001703773275949061,\n        0.023992955684661865,\n        0.035435751080513,\n        -0.015010977163910866,\n        0.0024061312433332205,\n        -0.01086860429495573,\n        -0.0027718357741832733,\n        -0.006729647982865572,\n        0.011729889549314976,\n        0.00763536524027586,\n        -0.02525070682168007,\n        -0.01723938249051571,\n        -0.0031119068153202534,\n        -0.0025342986918985844,\n        -0.009740729816257954,\n        0.015093004330992699,\n        0.02325471118092537,\n        -0.003105071373283863,\n        -0.01076607033610344,\n        0.006927880458533764,\n        0.012591174803674221,\n        -0.012105847708880901,\n        -0.012310915626585484,\n        -0.007232064846903086,\n        -0.029803216457366943,\n        -0.023774215951561928,\n        0.028627492487430573,\n        0.0159679614007473,\n        0.0015371555928140879,\n        0.007532831281423569,\n        -0.00964503176510334,\n        0.036693502217531204,\n        0.002694935305044055,\n        0.020424772053956985,\n        -0.018223710358142853,\n        0.014177034609019756,\n        -0.009911620058119297,\n        0.005222398322075605,\n        0.02587958239018917,\n        -0.0053488570265471935,\n        -0.004323516972362995,\n        -0.008004487492144108,\n        -0.014518814161419868,\n        -0.020780224353075027,\n        0.0011731598060578108,\n        0.011545328423380852,\n        0.09061271697282791,\n        0.040931571274995804,\n        -0.0016191827598959208,\n        0.015134017914533615,\n        0.007806255016475916,\n        0.03374052047729492,\n        0.015202374197542667,\n        -0.023774215951561928,\n        -0.024567145854234695,\n        -0.01641911081969738,\n        0.02917434088885784,\n        0.01099164504557848,\n        -0.01901663839817047,\n        -0.03311164677143097,\n        -0.0005280501209199429,\n        -0.02443043515086174,\n        0.006948387250304222,\n        0.019454117864370346,\n        -0.00039710564306005836,\n        0.014095007441937923,\n        0.03234605863690376,\n        0.03461547940969467,\n        0.03349443897604942,\n        0.027369743213057518,\n        -0.036420077085494995,\n        -0.02050679922103882,\n        0.045880548655986786,\n        -0.01801864244043827,\n        0.0014875974738970399,\n        -0.035435751080513,\n        0.02083490788936615,\n        -0.0001317989081144333,\n        -0.01929006353020668,\n        -0.017758889123797417,\n        -0.000527622876688838,\n        0.01717102713882923,\n        -0.002383915474638343,\n        -0.014368430711328983,\n        0.02572919800877571,\n        0.00013350781227927655,\n        -0.0074644749984145164,\n        -0.008565006777644157,\n        -0.03863481059670448,\n        -0.038935575634241104,\n        -0.021901262924075127,\n        0.019946280866861343,\n        0.007970309816300869,\n        -0.00807284377515316,\n        0.0011201839661225677\n      ],\n      \"index\": 0,\n      \"object\": \"embedding\"\n    }\n  ],\n  \"model\": \"ada\",\n  \"object\": \"list\",\n  \"usage\": {\n    \"prompt_tokens\": 10,\n    \"total_tokens\": 10\n  }\n}"}}],"links":[],"resource":{"attributes":{"service.name":"promptflow"},"schema_url":""}}],"xrequestid":"707ef388-3a17-45fe-9606-945ed4ee1d63","modelversion":"default","collectdatatype":"pandas.core.frame.DataFrame","agent":"azureml-ai-monitoring/0.1.0b4","contentrange":"bytes 0-98858/98859","correlationid":"707ef388-3a17-45fe-9606-945ed4ee1d63"}
{"specversion":"1.0","id":"2a1ab960-1377-4d48-a1de-10e60c155b2d","source":"/subscriptions/1aefdc5e-3a7c-4d71-a9f9-f5d3b03be19a/resourceGroups/yuachengtestrg/providers/Microsoft.MachineLearningServices/workspaces/ai-proj-eastus/onlineEndpoints/clone-vivi-log-test/deployments/clone-vivi-log-test-1","type":"azureml.inference.app_traces","datacontenttype":"application/json","time":"2024-04-11T18:07:31Z","data":[{"name":"Prompt_variants","context":{"trace_id":"0xa2f3f4f8267a482fa3bb96ad3e1f7f35","span_id":"0xb98967ebbd238946","trace_state":"[]"},"kind":"SpanKind.INTERNAL","parent_id":"0xc2bb84e37668431d","start_time":"2024-04-11T18:07:30.331014Z","end_time":"2024-04-11T18:07:30.334339Z","status":{"status_code":"OK"},"attributes":{"framework":"promptflow","span_type":"Function","function":"render_template_jinja2","node_name":"Prompt_variants","request_id":"ee2f5c78-77c1-4766-802d-49aa4b354ec3","line_run_id":"ee2f5c78-77c1-4766-802d-49aa4b354ec3","inputs":"{\n  \"template\": \"system: \\nYou are an AI assistant that helps users answer questions given a specific context and conversation history. You will be given a context and chat history, and then asked a question based on that context and history. Your answer should be as precise as possible, and should only come from the context.\\nPlease add citation after each sentence when possible in a form \\\"(Source: citation)\\\".\\n\\n user: \\n {{contexts}} \\n\\n chat history: \\n{% for item in chat_history %} user: \\n{{ item.inputs.question }} \\nassistant: \\n{{ item.outputs.output }} \\n{% endfor %}\\nuser: {{question}} \\nassistant:\",\n  \"chat_history\": [\n    {\n      \"inputs\": {\n        \"question\": \"what is aml?\"\n      },\n      \"outputs\": {\n        \"answer\": \"Azure Machine Learning (AML) is a cloud service used for accelerating and managing the machine learning project lifecycle. It is designed for ML professionals, data scientists, and engineers to facilitate their daily workflows in training and deploying models and managing machine learning operations (MLOps). You can create models in AML or use models built from open-source platforms like PyTorch, TensorFlow, or scikit-learn. Furthermore, Azure Machine Learning provides tools for monitoring, retraining, and redeploying models(Source: overview-what-is-azure-machine-learning.md).\"\n      }\n    }\n  ],\n  \"contexts\": \"Content: # Configure Apache Spark jobs in Azure Machine Learning\\n\\n3. Under **Add tags**, provide **Name** and **Value**, then select **Add**. Adding tags is optional.\\n    4. Under the **Code** section:\\n        1. Select **Azure Machine Learning workspace default blob storage** from **Choose code location** dropdown.\\n        2. Under **Path to code file to upload**, select **Browse**.\\n        3. In the pop-up screen titled **Path selection**, select the path of code file `titanic.py` on the workspace default datastore `workspaceblobstore`.\\n        4. Select **Save**.\\n        5. Input `titanic.py` as the name of **Entry file** for the standalone job.\\n        6. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter **Input name** as `titanic_data`. The input should refer to this name later in the **Arguments**.\\n            2. Select **Input type** as **Data**.\\n            3. Select **Data type** as **File**.\\n            4. Select **Data source** as **URI**.\\n            5. Enter an Azure Data Lake Storage (ADLS) Gen 2 data URI for `titanic.csv` file in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here, `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        7.  To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter **Output name** as `wrangled_data`. The output should refer to this name later in the **Arguments**.\\n            2. Select **Output type** as **Folder**.\\n            3. For **Output URI destination**, enter an Azure Data Lake Storage (ADLS) Gen 2 folder URI in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        8.  Enter **Arguments**  as `--titanic_data ${{inputs.titanic_data}} --wrangled_data ${{outputs.wrangled_data}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** as 2 and executor **Memory (GB)** as 2.\\n            2. For **Dynamically allocated executors**, select **Disabled**.\\n            3. Enter the number of **Executor instances** as 2.\\n        2. For **Driver size**, enter number of driver **Cores** as 1 and driver **Memory (GB)** as 2.\\n    6. Select **Next**.\\n6. On the **Review** screen:\\n    1. Review the job specification before submitting it.\\n    2. Select **Create** to submit the standalone Spark job.\\n\\n\u003e [!NOTE]\\n\u003e A standalone job submitted from the Studio UI using an Azure Machine Learning serverless Spark compute defaults to user identity passthrough for data access.\\n\\n\\n---\\n\\n\u003e [!TIP]\\n\u003e You might have an existing Synapse Spark pool in your Azure Synapse workspace. To use an existing Synapse Spark pool, please follow the instructions to [attach a Synapse Spark pool in Azure Machine Learning workspace](.\/how-to-manage-synapse-spark-pool.md).\\n\\n## Next steps\\n- [Apache Spark in Azure Machine Learning](.\/apache-spark-azure-ml-concepts.md)\\n- [Quickstart: Interactive Data Wrangling with Apache Spark](.\/apache-spark-environment-configuration.md)\\n- [Attach and manage a Synapse Spark pool in Azure Machine Learning](.\/how-to-manage-synapse-spark-pool.md)\\n- [Interactive Data Wrangling with Apache Spark in Azure Machine Learning](.\/interactive-data-wrangling-with-apache-spark-azure-ml.md)\\n- [Submit Spark jobs in Azure Machine Learning](.\/how-to-submit-spark-jobs.md)\\n- [Code samples for Spark jobs using Azure Machine Learning CLI](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/cli\/jobs\/spark)\\nSource: quickstart-spark-jobs.md\\n\\nContent: # Submit Spark jobs in Azure Machine Learning\\n\\n6. To add any Jar file(s) that the standalone job requires at runtime, select **+ Add file** under **Jars** and input the name of the `.jar` file to be included in the Spark driver. Also, add the executor `CLASSPATH` for successful job execution. Multiple files can be added.\\n        7. To add archive(s) that should be extracted into the working directory of each executor for successful job execution, select **+ Add file** under **Archives**, and input the name of the archive. Multiple archives can be added.\\n        8. Adding **Py files**, **Jars**, and **Archives** is optional.\\n        9. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter an **Input name**. The input should refer to this name later in the **Arguments**.\\n            2. Select an **Input type**.\\n            3. For type **Data**:\\n                1. Select **Data type** as **File** or **Folder**.\\n                2. Select **Data source** as **Upload from local**, **URI**, or **Datastore**.\\n                    - For **Upload from local**, select **Browse** under **Path to upload**, to choose the input file or folder.\\n                    - For **URI**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI), or enter a data asset `azureml:\/\/`.\\n                    - For **Datastore**:\\n                        1. **Select a datastore** from the dropdown menu.\\n                        2. Under **Path to data**, select **Browse**.\\n                        3. In the pop-up screen titled **Path selection**, select the path of the code files on the workspace default blob storage.\\n                        4. Select **Save**.\\n            4. For type **Integer**, enter an integer value as **Input value**.\\n            5. For type **Number**, enter a numeric value as **Input value**.\\n            6. For type **Boolean**, select **True** or **False** as **Input value**.\\n            7. For type **String**, enter a string as **Input value**.\\n        10. To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter an **Output name**. The output should refer to this name later to in the **Arguments**.\\n            2. Select **Output type** as **File** or **Folder**.\\n            3. For **Output URI destination**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI) or enter a data asset `azureml:\/\/`.\\n        11. Enter **Arguments** by using the names defined in the **Input name** and **Output name** fields in the earlier steps, and the names of input and output arguments used in the Python script **Entry file**. For example, if the **Input name** and **Output name** are defined as `job_input` and `job_output`, and the arguments are added in the **Entry file** as shown here\\n\\n            ``` python\\n            import argparse\\n\\n            parser = argparse.ArgumentParser()\\n            parser.add_argument(\\\"--input_param\\\")\\n            parser.add_argument(\\\"--output_param\\\")\\n            ```\\n\\n    then enter **Arguments** as `--input_param ${{inputs.job_input}} --output_param ${{outputs.job_output}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** and executor **Memory (GB)**, in gigabytes.\\n            2. For **Dynamically allocated executors**, select the **Disabled** or **Enabled** option.\\n        - If dynamic allocation of executors is **Disabled**, enter the number of **Executor instances**.\\n        - If dynamic allocation of executors is **Enabled**, use the slider to select the minimum and maximum number of executors.\\n        1. For **Driver size**:\\n            1. Enter number of driver **Cores** and driver **Memory (GB)**, in gigabytes.\\n            2. Enter **Name** and **Value** pairs for any **Additional configurations**, then select **Add**. Providing **Additional configurations** is optional.\\n    6. Select **Next**.\\n7. On the **Review** screen:\\nSource: how-to-submit-spark-jobs.md\\n\\nContent: # Configure Apache Spark jobs in Azure Machine Learning\\n\\n- [Code samples for Spark jobs using Azure Machine Learning Python SDK](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/sdk\/python\/jobs\/spark)\\nSource: quickstart-spark-jobs.md\",\n  \"question\": \"how to create a spark job?\"\n}","output":"\"system: \\nYou are an AI assistant that helps users answer questions given a specific context and conversation history. You will be given a context and chat history, and then asked a question based on that context and history. Your answer should be as precise as possible, and should only come from the context.\\nPlease add citation after each sentence when possible in a form \\\"(Source: citation)\\\".\\n\\n user: \\n Content: # Configure Apache Spark jobs in Azure Machine Learning\\n\\n3. Under **Add tags**, provide **Name** and **Value**, then select **Add**. Adding tags is optional.\\n    4. Under the **Code** section:\\n        1. Select **Azure Machine Learning workspace default blob storage** from **Choose code location** dropdown.\\n        2. Under **Path to code file to upload**, select **Browse**.\\n        3. In the pop-up screen titled **Path selection**, select the path of code file `titanic.py` on the workspace default datastore `workspaceblobstore`.\\n        4. Select **Save**.\\n        5. Input `titanic.py` as the name of **Entry file** for the standalone job.\\n        6. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter **Input name** as `titanic_data`. The input should refer to this name later in the **Arguments**.\\n            2. Select **Input type** as **Data**.\\n            3. Select **Data type** as **File**.\\n            4. Select **Data source** as **URI**.\\n            5. Enter an Azure Data Lake Storage (ADLS) Gen 2 data URI for `titanic.csv` file in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here, `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        7.  To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter **Output name** as `wrangled_data`. The output should refer to this name later in the **Arguments**.\\n            2. Select **Output type** as **Folder**.\\n            3. For **Output URI destination**, enter an Azure Data Lake Storage (ADLS) Gen 2 folder URI in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        8.  Enter **Arguments**  as `--titanic_data ${{inputs.titanic_data}} --wrangled_data ${{outputs.wrangled_data}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** as 2 and executor **Memory (GB)** as 2.\\n            2. For **Dynamically allocated executors**, select **Disabled**.\\n            3. Enter the number of **Executor instances** as 2.\\n        2. For **Driver size**, enter number of driver **Cores** as 1 and driver **Memory (GB)** as 2.\\n    6. Select **Next**.\\n6. On the **Review** screen:\\n    1. Review the job specification before submitting it.\\n    2. Select **Create** to submit the standalone Spark job.\\n\\n\u003e [!NOTE]\\n\u003e A standalone job submitted from the Studio UI using an Azure Machine Learning serverless Spark compute defaults to user identity passthrough for data access.\\n\\n\\n---\\n\\n\u003e [!TIP]\\n\u003e You might have an existing Synapse Spark pool in your Azure Synapse workspace. To use an existing Synapse Spark pool, please follow the instructions to [attach a Synapse Spark pool in Azure Machine Learning workspace](.\/how-to-manage-synapse-spark-pool.md).\\n\\n## Next steps\\n- [Apache Spark in Azure Machine Learning](.\/apache-spark-azure-ml-concepts.md)\\n- [Quickstart: Interactive Data Wrangling with Apache Spark](.\/apache-spark-environment-configuration.md)\\n- [Attach and manage a Synapse Spark pool in Azure Machine Learning](.\/how-to-manage-synapse-spark-pool.md)\\n- [Interactive Data Wrangling with Apache Spark in Azure Machine Learning](.\/interactive-data-wrangling-with-apache-spark-azure-ml.md)\\n- [Submit Spark jobs in Azure Machine Learning](.\/how-to-submit-spark-jobs.md)\\n- [Code samples for Spark jobs using Azure Machine Learning CLI](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/cli\/jobs\/spark)\\nSource: quickstart-spark-jobs.md\\n\\nContent: # Submit Spark jobs in Azure Machine Learning\\n\\n6. To add any Jar file(s) that the standalone job requires at runtime, select **+ Add file** under **Jars** and input the name of the `.jar` file to be included in the Spark driver. Also, add the executor `CLASSPATH` for successful job execution. Multiple files can be added.\\n        7. To add archive(s) that should be extracted into the working directory of each executor for successful job execution, select **+ Add file** under **Archives**, and input the name of the archive. Multiple archives can be added.\\n        8. Adding **Py files**, **Jars**, and **Archives** is optional.\\n        9. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter an **Input name**. The input should refer to this name later in the **Arguments**.\\n            2. Select an **Input type**.\\n            3. For type **Data**:\\n                1. Select **Data type** as **File** or **Folder**.\\n                2. Select **Data source** as **Upload from local**, **URI**, or **Datastore**.\\n                    - For **Upload from local**, select **Browse** under **Path to upload**, to choose the input file or folder.\\n                    - For **URI**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI), or enter a data asset `azureml:\/\/`.\\n                    - For **Datastore**:\\n                        1. **Select a datastore** from the dropdown menu.\\n                        2. Under **Path to data**, select **Browse**.\\n                        3. In the pop-up screen titled **Path selection**, select the path of the code files on the workspace default blob storage.\\n                        4. Select **Save**.\\n            4. For type **Integer**, enter an integer value as **Input value**.\\n            5. For type **Number**, enter a numeric value as **Input value**.\\n            6. For type **Boolean**, select **True** or **False** as **Input value**.\\n            7. For type **String**, enter a string as **Input value**.\\n        10. To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter an **Output name**. The output should refer to this name later to in the **Arguments**.\\n            2. Select **Output type** as **File** or **Folder**.\\n            3. For **Output URI destination**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI) or enter a data asset `azureml:\/\/`.\\n        11. Enter **Arguments** by using the names defined in the **Input name** and **Output name** fields in the earlier steps, and the names of input and output arguments used in the Python script **Entry file**. For example, if the **Input name** and **Output name** are defined as `job_input` and `job_output`, and the arguments are added in the **Entry file** as shown here\\n\\n            ``` python\\n            import argparse\\n\\n            parser = argparse.ArgumentParser()\\n            parser.add_argument(\\\"--input_param\\\")\\n            parser.add_argument(\\\"--output_param\\\")\\n            ```\\n\\n    then enter **Arguments** as `--input_param ${{inputs.job_input}} --output_param ${{outputs.job_output}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** and executor **Memory (GB)**, in gigabytes.\\n            2. For **Dynamically allocated executors**, select the **Disabled** or **Enabled** option.\\n        - If dynamic allocation of executors is **Disabled**, enter the number of **Executor instances**.\\n        - If dynamic allocation of executors is **Enabled**, use the slider to select the minimum and maximum number of executors.\\n        1. For **Driver size**:\\n            1. Enter number of driver **Cores** and driver **Memory (GB)**, in gigabytes.\\n            2. Enter **Name** and **Value** pairs for any **Additional configurations**, then select **Add**. Providing **Additional configurations** is optional.\\n    6. Select **Next**.\\n7. On the **Review** screen:\\nSource: how-to-submit-spark-jobs.md\\n\\nContent: # Configure Apache Spark jobs in Azure Machine Learning\\n\\n- [Code samples for Spark jobs using Azure Machine Learning Python SDK](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/sdk\/python\/jobs\/spark)\\nSource: quickstart-spark-jobs.md \\n\\n chat history: \\n user: \\nwhat is aml? \\nassistant: \\n \\nuser: how to create a spark job? \\nassistant:\""},"events":[{"name":"promptflow.function.inputs","timestamp":"2024-04-11T18:07:30.331990Z","attributes":{"payload":"{\n  \"template\": \"system: \\nYou are an AI assistant that helps users answer questions given a specific context and conversation history. You will be given a context and chat history, and then asked a question based on that context and history. Your answer should be as precise as possible, and should only come from the context.\\nPlease add citation after each sentence when possible in a form \\\"(Source: citation)\\\".\\n\\n user: \\n {{contexts}} \\n\\n chat history: \\n{% for item in chat_history %} user: \\n{{ item.inputs.question }} \\nassistant: \\n{{ item.outputs.output }} \\n{% endfor %}\\nuser: {{question}} \\nassistant:\",\n  \"chat_history\": [\n    {\n      \"inputs\": {\n        \"question\": \"what is aml?\"\n      },\n      \"outputs\": {\n        \"answer\": \"Azure Machine Learning (AML) is a cloud service used for accelerating and managing the machine learning project lifecycle. It is designed for ML professionals, data scientists, and engineers to facilitate their daily workflows in training and deploying models and managing machine learning operations (MLOps). You can create models in AML or use models built from open-source platforms like PyTorch, TensorFlow, or scikit-learn. Furthermore, Azure Machine Learning provides tools for monitoring, retraining, and redeploying models(Source: overview-what-is-azure-machine-learning.md).\"\n      }\n    }\n  ],\n  \"contexts\": \"Content: # Configure Apache Spark jobs in Azure Machine Learning\\n\\n3. Under **Add tags**, provide **Name** and **Value**, then select **Add**. Adding tags is optional.\\n    4. Under the **Code** section:\\n        1. Select **Azure Machine Learning workspace default blob storage** from **Choose code location** dropdown.\\n        2. Under **Path to code file to upload**, select **Browse**.\\n        3. In the pop-up screen titled **Path selection**, select the path of code file `titanic.py` on the workspace default datastore `workspaceblobstore`.\\n        4. Select **Save**.\\n        5. Input `titanic.py` as the name of **Entry file** for the standalone job.\\n        6. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter **Input name** as `titanic_data`. The input should refer to this name later in the **Arguments**.\\n            2. Select **Input type** as **Data**.\\n            3. Select **Data type** as **File**.\\n            4. Select **Data source** as **URI**.\\n            5. Enter an Azure Data Lake Storage (ADLS) Gen 2 data URI for `titanic.csv` file in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here, `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        7.  To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter **Output name** as `wrangled_data`. The output should refer to this name later in the **Arguments**.\\n            2. Select **Output type** as **Folder**.\\n            3. For **Output URI destination**, enter an Azure Data Lake Storage (ADLS) Gen 2 folder URI in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        8.  Enter **Arguments**  as `--titanic_data ${{inputs.titanic_data}} --wrangled_data ${{outputs.wrangled_data}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** as 2 and executor **Memory (GB)** as 2.\\n            2. For **Dynamically allocated executors**, select **Disabled**.\\n            3. Enter the number of **Executor instances** as 2.\\n        2. For **Driver size**, enter number of driver **Cores** as 1 and driver **Memory (GB)** as 2.\\n    6. Select **Next**.\\n6. On the **Review** screen:\\n    1. Review the job specification before submitting it.\\n    2. Select **Create** to submit the standalone Spark job.\\n\\n\u003e [!NOTE]\\n\u003e A standalone job submitted from the Studio UI using an Azure Machine Learning serverless Spark compute defaults to user identity passthrough for data access.\\n\\n\\n---\\n\\n\u003e [!TIP]\\n\u003e You might have an existing Synapse Spark pool in your Azure Synapse workspace. To use an existing Synapse Spark pool, please follow the instructions to [attach a Synapse Spark pool in Azure Machine Learning workspace](.\/how-to-manage-synapse-spark-pool.md).\\n\\n## Next steps\\n- [Apache Spark in Azure Machine Learning](.\/apache-spark-azure-ml-concepts.md)\\n- [Quickstart: Interactive Data Wrangling with Apache Spark](.\/apache-spark-environment-configuration.md)\\n- [Attach and manage a Synapse Spark pool in Azure Machine Learning](.\/how-to-manage-synapse-spark-pool.md)\\n- [Interactive Data Wrangling with Apache Spark in Azure Machine Learning](.\/interactive-data-wrangling-with-apache-spark-azure-ml.md)\\n- [Submit Spark jobs in Azure Machine Learning](.\/how-to-submit-spark-jobs.md)\\n- [Code samples for Spark jobs using Azure Machine Learning CLI](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/cli\/jobs\/spark)\\nSource: quickstart-spark-jobs.md\\n\\nContent: # Submit Spark jobs in Azure Machine Learning\\n\\n6. To add any Jar file(s) that the standalone job requires at runtime, select **+ Add file** under **Jars** and input the name of the `.jar` file to be included in the Spark driver. Also, add the executor `CLASSPATH` for successful job execution. Multiple files can be added.\\n        7. To add archive(s) that should be extracted into the working directory of each executor for successful job execution, select **+ Add file** under **Archives**, and input the name of the archive. Multiple archives can be added.\\n        8. Adding **Py files**, **Jars**, and **Archives** is optional.\\n        9. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter an **Input name**. The input should refer to this name later in the **Arguments**.\\n            2. Select an **Input type**.\\n            3. For type **Data**:\\n                1. Select **Data type** as **File** or **Folder**.\\n                2. Select **Data source** as **Upload from local**, **URI**, or **Datastore**.\\n                    - For **Upload from local**, select **Browse** under **Path to upload**, to choose the input file or folder.\\n                    - For **URI**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI), or enter a data asset `azureml:\/\/`.\\n                    - For **Datastore**:\\n                        1. **Select a datastore** from the dropdown menu.\\n                        2. Under **Path to data**, select **Browse**.\\n                        3. In the pop-up screen titled **Path selection**, select the path of the code files on the workspace default blob storage.\\n                        4. Select **Save**.\\n            4. For type **Integer**, enter an integer value as **Input value**.\\n            5. For type **Number**, enter a numeric value as **Input value**.\\n            6. For type **Boolean**, select **True** or **False** as **Input value**.\\n            7. For type **String**, enter a string as **Input value**.\\n        10. To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter an **Output name**. The output should refer to this name later to in the **Arguments**.\\n            2. Select **Output type** as **File** or **Folder**.\\n            3. For **Output URI destination**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI) or enter a data asset `azureml:\/\/`.\\n        11. Enter **Arguments** by using the names defined in the **Input name** and **Output name** fields in the earlier steps, and the names of input and output arguments used in the Python script **Entry file**. For example, if the **Input name** and **Output name** are defined as `job_input` and `job_output`, and the arguments are added in the **Entry file** as shown here\\n\\n            ``` python\\n            import argparse\\n\\n            parser = argparse.ArgumentParser()\\n            parser.add_argument(\\\"--input_param\\\")\\n            parser.add_argument(\\\"--output_param\\\")\\n            ```\\n\\n    then enter **Arguments** as `--input_param ${{inputs.job_input}} --output_param ${{outputs.job_output}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** and executor **Memory (GB)**, in gigabytes.\\n            2. For **Dynamically allocated executors**, select the **Disabled** or **Enabled** option.\\n        - If dynamic allocation of executors is **Disabled**, enter the number of **Executor instances**.\\n        - If dynamic allocation of executors is **Enabled**, use the slider to select the minimum and maximum number of executors.\\n        1. For **Driver size**:\\n            1. Enter number of driver **Cores** and driver **Memory (GB)**, in gigabytes.\\n            2. Enter **Name** and **Value** pairs for any **Additional configurations**, then select **Add**. Providing **Additional configurations** is optional.\\n    6. Select **Next**.\\n7. On the **Review** screen:\\nSource: how-to-submit-spark-jobs.md\\n\\nContent: # Configure Apache Spark jobs in Azure Machine Learning\\n\\n- [Code samples for Spark jobs using Azure Machine Learning Python SDK](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/sdk\/python\/jobs\/spark)\\nSource: quickstart-spark-jobs.md\",\n  \"question\": \"how to create a spark job?\"\n}"}},{"name":"promptflow.function.output","timestamp":"2024-04-11T18:07:30.334225Z","attributes":{"payload":"\"system: \\nYou are an AI assistant that helps users answer questions given a specific context and conversation history. You will be given a context and chat history, and then asked a question based on that context and history. Your answer should be as precise as possible, and should only come from the context.\\nPlease add citation after each sentence when possible in a form \\\"(Source: citation)\\\".\\n\\n user: \\n Content: # Configure Apache Spark jobs in Azure Machine Learning\\n\\n3. Under **Add tags**, provide **Name** and **Value**, then select **Add**. Adding tags is optional.\\n    4. Under the **Code** section:\\n        1. Select **Azure Machine Learning workspace default blob storage** from **Choose code location** dropdown.\\n        2. Under **Path to code file to upload**, select **Browse**.\\n        3. In the pop-up screen titled **Path selection**, select the path of code file `titanic.py` on the workspace default datastore `workspaceblobstore`.\\n        4. Select **Save**.\\n        5. Input `titanic.py` as the name of **Entry file** for the standalone job.\\n        6. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter **Input name** as `titanic_data`. The input should refer to this name later in the **Arguments**.\\n            2. Select **Input type** as **Data**.\\n            3. Select **Data type** as **File**.\\n            4. Select **Data source** as **URI**.\\n            5. Enter an Azure Data Lake Storage (ADLS) Gen 2 data URI for `titanic.csv` file in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here, `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        7.  To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter **Output name** as `wrangled_data`. The output should refer to this name later in the **Arguments**.\\n            2. Select **Output type** as **Folder**.\\n            3. For **Output URI destination**, enter an Azure Data Lake Storage (ADLS) Gen 2 folder URI in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        8.  Enter **Arguments**  as `--titanic_data ${{inputs.titanic_data}} --wrangled_data ${{outputs.wrangled_data}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** as 2 and executor **Memory (GB)** as 2.\\n            2. For **Dynamically allocated executors**, select **Disabled**.\\n            3. Enter the number of **Executor instances** as 2.\\n        2. For **Driver size**, enter number of driver **Cores** as 1 and driver **Memory (GB)** as 2.\\n    6. Select **Next**.\\n6. On the **Review** screen:\\n    1. Review the job specification before submitting it.\\n    2. Select **Create** to submit the standalone Spark job.\\n\\n\u003e [!NOTE]\\n\u003e A standalone job submitted from the Studio UI using an Azure Machine Learning serverless Spark compute defaults to user identity passthrough for data access.\\n\\n\\n---\\n\\n\u003e [!TIP]\\n\u003e You might have an existing Synapse Spark pool in your Azure Synapse workspace. To use an existing Synapse Spark pool, please follow the instructions to [attach a Synapse Spark pool in Azure Machine Learning workspace](.\/how-to-manage-synapse-spark-pool.md).\\n\\n## Next steps\\n- [Apache Spark in Azure Machine Learning](.\/apache-spark-azure-ml-concepts.md)\\n- [Quickstart: Interactive Data Wrangling with Apache Spark](.\/apache-spark-environment-configuration.md)\\n- [Attach and manage a Synapse Spark pool in Azure Machine Learning](.\/how-to-manage-synapse-spark-pool.md)\\n- [Interactive Data Wrangling with Apache Spark in Azure Machine Learning](.\/interactive-data-wrangling-with-apache-spark-azure-ml.md)\\n- [Submit Spark jobs in Azure Machine Learning](.\/how-to-submit-spark-jobs.md)\\n- [Code samples for Spark jobs using Azure Machine Learning CLI](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/cli\/jobs\/spark)\\nSource: quickstart-spark-jobs.md\\n\\nContent: # Submit Spark jobs in Azure Machine Learning\\n\\n6. To add any Jar file(s) that the standalone job requires at runtime, select **+ Add file** under **Jars** and input the name of the `.jar` file to be included in the Spark driver. Also, add the executor `CLASSPATH` for successful job execution. Multiple files can be added.\\n        7. To add archive(s) that should be extracted into the working directory of each executor for successful job execution, select **+ Add file** under **Archives**, and input the name of the archive. Multiple archives can be added.\\n        8. Adding **Py files**, **Jars**, and **Archives** is optional.\\n        9. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter an **Input name**. The input should refer to this name later in the **Arguments**.\\n            2. Select an **Input type**.\\n            3. For type **Data**:\\n                1. Select **Data type** as **File** or **Folder**.\\n                2. Select **Data source** as **Upload from local**, **URI**, or **Datastore**.\\n                    - For **Upload from local**, select **Browse** under **Path to upload**, to choose the input file or folder.\\n                    - For **URI**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI), or enter a data asset `azureml:\/\/`.\\n                    - For **Datastore**:\\n                        1. **Select a datastore** from the dropdown menu.\\n                        2. Under **Path to data**, select **Browse**.\\n                        3. In the pop-up screen titled **Path selection**, select the path of the code files on the workspace default blob storage.\\n                        4. Select **Save**.\\n            4. For type **Integer**, enter an integer value as **Input value**.\\n            5. For type **Number**, enter a numeric value as **Input value**.\\n            6. For type **Boolean**, select **True** or **False** as **Input value**.\\n            7. For type **String**, enter a string as **Input value**.\\n        10. To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter an **Output name**. The output should refer to this name later to in the **Arguments**.\\n            2. Select **Output type** as **File** or **Folder**.\\n            3. For **Output URI destination**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI) or enter a data asset `azureml:\/\/`.\\n        11. Enter **Arguments** by using the names defined in the **Input name** and **Output name** fields in the earlier steps, and the names of input and output arguments used in the Python script **Entry file**. For example, if the **Input name** and **Output name** are defined as `job_input` and `job_output`, and the arguments are added in the **Entry file** as shown here\\n\\n            ``` python\\n            import argparse\\n\\n            parser = argparse.ArgumentParser()\\n            parser.add_argument(\\\"--input_param\\\")\\n            parser.add_argument(\\\"--output_param\\\")\\n            ```\\n\\n    then enter **Arguments** as `--input_param ${{inputs.job_input}} --output_param ${{outputs.job_output}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** and executor **Memory (GB)**, in gigabytes.\\n            2. For **Dynamically allocated executors**, select the **Disabled** or **Enabled** option.\\n        - If dynamic allocation of executors is **Disabled**, enter the number of **Executor instances**.\\n        - If dynamic allocation of executors is **Enabled**, use the slider to select the minimum and maximum number of executors.\\n        1. For **Driver size**:\\n            1. Enter number of driver **Cores** and driver **Memory (GB)**, in gigabytes.\\n            2. Enter **Name** and **Value** pairs for any **Additional configurations**, then select **Add**. Providing **Additional configurations** is optional.\\n    6. Select **Next**.\\n7. On the **Review** screen:\\nSource: how-to-submit-spark-jobs.md\\n\\nContent: # Configure Apache Spark jobs in Azure Machine Learning\\n\\n- [Code samples for Spark jobs using Azure Machine Learning Python SDK](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/sdk\/python\/jobs\/spark)\\nSource: quickstart-spark-jobs.md \\n\\n chat history: \\n user: \\nwhat is aml? \\nassistant: \\n \\nuser: how to create a spark job? \\nassistant:\""}}],"links":[],"resource":{"attributes":{"service.name":"promptflow"},"schema_url":""}}],"contentrange":"bytes 0-37455/37456","correlationid":"a50b60ae-5c3e-4742-a36b-abbe42d97d34","xrequestid":"a50b60ae-5c3e-4742-a36b-abbe42d97d34","modelversion":"default","collectdatatype":"pandas.core.frame.DataFrame","agent":"azureml-ai-monitoring/0.1.0b4"}
{"specversion":"1.0","id":"077f09c3-953b-4ccc-9558-46ee517db8f7","source":"/subscriptions/1aefdc5e-3a7c-4d71-a9f9-f5d3b03be19a/resourceGroups/yuachengtestrg/providers/Microsoft.MachineLearningServices/workspaces/ai-proj-eastus/onlineEndpoints/clone-vivi-log-test/deployments/clone-vivi-log-test-1","type":"azureml.inference.app_traces","datacontenttype":"application/json","time":"2024-04-11T18:07:31Z","data":[{"name":"search","context":{"trace_id":"0xa2f3f4f8267a482fa3bb96ad3e1f7f35","span_id":"0x25f14e486ecbdcb7","trace_state":"[]"},"kind":"SpanKind.INTERNAL","parent_id":"0x74dcae90ed4c9542","start_time":"2024-04-11T18:07:28.355535Z","end_time":"2024-04-11T18:07:30.249003Z","status":{"status_code":"UNSET"},"attributes":{"span_type":"Retrieval","retrieval.query":"What are the steps to create a Spark job?","retrieval.documents":"[{\"document.content\": \"# Configure Apache Spark jobs in Azure Machine Learning\\n\\n3. Under **Add tags**, provide **Name** and **Value**, then select **Add**. Adding tags is optional.\\n    4. Under the **Code** section:\\n        1. Select **Azure Machine Learning workspace default blob storage** from **Choose code location** dropdown.\\n        2. Under **Path to code file to upload**, select **Browse**.\\n        3. In the pop-up screen titled **Path selection**, select the path of code file `titanic.py` on the workspace default datastore `workspaceblobstore`.\\n        4. Select **Save**.\\n        5. Input `titanic.py` as the name of **Entry file** for the standalone job.\\n        6. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter **Input name** as `titanic_data`. The input should refer to this name later in the **Arguments**.\\n            2. Select **Input type** as **Data**.\\n            3. Select **Data type** as **File**.\\n            4. Select **Data source** as **URI**.\\n            5. Enter an Azure Data Lake Storage (ADLS) Gen 2 data URI for `titanic.csv` file in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here, `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        7.  To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter **Output name** as `wrangled_data`. The output should refer to this name later in the **Arguments**.\\n            2. Select **Output type** as **Folder**.\\n            3. For **Output URI destination**, enter an Azure Data Lake Storage (ADLS) Gen 2 folder URI in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        8.  Enter **Arguments**  as `--titanic_data ${{inputs.titanic_data}} --wrangled_data ${{outputs.wrangled_data}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** as 2 and executor **Memory (GB)** as 2.\\n            2. For **Dynamically allocated executors**, select **Disabled**.\\n            3. Enter the number of **Executor instances** as 2.\\n        2. For **Driver size**, enter number of driver **Cores** as 1 and driver **Memory (GB)** as 2.\\n    6. Select **Next**.\\n6. On the **Review** screen:\\n    1. Review the job specification before submitting it.\\n    2. Select **Create** to submit the standalone Spark job.\\n\\n\u003e [!NOTE]\\n\u003e A standalone job submitted from the Studio UI using an Azure Machine Learning serverless Spark compute defaults to user identity passthrough for data access.\\n\\n\\n---\\n\\n\u003e [!TIP]\\n\u003e You might have an existing Synapse Spark pool in your Azure Synapse workspace. To use an existing Synapse Spark pool, please follow the instructions to [attach a Synapse Spark pool in Azure Machine Learning workspace](.\/how-to-manage-synapse-spark-pool.md).\\n\\n## Next steps\\n- [Apache Spark in Azure Machine Learning](.\/apache-spark-azure-ml-concepts.md)\\n- [Quickstart: Interactive Data Wrangling with Apache Spark](.\/apache-spark-environment-configuration.md)\\n- [Attach and manage a Synapse Spark pool in Azure Machine Learning](.\/how-to-manage-synapse-spark-pool.md)\\n- [Interactive Data Wrangling with Apache Spark in Azure Machine Learning](.\/interactive-data-wrangling-with-apache-spark-azure-ml.md)\\n- [Submit Spark jobs in Azure Machine Learning](.\/how-to-submit-spark-jobs.md)\\n- [Code samples for Spark jobs using Azure Machine Learning CLI](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/cli\/jobs\/spark)\", \"document.score\": 0.030751174315810204, \"document.metadata\": {\"id\": \"cXVpY2tzdGFydC1zcGFyay1qb2JzLm1kNA==\", \"source\": {\"title\": \"Configure Apache Spark jobs in Azure Machine Learning\", \"filename\": \"quickstart-spark-jobs.md\", \"url\": \"quickstart-spark-jobs.md\", \"mtime\": 1710206171.0}, \"stats\": {\"tiktokens\": 901, \"chars\": 3569, \"lines\": 47}, \"content_hash\": \"180236985807e2fb8630996332b1ac47df8c1aa7eda985ecb895df59c6ad2ec7\"}}, {\"document.content\": \"# Submit Spark jobs in Azure Machine Learning\\n\\n6. To add any Jar file(s) that the standalone job requires at runtime, select **+ Add file** under **Jars** and input the name of the `.jar` file to be included in the Spark driver. Also, add the executor `CLASSPATH` for successful job execution. Multiple files can be added.\\n        7. To add archive(s) that should be extracted into the working directory of each executor for successful job execution, select **+ Add file** under **Archives**, and input the name of the archive. Multiple archives can be added.\\n        8. Adding **Py files**, **Jars**, and **Archives** is optional.\\n        9. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter an **Input name**. The input should refer to this name later in the **Arguments**.\\n            2. Select an **Input type**.\\n            3. For type **Data**:\\n                1. Select **Data type** as **File** or **Folder**.\\n                2. Select **Data source** as **Upload from local**, **URI**, or **Datastore**.\\n                    - For **Upload from local**, select **Browse** under **Path to upload**, to choose the input file or folder.\\n                    - For **URI**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI), or enter a data asset `azureml:\/\/`.\\n                    - For **Datastore**:\\n                        1. **Select a datastore** from the dropdown menu.\\n                        2. Under **Path to data**, select **Browse**.\\n                        3. In the pop-up screen titled **Path selection**, select the path of the code files on the workspace default blob storage.\\n                        4. Select **Save**.\\n            4. For type **Integer**, enter an integer value as **Input value**.\\n            5. For type **Number**, enter a numeric value as **Input value**.\\n            6. For type **Boolean**, select **True** or **False** as **Input value**.\\n            7. For type **String**, enter a string as **Input value**.\\n        10. To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter an **Output name**. The output should refer to this name later to in the **Arguments**.\\n            2. Select **Output type** as **File** or **Folder**.\\n            3. For **Output URI destination**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI) or enter a data asset `azureml:\/\/`.\\n        11. Enter **Arguments** by using the names defined in the **Input name** and **Output name** fields in the earlier steps, and the names of input and output arguments used in the Python script **Entry file**. For example, if the **Input name** and **Output name** are defined as `job_input` and `job_output`, and the arguments are added in the **Entry file** as shown here\\n\\n            ``` python\\n            import argparse\\n\\n            parser = argparse.ArgumentParser()\\n            parser.add_argument(\\\"--input_param\\\")\\n            parser.add_argument(\\\"--output_param\\\")\\n            ```\\n\\n    then enter **Arguments** as `--input_param ${{inputs.job_input}} --output_param ${{outputs.job_output}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** and executor **Memory (GB)**, in gigabytes.\\n            2. For **Dynamically allocated executors**, select the **Disabled** or **Enabled** option.\\n        - If dynamic allocation of executors is **Disabled**, enter the number of **Executor instances**.\\n        - If dynamic allocation of executors is **Enabled**, use the slider to select the minimum and maximum number of executors.\\n        1. For **Driver size**:\\n            1. Enter number of driver **Cores** and driver **Memory (GB)**, in gigabytes.\\n            2. Enter **Name** and **Value** pairs for any **Additional configurations**, then select **Add**. Providing **Additional configurations** is optional.\\n    6. Select **Next**.\\n7. On the **Review** screen:\", \"document.score\": 0.025739235803484917, \"document.metadata\": {\"id\": \"aG93LXRvLXN1Ym1pdC1zcGFyay1qb2JzLm1kNw==\", \"source\": {\"title\": \"Submit Spark jobs in Azure Machine Learning\", \"filename\": \"how-to-submit-spark-jobs.md\", \"url\": \"how-to-submit-spark-jobs.md\", \"mtime\": 1710206154.0}, \"stats\": {\"tiktokens\": 933, \"chars\": 3974, \"lines\": 48}, \"content_hash\": \"4d20509f3e7b887d13bf41c0ef760f486cc1b45615c33bca6825cd23643bd058\"}}, {\"document.content\": \"# Configure Apache Spark jobs in Azure Machine Learning\\n\\n- [Code samples for Spark jobs using Azure Machine Learning Python SDK](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/sdk\/python\/jobs\/spark)\", \"document.score\": 0.02253928780555725, \"document.metadata\": {\"id\": \"cXVpY2tzdGFydC1zcGFyay1qb2JzLm1kNQ==\", \"source\": {\"title\": \"Configure Apache Spark jobs in Azure Machine Learning\", \"filename\": \"quickstart-spark-jobs.md\", \"url\": \"quickstart-spark-jobs.md\", \"mtime\": 1710206171.0}, \"stats\": {\"tiktokens\": 44, \"chars\": 203, \"lines\": 3}, \"content_hash\": \"9c6e5e25028d10af22f711dfc932d1c762f186375243340e341c3fe22463cf50\"}}]"},"events":[],"links":[],"resource":{"attributes":{"service.name":"promptflow"},"schema_url":""}}],"contentrange":"bytes 0-9989/9990","correlationid":"b000ea0d-ba01-4fa7-8b88-09390486d1d6","xrequestid":"b000ea0d-ba01-4fa7-8b88-09390486d1d6","agent":"azureml-ai-monitoring/0.1.0b4","modelversion":"default","collectdatatype":"pandas.core.frame.DataFrame"}
{"specversion":"1.0","id":"6c24e9b2-3624-4bbc-882c-455e2a27e31e","source":"/subscriptions/1aefdc5e-3a7c-4d71-a9f9-f5d3b03be19a/resourceGroups/yuachengtestrg/providers/Microsoft.MachineLearningServices/workspaces/ai-proj-eastus/onlineEndpoints/clone-vivi-log-test/deployments/clone-vivi-log-test-1","type":"azureml.inference.app_traces","datacontenttype":"application/json","time":"2024-04-11T18:07:51Z","data":[{"name":"openai_chat","context":{"trace_id":"0xa2f3f4f8267a482fa3bb96ad3e1f7f35","span_id":"0x75eedfd7f356d2cc","trace_state":"[]"},"kind":"SpanKind.INTERNAL","parent_id":"0x8fd94b3d721108ea","start_time":"2024-04-11T18:07:30.340535Z","end_time":"2024-04-11T18:07:46.727149Z","status":{"status_code":"OK"},"attributes":{"framework":"promptflow","span_type":"LLM","function":"openai.resources.chat.completions.Completions.create","node_name":"answer_the_question_with_context","request_id":"ee2f5c78-77c1-4766-802d-49aa4b354ec3","line_run_id":"ee2f5c78-77c1-4766-802d-49aa4b354ec3","inputs":"{\n  \"model\": \"gpt-4-32k\",\n  \"messages\": [\n    {\n      \"role\": \"system\",\n      \"content\": \"You are an AI assistant that helps users answer questions given a specific context and conversation history. You will be given a context and chat history, and then asked a question based on that context and history. Your answer should be as precise as possible, and should only come from the context.\\nPlease add citation after each sentence when possible in a form \\\"(Source: citation)\\\".\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"Content: # Configure Apache Spark jobs in Azure Machine Learning\\n\\n3. Under **Add tags**, provide **Name** and **Value**, then select **Add**. Adding tags is optional.\\n    4. Under the **Code** section:\\n        1. Select **Azure Machine Learning workspace default blob storage** from **Choose code location** dropdown.\\n        2. Under **Path to code file to upload**, select **Browse**.\\n        3. In the pop-up screen titled **Path selection**, select the path of code file `titanic.py` on the workspace default datastore `workspaceblobstore`.\\n        4. Select **Save**.\\n        5. Input `titanic.py` as the name of **Entry file** for the standalone job.\\n        6. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter **Input name** as `titanic_data`. The input should refer to this name later in the **Arguments**.\\n            2. Select **Input type** as **Data**.\\n            3. Select **Data type** as **File**.\\n            4. Select **Data source** as **URI**.\\n            5. Enter an Azure Data Lake Storage (ADLS) Gen 2 data URI for `titanic.csv` file in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here, `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        7.  To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter **Output name** as `wrangled_data`. The output should refer to this name later in the **Arguments**.\\n            2. Select **Output type** as **Folder**.\\n            3. For **Output URI destination**, enter an Azure Data Lake Storage (ADLS) Gen 2 folder URI in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        8.  Enter **Arguments**  as `--titanic_data ${{inputs.titanic_data}} --wrangled_data ${{outputs.wrangled_data}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** as 2 and executor **Memory (GB)** as 2.\\n            2. For **Dynamically allocated executors**, select **Disabled**.\\n            3. Enter the number of **Executor instances** as 2.\\n        2. For **Driver size**, enter number of driver **Cores** as 1 and driver **Memory (GB)** as 2.\\n    6. Select **Next**.\\n6. On the **Review** screen:\\n    1. Review the job specification before submitting it.\\n    2. Select **Create** to submit the standalone Spark job.\\n\\n\u003e [!NOTE]\\n\u003e A standalone job submitted from the Studio UI using an Azure Machine Learning serverless Spark compute defaults to user identity passthrough for data access.\\n\\n\\n---\\n\\n\u003e [!TIP]\\n\u003e You might have an existing Synapse Spark pool in your Azure Synapse workspace. To use an existing Synapse Spark pool, please follow the instructions to [attach a Synapse Spark pool in Azure Machine Learning workspace](.\/how-to-manage-synapse-spark-pool.md).\\n\\n## Next steps\\n- [Apache Spark in Azure Machine Learning](.\/apache-spark-azure-ml-concepts.md)\\n- [Quickstart: Interactive Data Wrangling with Apache Spark](.\/apache-spark-environment-configuration.md)\\n- [Attach and manage a Synapse Spark pool in Azure Machine Learning](.\/how-to-manage-synapse-spark-pool.md)\\n- [Interactive Data Wrangling with Apache Spark in Azure Machine Learning](.\/interactive-data-wrangling-with-apache-spark-azure-ml.md)\\n- [Submit Spark jobs in Azure Machine Learning](.\/how-to-submit-spark-jobs.md)\\n- [Code samples for Spark jobs using Azure Machine Learning CLI](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/cli\/jobs\/spark)\\nSource: quickstart-spark-jobs.md\\n\\nContent: # Submit Spark jobs in Azure Machine Learning\\n\\n6. To add any Jar file(s) that the standalone job requires at runtime, select **+ Add file** under **Jars** and input the name of the `.jar` file to be included in the Spark driver. Also, add the executor `CLASSPATH` for successful job execution. Multiple files can be added.\\n        7. To add archive(s) that should be extracted into the working directory of each executor for successful job execution, select **+ Add file** under **Archives**, and input the name of the archive. Multiple archives can be added.\\n        8. Adding **Py files**, **Jars**, and **Archives** is optional.\\n        9. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter an **Input name**. The input should refer to this name later in the **Arguments**.\\n            2. Select an **Input type**.\\n            3. For type **Data**:\\n                1. Select **Data type** as **File** or **Folder**.\\n                2. Select **Data source** as **Upload from local**, **URI**, or **Datastore**.\\n                    - For **Upload from local**, select **Browse** under **Path to upload**, to choose the input file or folder.\\n                    - For **URI**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI), or enter a data asset `azureml:\/\/`.\\n                    - For **Datastore**:\\n                        1. **Select a datastore** from the dropdown menu.\\n                        2. Under **Path to data**, select **Browse**.\\n                        3. In the pop-up screen titled **Path selection**, select the path of the code files on the workspace default blob storage.\\n                        4. Select **Save**.\\n            4. For type **Integer**, enter an integer value as **Input value**.\\n            5. For type **Number**, enter a numeric value as **Input value**.\\n            6. For type **Boolean**, select **True** or **False** as **Input value**.\\n            7. For type **String**, enter a string as **Input value**.\\n        10. To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter an **Output name**. The output should refer to this name later to in the **Arguments**.\\n            2. Select **Output type** as **File** or **Folder**.\\n            3. For **Output URI destination**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI) or enter a data asset `azureml:\/\/`.\\n        11. Enter **Arguments** by using the names defined in the **Input name** and **Output name** fields in the earlier steps, and the names of input and output arguments used in the Python script **Entry file**. For example, if the **Input name** and **Output name** are defined as `job_input` and `job_output`, and the arguments are added in the **Entry file** as shown here\\n\\n            ``` python\\n            import argparse\\n\\n            parser = argparse.ArgumentParser()\\n            parser.add_argument(\\\"--input_param\\\")\\n            parser.add_argument(\\\"--output_param\\\")\\n            ```\\n\\n    then enter **Arguments** as `--input_param ${{inputs.job_input}} --output_param ${{outputs.job_output}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** and executor **Memory (GB)**, in gigabytes.\\n            2. For **Dynamically allocated executors**, select the **Disabled** or **Enabled** option.\\n        - If dynamic allocation of executors is **Disabled**, enter the number of **Executor instances**.\\n        - If dynamic allocation of executors is **Enabled**, use the slider to select the minimum and maximum number of executors.\\n        1. For **Driver size**:\\n            1. Enter number of driver **Cores** and driver **Memory (GB)**, in gigabytes.\\n            2. Enter **Name** and **Value** pairs for any **Additional configurations**, then select **Add**. Providing **Additional configurations** is optional.\\n    6. Select **Next**.\\n7. On the **Review** screen:\\nSource: how-to-submit-spark-jobs.md\\n\\nContent: # Configure Apache Spark jobs in Azure Machine Learning\\n\\n- [Code samples for Spark jobs using Azure Machine Learning Python SDK](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/sdk\/python\/jobs\/spark)\\nSource: quickstart-spark-jobs.md \\n\\n chat history:\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"what is aml?\"\n    },\n    {\n      \"role\": \"assistant\",\n      \"content\": \"user: how to create a spark job? \\nassistant:\"\n    }\n  ],\n  \"temperature\": 1.0,\n  \"top_p\": 1.0,\n  \"n\": 1,\n  \"stream\": false,\n  \"presence_penalty\": 0.0,\n  \"frequency_penalty\": 0.0,\n  \"user\": \"\"\n}","llm.response.model":"gpt-4-32k","llm.generated_message":"{\n  \"content\": \"To create a Spark job in Azure Machine Learning, you need to firstly provide a Name and optionally a Value under the **Add tags**. Then in the **Code** section, you need to choose the workspace's default blob storage for code location and select the path of the code file to upload. You then need to input the name of the `titanic.py` as the **Entry file**. \\n\\nNext, you add an input by selecting **+ Add input** under **Inputs** and filling up required fields such as **Input name**, **Input type**, and **Data type**. Similarly, you add an output by selecting **+ Add output** under **Outputs** and entering required information. \\n\\nThen you need to enter **Arguments** for the job. \\n\\nIn the **Spark configurations** section, you can configure parameters such as number of executor cores, memory, and instances. Similarly, configure the driver size. Then, you can add any additional optional configurations. \\n\\nOnce everything is set up, you can review the job specifications and select **Create** to submit the standalone Spark job (Source: quickstart-spark-jobs.md).\\n\\nBear in mind that you have the option to add any necessary Jar files, Py files or Archives for the job under the respective sections (Source: how-to-submit-spark-jobs.md). Also, please note that the job submitted defaults to user identity passthrough for data access (Source: quickstart-spark-jobs.md).\\n\",\n  \"role\": \"assistant\",\n  \"function_call\": null,\n  \"tool_calls\": null\n}","__computed__.cumulative_token_count.completion":299,"__computed__.cumulative_token_count.prompt":2027,"__computed__.cumulative_token_count.total":2326,"llm.usage.completion_tokens":299,"llm.usage.prompt_tokens":2027,"llm.usage.total_tokens":2326,"output":"{\n  \"id\": \"chatcmpl-9Ct7bms0phqmD3aMhcRykATBNYjyw\",\n  \"choices\": [\n    {\n      \"finish_reason\": \"stop\",\n      \"index\": 0,\n      \"logprobs\": null,\n      \"message\": {\n        \"content\": \"To create a Spark job in Azure Machine Learning, you need to firstly provide a Name and optionally a Value under the **Add tags**. Then in the **Code** section, you need to choose the workspace's default blob storage for code location and select the path of the code file to upload. You then need to input the name of the `titanic.py` as the **Entry file**. \\n\\nNext, you add an input by selecting **+ Add input** under **Inputs** and filling up required fields such as **Input name**, **Input type**, and **Data type**. Similarly, you add an output by selecting **+ Add output** under **Outputs** and entering required information. \\n\\nThen you need to enter **Arguments** for the job. \\n\\nIn the **Spark configurations** section, you can configure parameters such as number of executor cores, memory, and instances. Similarly, configure the driver size. Then, you can add any additional optional configurations. \\n\\nOnce everything is set up, you can review the job specifications and select **Create** to submit the standalone Spark job (Source: quickstart-spark-jobs.md).\\n\\nBear in mind that you have the option to add any necessary Jar files, Py files or Archives for the job under the respective sections (Source: how-to-submit-spark-jobs.md). Also, please note that the job submitted defaults to user identity passthrough for data access (Source: quickstart-spark-jobs.md).\\n\",\n        \"role\": \"assistant\",\n        \"function_call\": null,\n        \"tool_calls\": null\n      },\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ],\n  \"created\": 1712858851,\n  \"model\": \"gpt-4-32k\",\n  \"object\": \"chat.completion\",\n  \"system_fingerprint\": null,\n  \"usage\": {\n    \"completion_tokens\": 299,\n    \"prompt_tokens\": 2027,\n    \"total_tokens\": 2326\n  },\n  \"prompt_filter_results\": [\n    {\n      \"prompt_index\": 0,\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ]\n}"},"events":[{"name":"promptflow.function.inputs","timestamp":"2024-04-11T18:07:30.342499Z","attributes":{"payload":"{\n  \"model\": \"gpt-4-32k\",\n  \"messages\": [\n    {\n      \"role\": \"system\",\n      \"content\": \"You are an AI assistant that helps users answer questions given a specific context and conversation history. You will be given a context and chat history, and then asked a question based on that context and history. Your answer should be as precise as possible, and should only come from the context.\\nPlease add citation after each sentence when possible in a form \\\"(Source: citation)\\\".\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"Content: # Configure Apache Spark jobs in Azure Machine Learning\\n\\n3. Under **Add tags**, provide **Name** and **Value**, then select **Add**. Adding tags is optional.\\n    4. Under the **Code** section:\\n        1. Select **Azure Machine Learning workspace default blob storage** from **Choose code location** dropdown.\\n        2. Under **Path to code file to upload**, select **Browse**.\\n        3. In the pop-up screen titled **Path selection**, select the path of code file `titanic.py` on the workspace default datastore `workspaceblobstore`.\\n        4. Select **Save**.\\n        5. Input `titanic.py` as the name of **Entry file** for the standalone job.\\n        6. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter **Input name** as `titanic_data`. The input should refer to this name later in the **Arguments**.\\n            2. Select **Input type** as **Data**.\\n            3. Select **Data type** as **File**.\\n            4. Select **Data source** as **URI**.\\n            5. Enter an Azure Data Lake Storage (ADLS) Gen 2 data URI for `titanic.csv` file in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here, `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        7.  To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter **Output name** as `wrangled_data`. The output should refer to this name later in the **Arguments**.\\n            2. Select **Output type** as **Folder**.\\n            3. For **Output URI destination**, enter an Azure Data Lake Storage (ADLS) Gen 2 folder URI in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        8.  Enter **Arguments**  as `--titanic_data ${{inputs.titanic_data}} --wrangled_data ${{outputs.wrangled_data}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** as 2 and executor **Memory (GB)** as 2.\\n            2. For **Dynamically allocated executors**, select **Disabled**.\\n            3. Enter the number of **Executor instances** as 2.\\n        2. For **Driver size**, enter number of driver **Cores** as 1 and driver **Memory (GB)** as 2.\\n    6. Select **Next**.\\n6. On the **Review** screen:\\n    1. Review the job specification before submitting it.\\n    2. Select **Create** to submit the standalone Spark job.\\n\\n\u003e [!NOTE]\\n\u003e A standalone job submitted from the Studio UI using an Azure Machine Learning serverless Spark compute defaults to user identity passthrough for data access.\\n\\n\\n---\\n\\n\u003e [!TIP]\\n\u003e You might have an existing Synapse Spark pool in your Azure Synapse workspace. To use an existing Synapse Spark pool, please follow the instructions to [attach a Synapse Spark pool in Azure Machine Learning workspace](.\/how-to-manage-synapse-spark-pool.md).\\n\\n## Next steps\\n- [Apache Spark in Azure Machine Learning](.\/apache-spark-azure-ml-concepts.md)\\n- [Quickstart: Interactive Data Wrangling with Apache Spark](.\/apache-spark-environment-configuration.md)\\n- [Attach and manage a Synapse Spark pool in Azure Machine Learning](.\/how-to-manage-synapse-spark-pool.md)\\n- [Interactive Data Wrangling with Apache Spark in Azure Machine Learning](.\/interactive-data-wrangling-with-apache-spark-azure-ml.md)\\n- [Submit Spark jobs in Azure Machine Learning](.\/how-to-submit-spark-jobs.md)\\n- [Code samples for Spark jobs using Azure Machine Learning CLI](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/cli\/jobs\/spark)\\nSource: quickstart-spark-jobs.md\\n\\nContent: # Submit Spark jobs in Azure Machine Learning\\n\\n6. To add any Jar file(s) that the standalone job requires at runtime, select **+ Add file** under **Jars** and input the name of the `.jar` file to be included in the Spark driver. Also, add the executor `CLASSPATH` for successful job execution. Multiple files can be added.\\n        7. To add archive(s) that should be extracted into the working directory of each executor for successful job execution, select **+ Add file** under **Archives**, and input the name of the archive. Multiple archives can be added.\\n        8. Adding **Py files**, **Jars**, and **Archives** is optional.\\n        9. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter an **Input name**. The input should refer to this name later in the **Arguments**.\\n            2. Select an **Input type**.\\n            3. For type **Data**:\\n                1. Select **Data type** as **File** or **Folder**.\\n                2. Select **Data source** as **Upload from local**, **URI**, or **Datastore**.\\n                    - For **Upload from local**, select **Browse** under **Path to upload**, to choose the input file or folder.\\n                    - For **URI**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI), or enter a data asset `azureml:\/\/`.\\n                    - For **Datastore**:\\n                        1. **Select a datastore** from the dropdown menu.\\n                        2. Under **Path to data**, select **Browse**.\\n                        3. In the pop-up screen titled **Path selection**, select the path of the code files on the workspace default blob storage.\\n                        4. Select **Save**.\\n            4. For type **Integer**, enter an integer value as **Input value**.\\n            5. For type **Number**, enter a numeric value as **Input value**.\\n            6. For type **Boolean**, select **True** or **False** as **Input value**.\\n            7. For type **String**, enter a string as **Input value**.\\n        10. To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter an **Output name**. The output should refer to this name later to in the **Arguments**.\\n            2. Select **Output type** as **File** or **Folder**.\\n            3. For **Output URI destination**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI) or enter a data asset `azureml:\/\/`.\\n        11. Enter **Arguments** by using the names defined in the **Input name** and **Output name** fields in the earlier steps, and the names of input and output arguments used in the Python script **Entry file**. For example, if the **Input name** and **Output name** are defined as `job_input` and `job_output`, and the arguments are added in the **Entry file** as shown here\\n\\n            ``` python\\n            import argparse\\n\\n            parser = argparse.ArgumentParser()\\n            parser.add_argument(\\\"--input_param\\\")\\n            parser.add_argument(\\\"--output_param\\\")\\n            ```\\n\\n    then enter **Arguments** as `--input_param ${{inputs.job_input}} --output_param ${{outputs.job_output}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** and executor **Memory (GB)**, in gigabytes.\\n            2. For **Dynamically allocated executors**, select the **Disabled** or **Enabled** option.\\n        - If dynamic allocation of executors is **Disabled**, enter the number of **Executor instances**.\\n        - If dynamic allocation of executors is **Enabled**, use the slider to select the minimum and maximum number of executors.\\n        1. For **Driver size**:\\n            1. Enter number of driver **Cores** and driver **Memory (GB)**, in gigabytes.\\n            2. Enter **Name** and **Value** pairs for any **Additional configurations**, then select **Add**. Providing **Additional configurations** is optional.\\n    6. Select **Next**.\\n7. On the **Review** screen:\\nSource: how-to-submit-spark-jobs.md\\n\\nContent: # Configure Apache Spark jobs in Azure Machine Learning\\n\\n- [Code samples for Spark jobs using Azure Machine Learning Python SDK](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/sdk\/python\/jobs\/spark)\\nSource: quickstart-spark-jobs.md \\n\\n chat history:\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"what is aml?\"\n    },\n    {\n      \"role\": \"assistant\",\n      \"content\": \"user: how to create a spark job? \\nassistant:\"\n    }\n  ],\n  \"temperature\": 1.0,\n  \"top_p\": 1.0,\n  \"n\": 1,\n  \"stream\": false,\n  \"presence_penalty\": 0.0,\n  \"frequency_penalty\": 0.0,\n  \"user\": \"\"\n}"}},{"name":"promptflow.llm.generated_message","timestamp":"2024-04-11T18:07:46.725296Z","attributes":{"payload":"{\n  \"content\": \"To create a Spark job in Azure Machine Learning, you need to firstly provide a Name and optionally a Value under the **Add tags**. Then in the **Code** section, you need to choose the workspace's default blob storage for code location and select the path of the code file to upload. You then need to input the name of the `titanic.py` as the **Entry file**. \\n\\nNext, you add an input by selecting **+ Add input** under **Inputs** and filling up required fields such as **Input name**, **Input type**, and **Data type**. Similarly, you add an output by selecting **+ Add output** under **Outputs** and entering required information. \\n\\nThen you need to enter **Arguments** for the job. \\n\\nIn the **Spark configurations** section, you can configure parameters such as number of executor cores, memory, and instances. Similarly, configure the driver size. Then, you can add any additional optional configurations. \\n\\nOnce everything is set up, you can review the job specifications and select **Create** to submit the standalone Spark job (Source: quickstart-spark-jobs.md).\\n\\nBear in mind that you have the option to add any necessary Jar files, Py files or Archives for the job under the respective sections (Source: how-to-submit-spark-jobs.md). Also, please note that the job submitted defaults to user identity passthrough for data access (Source: quickstart-spark-jobs.md).\\n\",\n  \"role\": \"assistant\",\n  \"function_call\": null,\n  \"tool_calls\": null\n}"}},{"name":"promptflow.function.output","timestamp":"2024-04-11T18:07:46.726891Z","attributes":{"payload":"{\n  \"id\": \"chatcmpl-9Ct7bms0phqmD3aMhcRykATBNYjyw\",\n  \"choices\": [\n    {\n      \"finish_reason\": \"stop\",\n      \"index\": 0,\n      \"logprobs\": null,\n      \"message\": {\n        \"content\": \"To create a Spark job in Azure Machine Learning, you need to firstly provide a Name and optionally a Value under the **Add tags**. Then in the **Code** section, you need to choose the workspace's default blob storage for code location and select the path of the code file to upload. You then need to input the name of the `titanic.py` as the **Entry file**. \\n\\nNext, you add an input by selecting **+ Add input** under **Inputs** and filling up required fields such as **Input name**, **Input type**, and **Data type**. Similarly, you add an output by selecting **+ Add output** under **Outputs** and entering required information. \\n\\nThen you need to enter **Arguments** for the job. \\n\\nIn the **Spark configurations** section, you can configure parameters such as number of executor cores, memory, and instances. Similarly, configure the driver size. Then, you can add any additional optional configurations. \\n\\nOnce everything is set up, you can review the job specifications and select **Create** to submit the standalone Spark job (Source: quickstart-spark-jobs.md).\\n\\nBear in mind that you have the option to add any necessary Jar files, Py files or Archives for the job under the respective sections (Source: how-to-submit-spark-jobs.md). Also, please note that the job submitted defaults to user identity passthrough for data access (Source: quickstart-spark-jobs.md).\\n\",\n        \"role\": \"assistant\",\n        \"function_call\": null,\n        \"tool_calls\": null\n      },\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ],\n  \"created\": 1712858851,\n  \"model\": \"gpt-4-32k\",\n  \"object\": \"chat.completion\",\n  \"system_fingerprint\": null,\n  \"usage\": {\n    \"completion_tokens\": 299,\n    \"prompt_tokens\": 2027,\n    \"total_tokens\": 2326\n  },\n  \"prompt_filter_results\": [\n    {\n      \"prompt_index\": 0,\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ]\n}"}}],"links":[],"resource":{"attributes":{"service.name":"promptflow"},"schema_url":""}}],"xrequestid":"6d6b67e2-4f30-455c-826d-2a98f33e3e67","modelversion":"default","collectdatatype":"pandas.core.frame.DataFrame","agent":"azureml-ai-monitoring/0.1.0b4","contentrange":"bytes 0-28450/28451","correlationid":"6d6b67e2-4f30-455c-826d-2a98f33e3e67"}
{"specversion":"1.0","id":"8fec7922-cdaf-4546-825d-41e357af046b","source":"/subscriptions/1aefdc5e-3a7c-4d71-a9f9-f5d3b03be19a/resourceGroups/yuachengtestrg/providers/Microsoft.MachineLearningServices/workspaces/ai-proj-eastus/onlineEndpoints/clone-vivi-log-test/deployments/clone-vivi-log-test-1","type":"azureml.inference.app_traces","datacontenttype":"application/json","time":"2024-04-11T18:07:51Z","data":[{"name":"answer_the_question_with_context","context":{"trace_id":"0xa2f3f4f8267a482fa3bb96ad3e1f7f35","span_id":"0x8fd94b3d721108ea","trace_state":"[]"},"kind":"SpanKind.INTERNAL","parent_id":"0xc2bb84e37668431d","start_time":"2024-04-11T18:07:30.336238Z","end_time":"2024-04-11T18:07:46.727420Z","status":{"status_code":"OK"},"attributes":{"framework":"promptflow","span_type":"Function","function":"AzureOpenAI.chat","node_name":"answer_the_question_with_context","request_id":"ee2f5c78-77c1-4766-802d-49aa4b354ec3","line_run_id":"ee2f5c78-77c1-4766-802d-49aa4b354ec3","prompt.template":"{{prompt_text}}","prompt.variables":"{\n  \"prompt_text\": \"system: \\nYou are an AI assistant that helps users answer questions given a specific context and conversation history. You will be given a context and chat history, and then asked a question based on that context and history. Your answer should be as precise as possible, and should only come from the context.\\nPlease add citation after each sentence when possible in a form \\\"(Source: citation)\\\".\\n\\n user: \\n Content: # Configure Apache Spark jobs in Azure Machine Learning\\n\\n3. Under **Add tags**, provide **Name** and **Value**, then select **Add**. Adding tags is optional.\\n    4. Under the **Code** section:\\n        1. Select **Azure Machine Learning workspace default blob storage** from **Choose code location** dropdown.\\n        2. Under **Path to code file to upload**, select **Browse**.\\n        3. In the pop-up screen titled **Path selection**, select the path of code file `titanic.py` on the workspace default datastore `workspaceblobstore`.\\n        4. Select **Save**.\\n        5. Input `titanic.py` as the name of **Entry file** for the standalone job.\\n        6. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter **Input name** as `titanic_data`. The input should refer to this name later in the **Arguments**.\\n            2. Select **Input type** as **Data**.\\n            3. Select **Data type** as **File**.\\n            4. Select **Data source** as **URI**.\\n            5. Enter an Azure Data Lake Storage (ADLS) Gen 2 data URI for `titanic.csv` file in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here, `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        7.  To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter **Output name** as `wrangled_data`. The output should refer to this name later in the **Arguments**.\\n            2. Select **Output type** as **Folder**.\\n            3. For **Output URI destination**, enter an Azure Data Lake Storage (ADLS) Gen 2 folder URI in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        8.  Enter **Arguments**  as `--titanic_data ${{inputs.titanic_data}} --wrangled_data ${{outputs.wrangled_data}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** as 2 and executor **Memory (GB)** as 2.\\n            2. For **Dynamically allocated executors**, select **Disabled**.\\n            3. Enter the number of **Executor instances** as 2.\\n        2. For **Driver size**, enter number of driver **Cores** as 1 and driver **Memory (GB)** as 2.\\n    6. Select **Next**.\\n6. On the **Review** screen:\\n    1. Review the job specification before submitting it.\\n    2. Select **Create** to submit the standalone Spark job.\\n\\n\u003e [!NOTE]\\n\u003e A standalone job submitted from the Studio UI using an Azure Machine Learning serverless Spark compute defaults to user identity passthrough for data access.\\n\\n\\n---\\n\\n\u003e [!TIP]\\n\u003e You might have an existing Synapse Spark pool in your Azure Synapse workspace. To use an existing Synapse Spark pool, please follow the instructions to [attach a Synapse Spark pool in Azure Machine Learning workspace](.\/how-to-manage-synapse-spark-pool.md).\\n\\n## Next steps\\n- [Apache Spark in Azure Machine Learning](.\/apache-spark-azure-ml-concepts.md)\\n- [Quickstart: Interactive Data Wrangling with Apache Spark](.\/apache-spark-environment-configuration.md)\\n- [Attach and manage a Synapse Spark pool in Azure Machine Learning](.\/how-to-manage-synapse-spark-pool.md)\\n- [Interactive Data Wrangling with Apache Spark in Azure Machine Learning](.\/interactive-data-wrangling-with-apache-spark-azure-ml.md)\\n- [Submit Spark jobs in Azure Machine Learning](.\/how-to-submit-spark-jobs.md)\\n- [Code samples for Spark jobs using Azure Machine Learning CLI](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/cli\/jobs\/spark)\\nSource: quickstart-spark-jobs.md\\n\\nContent: # Submit Spark jobs in Azure Machine Learning\\n\\n6. To add any Jar file(s) that the standalone job requires at runtime, select **+ Add file** under **Jars** and input the name of the `.jar` file to be included in the Spark driver. Also, add the executor `CLASSPATH` for successful job execution. Multiple files can be added.\\n        7. To add archive(s) that should be extracted into the working directory of each executor for successful job execution, select **+ Add file** under **Archives**, and input the name of the archive. Multiple archives can be added.\\n        8. Adding **Py files**, **Jars**, and **Archives** is optional.\\n        9. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter an **Input name**. The input should refer to this name later in the **Arguments**.\\n            2. Select an **Input type**.\\n            3. For type **Data**:\\n                1. Select **Data type** as **File** or **Folder**.\\n                2. Select **Data source** as **Upload from local**, **URI**, or **Datastore**.\\n                    - For **Upload from local**, select **Browse** under **Path to upload**, to choose the input file or folder.\\n                    - For **URI**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI), or enter a data asset `azureml:\/\/`.\\n                    - For **Datastore**:\\n                        1. **Select a datastore** from the dropdown menu.\\n                        2. Under **Path to data**, select **Browse**.\\n                        3. In the pop-up screen titled **Path selection**, select the path of the code files on the workspace default blob storage.\\n                        4. Select **Save**.\\n            4. For type **Integer**, enter an integer value as **Input value**.\\n            5. For type **Number**, enter a numeric value as **Input value**.\\n            6. For type **Boolean**, select **True** or **False** as **Input value**.\\n            7. For type **String**, enter a string as **Input value**.\\n        10. To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter an **Output name**. The output should refer to this name later to in the **Arguments**.\\n            2. Select **Output type** as **File** or **Folder**.\\n            3. For **Output URI destination**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI) or enter a data asset `azureml:\/\/`.\\n        11. Enter **Arguments** by using the names defined in the **Input name** and **Output name** fields in the earlier steps, and the names of input and output arguments used in the Python script **Entry file**. For example, if the **Input name** and **Output name** are defined as `job_input` and `job_output`, and the arguments are added in the **Entry file** as shown here\\n\\n            ``` python\\n            import argparse\\n\\n            parser = argparse.ArgumentParser()\\n            parser.add_argument(\\\"--input_param\\\")\\n            parser.add_argument(\\\"--output_param\\\")\\n            ```\\n\\n    then enter **Arguments** as `--input_param ${{inputs.job_input}} --output_param ${{outputs.job_output}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** and executor **Memory (GB)**, in gigabytes.\\n            2. For **Dynamically allocated executors**, select the **Disabled** or **Enabled** option.\\n        - If dynamic allocation of executors is **Disabled**, enter the number of **Executor instances**.\\n        - If dynamic allocation of executors is **Enabled**, use the slider to select the minimum and maximum number of executors.\\n        1. For **Driver size**:\\n            1. Enter number of driver **Cores** and driver **Memory (GB)**, in gigabytes.\\n            2. Enter **Name** and **Value** pairs for any **Additional configurations**, then select **Add**. Providing **Additional configurations** is optional.\\n    6. Select **Next**.\\n7. On the **Review** screen:\\nSource: how-to-submit-spark-jobs.md\\n\\nContent: # Configure Apache Spark jobs in Azure Machine Learning\\n\\n- [Code samples for Spark jobs using Azure Machine Learning Python SDK](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/sdk\/python\/jobs\/spark)\\nSource: quickstart-spark-jobs.md \\n\\n chat history: \\n user: \\nwhat is aml? \\nassistant: \\n \\nuser: how to create a spark job? \\nassistant:\"\n}","inputs":"{\n  \"prompt\": \"{{prompt_text}}\",\n  \"deployment_name\": \"gpt-4-32k\",\n  \"temperature\": 1.0,\n  \"top_p\": 1.0,\n  \"presence_penalty\": 0.0,\n  \"frequency_penalty\": 0.0,\n  \"prompt_text\": \"system: \\nYou are an AI assistant that helps users answer questions given a specific context and conversation history. You will be given a context and chat history, and then asked a question based on that context and history. Your answer should be as precise as possible, and should only come from the context.\\nPlease add citation after each sentence when possible in a form \\\"(Source: citation)\\\".\\n\\n user: \\n Content: # Configure Apache Spark jobs in Azure Machine Learning\\n\\n3. Under **Add tags**, provide **Name** and **Value**, then select **Add**. Adding tags is optional.\\n    4. Under the **Code** section:\\n        1. Select **Azure Machine Learning workspace default blob storage** from **Choose code location** dropdown.\\n        2. Under **Path to code file to upload**, select **Browse**.\\n        3. In the pop-up screen titled **Path selection**, select the path of code file `titanic.py` on the workspace default datastore `workspaceblobstore`.\\n        4. Select **Save**.\\n        5. Input `titanic.py` as the name of **Entry file** for the standalone job.\\n        6. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter **Input name** as `titanic_data`. The input should refer to this name later in the **Arguments**.\\n            2. Select **Input type** as **Data**.\\n            3. Select **Data type** as **File**.\\n            4. Select **Data source** as **URI**.\\n            5. Enter an Azure Data Lake Storage (ADLS) Gen 2 data URI for `titanic.csv` file in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here, `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        7.  To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter **Output name** as `wrangled_data`. The output should refer to this name later in the **Arguments**.\\n            2. Select **Output type** as **Folder**.\\n            3. For **Output URI destination**, enter an Azure Data Lake Storage (ADLS) Gen 2 folder URI in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        8.  Enter **Arguments**  as `--titanic_data ${{inputs.titanic_data}} --wrangled_data ${{outputs.wrangled_data}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** as 2 and executor **Memory (GB)** as 2.\\n            2. For **Dynamically allocated executors**, select **Disabled**.\\n            3. Enter the number of **Executor instances** as 2.\\n        2. For **Driver size**, enter number of driver **Cores** as 1 and driver **Memory (GB)** as 2.\\n    6. Select **Next**.\\n6. On the **Review** screen:\\n    1. Review the job specification before submitting it.\\n    2. Select **Create** to submit the standalone Spark job.\\n\\n\u003e [!NOTE]\\n\u003e A standalone job submitted from the Studio UI using an Azure Machine Learning serverless Spark compute defaults to user identity passthrough for data access.\\n\\n\\n---\\n\\n\u003e [!TIP]\\n\u003e You might have an existing Synapse Spark pool in your Azure Synapse workspace. To use an existing Synapse Spark pool, please follow the instructions to [attach a Synapse Spark pool in Azure Machine Learning workspace](.\/how-to-manage-synapse-spark-pool.md).\\n\\n## Next steps\\n- [Apache Spark in Azure Machine Learning](.\/apache-spark-azure-ml-concepts.md)\\n- [Quickstart: Interactive Data Wrangling with Apache Spark](.\/apache-spark-environment-configuration.md)\\n- [Attach and manage a Synapse Spark pool in Azure Machine Learning](.\/how-to-manage-synapse-spark-pool.md)\\n- [Interactive Data Wrangling with Apache Spark in Azure Machine Learning](.\/interactive-data-wrangling-with-apache-spark-azure-ml.md)\\n- [Submit Spark jobs in Azure Machine Learning](.\/how-to-submit-spark-jobs.md)\\n- [Code samples for Spark jobs using Azure Machine Learning CLI](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/cli\/jobs\/spark)\\nSource: quickstart-spark-jobs.md\\n\\nContent: # Submit Spark jobs in Azure Machine Learning\\n\\n6. To add any Jar file(s) that the standalone job requires at runtime, select **+ Add file** under **Jars** and input the name of the `.jar` file to be included in the Spark driver. Also, add the executor `CLASSPATH` for successful job execution. Multiple files can be added.\\n        7. To add archive(s) that should be extracted into the working directory of each executor for successful job execution, select **+ Add file** under **Archives**, and input the name of the archive. Multiple archives can be added.\\n        8. Adding **Py files**, **Jars**, and **Archives** is optional.\\n        9. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter an **Input name**. The input should refer to this name later in the **Arguments**.\\n            2. Select an **Input type**.\\n            3. For type **Data**:\\n                1. Select **Data type** as **File** or **Folder**.\\n                2. Select **Data source** as **Upload from local**, **URI**, or **Datastore**.\\n                    - For **Upload from local**, select **Browse** under **Path to upload**, to choose the input file or folder.\\n                    - For **URI**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI), or enter a data asset `azureml:\/\/`.\\n                    - For **Datastore**:\\n                        1. **Select a datastore** from the dropdown menu.\\n                        2. Under **Path to data**, select **Browse**.\\n                        3. In the pop-up screen titled **Path selection**, select the path of the code files on the workspace default blob storage.\\n                        4. Select **Save**.\\n            4. For type **Integer**, enter an integer value as **Input value**.\\n            5. For type **Number**, enter a numeric value as **Input value**.\\n            6. For type **Boolean**, select **True** or **False** as **Input value**.\\n            7. For type **String**, enter a string as **Input value**.\\n        10. To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter an **Output name**. The output should refer to this name later to in the **Arguments**.\\n            2. Select **Output type** as **File** or **Folder**.\\n            3. For **Output URI destination**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI) or enter a data asset `azureml:\/\/`.\\n        11. Enter **Arguments** by using the names defined in the **Input name** and **Output name** fields in the earlier steps, and the names of input and output arguments used in the Python script **Entry file**. For example, if the **Input name** and **Output name** are defined as `job_input` and `job_output`, and the arguments are added in the **Entry file** as shown here\\n\\n            ``` python\\n            import argparse\\n\\n            parser = argparse.ArgumentParser()\\n            parser.add_argument(\\\"--input_param\\\")\\n            parser.add_argument(\\\"--output_param\\\")\\n            ```\\n\\n    then enter **Arguments** as `--input_param ${{inputs.job_input}} --output_param ${{outputs.job_output}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** and executor **Memory (GB)**, in gigabytes.\\n            2. For **Dynamically allocated executors**, select the **Disabled** or **Enabled** option.\\n        - If dynamic allocation of executors is **Disabled**, enter the number of **Executor instances**.\\n        - If dynamic allocation of executors is **Enabled**, use the slider to select the minimum and maximum number of executors.\\n        1. For **Driver size**:\\n            1. Enter number of driver **Cores** and driver **Memory (GB)**, in gigabytes.\\n            2. Enter **Name** and **Value** pairs for any **Additional configurations**, then select **Add**. Providing **Additional configurations** is optional.\\n    6. Select **Next**.\\n7. On the **Review** screen:\\nSource: how-to-submit-spark-jobs.md\\n\\nContent: # Configure Apache Spark jobs in Azure Machine Learning\\n\\n- [Code samples for Spark jobs using Azure Machine Learning Python SDK](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/sdk\/python\/jobs\/spark)\\nSource: quickstart-spark-jobs.md \\n\\n chat history: \\n user: \\nwhat is aml? \\nassistant: \\n \\nuser: how to create a spark job? \\nassistant:\",\n  \"stream\": false\n}","__computed__.cumulative_token_count.completion":299,"__computed__.cumulative_token_count.prompt":2027,"__computed__.cumulative_token_count.total":2326,"output":"\"To create a Spark job in Azure Machine Learning, you need to firstly provide a Name and optionally a Value under the **Add tags**. Then in the **Code** section, you need to choose the workspace's default blob storage for code location and select the path of the code file to upload. You then need to input the name of the `titanic.py` as the **Entry file**. \\n\\nNext, you add an input by selecting **+ Add input** under **Inputs** and filling up required fields such as **Input name**, **Input type**, and **Data type**. Similarly, you add an output by selecting **+ Add output** under **Outputs** and entering required information. \\n\\nThen you need to enter **Arguments** for the job. \\n\\nIn the **Spark configurations** section, you can configure parameters such as number of executor cores, memory, and instances. Similarly, configure the driver size. Then, you can add any additional optional configurations. \\n\\nOnce everything is set up, you can review the job specifications and select **Create** to submit the standalone Spark job (Source: quickstart-spark-jobs.md).\\n\\nBear in mind that you have the option to add any necessary Jar files, Py files or Archives for the job under the respective sections (Source: how-to-submit-spark-jobs.md). Also, please note that the job submitted defaults to user identity passthrough for data access (Source: quickstart-spark-jobs.md).\\n\""},"events":[{"name":"promptflow.prompt.template","timestamp":"2024-04-11T18:07:30.337175Z","attributes":{"payload":"{\n  \"prompt.template\": \"{{prompt_text}}\",\n  \"prompt.variables\": \"{\\n  \\\"prompt_text\\\": \\\"system: \\\\nYou are an AI assistant that helps users answer questions given a specific context and conversation history. You will be given a context and chat history, and then asked a question based on that context and history. Your answer should be as precise as possible, and should only come from the context.\\\\nPlease add citation after each sentence when possible in a form \\\\\\\"(Source: citation)\\\\\\\".\\\\n\\\\n user: \\\\n Content: # Configure Apache Spark jobs in Azure Machine Learning\\\\n\\\\n3. Under **Add tags**, provide **Name** and **Value**, then select **Add**. Adding tags is optional.\\\\n    4. Under the **Code** section:\\\\n        1. Select **Azure Machine Learning workspace default blob storage** from **Choose code location** dropdown.\\\\n        2. Under **Path to code file to upload**, select **Browse**.\\\\n        3. In the pop-up screen titled **Path selection**, select the path of code file `titanic.py` on the workspace default datastore `workspaceblobstore`.\\\\n        4. Select **Save**.\\\\n        5. Input `titanic.py` as the name of **Entry file** for the standalone job.\\\\n        6. To add an input, select **+ Add input** under **Inputs** and\\\\n            1. Enter **Input name** as `titanic_data`. The input should refer to this name later in the **Arguments**.\\\\n            2. Select **Input type** as **Data**.\\\\n            3. Select **Data type** as **File**.\\\\n            4. Select **Data source** as **URI**.\\\\n            5. Enter an Azure Data Lake Storage (ADLS) Gen 2 data URI for `titanic.csv` file in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here, `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\\\n        7.  To add an input, select **+ Add output** under **Outputs** and\\\\n            1. Enter **Output name** as `wrangled_data`. The output should refer to this name later in the **Arguments**.\\\\n            2. Select **Output type** as **Folder**.\\\\n            3. For **Output URI destination**, enter an Azure Data Lake Storage (ADLS) Gen 2 folder URI in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\\\n        8.  Enter **Arguments**  as `--titanic_data ${{inputs.titanic_data}} --wrangled_data ${{outputs.wrangled_data}}`.\\\\n    5. Under the **Spark configurations** section:\\\\n        1. For **Executor size**:\\\\n            1. Enter the number of executor **Cores** as 2 and executor **Memory (GB)** as 2.\\\\n            2. For **Dynamically allocated executors**, select **Disabled**.\\\\n            3. Enter the number of **Executor instances** as 2.\\\\n        2. For **Driver size**, enter number of driver **Cores** as 1 and driver **Memory (GB)** as 2.\\\\n    6. Select **Next**.\\\\n6. On the **Review** screen:\\\\n    1. Review the job specification before submitting it.\\\\n    2. Select **Create** to submit the standalone Spark job.\\\\n\\\\n\u003e [!NOTE]\\\\n\u003e A standalone job submitted from the Studio UI using an Azure Machine Learning serverless Spark compute defaults to user identity passthrough for data access.\\\\n\\\\n\\\\n---\\\\n\\\\n\u003e [!TIP]\\\\n\u003e You might have an existing Synapse Spark pool in your Azure Synapse workspace. To use an existing Synapse Spark pool, please follow the instructions to [attach a Synapse Spark pool in Azure Machine Learning workspace](.\/how-to-manage-synapse-spark-pool.md).\\\\n\\\\n## Next steps\\\\n- [Apache Spark in Azure Machine Learning](.\/apache-spark-azure-ml-concepts.md)\\\\n- [Quickstart: Interactive Data Wrangling with Apache Spark](.\/apache-spark-environment-configuration.md)\\\\n- [Attach and manage a Synapse Spark pool in Azure Machine Learning](.\/how-to-manage-synapse-spark-pool.md)\\\\n- [Interactive Data Wrangling with Apache Spark in Azure Machine Learning](.\/interactive-data-wrangling-with-apache-spark-azure-ml.md)\\\\n- [Submit Spark jobs in Azure Machine Learning](.\/how-to-submit-spark-jobs.md)\\\\n- [Code samples for Spark jobs using Azure Machine Learning CLI](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/cli\/jobs\/spark)\\\\nSource: quickstart-spark-jobs.md\\\\n\\\\nContent: # Submit Spark jobs in Azure Machine Learning\\\\n\\\\n6. To add any Jar file(s) that the standalone job requires at runtime, select **+ Add file** under **Jars** and input the name of the `.jar` file to be included in the Spark driver. Also, add the executor `CLASSPATH` for successful job execution. Multiple files can be added.\\\\n        7. To add archive(s) that should be extracted into the working directory of each executor for successful job execution, select **+ Add file** under **Archives**, and input the name of the archive. Multiple archives can be added.\\\\n        8. Adding **Py files**, **Jars**, and **Archives** is optional.\\\\n        9. To add an input, select **+ Add input** under **Inputs** and\\\\n            1. Enter an **Input name**. The input should refer to this name later in the **Arguments**.\\\\n            2. Select an **Input type**.\\\\n            3. For type **Data**:\\\\n                1. Select **Data type** as **File** or **Folder**.\\\\n                2. Select **Data source** as **Upload from local**, **URI**, or **Datastore**.\\\\n                    - For **Upload from local**, select **Browse** under **Path to upload**, to choose the input file or folder.\\\\n                    - For **URI**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI), or enter a data asset `azureml:\/\/`.\\\\n                    - For **Datastore**:\\\\n                        1. **Select a datastore** from the dropdown menu.\\\\n                        2. Under **Path to data**, select **Browse**.\\\\n                        3. In the pop-up screen titled **Path selection**, select the path of the code files on the workspace default blob storage.\\\\n                        4. Select **Save**.\\\\n            4. For type **Integer**, enter an integer value as **Input value**.\\\\n            5. For type **Number**, enter a numeric value as **Input value**.\\\\n            6. For type **Boolean**, select **True** or **False** as **Input value**.\\\\n            7. For type **String**, enter a string as **Input value**.\\\\n        10. To add an input, select **+ Add output** under **Outputs** and\\\\n            1. Enter an **Output name**. The output should refer to this name later to in the **Arguments**.\\\\n            2. Select **Output type** as **File** or **Folder**.\\\\n            3. For **Output URI destination**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI) or enter a data asset `azureml:\/\/`.\\\\n        11. Enter **Arguments** by using the names defined in the **Input name** and **Output name** fields in the earlier steps, and the names of input and output arguments used in the Python script **Entry file**. For example, if the **Input name** and **Output name** are defined as `job_input` and `job_output`, and the arguments are added in the **Entry file** as shown here\\\\n\\\\n            ``` python\\\\n            import argparse\\\\n\\\\n            parser = argparse.ArgumentParser()\\\\n            parser.add_argument(\\\\\\\"--input_param\\\\\\\")\\\\n            parser.add_argument(\\\\\\\"--output_param\\\\\\\")\\\\n            ```\\\\n\\\\n    then enter **Arguments** as `--input_param ${{inputs.job_input}} --output_param ${{outputs.job_output}}`.\\\\n    5. Under the **Spark configurations** section:\\\\n        1. For **Executor size**:\\\\n            1. Enter the number of executor **Cores** and executor **Memory (GB)**, in gigabytes.\\\\n            2. For **Dynamically allocated executors**, select the **Disabled** or **Enabled** option.\\\\n        - If dynamic allocation of executors is **Disabled**, enter the number of **Executor instances**.\\\\n        - If dynamic allocation of executors is **Enabled**, use the slider to select the minimum and maximum number of executors.\\\\n        1. For **Driver size**:\\\\n            1. Enter number of driver **Cores** and driver **Memory (GB)**, in gigabytes.\\\\n            2. Enter **Name** and **Value** pairs for any **Additional configurations**, then select **Add**. Providing **Additional configurations** is optional.\\\\n    6. Select **Next**.\\\\n7. On the **Review** screen:\\\\nSource: how-to-submit-spark-jobs.md\\\\n\\\\nContent: # Configure Apache Spark jobs in Azure Machine Learning\\\\n\\\\n- [Code samples for Spark jobs using Azure Machine Learning Python SDK](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/sdk\/python\/jobs\/spark)\\\\nSource: quickstart-spark-jobs.md \\\\n\\\\n chat history: \\\\n user: \\\\nwhat is aml? \\\\nassistant: \\\\n \\\\nuser: how to create a spark job? \\\\nassistant:\\\"\\n}\"\n}"}},{"name":"promptflow.function.inputs","timestamp":"2024-04-11T18:07:30.338373Z","attributes":{"payload":"{\n  \"prompt\": \"{{prompt_text}}\",\n  \"deployment_name\": \"gpt-4-32k\",\n  \"temperature\": 1.0,\n  \"top_p\": 1.0,\n  \"presence_penalty\": 0.0,\n  \"frequency_penalty\": 0.0,\n  \"prompt_text\": \"system: \\nYou are an AI assistant that helps users answer questions given a specific context and conversation history. You will be given a context and chat history, and then asked a question based on that context and history. Your answer should be as precise as possible, and should only come from the context.\\nPlease add citation after each sentence when possible in a form \\\"(Source: citation)\\\".\\n\\n user: \\n Content: # Configure Apache Spark jobs in Azure Machine Learning\\n\\n3. Under **Add tags**, provide **Name** and **Value**, then select **Add**. Adding tags is optional.\\n    4. Under the **Code** section:\\n        1. Select **Azure Machine Learning workspace default blob storage** from **Choose code location** dropdown.\\n        2. Under **Path to code file to upload**, select **Browse**.\\n        3. In the pop-up screen titled **Path selection**, select the path of code file `titanic.py` on the workspace default datastore `workspaceblobstore`.\\n        4. Select **Save**.\\n        5. Input `titanic.py` as the name of **Entry file** for the standalone job.\\n        6. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter **Input name** as `titanic_data`. The input should refer to this name later in the **Arguments**.\\n            2. Select **Input type** as **Data**.\\n            3. Select **Data type** as **File**.\\n            4. Select **Data source** as **URI**.\\n            5. Enter an Azure Data Lake Storage (ADLS) Gen 2 data URI for `titanic.csv` file in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here, `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        7.  To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter **Output name** as `wrangled_data`. The output should refer to this name later in the **Arguments**.\\n            2. Select **Output type** as **Folder**.\\n            3. For **Output URI destination**, enter an Azure Data Lake Storage (ADLS) Gen 2 folder URI in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        8.  Enter **Arguments**  as `--titanic_data ${{inputs.titanic_data}} --wrangled_data ${{outputs.wrangled_data}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** as 2 and executor **Memory (GB)** as 2.\\n            2. For **Dynamically allocated executors**, select **Disabled**.\\n            3. Enter the number of **Executor instances** as 2.\\n        2. For **Driver size**, enter number of driver **Cores** as 1 and driver **Memory (GB)** as 2.\\n    6. Select **Next**.\\n6. On the **Review** screen:\\n    1. Review the job specification before submitting it.\\n    2. Select **Create** to submit the standalone Spark job.\\n\\n\u003e [!NOTE]\\n\u003e A standalone job submitted from the Studio UI using an Azure Machine Learning serverless Spark compute defaults to user identity passthrough for data access.\\n\\n\\n---\\n\\n\u003e [!TIP]\\n\u003e You might have an existing Synapse Spark pool in your Azure Synapse workspace. To use an existing Synapse Spark pool, please follow the instructions to [attach a Synapse Spark pool in Azure Machine Learning workspace](.\/how-to-manage-synapse-spark-pool.md).\\n\\n## Next steps\\n- [Apache Spark in Azure Machine Learning](.\/apache-spark-azure-ml-concepts.md)\\n- [Quickstart: Interactive Data Wrangling with Apache Spark](.\/apache-spark-environment-configuration.md)\\n- [Attach and manage a Synapse Spark pool in Azure Machine Learning](.\/how-to-manage-synapse-spark-pool.md)\\n- [Interactive Data Wrangling with Apache Spark in Azure Machine Learning](.\/interactive-data-wrangling-with-apache-spark-azure-ml.md)\\n- [Submit Spark jobs in Azure Machine Learning](.\/how-to-submit-spark-jobs.md)\\n- [Code samples for Spark jobs using Azure Machine Learning CLI](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/cli\/jobs\/spark)\\nSource: quickstart-spark-jobs.md\\n\\nContent: # Submit Spark jobs in Azure Machine Learning\\n\\n6. To add any Jar file(s) that the standalone job requires at runtime, select **+ Add file** under **Jars** and input the name of the `.jar` file to be included in the Spark driver. Also, add the executor `CLASSPATH` for successful job execution. Multiple files can be added.\\n        7. To add archive(s) that should be extracted into the working directory of each executor for successful job execution, select **+ Add file** under **Archives**, and input the name of the archive. Multiple archives can be added.\\n        8. Adding **Py files**, **Jars**, and **Archives** is optional.\\n        9. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter an **Input name**. The input should refer to this name later in the **Arguments**.\\n            2. Select an **Input type**.\\n            3. For type **Data**:\\n                1. Select **Data type** as **File** or **Folder**.\\n                2. Select **Data source** as **Upload from local**, **URI**, or **Datastore**.\\n                    - For **Upload from local**, select **Browse** under **Path to upload**, to choose the input file or folder.\\n                    - For **URI**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI), or enter a data asset `azureml:\/\/`.\\n                    - For **Datastore**:\\n                        1. **Select a datastore** from the dropdown menu.\\n                        2. Under **Path to data**, select **Browse**.\\n                        3. In the pop-up screen titled **Path selection**, select the path of the code files on the workspace default blob storage.\\n                        4. Select **Save**.\\n            4. For type **Integer**, enter an integer value as **Input value**.\\n            5. For type **Number**, enter a numeric value as **Input value**.\\n            6. For type **Boolean**, select **True** or **False** as **Input value**.\\n            7. For type **String**, enter a string as **Input value**.\\n        10. To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter an **Output name**. The output should refer to this name later to in the **Arguments**.\\n            2. Select **Output type** as **File** or **Folder**.\\n            3. For **Output URI destination**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI) or enter a data asset `azureml:\/\/`.\\n        11. Enter **Arguments** by using the names defined in the **Input name** and **Output name** fields in the earlier steps, and the names of input and output arguments used in the Python script **Entry file**. For example, if the **Input name** and **Output name** are defined as `job_input` and `job_output`, and the arguments are added in the **Entry file** as shown here\\n\\n            ``` python\\n            import argparse\\n\\n            parser = argparse.ArgumentParser()\\n            parser.add_argument(\\\"--input_param\\\")\\n            parser.add_argument(\\\"--output_param\\\")\\n            ```\\n\\n    then enter **Arguments** as `--input_param ${{inputs.job_input}} --output_param ${{outputs.job_output}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** and executor **Memory (GB)**, in gigabytes.\\n            2. For **Dynamically allocated executors**, select the **Disabled** or **Enabled** option.\\n        - If dynamic allocation of executors is **Disabled**, enter the number of **Executor instances**.\\n        - If dynamic allocation of executors is **Enabled**, use the slider to select the minimum and maximum number of executors.\\n        1. For **Driver size**:\\n            1. Enter number of driver **Cores** and driver **Memory (GB)**, in gigabytes.\\n            2. Enter **Name** and **Value** pairs for any **Additional configurations**, then select **Add**. Providing **Additional configurations** is optional.\\n    6. Select **Next**.\\n7. On the **Review** screen:\\nSource: how-to-submit-spark-jobs.md\\n\\nContent: # Configure Apache Spark jobs in Azure Machine Learning\\n\\n- [Code samples for Spark jobs using Azure Machine Learning Python SDK](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/sdk\/python\/jobs\/spark)\\nSource: quickstart-spark-jobs.md \\n\\n chat history: \\n user: \\nwhat is aml? \\nassistant: \\n \\nuser: how to create a spark job? \\nassistant:\",\n  \"stream\": false\n}"}},{"name":"promptflow.function.output","timestamp":"2024-04-11T18:07:46.727347Z","attributes":{"payload":"\"To create a Spark job in Azure Machine Learning, you need to firstly provide a Name and optionally a Value under the **Add tags**. Then in the **Code** section, you need to choose the workspace's default blob storage for code location and select the path of the code file to upload. You then need to input the name of the `titanic.py` as the **Entry file**. \\n\\nNext, you add an input by selecting **+ Add input** under **Inputs** and filling up required fields such as **Input name**, **Input type**, and **Data type**. Similarly, you add an output by selecting **+ Add output** under **Outputs** and entering required information. \\n\\nThen you need to enter **Arguments** for the job. \\n\\nIn the **Spark configurations** section, you can configure parameters such as number of executor cores, memory, and instances. Similarly, configure the driver size. Then, you can add any additional optional configurations. \\n\\nOnce everything is set up, you can review the job specifications and select **Create** to submit the standalone Spark job (Source: quickstart-spark-jobs.md).\\n\\nBear in mind that you have the option to add any necessary Jar files, Py files or Archives for the job under the respective sections (Source: how-to-submit-spark-jobs.md). Also, please note that the job submitted defaults to user identity passthrough for data access (Source: quickstart-spark-jobs.md).\\n\""}}],"links":[],"resource":{"attributes":{"service.name":"promptflow"},"schema_url":""}}],"contentrange":"bytes 0-39584/39585","correlationid":"f1f7413c-a56b-418d-bf32-bcd60c1406df","xrequestid":"f1f7413c-a56b-418d-bf32-bcd60c1406df","modelversion":"default","collectdatatype":"pandas.core.frame.DataFrame","agent":"azureml-ai-monitoring/0.1.0b4"}
{"specversion":"1.0","id":"e82d4230-36e7-4436-8b03-32f8b362a83f","source":"/subscriptions/1aefdc5e-3a7c-4d71-a9f9-f5d3b03be19a/resourceGroups/yuachengtestrg/providers/Microsoft.MachineLearningServices/workspaces/ai-proj-eastus/onlineEndpoints/clone-vivi-log-test/deployments/clone-vivi-log-test-1","type":"azureml.inference.app_traces","datacontenttype":"application/json","time":"2024-04-11T18:07:51Z","data":[{"name":"model","context":{"trace_id":"0xa2f3f4f8267a482fa3bb96ad3e1f7f35","span_id":"0xc2bb84e37668431d","trace_state":"[]"},"kind":"SpanKind.INTERNAL","parent_id":"0x5a7a6a8bba9ac56c","start_time":"2024-04-11T18:07:26.689057Z","end_time":"2024-04-11T18:07:46.731481Z","status":{"status_code":"OK"},"attributes":{"framework":"promptflow","span_type":"Flow","request_id":"ee2f5c78-77c1-4766-802d-49aa4b354ec3","line_run_id":"ee2f5c78-77c1-4766-802d-49aa4b354ec3","inputs":"{\n  \"question\": \"how to create a spark job?\",\n  \"chat_history\": [\n    {\n      \"inputs\": {\n        \"question\": \"what is aml?\"\n      },\n      \"outputs\": {\n        \"answer\": \"Azure Machine Learning (AML) is a cloud service used for accelerating and managing the machine learning project lifecycle. It is designed for ML professionals, data scientists, and engineers to facilitate their daily workflows in training and deploying models and managing machine learning operations (MLOps). You can create models in AML or use models built from open-source platforms like PyTorch, TensorFlow, or scikit-learn. Furthermore, Azure Machine Learning provides tools for monitoring, retraining, and redeploying models(Source: overview-what-is-azure-machine-learning.md).\"\n      }\n    }\n  ]\n}","__computed__.cumulative_token_count.prompt":2119,"__computed__.cumulative_token_count.completion":309,"__computed__.cumulative_token_count.total":2428,"output":"{\n  \"answer\": \"To create a Spark job in Azure Machine Learning, you need to firstly provide a Name and optionally a Value under the **Add tags**. Then in the **Code** section, you need to choose the workspace's default blob storage for code location and select the path of the code file to upload. You then need to input the name of the `titanic.py` as the **Entry file**. \\n\\nNext, you add an input by selecting **+ Add input** under **Inputs** and filling up required fields such as **Input name**, **Input type**, and **Data type**. Similarly, you add an output by selecting **+ Add output** under **Outputs** and entering required information. \\n\\nThen you need to enter **Arguments** for the job. \\n\\nIn the **Spark configurations** section, you can configure parameters such as number of executor cores, memory, and instances. Similarly, configure the driver size. Then, you can add any additional optional configurations. \\n\\nOnce everything is set up, you can review the job specifications and select **Create** to submit the standalone Spark job (Source: quickstart-spark-jobs.md).\\n\\nBear in mind that you have the option to add any necessary Jar files, Py files or Archives for the job under the respective sections (Source: how-to-submit-spark-jobs.md). Also, please note that the job submitted defaults to user identity passthrough for data access (Source: quickstart-spark-jobs.md).\\n\"\n}"},"events":[{"name":"promptflow.function.inputs","timestamp":"2024-04-11T18:07:26.689803Z","attributes":{"payload":"{\n  \"question\": \"how to create a spark job?\",\n  \"chat_history\": [\n    {\n      \"inputs\": {\n        \"question\": \"what is aml?\"\n      },\n      \"outputs\": {\n        \"answer\": \"Azure Machine Learning (AML) is a cloud service used for accelerating and managing the machine learning project lifecycle. It is designed for ML professionals, data scientists, and engineers to facilitate their daily workflows in training and deploying models and managing machine learning operations (MLOps). You can create models in AML or use models built from open-source platforms like PyTorch, TensorFlow, or scikit-learn. Furthermore, Azure Machine Learning provides tools for monitoring, retraining, and redeploying models(Source: overview-what-is-azure-machine-learning.md).\"\n      }\n    }\n  ]\n}"}},{"name":"promptflow.function.output","timestamp":"2024-04-11T18:07:46.731454Z","attributes":{"payload":"{\n  \"answer\": \"To create a Spark job in Azure Machine Learning, you need to firstly provide a Name and optionally a Value under the **Add tags**. Then in the **Code** section, you need to choose the workspace's default blob storage for code location and select the path of the code file to upload. You then need to input the name of the `titanic.py` as the **Entry file**. \\n\\nNext, you add an input by selecting **+ Add input** under **Inputs** and filling up required fields such as **Input name**, **Input type**, and **Data type**. Similarly, you add an output by selecting **+ Add output** under **Outputs** and entering required information. \\n\\nThen you need to enter **Arguments** for the job. \\n\\nIn the **Spark configurations** section, you can configure parameters such as number of executor cores, memory, and instances. Similarly, configure the driver size. Then, you can add any additional optional configurations. \\n\\nOnce everything is set up, you can review the job specifications and select **Create** to submit the standalone Spark job (Source: quickstart-spark-jobs.md).\\n\\nBear in mind that you have the option to add any necessary Jar files, Py files or Archives for the job under the respective sections (Source: how-to-submit-spark-jobs.md). Also, please note that the job submitted defaults to user identity passthrough for data access (Source: quickstart-spark-jobs.md).\\n\"\n}"}}],"links":[],"resource":{"attributes":{"service.name":"promptflow"},"schema_url":""}}],"xrequestid":"70733cba-de6a-4430-b8fd-d545773d3285","modelversion":"default","collectdatatype":"pandas.core.frame.DataFrame","agent":"azureml-ai-monitoring/0.1.0b4","contentrange":"bytes 0-5399/5400","correlationid":"70733cba-de6a-4430-b8fd-d545773d3285"}
{"specversion":"1.0","id":"7ea95201-bb94-4d6b-a768-6b12f08f80d8","source":"/subscriptions/1aefdc5e-3a7c-4d71-a9f9-f5d3b03be19a/resourceGroups/yuachengtestrg/providers/Microsoft.MachineLearningServices/workspaces/ai-proj-eastus/onlineEndpoints/clone-vivi-log-test/deployments/clone-vivi-log-test-1","type":"azureml.inference.app_traces","datacontenttype":"application/json","time":"2024-04-11T18:08:06Z","data":[{"name":"openai_chat","context":{"trace_id":"0xa2f3f4f8267a482fa3bb96ad3e1f7f35","span_id":"0x39e48aa9cb90df08","trace_state":"[]"},"kind":"SpanKind.INTERNAL","parent_id":"0xaab71da957eadc51","start_time":"2024-04-11T18:08:03.681903Z","end_time":"2024-04-11T18:08:05.429217Z","status":{"status_code":"OK"},"attributes":{"framework":"promptflow","span_type":"LLM","function":"openai.resources.chat.completions.Completions.create","node_name":"modify_query_with_history","request_id":"8d0a7bf5-bd46-4c69-95b6-e2cc925bfa4c","line_run_id":"8d0a7bf5-bd46-4c69-95b6-e2cc925bfa4c","inputs":"{\n  \"model\": \"gpt-4-32k\",\n  \"messages\": [\n    {\n      \"role\": \"system\",\n      \"content\": \"Given the following conversation history and the users next question,rephrase the question to be a stand alone question.\\nIf the conversation is irrelevant or empty, just restate the original question.\\nDo not add more details than necessary to the question.\\nconversation:\\n\\n chat history:\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"what is aml?\"\n    },\n    {\n      \"role\": \"assistant\",\n      \"content\": \"\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"how to create a spark job?\"\n    },\n    {\n      \"role\": \"assistant\",\n      \"content\": \"\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"Follow up Input: thank you \\nStandalone Question:\"\n    }\n  ],\n  \"temperature\": 1.0,\n  \"top_p\": 1.0,\n  \"n\": 1,\n  \"stream\": false,\n  \"presence_penalty\": 0.0,\n  \"frequency_penalty\": 0.0,\n  \"user\": \"\",\n  \"max_tokens\": 16\n}","llm.response.model":"gpt-4-32k","llm.generated_message":"{\n  \"content\": \"What are the steps to create a Spark job?\",\n  \"role\": \"assistant\",\n  \"function_call\": null,\n  \"tool_calls\": null\n}","__computed__.cumulative_token_count.completion":10,"__computed__.cumulative_token_count.prompt":102,"__computed__.cumulative_token_count.total":112,"llm.usage.completion_tokens":10,"llm.usage.prompt_tokens":102,"llm.usage.total_tokens":112,"output":"{\n  \"id\": \"chatcmpl-9Ct88aGDkYLJcDBaMtxS9ry7ntdHr\",\n  \"choices\": [\n    {\n      \"finish_reason\": \"stop\",\n      \"index\": 0,\n      \"logprobs\": null,\n      \"message\": {\n        \"content\": \"What are the steps to create a Spark job?\",\n        \"role\": \"assistant\",\n        \"function_call\": null,\n        \"tool_calls\": null\n      },\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ],\n  \"created\": 1712858884,\n  \"model\": \"gpt-4-32k\",\n  \"object\": \"chat.completion\",\n  \"system_fingerprint\": null,\n  \"usage\": {\n    \"completion_tokens\": 10,\n    \"prompt_tokens\": 102,\n    \"total_tokens\": 112\n  },\n  \"prompt_filter_results\": [\n    {\n      \"prompt_index\": 0,\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ]\n}"},"events":[{"name":"promptflow.function.inputs","timestamp":"2024-04-11T18:08:03.688491Z","attributes":{"payload":"{\n  \"model\": \"gpt-4-32k\",\n  \"messages\": [\n    {\n      \"role\": \"system\",\n      \"content\": \"Given the following conversation history and the users next question,rephrase the question to be a stand alone question.\\nIf the conversation is irrelevant or empty, just restate the original question.\\nDo not add more details than necessary to the question.\\nconversation:\\n\\n chat history:\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"what is aml?\"\n    },\n    {\n      \"role\": \"assistant\",\n      \"content\": \"\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"how to create a spark job?\"\n    },\n    {\n      \"role\": \"assistant\",\n      \"content\": \"\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"Follow up Input: thank you \\nStandalone Question:\"\n    }\n  ],\n  \"temperature\": 1.0,\n  \"top_p\": 1.0,\n  \"n\": 1,\n  \"stream\": false,\n  \"presence_penalty\": 0.0,\n  \"frequency_penalty\": 0.0,\n  \"user\": \"\",\n  \"max_tokens\": 16\n}"}},{"name":"promptflow.llm.generated_message","timestamp":"2024-04-11T18:08:05.425789Z","attributes":{"payload":"{\n  \"content\": \"What are the steps to create a Spark job?\",\n  \"role\": \"assistant\",\n  \"function_call\": null,\n  \"tool_calls\": null\n}"}},{"name":"promptflow.function.output","timestamp":"2024-04-11T18:08:05.428758Z","attributes":{"payload":"{\n  \"id\": \"chatcmpl-9Ct88aGDkYLJcDBaMtxS9ry7ntdHr\",\n  \"choices\": [\n    {\n      \"finish_reason\": \"stop\",\n      \"index\": 0,\n      \"logprobs\": null,\n      \"message\": {\n        \"content\": \"What are the steps to create a Spark job?\",\n        \"role\": \"assistant\",\n        \"function_call\": null,\n        \"tool_calls\": null\n      },\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ],\n  \"created\": 1712858884,\n  \"model\": \"gpt-4-32k\",\n  \"object\": \"chat.completion\",\n  \"system_fingerprint\": null,\n  \"usage\": {\n    \"completion_tokens\": 10,\n    \"prompt_tokens\": 102,\n    \"total_tokens\": 112\n  },\n  \"prompt_filter_results\": [\n    {\n      \"prompt_index\": 0,\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ]\n}"}}],"links":[],"resource":{"attributes":{"service.name":"promptflow"},"schema_url":""}}],"contentrange":"bytes 0-6889/6890","correlationid":"ca4f2ac3-de4f-4f7c-98e0-59ab7e9d0942","xrequestid":"ca4f2ac3-de4f-4f7c-98e0-59ab7e9d0942","modelversion":"default","collectdatatype":"pandas.core.frame.DataFrame","agent":"azureml-ai-monitoring/0.1.0b4"}
{"specversion":"1.0","id":"8181b9b4-638a-4e14-9280-a03d0b759768","source":"/subscriptions/1aefdc5e-3a7c-4d71-a9f9-f5d3b03be19a/resourceGroups/yuachengtestrg/providers/Microsoft.MachineLearningServices/workspaces/ai-proj-eastus/onlineEndpoints/clone-vivi-log-test/deployments/clone-vivi-log-test-1","type":"azureml.inference.app_traces","datacontenttype":"application/json","time":"2024-04-11T18:08:06Z","data":[{"name":"modify_query_with_history","context":{"trace_id":"0xa2f3f4f8267a482fa3bb96ad3e1f7f35","span_id":"0xaab71da957eadc51","trace_state":"[]"},"kind":"SpanKind.INTERNAL","parent_id":"0x22865871c42ca40c","start_time":"2024-04-11T18:08:03.669788Z","end_time":"2024-04-11T18:08:05.429816Z","status":{"status_code":"OK"},"attributes":{"framework":"promptflow","span_type":"Function","function":"AzureOpenAI.chat","node_name":"modify_query_with_history","request_id":"8d0a7bf5-bd46-4c69-95b6-e2cc925bfa4c","line_run_id":"8d0a7bf5-bd46-4c69-95b6-e2cc925bfa4c","prompt.template":"system: \nGiven the following conversation history and the users next question,rephrase the question to be a stand alone question.\nIf the conversation is irrelevant or empty, just restate the original question.\nDo not add more details than necessary to the question.\nconversation:\n\n chat history: \n{% for item in chat_history %} user: \n{{ item.inputs.question }} \nassistant: \n{{ item.outputs.output }} \n{% endfor %}\n\nuser:\nFollow up Input: {{question}} \nStandalone Question:","prompt.variables":"{\n  \"question\": \"thank you\",\n  \"chat_history\": [\n    {\n      \"inputs\": {\n        \"question\": \"what is aml?\"\n      },\n      \"outputs\": {\n        \"answer\": \"Azure Machine Learning (AML) is a cloud service used for accelerating and managing the machine learning project lifecycle. It is designed for ML professionals, data scientists, and engineers to facilitate their daily workflows in training and deploying models and managing machine learning operations (MLOps). You can create models in AML or use models built from open-source platforms like PyTorch, TensorFlow, or scikit-learn. Furthermore, Azure Machine Learning provides tools for monitoring, retraining, and redeploying models(Source: overview-what-is-azure-machine-learning.md).\"\n      }\n    },\n    {\n      \"inputs\": {\n        \"question\": \"how to create a spark job?\"\n      },\n      \"outputs\": {\n        \"answer\": \"To create a Spark job in Azure Machine Learning, you need to firstly provide a Name and optionally a Value under the **Add tags**. Then in the **Code** section, you need to choose the workspace's default blob storage for code location and select the path of the code file to upload. You then need to input the name of the `titanic.py` as the **Entry file**. \\n\\nNext, you add an input by selecting **+ Add input** under **Inputs** and filling up required fields such as **Input name**, **Input type**, and **Data type**. Similarly, you add an output by selecting **+ Add output** under **Outputs** and entering required information. \\n\\nThen you need to enter **Arguments** for the job. \\n\\nIn the **Spark configurations** section, you can configure parameters such as number of executor cores, memory, and instances. Similarly, configure the driver size. Then, you can add any additional optional configurations. \\n\\nOnce everything is set up, you can review the job specifications and select **Create** to submit the standalone Spark job (Source: quickstart-spark-jobs.md).\\n\\nBear in mind that you have the option to add any necessary Jar files, Py files or Archives for the job under the respective sections (Source: how-to-submit-spark-jobs.md). Also, please note that the job submitted defaults to user identity passthrough for data access (Source: quickstart-spark-jobs.md).\\n\"\n      }\n    }\n  ]\n}","inputs":"{\n  \"prompt\": \"system: \\nGiven the following conversation history and the users next question,rephrase the question to be a stand alone question.\\nIf the conversation is irrelevant or empty, just restate the original question.\\nDo not add more details than necessary to the question.\\nconversation:\\n\\n chat history: \\n{% for item in chat_history %} user: \\n{{ item.inputs.question }} \\nassistant: \\n{{ item.outputs.output }} \\n{% endfor %}\\n\\nuser:\\nFollow up Input: {{question}} \\nStandalone Question:\",\n  \"deployment_name\": \"gpt-4-32k\",\n  \"temperature\": 1.0,\n  \"top_p\": 1.0,\n  \"max_tokens\": 16,\n  \"presence_penalty\": 0.0,\n  \"frequency_penalty\": 0.0,\n  \"chat_history\": [\n    {\n      \"inputs\": {\n        \"question\": \"what is aml?\"\n      },\n      \"outputs\": {\n        \"answer\": \"Azure Machine Learning (AML) is a cloud service used for accelerating and managing the machine learning project lifecycle. It is designed for ML professionals, data scientists, and engineers to facilitate their daily workflows in training and deploying models and managing machine learning operations (MLOps). You can create models in AML or use models built from open-source platforms like PyTorch, TensorFlow, or scikit-learn. Furthermore, Azure Machine Learning provides tools for monitoring, retraining, and redeploying models(Source: overview-what-is-azure-machine-learning.md).\"\n      }\n    },\n    {\n      \"inputs\": {\n        \"question\": \"how to create a spark job?\"\n      },\n      \"outputs\": {\n        \"answer\": \"To create a Spark job in Azure Machine Learning, you need to firstly provide a Name and optionally a Value under the **Add tags**. Then in the **Code** section, you need to choose the workspace's default blob storage for code location and select the path of the code file to upload. You then need to input the name of the `titanic.py` as the **Entry file**. \\n\\nNext, you add an input by selecting **+ Add input** under **Inputs** and filling up required fields such as **Input name**, **Input type**, and **Data type**. Similarly, you add an output by selecting **+ Add output** under **Outputs** and entering required information. \\n\\nThen you need to enter **Arguments** for the job. \\n\\nIn the **Spark configurations** section, you can configure parameters such as number of executor cores, memory, and instances. Similarly, configure the driver size. Then, you can add any additional optional configurations. \\n\\nOnce everything is set up, you can review the job specifications and select **Create** to submit the standalone Spark job (Source: quickstart-spark-jobs.md).\\n\\nBear in mind that you have the option to add any necessary Jar files, Py files or Archives for the job under the respective sections (Source: how-to-submit-spark-jobs.md). Also, please note that the job submitted defaults to user identity passthrough for data access (Source: quickstart-spark-jobs.md).\\n\"\n      }\n    }\n  ],\n  \"question\": \"thank you\"\n}","__computed__.cumulative_token_count.completion":10,"__computed__.cumulative_token_count.prompt":102,"__computed__.cumulative_token_count.total":112,"output":"\"What are the steps to create a Spark job?\""},"events":[{"name":"promptflow.prompt.template","timestamp":"2024-04-11T18:08:03.674470Z","attributes":{"payload":"{\n  \"prompt.template\": \"system: \\nGiven the following conversation history and the users next question,rephrase the question to be a stand alone question.\\nIf the conversation is irrelevant or empty, just restate the original question.\\nDo not add more details than necessary to the question.\\nconversation:\\n\\n chat history: \\n{% for item in chat_history %} user: \\n{{ item.inputs.question }} \\nassistant: \\n{{ item.outputs.output }} \\n{% endfor %}\\n\\nuser:\\nFollow up Input: {{question}} \\nStandalone Question:\",\n  \"prompt.variables\": \"{\\n  \\\"question\\\": \\\"thank you\\\",\\n  \\\"chat_history\\\": [\\n    {\\n      \\\"inputs\\\": {\\n        \\\"question\\\": \\\"what is aml?\\\"\\n      },\\n      \\\"outputs\\\": {\\n        \\\"answer\\\": \\\"Azure Machine Learning (AML) is a cloud service used for accelerating and managing the machine learning project lifecycle. It is designed for ML professionals, data scientists, and engineers to facilitate their daily workflows in training and deploying models and managing machine learning operations (MLOps). You can create models in AML or use models built from open-source platforms like PyTorch, TensorFlow, or scikit-learn. Furthermore, Azure Machine Learning provides tools for monitoring, retraining, and redeploying models(Source: overview-what-is-azure-machine-learning.md).\\\"\\n      }\\n    },\\n    {\\n      \\\"inputs\\\": {\\n        \\\"question\\\": \\\"how to create a spark job?\\\"\\n      },\\n      \\\"outputs\\\": {\\n        \\\"answer\\\": \\\"To create a Spark job in Azure Machine Learning, you need to firstly provide a Name and optionally a Value under the **Add tags**. Then in the **Code** section, you need to choose the workspace's default blob storage for code location and select the path of the code file to upload. You then need to input the name of the `titanic.py` as the **Entry file**. \\\\n\\\\nNext, you add an input by selecting **+ Add input** under **Inputs** and filling up required fields such as **Input name**, **Input type**, and **Data type**. Similarly, you add an output by selecting **+ Add output** under **Outputs** and entering required information. \\\\n\\\\nThen you need to enter **Arguments** for the job. \\\\n\\\\nIn the **Spark configurations** section, you can configure parameters such as number of executor cores, memory, and instances. Similarly, configure the driver size. Then, you can add any additional optional configurations. \\\\n\\\\nOnce everything is set up, you can review the job specifications and select **Create** to submit the standalone Spark job (Source: quickstart-spark-jobs.md).\\\\n\\\\nBear in mind that you have the option to add any necessary Jar files, Py files or Archives for the job under the respective sections (Source: how-to-submit-spark-jobs.md). Also, please note that the job submitted defaults to user identity passthrough for data access (Source: quickstart-spark-jobs.md).\\\\n\\\"\\n      }\\n    }\\n  ]\\n}\"\n}"}},{"name":"promptflow.function.inputs","timestamp":"2024-04-11T18:08:03.678217Z","attributes":{"payload":"{\n  \"prompt\": \"system: \\nGiven the following conversation history and the users next question,rephrase the question to be a stand alone question.\\nIf the conversation is irrelevant or empty, just restate the original question.\\nDo not add more details than necessary to the question.\\nconversation:\\n\\n chat history: \\n{% for item in chat_history %} user: \\n{{ item.inputs.question }} \\nassistant: \\n{{ item.outputs.output }} \\n{% endfor %}\\n\\nuser:\\nFollow up Input: {{question}} \\nStandalone Question:\",\n  \"deployment_name\": \"gpt-4-32k\",\n  \"temperature\": 1.0,\n  \"top_p\": 1.0,\n  \"max_tokens\": 16,\n  \"presence_penalty\": 0.0,\n  \"frequency_penalty\": 0.0,\n  \"chat_history\": [\n    {\n      \"inputs\": {\n        \"question\": \"what is aml?\"\n      },\n      \"outputs\": {\n        \"answer\": \"Azure Machine Learning (AML) is a cloud service used for accelerating and managing the machine learning project lifecycle. It is designed for ML professionals, data scientists, and engineers to facilitate their daily workflows in training and deploying models and managing machine learning operations (MLOps). You can create models in AML or use models built from open-source platforms like PyTorch, TensorFlow, or scikit-learn. Furthermore, Azure Machine Learning provides tools for monitoring, retraining, and redeploying models(Source: overview-what-is-azure-machine-learning.md).\"\n      }\n    },\n    {\n      \"inputs\": {\n        \"question\": \"how to create a spark job?\"\n      },\n      \"outputs\": {\n        \"answer\": \"To create a Spark job in Azure Machine Learning, you need to firstly provide a Name and optionally a Value under the **Add tags**. Then in the **Code** section, you need to choose the workspace's default blob storage for code location and select the path of the code file to upload. You then need to input the name of the `titanic.py` as the **Entry file**. \\n\\nNext, you add an input by selecting **+ Add input** under **Inputs** and filling up required fields such as **Input name**, **Input type**, and **Data type**. Similarly, you add an output by selecting **+ Add output** under **Outputs** and entering required information. \\n\\nThen you need to enter **Arguments** for the job. \\n\\nIn the **Spark configurations** section, you can configure parameters such as number of executor cores, memory, and instances. Similarly, configure the driver size. Then, you can add any additional optional configurations. \\n\\nOnce everything is set up, you can review the job specifications and select **Create** to submit the standalone Spark job (Source: quickstart-spark-jobs.md).\\n\\nBear in mind that you have the option to add any necessary Jar files, Py files or Archives for the job under the respective sections (Source: how-to-submit-spark-jobs.md). Also, please note that the job submitted defaults to user identity passthrough for data access (Source: quickstart-spark-jobs.md).\\n\"\n      }\n    }\n  ],\n  \"question\": \"thank you\"\n}"}},{"name":"promptflow.function.output","timestamp":"2024-04-11T18:08:05.429649Z","attributes":{"payload":"\"What are the steps to create a Spark job?\""}}],"links":[],"resource":{"attributes":{"service.name":"promptflow"},"schema_url":""}}],"agent":"azureml-ai-monitoring/0.1.0b4","contentrange":"bytes 0-13182/13183","correlationid":"34af1c16-b6e4-4889-a873-effb05ca3648","xrequestid":"34af1c16-b6e4-4889-a873-effb05ca3648","modelversion":"default","collectdatatype":"pandas.core.frame.DataFrame"}
{"specversion":"1.0","id":"475c0d63-c895-4c84-853c-72fc55081f58","source":"/subscriptions/1aefdc5e-3a7c-4d71-a9f9-f5d3b03be19a/resourceGroups/yuachengtestrg/providers/Microsoft.MachineLearningServices/workspaces/ai-proj-eastus/onlineEndpoints/clone-vivi-log-test/deployments/clone-vivi-log-test-1","type":"azureml.inference.app_traces","datacontenttype":"application/json","time":"2024-04-11T18:08:06Z","data":[{"name":"openai_embeddings","context":{"trace_id":"0xa2f3f4f8267a482fa3bb96ad3e1f7f35","span_id":"0xd24b7aaaeb12c81c","trace_state":"[]"},"kind":"SpanKind.INTERNAL","parent_id":"0xa265310d5ea11b31","start_time":"2024-04-11T18:08:05.439477Z","end_time":"2024-04-11T18:08:06.454050Z","status":{"status_code":"OK"},"attributes":{"framework":"promptflow","span_type":"Embedding","function":"openai.resources.embeddings.Embeddings.create","node_name":"lookup","request_id":"8d0a7bf5-bd46-4c69-95b6-e2cc925bfa4c","line_run_id":"8d0a7bf5-bd46-4c69-95b6-e2cc925bfa4c","inputs":"{\n  \"input\": [\n    [\n      3923,\n      527,\n      279,\n      7504,\n      311,\n      1893,\n      264,\n      27565,\n      2683,\n      30\n    ]\n  ],\n  \"model\": \"text-embedding-ada-002\"\n}","llm.response.model":"ada","embedding.embeddings":"[\n  {\n    \"embedding.vector\": \"\u003c1536 dimensional vector\u003e\",\n    \"embedding.text\": \"\u003c10 dimensional token\u003e\"\n  }\n]","__computed__.cumulative_token_count.prompt":10,"__computed__.cumulative_token_count.total":10,"llm.usage.prompt_tokens":10,"llm.usage.total_tokens":10,"output":"{\n  \"data\": [\n    {\n      \"embedding\": [\n        -0.0094194570556283,\n        -0.016255056485533714,\n        -0.021914932876825333,\n        -0.019823240116238594,\n        -0.010615686886012554,\n        0.005359110422432423,\n        -0.013637022115290165,\n        -0.02038375847041607,\n        -0.02170986495912075,\n        -0.017047986388206482,\n        -0.0013269608607515693,\n        0.005205309484153986,\n        -0.015762893483042717,\n        -0.005882033612579107,\n        -0.0031101980712264776,\n        -0.001731970114633441,\n        0.008312089368700981,\n        -0.02667251043021679,\n        0.012809914536774158,\n        -0.018497133627533913,\n        -0.039537109434604645,\n        0.012864599004387856,\n        0.014477800577878952,\n        -0.002741075586527586,\n        0.005157459992915392,\n        0.009105019271373749,\n        0.01611834391951561,\n        0.008749567903578281,\n        -0.0019344747997820377,\n        3.212198134860955e-05,\n        0.005427466239780188,\n        -0.01030808500945568,\n        -0.012816749513149261,\n        -0.026385415345430374,\n        -0.03606462478637695,\n        0.01669253595173359,\n        -0.00877007469534874,\n        -0.005174549296498299,\n        -0.0033374817576259375,\n        -0.026084650307893753,\n        0.0278208926320076,\n        0.0127894077450037,\n        -0.008093350566923618,\n        -0.0069347163662314415,\n        -0.0062409029342234135,\n        0.021778222173452377,\n        -0.023596491664648056,\n        -0.01566719450056553,\n        0.008004487492144108,\n        0.0067125591449439526,\n        0.0035784365609288216,\n        -0.002146378392353654,\n        -0.056653451174497604,\n        0.012536490336060524,\n        0.017430780455470085,\n        -0.006452806293964386,\n        0.004624283406883478,\n        0.03322101756930351,\n        -0.009774908423423767,\n        -0.003163173794746399,\n        0.003626285819336772,\n        -0.0057555753737688065,\n        -0.01699330098927021,\n        0.014327417127788067,\n        -0.0010219222167506814,\n        -0.013821583241224289,\n        0.0069107916206121445,\n        0.008817924186587334,\n        -0.02210633084177971,\n        -0.008359938859939575,\n        0.06168445572257042,\n        0.003275961382314563,\n        -0.006247738376259804,\n        0.008975142613053322,\n        0.0013286697212606668,\n        -0.001356012187898159,\n        -0.006480148993432522,\n        -0.024061311036348343,\n        0.012242559343576431,\n        0.014792238362133503,\n        0.002252330305054784,\n        0.013794240541756153,\n        -0.04175184294581413,\n        0.020916935056447983,\n        0.002252330305054784,\n        0.006497237831354141,\n        -0.005010494962334633,\n        0.0016619052039459348,\n        -0.01236560009419918,\n        -0.001225281273946166,\n        0.002394168870523572,\n        -0.00019342612358741462,\n        0.02016502059996128,\n        0.0030025371816009283,\n        0.006257991772145033,\n        0.014354759827256203,\n        0.010041496716439724,\n        -0.013226886279881,\n        0.017403436824679375,\n        -0.033275701105594635,\n        -0.013281570747494698,\n        0.00011342823563609272,\n        -0.03551777824759483,\n        -0.010014154016971588,\n        -0.02195594646036625,\n        -0.0015781691763550043,\n        0.0037048952654004097,\n        -0.0110394936054945,\n        0.01844244822859764,\n        0.00933059398084879,\n        0.0059025404043495655,\n        0.009214389137923717,\n        -0.019180692732334137,\n        -0.04084954410791397,\n        -0.017047986388206482,\n        -0.009139196947216988,\n        0.00798398070037365,\n        -0.023596491664648056,\n        -0.011155699379742146,\n        -0.026070978492498398,\n        0.03059614636003971,\n        0.033248357474803925,\n        0.036666158586740494,\n        -0.02510032244026661,\n        0.021819235756993294,\n        -0.015229716897010803,\n        -0.010096181184053421,\n        -0.020602498203516006,\n        0.014915279112756252,\n        -0.023350410163402557,\n        0.017676861956715584,\n        0.015120347030460835,\n        0.003964648116379976,\n        0.00618280004709959,\n        -0.03461547940969467,\n        0.013117516413331032,\n        0.0026932263281196356,\n        -0.0001705695758573711,\n        -0.0288188885897398,\n        -0.013671199791133404,\n        0.028408752754330635,\n        0.023719532415270805,\n        0.008414623327553272,\n        -0.016337083652615547,\n        0.02996727079153061,\n        -0.00538303516805172,\n        0.012481805868446827,\n        -0.01326106395572424,\n        -0.015475798398256302,\n        -0.021819235756993294,\n        -0.00028410463710315526,\n        -0.005646205507218838,\n        0.016460124403238297,\n        -0.013917281292378902,\n        -0.0011603430612012744,\n        0.014983635395765305,\n        0.0008706845692358911,\n        0.013247393071651459,\n        -0.0053249322809278965,\n        0.00040351401548832655,\n        0.03800593689084053,\n        0.04199792444705963,\n        0.03190857917070389,\n        -0.008387281559407711,\n        -0.011374438181519508,\n        0.029064971953630447,\n        0.01913967914879322,\n        -0.013172200880944729,\n        -0.008079678751528263,\n        -0.00330672156997025,\n        -0.010075674392282963,\n        -0.01445045880973339,\n        -0.03806062042713165,\n        0.03313899040222168,\n        -0.010615686886012554,\n        0.014942621812224388,\n        0.003619450144469738,\n        -0.002723986515775323,\n        0.00213954271748662,\n        -0.006681798957288265,\n        0.020930606871843338,\n        -0.005468479823321104,\n        0.005099357571452856,\n        0.009480977430939674,\n        -0.014874265529215336,\n        -0.011333424597978592,\n        -0.010663536377251148,\n        -0.020342744886875153,\n        0.00956983957439661,\n        -0.009378443472087383,\n        0.010718220844864845,\n        0.013650692999362946,\n        -0.01654215157032013,\n        0.01315169408917427,\n        -0.6430932283401489,\n        -0.024471448734402657,\n        0.012256231158971786,\n        -0.034396737813949585,\n        -0.013637022115290165,\n        -0.008202720433473587,\n        -0.0019566905684769154,\n        -0.03341241180896759,\n        -0.0052702478133141994,\n        0.015380100347101688,\n        0.01134026050567627,\n        0.02228405512869358,\n        0.03226403146982193,\n        -0.002007957547903061,\n        -0.00907084159553051,\n        -0.009884277358651161,\n        0.02527804858982563,\n        -0.021696195006370544,\n        -0.02140909992158413,\n        0.02879154682159424,\n        -0.026180347427725792,\n        -0.013903610408306122,\n        -0.0034297623205929995,\n        -0.017253054305911064,\n        0.0035579297691583633,\n        -0.009597182273864746,\n        -0.0021703029051423073,\n        -0.014218048192560673,\n        0.003463940229266882,\n        -0.017512807622551918,\n        -0.0017242800677195191,\n        0.00011823451495729387,\n        0.019823240116238594,\n        0.0026795552112162113,\n        0.031225020065903664,\n        0.004996823612600565,\n        -0.03598259761929512,\n        0.022762548178434372,\n        -0.008359938859939575,\n        0.06742636114358902,\n        -0.03516232594847679,\n        -0.016227714717388153,\n        0.018073325976729393,\n        -0.016514809802174568,\n        0.0014423115644603968,\n        -0.003453686833381653,\n        -0.00470972852781415,\n        -0.004159462638199329,\n        -0.0008224081248044968,\n        0.018251052126288414,\n        0.019331077113747597,\n        -0.011114685796201229,\n        -0.00037189936847425997,\n        0.010178208351135254,\n        0.007799419574439526,\n        -0.007115859538316727,\n        0.017006972804665565,\n        0.0005036982474848628,\n        -0.00652458006516099,\n        0.02315901219844818,\n        0.003892874112352729,\n        -0.0023429018910974264,\n        -0.013404611498117447,\n        -0.030896911397576332,\n        -0.009392114356160164,\n        0.006292169913649559,\n        -0.013117516413331032,\n        -0.016309741884469986,\n        0.009891113266348839,\n        -0.03456079214811325,\n        0.00696205860003829,\n        -0.0010424290085211396,\n        0.0011201839661225677,\n        -0.012427120469510555,\n        -0.006531415972858667,\n        0.0033050125930458307,\n        0.0003601506759878248,\n        -0.004402126185595989,\n        0.006647620815783739,\n        -0.007525995373725891,\n        0.006592936348170042,\n        -0.008079678751528263,\n        -0.03535372391343117,\n        -0.003137540305033326,\n        -0.010465303435921669,\n        0.008243734017014503,\n        -0.02283090353012085,\n        -0.04109562560915947,\n        0.015051990747451782,\n        0.013404611498117447,\n        0.02890091761946678,\n        0.015448455698788166,\n        -0.005051508545875549,\n        -0.045579779893159866,\n        -0.008462472818791866,\n        0.013671199791133404,\n        0.027164673432707787,\n        -0.004361112602055073,\n        -0.004323516972362995,\n        -0.007778912782669067,\n        -0.023637505248188972,\n        0.007833597250282764,\n        -0.0028487362433224916,\n        -0.0006797149544581771,\n        0.037295032292604446,\n        -0.009617689065635204,\n        -0.028408752754330635,\n        -0.009269073605537415,\n        0.029283709824085236,\n        -0.017704203724861145,\n        -0.005984567571431398,\n        0.01656949520111084,\n        -0.021149346604943275,\n        -0.0014670906821265817,\n        -0.012721051461994648,\n        -0.033877234905958176,\n        0.030732857063412666,\n        -0.008606020361185074,\n        0.017225712537765503,\n        -0.014532485976815224,\n        -0.001320979674346745,\n        0.0050241658464074135,\n        0.008318925276398659,\n        -0.0049318852834403515,\n        -0.010383276268839836,\n        0.026918591931462288,\n        0.007908789440989494,\n        -0.004532002843916416,\n        0.007874610833823681,\n        -0.02437574975192547,\n        -0.012639024294912815,\n        0.010164537467062473,\n        0.015940619632601738,\n        0.008776910603046417,\n        0.017198368906974792,\n        -0.0014371848665177822,\n        -0.006545086856931448,\n        0.006924462970346212,\n        -0.0058341845870018005,\n        -0.023336738348007202,\n        -0.01893461123108864,\n        0.011572671122848988,\n        -0.005899122916162014,\n        -0.012057998217642307,\n        -0.01055416651070118,\n        0.0012039199937134981,\n        -0.02031540311872959,\n        -0.0036946418695151806,\n        -0.00784726906567812,\n        -0.006093937437981367,\n        -0.013507145456969738,\n        -0.004559345077723265,\n        -0.013199543580412865,\n        0.020370088517665863,\n        0.008749567903578281,\n        -0.007744734641164541,\n        0.005328350234776735,\n        -0.019303733482956886,\n        -0.00683218240737915,\n        -0.03513498231768608,\n        0.006292169913649559,\n        0.0356818325817585,\n        -0.019631844013929367,\n        0.006391285918653011,\n        -0.026139333844184875,\n        -0.015790235251188278,\n        -0.01056783739477396,\n        -0.013855760917067528,\n        0.003091400023549795,\n        -0.032072633504867554,\n        0.02258482202887535,\n        -0.025592485442757607,\n        -0.007102188188582659,\n        0.02742442674934864,\n        -0.012064834125339985,\n        0.014327417127788067,\n        -0.014682868495583534,\n        -0.0035852722357958555,\n        0.013548159040510654,\n        0.0030435509979724884,\n        -0.008353102952241898,\n        0.019344747066497803,\n        -0.01689760386943817,\n        0.002274545840919018,\n        0.01099164504557848,\n        0.030076639726758003,\n        0.0068048397079110146,\n        0.005550506990402937,\n        -0.035271696746349335,\n        0.0048396047204732895,\n        -0.009241730906069279,\n        0.03587322682142258,\n        0.035545118153095245,\n        0.010226057842373848,\n        0.011183041147887707,\n        0.02437574975192547,\n        -0.00952199101448059,\n        -0.021327072754502296,\n        -0.016049988567829132,\n        0.006220396142452955,\n        0.032072633504867554,\n        0.011764067225158215,\n        -0.006654456723481417,\n        -0.00427908543497324,\n        0.013336255215108395,\n        -0.02942042239010334,\n        0.019057651981711388,\n        -0.018086997792124748,\n        0.002341192914173007,\n        0.006066595204174519,\n        0.009166539646685123,\n        -0.02138175629079342,\n        -0.015079333446919918,\n        0.002199354348704219,\n        0.01669253595173359,\n        0.0165968369692564,\n        -0.009228060021996498,\n        0.02173720858991146,\n        -0.039263688027858734,\n        0.019358418881893158,\n        0.012509147636592388,\n        -0.0010167955188080668,\n        0.02939308062195778,\n        -0.006866360083222389,\n        -0.01853814721107483,\n        0.01226306613534689,\n        -8.272143895737827e-05,\n        0.0006327202427200973,\n        0.006353690288960934,\n        -0.00964503176510334,\n        0.00808651465922594,\n        -0.01134026050567627,\n        0.0032349477987736464,\n        -0.0017379513010382652,\n        0.04358378425240517,\n        0.014026651158928871,\n        -0.00987060647457838,\n        -0.011723053641617298,\n        0.013637022115290165,\n        0.009446798823773861,\n        -0.007177379913628101,\n        -0.006114444229751825,\n        0.030623488128185272,\n        -0.004436304327100515,\n        0.023719532415270805,\n        0.018797900527715683,\n        0.04946240037679672,\n        0.001576460199430585,\n        0.0019464370561763644,\n        0.03628336638212204,\n        -0.007990816608071327,\n        -0.024485118687152863,\n        -0.018633846193552017,\n        0.026904921978712082,\n        0.005820513237267733,\n        -0.025537801906466484,\n        -0.0026863908860832453,\n        -0.007929296232759953,\n        -0.0063878679648041725,\n        0.03313899040222168,\n        0.006924462970346212,\n        0.01916702277958393,\n        0.03313899040222168,\n        -0.010697714053094387,\n        -0.0002670156245585531,\n        -0.012085340917110443,\n        -0.009036662988364697,\n        -0.011969135142862797,\n        0.0026539217215031385,\n        -0.020342744886875153,\n        6.798217509640381e-05,\n        0.002503538504242897,\n        -0.017335081472992897,\n        -0.029338395223021507,\n        0.020670853555202484,\n        0.021504797041416168,\n        -0.0029102566186338663,\n        0.017376095056533813,\n        0.007539666723459959,\n        0.030650829896330833,\n        -0.029037628322839737,\n        -0.015120347030460835,\n        0.022844575345516205,\n        0.0078609399497509,\n        -0.022776219993829727,\n        -0.019057651981711388,\n        0.011893943883478642,\n        0.00151579431258142,\n        0.010349098592996597,\n        0.020998962223529816,\n        0.013076502829790115,\n        0.002612908137962222,\n        0.0015969669912010431,\n        0.011251397430896759,\n        0.003134122584015131,\n        -0.0008386426488868892,\n        0.02887357398867607,\n        -0.020397430285811424,\n        0.0094194570556283,\n        -0.0017516225343570113,\n        -0.010513152927160263,\n        0.01754014939069748,\n        0.002876078709959984,\n        -0.02475854381918907,\n        0.038416072726249695,\n        -0.002645377302542329,\n        -0.000711756874807179,\n        -0.02016502059996128,\n        -0.0038860386703163385,\n        -0.03595525771379471,\n        -0.004477317910641432,\n        -0.014874265529215336,\n        0.003903127508237958,\n        -0.003091400023549795,\n        0.013630186207592487,\n        -0.01348663866519928,\n        -0.02155948244035244,\n        -0.007785748224705458,\n        0.013336255215108395,\n        0.01759483478963375,\n        0.005003659054636955,\n        -0.023637505248188972,\n        -0.005160877946764231,\n        0.024321064352989197,\n        0.040439408272504807,\n        0.04134170711040497,\n        -0.0044465577229857445,\n        0.009815922006964684,\n        -0.037240348756313324,\n        0.00436794850975275,\n        0.003971483558416367,\n        -0.010096181184053421,\n        -0.0072115580551326275,\n        -0.0008484688587486744,\n        -0.004371365997940302,\n        -0.006257991772145033,\n        0.006422046106308699,\n        -0.012099011801183224,\n        0.000281541288131848,\n        -0.008729061111807823,\n        -0.004405544139444828,\n        -0.010588344186544418,\n        0.01741710864007473,\n        -0.019276391714811325,\n        0.0026402506045997143,\n        -0.002209607744589448,\n        0.018456120043992996,\n        -0.003451978089287877,\n        0.018428778275847435,\n        0.03174452483654022,\n        0.011497478932142258,\n        -0.008291582576930523,\n        -0.0112308906391263,\n        -0.007232064846903086,\n        0.001767002628184855,\n        0.009125526063144207,\n        0.009337429888546467,\n        0.01624138467013836,\n        0.007655872032046318,\n        0.05104826018214226,\n        0.009351100772619247,\n        0.023596491664648056,\n        0.011750396341085434,\n        0.017403436824679375,\n        -0.01126506831496954,\n        0.0027034797240048647,\n        0.007649036590009928,\n        0.015489469282329082,\n        0.0152844013646245,\n        -0.009877442382276058,\n        -0.002595819067209959,\n        0.013930953107774258,\n        0.027643166482448578,\n        -0.004969481378793716,\n        0.020000966265797615,\n        0.003739073174074292,\n        -0.0031683004926890135,\n        0.010622522793710232,\n        -0.004156044684350491,\n        0.03111565113067627,\n        -0.022653179243206978,\n        -0.005188220180571079,\n        0.012591174803674221,\n        -0.03576385974884033,\n        -0.04604460299015045,\n        0.008011323399841785,\n        0.004350859206169844,\n        0.00763536524027586,\n        -0.009713387116789818,\n        -0.014641854912042618,\n        0.0034724848810583353,\n        -0.0038826207164674997,\n        -0.023145342245697975,\n        -0.008318925276398659,\n        -0.01626872830092907,\n        -0.0056256987154483795,\n        -0.044677481055259705,\n        0.015776565298438072,\n        0.025988951325416565,\n        0.016938617452979088,\n        0.0032708346843719482,\n        -0.018155353143811226,\n        -0.0035408406984061003,\n        -0.018797900527715683,\n        -0.018975624814629555,\n        -0.02373320236802101,\n        0.008523993194103241,\n        -0.0053249322809278965,\n        0.0017413691384717822,\n        0.002021628664806485,\n        -0.005923047196120024,\n        0.008920458145439625,\n        0.009891113266348839,\n        0.01926271989941597,\n        -0.021545810624957085,\n        0.024867912754416466,\n        -0.01540744211524725,\n        -0.022502794861793518,\n        0.006914209574460983,\n        0.027014290913939476,\n        0.02237975411117077,\n        0.021477455273270607,\n        -0.00630584079772234,\n        -7.802196341799572e-05,\n        -0.016255056485533714,\n        -0.04232603684067726,\n        0.00459694117307663,\n        -0.014026651158928871,\n        -0.020274389535188675,\n        0.007744734641164541,\n        0.013377268798649311,\n        0.0045388382859528065,\n        -0.016528481617569923,\n        -0.020520471036434174,\n        0.012078505009412766,\n        0.005769246257841587,\n        0.029584476724267006,\n        0.001083442592062056,\n        0.014778567478060722,\n        0.01445045880973339,\n        0.00572139723226428,\n        0.017335081472992897,\n        -0.012468134053051472,\n        0.014026651158928871,\n        0.016309741884469986,\n        -0.020821237936615944,\n        0.04429468885064125,\n        0.04369315505027771,\n        -0.036119312047958374,\n        0.030760200694203377,\n        0.004672132432460785,\n        -0.02567451260983944,\n        -0.006880031432956457,\n        -0.001044992357492447,\n        -0.004576434381306171,\n        0.044376716017723083,\n        0.0008664123015478253,\n        -0.017034314572811127,\n        -0.022994957864284515,\n        -0.008428295142948627,\n        0.0028282294515520334,\n        0.015913276001811028,\n        -0.01168887596577406,\n        -0.01723938249051571,\n        -0.009392114356160164,\n        -0.006668127607554197,\n        0.0070953527465462685,\n        -0.0037493265699595213,\n        0.021942276507616043,\n        -0.01893461123108864,\n        -0.031853895634412766,\n        0.007977144792675972,\n        -0.008899951353669167,\n        0.017950285226106644,\n        -0.02198329009115696,\n        0.00196181726641953,\n        -0.0511576309800148,\n        -0.02702796272933483,\n        0.009829592891037464,\n        -0.015598839148879051,\n        0.005536836106330156,\n        -0.014682868495583534,\n        0.02829938381910324,\n        0.025592485442757607,\n        0.02198329009115696,\n        0.014983635395765305,\n        0.013978801667690277,\n        -0.010075674392282963,\n        0.0015559534076601267,\n        -0.007710556965321302,\n        0.0006451097433455288,\n        0.003180262865498662,\n        0.002283090492710471,\n        0.007519159931689501,\n        0.02031540311872959,\n        -0.013479802757501602,\n        -0.00763536524027586,\n        0.007252571638673544,\n        0.006230649538338184,\n        0.011237726546823978,\n        -0.013069666922092438,\n        -0.023200025781989098,\n        0.0030298796482384205,\n        -0.04577117785811424,\n        -0.0057384860701859,\n        0.011613684706389904,\n        -0.014928949996829033,\n        0.017854586243629456,\n        -0.039564453065395355,\n        -0.011900779791176319,\n        0.02370586059987545,\n        0.013671199791133404,\n        0.017731545493006706,\n        0.02031540311872959,\n        0.023897256702184677,\n        0.0007980563095770776,\n        0.009610853157937527,\n        -0.004405544139444828,\n        0.011620519682765007,\n        -0.01472388207912445,\n        -0.017772559076547623,\n        -0.014983635395765305,\n        0.006770661566406488,\n        0.002457398222759366,\n        0.02824469842016697,\n        -0.0010791703825816512,\n        -0.009747565723955631,\n        0.015557825565338135,\n        0.013930953107774258,\n        0.018674859777092934,\n        -0.015858592465519905,\n        0.00515404250472784,\n        0.011285575106739998,\n        -0.03251011297106743,\n        -0.012891941703855991,\n        -0.031033623963594437,\n        0.020096663385629654,\n        0.019877925515174866,\n        0.005328350234776735,\n        -0.0018063073512166739,\n        0.002823102753609419,\n        0.011490643955767155,\n        -0.012693708762526512,\n        -0.017157355323433876,\n        0.009474141523241997,\n        -0.012310915626585484,\n        0.026959605515003204,\n        0.025715526193380356,\n        0.028463438153266907,\n        0.003434889018535614,\n        0.009029828011989594,\n        0.00425516115501523,\n        -0.018797900527715683,\n        -0.002659048419445753,\n        -0.005854691378772259,\n        0.011470137163996696,\n        0.012167368084192276,\n        0.002900003222748637,\n        -0.016938617452979088,\n        0.0018370675388723612,\n        0.0012731305323541164,\n        -0.004573016427457333,\n        -0.010793412104249,\n        0.03423268347978592,\n        -0.0024898673873394728,\n        -0.0008061736007221043,\n        -0.001030466752126813,\n        -0.008346267975866795,\n        0.002942725783213973,\n        0.020821237936615944,\n        0.010178208351135254,\n        0.009576675482094288,\n        0.007737899199128151,\n        -0.007614858448505402,\n        -0.002404422266408801,\n        0.015462127514183521,\n        -0.011422287672758102,\n        0.037295032292604446,\n        -0.006059759296476841,\n        -0.012119518592953682,\n        0.004251743201166391,\n        0.012010148726403713,\n        -0.025072980672121048,\n        -0.00034647947177290916,\n        0.0012261357624083757,\n        0.006839017849415541,\n        0.0014525649603456259,\n        0.013739556074142456,\n        -0.0009159704204648733,\n        0.007587515749037266,\n        -0.019604500383138657,\n        -0.009897949174046516,\n        0.019084995612502098,\n        0.03562714532017708,\n        -0.029338395223021507,\n        0.00035865537938661873,\n        -0.0040535107254981995,\n        -0.00641862815245986,\n        0.01816902495920658,\n        -0.0058581093326210976,\n        0.0008792290464043617,\n        0.007881446741521358,\n        0.0024078399874269962,\n        0.008400952443480492,\n        0.0391816608607769,\n        -0.002368535380810499,\n        -0.004303010180592537,\n        -0.005813677795231342,\n        0.0033238104078918695,\n        -0.005273665301501751,\n        0.029857899993658066,\n        0.011422287672758102,\n        -0.0005968332989141345,\n        -0.0255788154900074,\n        -0.004549091681838036,\n        -0.014819581061601639,\n        0.013896774500608444,\n        0.016077330335974693,\n        0.014682868495583534,\n        0.011524821631610394,\n        0.018073325976729393,\n        0.02155948244035244,\n        -0.002741075586527586,\n        -0.02352813445031643,\n        0.023241039365530014,\n        -0.014436786994338036,\n        -0.021217701956629753,\n        -0.00020506800501607358,\n        -0.015106676146388054,\n        -0.005290754605084658,\n        0.038689494132995605,\n        -0.010526823811233044,\n        -0.01784091629087925,\n        -0.034670162945985794,\n        0.03026803582906723,\n        -0.0037117307074368,\n        -0.013315748423337936,\n        -0.020342744886875153,\n        -0.016077330335974693,\n        0.0033802040852606297,\n        0.0037971758283674717,\n        0.011538492515683174,\n        0.016883932054042816,\n        0.013842090032994747,\n        -0.027315057814121246,\n        0.008414623327553272,\n        0.006815093103796244,\n        -0.003940723370760679,\n        0.007054339163005352,\n        -0.03283822163939476,\n        -0.0001453633012715727,\n        0.018524475395679474,\n        -0.0331936739385128,\n        -0.02412966825067997,\n        0.015434784814715385,\n        0.019208036363124847,\n        -0.021340742707252502,\n        0.011586342006921768,\n        0.007355105597525835,\n        -0.012406613677740097,\n        -0.013452460989356041,\n        0.021053647622466087,\n        -0.018784228712320328,\n        -0.0056496234610676765,\n        -0.015079333446919918,\n        0.024539804086089134,\n        0.010547330603003502,\n        0.016255056485533714,\n        -0.009357936680316925,\n        -0.010827590711414814,\n        -0.005960643291473389,\n        -0.024908926337957382,\n        -0.03251011297106743,\n        -0.026262374594807625,\n        0.00833259616047144,\n        0.02525070682168007,\n        -0.0029769036918878555,\n        -0.015393771231174469,\n        -0.02400662750005722,\n        -0.02113567478954792,\n        -0.010526823811233044,\n        0.009515155106782913,\n        -0.004904543049633503,\n        0.008817924186587334,\n        0.016378097236156464,\n        -0.0037527442909777164,\n        0.016227714717388153,\n        0.007307256571948528,\n        0.01759483478963375,\n        0.007724227849394083,\n        -0.0034041288308799267,\n        -0.0019959951750934124,\n        -0.010137194767594337,\n        0.007676378823816776,\n        0.0013158529764041305,\n        -0.020903265103697777,\n        -0.047794513404369354,\n        0.009412621147930622,\n        0.005577849689871073,\n        0.01602264679968357,\n        0.012844092212617397,\n        0.008004487492144108,\n        -0.015298073180019855,\n        -0.0170889999717474,\n        -0.004477317910641432,\n        -0.004002243746072054,\n        0.022270385175943375,\n        0.030213352292776108,\n        0.020930606871843338,\n        -0.030705515295267105,\n        -0.011490643955767155,\n        0.014997306279838085,\n        -0.024922598153352737,\n        -0.003260581288486719,\n        -0.01362335029989481,\n        0.007874610833823681,\n        -0.019946280866861343,\n        0.005451390985399485,\n        -0.016132015734910965,\n        -0.009624524973332882,\n        -0.013869432732462883,\n        0.0012175912270322442,\n        0.022926602512598038,\n        0.0018832078203558922,\n        0.019522473216056824,\n        0.014600841328501701,\n        -0.00887260865420103,\n        0.00460377661511302,\n        -0.004019332583993673,\n        -0.01257750391960144,\n        -0.026945935562253,\n        -0.016227714717388153,\n        0.016104673966765404,\n        -0.03808796405792236,\n        -0.028162671253085136,\n        -0.005037837196141481,\n        -0.012345093302428722,\n        -0.015926947817206383,\n        -0.005817095749080181,\n        -0.007109024096280336,\n        0.005092522129416466,\n        2.7475907700136304e-05,\n        0.016063660383224487,\n        0.004832769278436899,\n        -0.02996727079153061,\n        -0.013650692999362946,\n        -0.01425906177610159,\n        -0.027492783963680267,\n        -0.001508958637714386,\n        0.00427224999293685,\n        0.0024727783165872097,\n        -0.007443968206644058,\n        0.007621693890541792,\n        -0.02887357398867607,\n        -0.03190857917070389,\n        -0.005331768188625574,\n        0.012536490336060524,\n        0.01956348679959774,\n        0.02061617001891136,\n        0.011962300166487694,\n        0.23164480924606323,\n        -0.007601187098771334,\n        0.0009928708896040916,\n        0.03510764241218567,\n        0.01584492065012455,\n        -0.0009424583404324949,\n        0.009241730906069279,\n        0.007854104042053223,\n        0.0017131722997874022,\n        0.008161705918610096,\n        -0.008202720433473587,\n        -0.013944623991847038,\n        -0.003308430314064026,\n        0.008756403811275959,\n        0.013390940614044666,\n        -0.03292024880647659,\n        -0.03406862914562225,\n        0.007573844864964485,\n        -0.014177034609019756,\n        -0.03595525771379471,\n        0.006985983345657587,\n        -0.008763238787651062,\n        -0.037295032292604446,\n        -0.016924945637583733,\n        0.04084954410791397,\n        0.010267071425914764,\n        -0.012290408834815025,\n        0.015134017914533615,\n        0.015913276001811028,\n        0.018633846193552017,\n        -0.019549816846847534,\n        0.021094661206007004,\n        0.010581509210169315,\n        0.010164537467062473,\n        0.014341088943183422,\n        -0.014819581061601639,\n        0.010759234428405762,\n        -0.01226306613534689,\n        0.01413602102547884,\n        0.01629607006907463,\n        0.019002968445420265,\n        0.0017892182804644108,\n        -0.011531657539308071,\n        -0.03620133921504021,\n        -0.003592107677832246,\n        0.0042859213426709175,\n        -0.028381410986185074,\n        -0.009528825990855694,\n        0.007840433157980442,\n        0.011627355590462685,\n        -0.022871917113661766,\n        -0.020452115684747696,\n        0.0321820043027401,\n        0.011367603205144405,\n        0.014040322043001652,\n        0.009843263775110245,\n        0.00572139723226428,\n        -0.001030466752126813,\n        0.023664847016334534,\n        0.014245389960706234,\n        -0.017786230891942978,\n        0.03786922246217728,\n        -0.008066007867455482,\n        0.012857763096690178,\n        0.004484153352677822,\n        -0.006145204417407513,\n        -0.016801904886960983,\n        0.014300075359642506,\n        0.023965613916516304,\n        0.02300862967967987,\n        -0.02403396926820278,\n        -0.008462472818791866,\n        0.0011406907578930259,\n        -0.017102671787142754,\n        -0.011880272999405861,\n        -0.025483116507530212,\n        0.018497133627533913,\n        0.015161360614001751,\n        0.03426002711057663,\n        0.03395926207304001,\n        -0.010506317019462585,\n        -0.010171372443437576,\n        -0.00060580502031371,\n        -0.0255788154900074,\n        0.008667540736496449,\n        -0.017909271642565727,\n        0.002712024375796318,\n        -0.006903956178575754,\n        -0.032400742173194885,\n        0.01868852972984314,\n        -0.001696083229035139,\n        0.0026111991610378027,\n        -0.014464129693806171,\n        -0.017458122223615646,\n        0.017786230891942978,\n        0.00887260865420103,\n        0.010889111086726189,\n        0.01959083043038845,\n        0.001661050831899047,\n        -0.0021908096969127655,\n        -0.04883352667093277,\n        0.043665811419487,\n        0.008066007867455482,\n        0.00551974680274725,\n        -0.02228405512869358,\n        -0.005639370065182447,\n        -0.004873782861977816,\n        0.00877007469534874,\n        0.036146651953458786,\n        -0.01896195486187935,\n        0.0021412516944110394,\n        -0.03978319093585014,\n        0.023869914934039116,\n        -0.0070816813968122005,\n        -0.019153350964188576,\n        0.009439963847398758,\n        -0.01401298027485609,\n        -0.010451632551848888,\n        -0.0013337964192032814,\n        -0.011634191498160362,\n        0.009098183363676071,\n        0.004309845622628927,\n        -0.008373609744012356,\n        0.010684043169021606,\n        -0.0029581058770418167,\n        -0.036173995584249496,\n        0.007177379913628101,\n        -0.005147206597030163,\n        -0.020903265103697777,\n        -0.03633804991841316,\n        0.020082993432879448,\n        0.012871434912085533,\n        -0.005577849689871073,\n        -0.002971776993945241,\n        -0.006944969762116671,\n        -0.01179140992462635,\n        -0.017676861956715584,\n        0.019700199365615845,\n        0.011941793374717236,\n        -0.01179140992462635,\n        0.008038665167987347,\n        -0.007273078430444002,\n        0.016760891303420067,\n        0.017047986388206482,\n        -0.011873437091708183,\n        -0.02639908716082573,\n        0.02123137377202511,\n        -0.02542843110859394,\n        -0.007143201772123575,\n        -0.03084222786128521,\n        -0.018770556896924973,\n        0.005666712298989296,\n        -0.01248864084482193,\n        -0.03450610861182213,\n        0.02428005076944828,\n        -0.018579160794615746,\n        -0.0011526530142873526,\n        -0.024608159437775612,\n        -0.008776910603046417,\n        -0.01200331375002861,\n        -0.03680286929011345,\n        0.004224400967359543,\n        0.014245389960706234,\n        -0.0037595799658447504,\n        -0.017772559076547623,\n        -0.024799557402729988,\n        -0.17531946301460266,\n        -0.015161360614001751,\n        0.03822467476129532,\n        -0.023664847016334534,\n        0.022147344425320625,\n        0.021450113505125046,\n        0.021149346604943275,\n        -0.002840191824361682,\n        -0.031006282195448875,\n        0.023637505248188972,\n        0.014327417127788067,\n        -0.010663536377251148,\n        -0.042380720376968384,\n        -0.0035579297691583633,\n        0.0025086652021855116,\n        -0.002946143504232168,\n        0.01077974122017622,\n        0.0316898413002491,\n        0.04943506047129631,\n        0.01756749115884304,\n        0.015940619632601738,\n        -0.01953614503145218,\n        -0.018223710358142853,\n        0.010226057842373848,\n        -0.0168429184705019,\n        0.0009005902684293687,\n        -0.021723536774516106,\n        0.005229233764111996,\n        0.014778567478060722,\n        -0.02627604641020298,\n        -0.00023283762857317924,\n        0.007785748224705458,\n        0.0036878061946481466,\n        -0.006985983345657587,\n        -0.0039373054169118404,\n        -0.03229137510061264,\n        0.0012731305323541164,\n        -0.02080756612122059,\n        -0.005406959448009729,\n        0.0031888072844594717,\n        0.018251052126288414,\n        0.01669253595173359,\n        0.0030538043938577175,\n        -0.0021327072754502296,\n        0.017034314572811127,\n        0.022940274327993393,\n        0.0037869224324822426,\n        0.0015004142187535763,\n        0.0037629976868629456,\n        0.0003041841846425086,\n        0.03311164677143097,\n        -0.004528584890067577,\n        -0.019754884764552116,\n        -0.006640785373747349,\n        0.00235828198492527,\n        -0.025961609557271004,\n        -0.013158529996871948,\n        0.027287714183330536,\n        0.0010484101949259639,\n        -0.02860015071928501,\n        0.010301249101758003,\n        -0.027561139315366745,\n        0.00029478524811565876,\n        -0.029584476724267006,\n        -0.02827204205095768,\n        -0.011196712963283062,\n        0.005420630797743797,\n        0.01674721948802471,\n        -0.03590057045221329,\n        0.005639370065182447,\n        0.006927880458533764,\n        -0.0010210677282884717,\n        -0.013596008531749249,\n        0.0036809705197811127,\n        -0.0034468513913452625,\n        0.000853595556691289,\n        -0.00920755323022604,\n        0.035818543285131454,\n        0.0016302906442433596,\n        0.001154361991211772,\n        0.007129530888050795,\n        0.06502022594213486,\n        -0.004644790198653936,\n        0.016651522368192673,\n        0.015393771231174469,\n        0.00843513011932373,\n        -0.002067768946290016,\n        0.0029017121996730566,\n        -0.0341779999434948,\n        -0.028053302317857742,\n        0.0027889248449355364,\n        0.005594938527792692,\n        -0.02467651665210724,\n        0.004884036257863045,\n        0.0007305547478608787,\n        0.007245736196637154,\n        0.016514809802174568,\n        -0.0069347163662314415,\n        0.019098665565252304,\n        0.0062409029342234135,\n        0.005782917607575655,\n        0.015708208084106445,\n        -0.04306428134441376,\n        0.019782226532697678,\n        0.03797859326004982,\n        0.006811675149947405,\n        0.009460470639169216,\n        0.02328205294907093,\n        0.03281088173389435,\n        -0.00685610668733716,\n        -0.010820754803717136,\n        0.019358418881893158,\n        0.005987985525280237,\n        0.034095972776412964,\n        -0.0001542282261652872,\n        0.02403396926820278,\n        -0.013520816341042519,\n        -0.026166677474975586,\n        0.008230062201619148,\n        0.0032657079864293337,\n        0.020301731303334236,\n        -0.008599184453487396,\n        -0.017102671787142754,\n        0.023774215951561928,\n        -0.028326725587248802,\n        -0.010390112176537514,\n        -0.1020418331027031,\n        -0.00406034616753459,\n        0.0007040667696855962,\n        0.03199060633778572,\n        0.009173375554382801,\n        0.015393771231174469,\n        -0.0013363597681745887,\n        0.02545577473938465,\n        -0.018128011375665665,\n        0.0074234614148736,\n        0.0031016534194350243,\n        -0.016952287405729294,\n        0.010882275179028511,\n        -0.011162534356117249,\n        -0.009884277358651161,\n        -0.013513981364667416,\n        -0.001104803872294724,\n        -0.0027256954926997423,\n        0.012222052551805973,\n        0.0258248969912529,\n        -0.022967616096138954,\n        -0.01868852972984314,\n        -0.013876267708837986,\n        -0.008701718412339687,\n        0.0054411375895142555,\n        0.00022044809884391725,\n        -0.006876613479107618,\n        0.0036741350777447224,\n        0.012105847708880901,\n        -0.004620865453034639,\n        0.004648208152502775,\n        -0.017006972804665565,\n        -0.0018080162117257714,\n        -0.0009834719821810722,\n        -0.017950285226106644,\n        0.0006788605242036283,\n        -0.02123137377202511,\n        -0.03379520773887634,\n        0.0144094442948699,\n        -0.033002275973558426,\n        0.0074644749984145164,\n        0.01428640354424715,\n        0.02403396926820278,\n        -0.009911620058119297,\n        -0.009474141523241997,\n        0.013637022115290165,\n        -0.0288188885897398,\n        0.036693502217531204,\n        0.002474487293511629,\n        -0.017553821206092834,\n        -0.006678381003439426,\n        0.014231719076633453,\n        -0.03573651611804962,\n        -0.014860594645142555,\n        0.0057384860701859,\n        -0.007977144792675972,\n        0.00470972852781415,\n        0.024567145854234695,\n        -0.01844244822859764,\n        -0.005789753049612045,\n        0.01953614503145218,\n        0.011060000397264957,\n        -0.004607194568961859,\n        0.004853276070207357,\n        0.012604846619069576,\n        -0.01617302931845188,\n        -0.0294477641582489,\n        -0.020301731303334236,\n        -0.004959227982908487,\n        -0.023117998614907265,\n        -0.033029619604349136,\n        -0.0020848580170422792,\n        -0.026344401761889458,\n        0.016255056485533714,\n        -0.010178208351135254,\n        -0.01527073048055172,\n        -0.005413795355707407,\n        -0.010889111086726189,\n        0.020028308033943176,\n        -0.008674376644194126,\n        -0.0165968369692564,\n        -0.013103845529258251,\n        0.011312917806208134,\n        -0.023323066532611847,\n        0.022338740527629852,\n        0.00041697159758768976,\n        -0.007669543381780386,\n        -0.002595819067209959,\n        0.010813918896019459,\n        -0.026440100744366646,\n        0.0014363304944708943,\n        0.028436096385121346,\n        -0.007238900288939476,\n        0.0006609170814044774,\n        -0.019098665565252304,\n        -0.010472139343619347,\n        -0.014915279112756252,\n        0.013062831945717335,\n        0.011811916716396809,\n        0.026891250163316727,\n        0.006709141191095114,\n        -0.00143034930806607,\n        -0.06053607165813446,\n        0.023965613916516304,\n        -0.007457639556378126,\n        -0.013213214464485645,\n        -0.011114685796201229,\n        -0.0015106676146388054,\n        0.00890678633004427,\n        0.0031101980712264776,\n        -0.009152868762612343,\n        0.010048331692814827,\n        -0.007649036590009928,\n        0.016774563118815422,\n        -0.02201063185930252,\n        0.0012799660908058286,\n        0.0031324136070907116,\n        -0.001912259147502482,\n        0.022639507427811623,\n        -0.01280307862907648,\n        -0.010772905312478542,\n        -0.005328350234776735,\n        -0.03275619447231293,\n        0.0006498091970570385,\n        0.003385330783203244,\n        0.020971620455384254,\n        0.003296468174085021,\n        -0.009446798823773861,\n        0.0005887160659767687,\n        0.0394277423620224,\n        -0.0039475588127970695,\n        -0.03491624444723129,\n        0.01100531592965126,\n        -0.015803907066583633,\n        0.009843263775110245,\n        0.027287714183330536,\n        0.009282744489610195,\n        -0.019249049946665764,\n        0.01581757888197899,\n        0.016952287405729294,\n        0.008660704828798771,\n        0.018647516146302223,\n        -0.005591520573943853,\n        -0.014792238362133503,\n        0.0019686527084559202,\n        -0.014327417127788067,\n        0.007690050173550844,\n        -0.003487864974886179,\n        0.012317751534283161,\n        -0.005393288563936949,\n        0.005622280761599541,\n        0.005991403479129076,\n        0.02073921076953411,\n        0.016501137986779213,\n        -0.009474141523241997,\n        -0.021750878542661667,\n        -0.014067664742469788,\n        -0.008694883435964584,\n        0.02283090353012085,\n        -0.018524475395679474,\n        -0.010089345276355743,\n        -0.033248357474803925,\n        0.05547773092985153,\n        0.011504314839839935,\n        0.002816267078742385,\n        -0.002638541627675295,\n        -0.0019447281956672668,\n        -0.006903956178575754,\n        0.0012440792052075267,\n        0.0021327072754502296,\n        0.012885105796158314,\n        -0.03024069406092167,\n        -0.002129289321601391,\n        -0.005813677795231342,\n        0.0018080162117257714,\n        0.00595722533762455,\n        -0.007341434247791767,\n        -0.0030623488128185272,\n        -0.008414623327553272,\n        -0.001274839392863214,\n        -0.008824759162962437,\n        0.013842090032994747,\n        0.01439577341079712,\n        -0.011333424597978592,\n        -0.015065662562847137,\n        0.009672373533248901,\n        0.041287023574113846,\n        0.03174452483654022,\n        -0.0035647654440253973,\n        0.003626285819336772,\n        -0.017376095056533813,\n        -0.016132015734910965,\n        0.0003838616539724171,\n        -0.0067945863120257854,\n        0.0037835044786334038,\n        0.001703773275949061,\n        0.023992955684661865,\n        0.035435751080513,\n        -0.015010977163910866,\n        0.0024061312433332205,\n        -0.01086860429495573,\n        -0.0027718357741832733,\n        -0.006729647982865572,\n        0.011729889549314976,\n        0.00763536524027586,\n        -0.02525070682168007,\n        -0.01723938249051571,\n        -0.0031119068153202534,\n        -0.0025342986918985844,\n        -0.009740729816257954,\n        0.015093004330992699,\n        0.02325471118092537,\n        -0.003105071373283863,\n        -0.01076607033610344,\n        0.006927880458533764,\n        0.012591174803674221,\n        -0.012105847708880901,\n        -0.012310915626585484,\n        -0.007232064846903086,\n        -0.029803216457366943,\n        -0.023774215951561928,\n        0.028627492487430573,\n        0.0159679614007473,\n        0.0015371555928140879,\n        0.007532831281423569,\n        -0.00964503176510334,\n        0.036693502217531204,\n        0.002694935305044055,\n        0.020424772053956985,\n        -0.018223710358142853,\n        0.014177034609019756,\n        -0.009911620058119297,\n        0.005222398322075605,\n        0.02587958239018917,\n        -0.0053488570265471935,\n        -0.004323516972362995,\n        -0.008004487492144108,\n        -0.014518814161419868,\n        -0.020780224353075027,\n        0.0011731598060578108,\n        0.011545328423380852,\n        0.09061271697282791,\n        0.040931571274995804,\n        -0.0016191827598959208,\n        0.015134017914533615,\n        0.007806255016475916,\n        0.03374052047729492,\n        0.015202374197542667,\n        -0.023774215951561928,\n        -0.024567145854234695,\n        -0.01641911081969738,\n        0.02917434088885784,\n        0.01099164504557848,\n        -0.01901663839817047,\n        -0.03311164677143097,\n        -0.0005280501209199429,\n        -0.02443043515086174,\n        0.006948387250304222,\n        0.019454117864370346,\n        -0.00039710564306005836,\n        0.014095007441937923,\n        0.03234605863690376,\n        0.03461547940969467,\n        0.03349443897604942,\n        0.027369743213057518,\n        -0.036420077085494995,\n        -0.02050679922103882,\n        0.045880548655986786,\n        -0.01801864244043827,\n        0.0014875974738970399,\n        -0.035435751080513,\n        0.02083490788936615,\n        -0.0001317989081144333,\n        -0.01929006353020668,\n        -0.017758889123797417,\n        -0.000527622876688838,\n        0.01717102713882923,\n        -0.002383915474638343,\n        -0.014368430711328983,\n        0.02572919800877571,\n        0.00013350781227927655,\n        -0.0074644749984145164,\n        -0.008565006777644157,\n        -0.03863481059670448,\n        -0.038935575634241104,\n        -0.021901262924075127,\n        0.019946280866861343,\n        0.007970309816300869,\n        -0.00807284377515316,\n        0.0011201839661225677\n      ],\n      \"index\": 0,\n      \"object\": \"embedding\"\n    }\n  ],\n  \"model\": \"ada\",\n  \"object\": \"list\",\n  \"usage\": {\n    \"prompt_tokens\": 10,\n    \"total_tokens\": 10\n  }\n}"},"events":[{"name":"promptflow.function.inputs","timestamp":"2024-04-11T18:08:05.440775Z","attributes":{"payload":"{\n  \"input\": [\n    [\n      3923,\n      527,\n      279,\n      7504,\n      311,\n      1893,\n      264,\n      27565,\n      2683,\n      30\n    ]\n  ],\n  \"model\": \"text-embedding-ada-002\"\n}"}},{"name":"promptflow.embedding.embeddings","timestamp":"2024-04-11T18:08:06.334041Z","attributes":{"payload":"[\n  {\n    \"embedding.vector\": \"\u003c1536 dimensional vector\u003e\",\n    \"embedding.text\": \"\u003c10 dimensional token\u003e\"\n  }\n]"}},{"name":"promptflow.function.output","timestamp":"2024-04-11T18:08:06.452181Z","attributes":{"payload":"{\n  \"data\": [\n    {\n      \"embedding\": [\n        -0.0094194570556283,\n        -0.016255056485533714,\n        -0.021914932876825333,\n        -0.019823240116238594,\n        -0.010615686886012554,\n        0.005359110422432423,\n        -0.013637022115290165,\n        -0.02038375847041607,\n        -0.02170986495912075,\n        -0.017047986388206482,\n        -0.0013269608607515693,\n        0.005205309484153986,\n        -0.015762893483042717,\n        -0.005882033612579107,\n        -0.0031101980712264776,\n        -0.001731970114633441,\n        0.008312089368700981,\n        -0.02667251043021679,\n        0.012809914536774158,\n        -0.018497133627533913,\n        -0.039537109434604645,\n        0.012864599004387856,\n        0.014477800577878952,\n        -0.002741075586527586,\n        0.005157459992915392,\n        0.009105019271373749,\n        0.01611834391951561,\n        0.008749567903578281,\n        -0.0019344747997820377,\n        3.212198134860955e-05,\n        0.005427466239780188,\n        -0.01030808500945568,\n        -0.012816749513149261,\n        -0.026385415345430374,\n        -0.03606462478637695,\n        0.01669253595173359,\n        -0.00877007469534874,\n        -0.005174549296498299,\n        -0.0033374817576259375,\n        -0.026084650307893753,\n        0.0278208926320076,\n        0.0127894077450037,\n        -0.008093350566923618,\n        -0.0069347163662314415,\n        -0.0062409029342234135,\n        0.021778222173452377,\n        -0.023596491664648056,\n        -0.01566719450056553,\n        0.008004487492144108,\n        0.0067125591449439526,\n        0.0035784365609288216,\n        -0.002146378392353654,\n        -0.056653451174497604,\n        0.012536490336060524,\n        0.017430780455470085,\n        -0.006452806293964386,\n        0.004624283406883478,\n        0.03322101756930351,\n        -0.009774908423423767,\n        -0.003163173794746399,\n        0.003626285819336772,\n        -0.0057555753737688065,\n        -0.01699330098927021,\n        0.014327417127788067,\n        -0.0010219222167506814,\n        -0.013821583241224289,\n        0.0069107916206121445,\n        0.008817924186587334,\n        -0.02210633084177971,\n        -0.008359938859939575,\n        0.06168445572257042,\n        0.003275961382314563,\n        -0.006247738376259804,\n        0.008975142613053322,\n        0.0013286697212606668,\n        -0.001356012187898159,\n        -0.006480148993432522,\n        -0.024061311036348343,\n        0.012242559343576431,\n        0.014792238362133503,\n        0.002252330305054784,\n        0.013794240541756153,\n        -0.04175184294581413,\n        0.020916935056447983,\n        0.002252330305054784,\n        0.006497237831354141,\n        -0.005010494962334633,\n        0.0016619052039459348,\n        -0.01236560009419918,\n        -0.001225281273946166,\n        0.002394168870523572,\n        -0.00019342612358741462,\n        0.02016502059996128,\n        0.0030025371816009283,\n        0.006257991772145033,\n        0.014354759827256203,\n        0.010041496716439724,\n        -0.013226886279881,\n        0.017403436824679375,\n        -0.033275701105594635,\n        -0.013281570747494698,\n        0.00011342823563609272,\n        -0.03551777824759483,\n        -0.010014154016971588,\n        -0.02195594646036625,\n        -0.0015781691763550043,\n        0.0037048952654004097,\n        -0.0110394936054945,\n        0.01844244822859764,\n        0.00933059398084879,\n        0.0059025404043495655,\n        0.009214389137923717,\n        -0.019180692732334137,\n        -0.04084954410791397,\n        -0.017047986388206482,\n        -0.009139196947216988,\n        0.00798398070037365,\n        -0.023596491664648056,\n        -0.011155699379742146,\n        -0.026070978492498398,\n        0.03059614636003971,\n        0.033248357474803925,\n        0.036666158586740494,\n        -0.02510032244026661,\n        0.021819235756993294,\n        -0.015229716897010803,\n        -0.010096181184053421,\n        -0.020602498203516006,\n        0.014915279112756252,\n        -0.023350410163402557,\n        0.017676861956715584,\n        0.015120347030460835,\n        0.003964648116379976,\n        0.00618280004709959,\n        -0.03461547940969467,\n        0.013117516413331032,\n        0.0026932263281196356,\n        -0.0001705695758573711,\n        -0.0288188885897398,\n        -0.013671199791133404,\n        0.028408752754330635,\n        0.023719532415270805,\n        0.008414623327553272,\n        -0.016337083652615547,\n        0.02996727079153061,\n        -0.00538303516805172,\n        0.012481805868446827,\n        -0.01326106395572424,\n        -0.015475798398256302,\n        -0.021819235756993294,\n        -0.00028410463710315526,\n        -0.005646205507218838,\n        0.016460124403238297,\n        -0.013917281292378902,\n        -0.0011603430612012744,\n        0.014983635395765305,\n        0.0008706845692358911,\n        0.013247393071651459,\n        -0.0053249322809278965,\n        0.00040351401548832655,\n        0.03800593689084053,\n        0.04199792444705963,\n        0.03190857917070389,\n        -0.008387281559407711,\n        -0.011374438181519508,\n        0.029064971953630447,\n        0.01913967914879322,\n        -0.013172200880944729,\n        -0.008079678751528263,\n        -0.00330672156997025,\n        -0.010075674392282963,\n        -0.01445045880973339,\n        -0.03806062042713165,\n        0.03313899040222168,\n        -0.010615686886012554,\n        0.014942621812224388,\n        0.003619450144469738,\n        -0.002723986515775323,\n        0.00213954271748662,\n        -0.006681798957288265,\n        0.020930606871843338,\n        -0.005468479823321104,\n        0.005099357571452856,\n        0.009480977430939674,\n        -0.014874265529215336,\n        -0.011333424597978592,\n        -0.010663536377251148,\n        -0.020342744886875153,\n        0.00956983957439661,\n        -0.009378443472087383,\n        0.010718220844864845,\n        0.013650692999362946,\n        -0.01654215157032013,\n        0.01315169408917427,\n        -0.6430932283401489,\n        -0.024471448734402657,\n        0.012256231158971786,\n        -0.034396737813949585,\n        -0.013637022115290165,\n        -0.008202720433473587,\n        -0.0019566905684769154,\n        -0.03341241180896759,\n        -0.0052702478133141994,\n        0.015380100347101688,\n        0.01134026050567627,\n        0.02228405512869358,\n        0.03226403146982193,\n        -0.002007957547903061,\n        -0.00907084159553051,\n        -0.009884277358651161,\n        0.02527804858982563,\n        -0.021696195006370544,\n        -0.02140909992158413,\n        0.02879154682159424,\n        -0.026180347427725792,\n        -0.013903610408306122,\n        -0.0034297623205929995,\n        -0.017253054305911064,\n        0.0035579297691583633,\n        -0.009597182273864746,\n        -0.0021703029051423073,\n        -0.014218048192560673,\n        0.003463940229266882,\n        -0.017512807622551918,\n        -0.0017242800677195191,\n        0.00011823451495729387,\n        0.019823240116238594,\n        0.0026795552112162113,\n        0.031225020065903664,\n        0.004996823612600565,\n        -0.03598259761929512,\n        0.022762548178434372,\n        -0.008359938859939575,\n        0.06742636114358902,\n        -0.03516232594847679,\n        -0.016227714717388153,\n        0.018073325976729393,\n        -0.016514809802174568,\n        0.0014423115644603968,\n        -0.003453686833381653,\n        -0.00470972852781415,\n        -0.004159462638199329,\n        -0.0008224081248044968,\n        0.018251052126288414,\n        0.019331077113747597,\n        -0.011114685796201229,\n        -0.00037189936847425997,\n        0.010178208351135254,\n        0.007799419574439526,\n        -0.007115859538316727,\n        0.017006972804665565,\n        0.0005036982474848628,\n        -0.00652458006516099,\n        0.02315901219844818,\n        0.003892874112352729,\n        -0.0023429018910974264,\n        -0.013404611498117447,\n        -0.030896911397576332,\n        -0.009392114356160164,\n        0.006292169913649559,\n        -0.013117516413331032,\n        -0.016309741884469986,\n        0.009891113266348839,\n        -0.03456079214811325,\n        0.00696205860003829,\n        -0.0010424290085211396,\n        0.0011201839661225677,\n        -0.012427120469510555,\n        -0.006531415972858667,\n        0.0033050125930458307,\n        0.0003601506759878248,\n        -0.004402126185595989,\n        0.006647620815783739,\n        -0.007525995373725891,\n        0.006592936348170042,\n        -0.008079678751528263,\n        -0.03535372391343117,\n        -0.003137540305033326,\n        -0.010465303435921669,\n        0.008243734017014503,\n        -0.02283090353012085,\n        -0.04109562560915947,\n        0.015051990747451782,\n        0.013404611498117447,\n        0.02890091761946678,\n        0.015448455698788166,\n        -0.005051508545875549,\n        -0.045579779893159866,\n        -0.008462472818791866,\n        0.013671199791133404,\n        0.027164673432707787,\n        -0.004361112602055073,\n        -0.004323516972362995,\n        -0.007778912782669067,\n        -0.023637505248188972,\n        0.007833597250282764,\n        -0.0028487362433224916,\n        -0.0006797149544581771,\n        0.037295032292604446,\n        -0.009617689065635204,\n        -0.028408752754330635,\n        -0.009269073605537415,\n        0.029283709824085236,\n        -0.017704203724861145,\n        -0.005984567571431398,\n        0.01656949520111084,\n        -0.021149346604943275,\n        -0.0014670906821265817,\n        -0.012721051461994648,\n        -0.033877234905958176,\n        0.030732857063412666,\n        -0.008606020361185074,\n        0.017225712537765503,\n        -0.014532485976815224,\n        -0.001320979674346745,\n        0.0050241658464074135,\n        0.008318925276398659,\n        -0.0049318852834403515,\n        -0.010383276268839836,\n        0.026918591931462288,\n        0.007908789440989494,\n        -0.004532002843916416,\n        0.007874610833823681,\n        -0.02437574975192547,\n        -0.012639024294912815,\n        0.010164537467062473,\n        0.015940619632601738,\n        0.008776910603046417,\n        0.017198368906974792,\n        -0.0014371848665177822,\n        -0.006545086856931448,\n        0.006924462970346212,\n        -0.0058341845870018005,\n        -0.023336738348007202,\n        -0.01893461123108864,\n        0.011572671122848988,\n        -0.005899122916162014,\n        -0.012057998217642307,\n        -0.01055416651070118,\n        0.0012039199937134981,\n        -0.02031540311872959,\n        -0.0036946418695151806,\n        -0.00784726906567812,\n        -0.006093937437981367,\n        -0.013507145456969738,\n        -0.004559345077723265,\n        -0.013199543580412865,\n        0.020370088517665863,\n        0.008749567903578281,\n        -0.007744734641164541,\n        0.005328350234776735,\n        -0.019303733482956886,\n        -0.00683218240737915,\n        -0.03513498231768608,\n        0.006292169913649559,\n        0.0356818325817585,\n        -0.019631844013929367,\n        0.006391285918653011,\n        -0.026139333844184875,\n        -0.015790235251188278,\n        -0.01056783739477396,\n        -0.013855760917067528,\n        0.003091400023549795,\n        -0.032072633504867554,\n        0.02258482202887535,\n        -0.025592485442757607,\n        -0.007102188188582659,\n        0.02742442674934864,\n        -0.012064834125339985,\n        0.014327417127788067,\n        -0.014682868495583534,\n        -0.0035852722357958555,\n        0.013548159040510654,\n        0.0030435509979724884,\n        -0.008353102952241898,\n        0.019344747066497803,\n        -0.01689760386943817,\n        0.002274545840919018,\n        0.01099164504557848,\n        0.030076639726758003,\n        0.0068048397079110146,\n        0.005550506990402937,\n        -0.035271696746349335,\n        0.0048396047204732895,\n        -0.009241730906069279,\n        0.03587322682142258,\n        0.035545118153095245,\n        0.010226057842373848,\n        0.011183041147887707,\n        0.02437574975192547,\n        -0.00952199101448059,\n        -0.021327072754502296,\n        -0.016049988567829132,\n        0.006220396142452955,\n        0.032072633504867554,\n        0.011764067225158215,\n        -0.006654456723481417,\n        -0.00427908543497324,\n        0.013336255215108395,\n        -0.02942042239010334,\n        0.019057651981711388,\n        -0.018086997792124748,\n        0.002341192914173007,\n        0.006066595204174519,\n        0.009166539646685123,\n        -0.02138175629079342,\n        -0.015079333446919918,\n        0.002199354348704219,\n        0.01669253595173359,\n        0.0165968369692564,\n        -0.009228060021996498,\n        0.02173720858991146,\n        -0.039263688027858734,\n        0.019358418881893158,\n        0.012509147636592388,\n        -0.0010167955188080668,\n        0.02939308062195778,\n        -0.006866360083222389,\n        -0.01853814721107483,\n        0.01226306613534689,\n        -8.272143895737827e-05,\n        0.0006327202427200973,\n        0.006353690288960934,\n        -0.00964503176510334,\n        0.00808651465922594,\n        -0.01134026050567627,\n        0.0032349477987736464,\n        -0.0017379513010382652,\n        0.04358378425240517,\n        0.014026651158928871,\n        -0.00987060647457838,\n        -0.011723053641617298,\n        0.013637022115290165,\n        0.009446798823773861,\n        -0.007177379913628101,\n        -0.006114444229751825,\n        0.030623488128185272,\n        -0.004436304327100515,\n        0.023719532415270805,\n        0.018797900527715683,\n        0.04946240037679672,\n        0.001576460199430585,\n        0.0019464370561763644,\n        0.03628336638212204,\n        -0.007990816608071327,\n        -0.024485118687152863,\n        -0.018633846193552017,\n        0.026904921978712082,\n        0.005820513237267733,\n        -0.025537801906466484,\n        -0.0026863908860832453,\n        -0.007929296232759953,\n        -0.0063878679648041725,\n        0.03313899040222168,\n        0.006924462970346212,\n        0.01916702277958393,\n        0.03313899040222168,\n        -0.010697714053094387,\n        -0.0002670156245585531,\n        -0.012085340917110443,\n        -0.009036662988364697,\n        -0.011969135142862797,\n        0.0026539217215031385,\n        -0.020342744886875153,\n        6.798217509640381e-05,\n        0.002503538504242897,\n        -0.017335081472992897,\n        -0.029338395223021507,\n        0.020670853555202484,\n        0.021504797041416168,\n        -0.0029102566186338663,\n        0.017376095056533813,\n        0.007539666723459959,\n        0.030650829896330833,\n        -0.029037628322839737,\n        -0.015120347030460835,\n        0.022844575345516205,\n        0.0078609399497509,\n        -0.022776219993829727,\n        -0.019057651981711388,\n        0.011893943883478642,\n        0.00151579431258142,\n        0.010349098592996597,\n        0.020998962223529816,\n        0.013076502829790115,\n        0.002612908137962222,\n        0.0015969669912010431,\n        0.011251397430896759,\n        0.003134122584015131,\n        -0.0008386426488868892,\n        0.02887357398867607,\n        -0.020397430285811424,\n        0.0094194570556283,\n        -0.0017516225343570113,\n        -0.010513152927160263,\n        0.01754014939069748,\n        0.002876078709959984,\n        -0.02475854381918907,\n        0.038416072726249695,\n        -0.002645377302542329,\n        -0.000711756874807179,\n        -0.02016502059996128,\n        -0.0038860386703163385,\n        -0.03595525771379471,\n        -0.004477317910641432,\n        -0.014874265529215336,\n        0.003903127508237958,\n        -0.003091400023549795,\n        0.013630186207592487,\n        -0.01348663866519928,\n        -0.02155948244035244,\n        -0.007785748224705458,\n        0.013336255215108395,\n        0.01759483478963375,\n        0.005003659054636955,\n        -0.023637505248188972,\n        -0.005160877946764231,\n        0.024321064352989197,\n        0.040439408272504807,\n        0.04134170711040497,\n        -0.0044465577229857445,\n        0.009815922006964684,\n        -0.037240348756313324,\n        0.00436794850975275,\n        0.003971483558416367,\n        -0.010096181184053421,\n        -0.0072115580551326275,\n        -0.0008484688587486744,\n        -0.004371365997940302,\n        -0.006257991772145033,\n        0.006422046106308699,\n        -0.012099011801183224,\n        0.000281541288131848,\n        -0.008729061111807823,\n        -0.004405544139444828,\n        -0.010588344186544418,\n        0.01741710864007473,\n        -0.019276391714811325,\n        0.0026402506045997143,\n        -0.002209607744589448,\n        0.018456120043992996,\n        -0.003451978089287877,\n        0.018428778275847435,\n        0.03174452483654022,\n        0.011497478932142258,\n        -0.008291582576930523,\n        -0.0112308906391263,\n        -0.007232064846903086,\n        0.001767002628184855,\n        0.009125526063144207,\n        0.009337429888546467,\n        0.01624138467013836,\n        0.007655872032046318,\n        0.05104826018214226,\n        0.009351100772619247,\n        0.023596491664648056,\n        0.011750396341085434,\n        0.017403436824679375,\n        -0.01126506831496954,\n        0.0027034797240048647,\n        0.007649036590009928,\n        0.015489469282329082,\n        0.0152844013646245,\n        -0.009877442382276058,\n        -0.002595819067209959,\n        0.013930953107774258,\n        0.027643166482448578,\n        -0.004969481378793716,\n        0.020000966265797615,\n        0.003739073174074292,\n        -0.0031683004926890135,\n        0.010622522793710232,\n        -0.004156044684350491,\n        0.03111565113067627,\n        -0.022653179243206978,\n        -0.005188220180571079,\n        0.012591174803674221,\n        -0.03576385974884033,\n        -0.04604460299015045,\n        0.008011323399841785,\n        0.004350859206169844,\n        0.00763536524027586,\n        -0.009713387116789818,\n        -0.014641854912042618,\n        0.0034724848810583353,\n        -0.0038826207164674997,\n        -0.023145342245697975,\n        -0.008318925276398659,\n        -0.01626872830092907,\n        -0.0056256987154483795,\n        -0.044677481055259705,\n        0.015776565298438072,\n        0.025988951325416565,\n        0.016938617452979088,\n        0.0032708346843719482,\n        -0.018155353143811226,\n        -0.0035408406984061003,\n        -0.018797900527715683,\n        -0.018975624814629555,\n        -0.02373320236802101,\n        0.008523993194103241,\n        -0.0053249322809278965,\n        0.0017413691384717822,\n        0.002021628664806485,\n        -0.005923047196120024,\n        0.008920458145439625,\n        0.009891113266348839,\n        0.01926271989941597,\n        -0.021545810624957085,\n        0.024867912754416466,\n        -0.01540744211524725,\n        -0.022502794861793518,\n        0.006914209574460983,\n        0.027014290913939476,\n        0.02237975411117077,\n        0.021477455273270607,\n        -0.00630584079772234,\n        -7.802196341799572e-05,\n        -0.016255056485533714,\n        -0.04232603684067726,\n        0.00459694117307663,\n        -0.014026651158928871,\n        -0.020274389535188675,\n        0.007744734641164541,\n        0.013377268798649311,\n        0.0045388382859528065,\n        -0.016528481617569923,\n        -0.020520471036434174,\n        0.012078505009412766,\n        0.005769246257841587,\n        0.029584476724267006,\n        0.001083442592062056,\n        0.014778567478060722,\n        0.01445045880973339,\n        0.00572139723226428,\n        0.017335081472992897,\n        -0.012468134053051472,\n        0.014026651158928871,\n        0.016309741884469986,\n        -0.020821237936615944,\n        0.04429468885064125,\n        0.04369315505027771,\n        -0.036119312047958374,\n        0.030760200694203377,\n        0.004672132432460785,\n        -0.02567451260983944,\n        -0.006880031432956457,\n        -0.001044992357492447,\n        -0.004576434381306171,\n        0.044376716017723083,\n        0.0008664123015478253,\n        -0.017034314572811127,\n        -0.022994957864284515,\n        -0.008428295142948627,\n        0.0028282294515520334,\n        0.015913276001811028,\n        -0.01168887596577406,\n        -0.01723938249051571,\n        -0.009392114356160164,\n        -0.006668127607554197,\n        0.0070953527465462685,\n        -0.0037493265699595213,\n        0.021942276507616043,\n        -0.01893461123108864,\n        -0.031853895634412766,\n        0.007977144792675972,\n        -0.008899951353669167,\n        0.017950285226106644,\n        -0.02198329009115696,\n        0.00196181726641953,\n        -0.0511576309800148,\n        -0.02702796272933483,\n        0.009829592891037464,\n        -0.015598839148879051,\n        0.005536836106330156,\n        -0.014682868495583534,\n        0.02829938381910324,\n        0.025592485442757607,\n        0.02198329009115696,\n        0.014983635395765305,\n        0.013978801667690277,\n        -0.010075674392282963,\n        0.0015559534076601267,\n        -0.007710556965321302,\n        0.0006451097433455288,\n        0.003180262865498662,\n        0.002283090492710471,\n        0.007519159931689501,\n        0.02031540311872959,\n        -0.013479802757501602,\n        -0.00763536524027586,\n        0.007252571638673544,\n        0.006230649538338184,\n        0.011237726546823978,\n        -0.013069666922092438,\n        -0.023200025781989098,\n        0.0030298796482384205,\n        -0.04577117785811424,\n        -0.0057384860701859,\n        0.011613684706389904,\n        -0.014928949996829033,\n        0.017854586243629456,\n        -0.039564453065395355,\n        -0.011900779791176319,\n        0.02370586059987545,\n        0.013671199791133404,\n        0.017731545493006706,\n        0.02031540311872959,\n        0.023897256702184677,\n        0.0007980563095770776,\n        0.009610853157937527,\n        -0.004405544139444828,\n        0.011620519682765007,\n        -0.01472388207912445,\n        -0.017772559076547623,\n        -0.014983635395765305,\n        0.006770661566406488,\n        0.002457398222759366,\n        0.02824469842016697,\n        -0.0010791703825816512,\n        -0.009747565723955631,\n        0.015557825565338135,\n        0.013930953107774258,\n        0.018674859777092934,\n        -0.015858592465519905,\n        0.00515404250472784,\n        0.011285575106739998,\n        -0.03251011297106743,\n        -0.012891941703855991,\n        -0.031033623963594437,\n        0.020096663385629654,\n        0.019877925515174866,\n        0.005328350234776735,\n        -0.0018063073512166739,\n        0.002823102753609419,\n        0.011490643955767155,\n        -0.012693708762526512,\n        -0.017157355323433876,\n        0.009474141523241997,\n        -0.012310915626585484,\n        0.026959605515003204,\n        0.025715526193380356,\n        0.028463438153266907,\n        0.003434889018535614,\n        0.009029828011989594,\n        0.00425516115501523,\n        -0.018797900527715683,\n        -0.002659048419445753,\n        -0.005854691378772259,\n        0.011470137163996696,\n        0.012167368084192276,\n        0.002900003222748637,\n        -0.016938617452979088,\n        0.0018370675388723612,\n        0.0012731305323541164,\n        -0.004573016427457333,\n        -0.010793412104249,\n        0.03423268347978592,\n        -0.0024898673873394728,\n        -0.0008061736007221043,\n        -0.001030466752126813,\n        -0.008346267975866795,\n        0.002942725783213973,\n        0.020821237936615944,\n        0.010178208351135254,\n        0.009576675482094288,\n        0.007737899199128151,\n        -0.007614858448505402,\n        -0.002404422266408801,\n        0.015462127514183521,\n        -0.011422287672758102,\n        0.037295032292604446,\n        -0.006059759296476841,\n        -0.012119518592953682,\n        0.004251743201166391,\n        0.012010148726403713,\n        -0.025072980672121048,\n        -0.00034647947177290916,\n        0.0012261357624083757,\n        0.006839017849415541,\n        0.0014525649603456259,\n        0.013739556074142456,\n        -0.0009159704204648733,\n        0.007587515749037266,\n        -0.019604500383138657,\n        -0.009897949174046516,\n        0.019084995612502098,\n        0.03562714532017708,\n        -0.029338395223021507,\n        0.00035865537938661873,\n        -0.0040535107254981995,\n        -0.00641862815245986,\n        0.01816902495920658,\n        -0.0058581093326210976,\n        0.0008792290464043617,\n        0.007881446741521358,\n        0.0024078399874269962,\n        0.008400952443480492,\n        0.0391816608607769,\n        -0.002368535380810499,\n        -0.004303010180592537,\n        -0.005813677795231342,\n        0.0033238104078918695,\n        -0.005273665301501751,\n        0.029857899993658066,\n        0.011422287672758102,\n        -0.0005968332989141345,\n        -0.0255788154900074,\n        -0.004549091681838036,\n        -0.014819581061601639,\n        0.013896774500608444,\n        0.016077330335974693,\n        0.014682868495583534,\n        0.011524821631610394,\n        0.018073325976729393,\n        0.02155948244035244,\n        -0.002741075586527586,\n        -0.02352813445031643,\n        0.023241039365530014,\n        -0.014436786994338036,\n        -0.021217701956629753,\n        -0.00020506800501607358,\n        -0.015106676146388054,\n        -0.005290754605084658,\n        0.038689494132995605,\n        -0.010526823811233044,\n        -0.01784091629087925,\n        -0.034670162945985794,\n        0.03026803582906723,\n        -0.0037117307074368,\n        -0.013315748423337936,\n        -0.020342744886875153,\n        -0.016077330335974693,\n        0.0033802040852606297,\n        0.0037971758283674717,\n        0.011538492515683174,\n        0.016883932054042816,\n        0.013842090032994747,\n        -0.027315057814121246,\n        0.008414623327553272,\n        0.006815093103796244,\n        -0.003940723370760679,\n        0.007054339163005352,\n        -0.03283822163939476,\n        -0.0001453633012715727,\n        0.018524475395679474,\n        -0.0331936739385128,\n        -0.02412966825067997,\n        0.015434784814715385,\n        0.019208036363124847,\n        -0.021340742707252502,\n        0.011586342006921768,\n        0.007355105597525835,\n        -0.012406613677740097,\n        -0.013452460989356041,\n        0.021053647622466087,\n        -0.018784228712320328,\n        -0.0056496234610676765,\n        -0.015079333446919918,\n        0.024539804086089134,\n        0.010547330603003502,\n        0.016255056485533714,\n        -0.009357936680316925,\n        -0.010827590711414814,\n        -0.005960643291473389,\n        -0.024908926337957382,\n        -0.03251011297106743,\n        -0.026262374594807625,\n        0.00833259616047144,\n        0.02525070682168007,\n        -0.0029769036918878555,\n        -0.015393771231174469,\n        -0.02400662750005722,\n        -0.02113567478954792,\n        -0.010526823811233044,\n        0.009515155106782913,\n        -0.004904543049633503,\n        0.008817924186587334,\n        0.016378097236156464,\n        -0.0037527442909777164,\n        0.016227714717388153,\n        0.007307256571948528,\n        0.01759483478963375,\n        0.007724227849394083,\n        -0.0034041288308799267,\n        -0.0019959951750934124,\n        -0.010137194767594337,\n        0.007676378823816776,\n        0.0013158529764041305,\n        -0.020903265103697777,\n        -0.047794513404369354,\n        0.009412621147930622,\n        0.005577849689871073,\n        0.01602264679968357,\n        0.012844092212617397,\n        0.008004487492144108,\n        -0.015298073180019855,\n        -0.0170889999717474,\n        -0.004477317910641432,\n        -0.004002243746072054,\n        0.022270385175943375,\n        0.030213352292776108,\n        0.020930606871843338,\n        -0.030705515295267105,\n        -0.011490643955767155,\n        0.014997306279838085,\n        -0.024922598153352737,\n        -0.003260581288486719,\n        -0.01362335029989481,\n        0.007874610833823681,\n        -0.019946280866861343,\n        0.005451390985399485,\n        -0.016132015734910965,\n        -0.009624524973332882,\n        -0.013869432732462883,\n        0.0012175912270322442,\n        0.022926602512598038,\n        0.0018832078203558922,\n        0.019522473216056824,\n        0.014600841328501701,\n        -0.00887260865420103,\n        0.00460377661511302,\n        -0.004019332583993673,\n        -0.01257750391960144,\n        -0.026945935562253,\n        -0.016227714717388153,\n        0.016104673966765404,\n        -0.03808796405792236,\n        -0.028162671253085136,\n        -0.005037837196141481,\n        -0.012345093302428722,\n        -0.015926947817206383,\n        -0.005817095749080181,\n        -0.007109024096280336,\n        0.005092522129416466,\n        2.7475907700136304e-05,\n        0.016063660383224487,\n        0.004832769278436899,\n        -0.02996727079153061,\n        -0.013650692999362946,\n        -0.01425906177610159,\n        -0.027492783963680267,\n        -0.001508958637714386,\n        0.00427224999293685,\n        0.0024727783165872097,\n        -0.007443968206644058,\n        0.007621693890541792,\n        -0.02887357398867607,\n        -0.03190857917070389,\n        -0.005331768188625574,\n        0.012536490336060524,\n        0.01956348679959774,\n        0.02061617001891136,\n        0.011962300166487694,\n        0.23164480924606323,\n        -0.007601187098771334,\n        0.0009928708896040916,\n        0.03510764241218567,\n        0.01584492065012455,\n        -0.0009424583404324949,\n        0.009241730906069279,\n        0.007854104042053223,\n        0.0017131722997874022,\n        0.008161705918610096,\n        -0.008202720433473587,\n        -0.013944623991847038,\n        -0.003308430314064026,\n        0.008756403811275959,\n        0.013390940614044666,\n        -0.03292024880647659,\n        -0.03406862914562225,\n        0.007573844864964485,\n        -0.014177034609019756,\n        -0.03595525771379471,\n        0.006985983345657587,\n        -0.008763238787651062,\n        -0.037295032292604446,\n        -0.016924945637583733,\n        0.04084954410791397,\n        0.010267071425914764,\n        -0.012290408834815025,\n        0.015134017914533615,\n        0.015913276001811028,\n        0.018633846193552017,\n        -0.019549816846847534,\n        0.021094661206007004,\n        0.010581509210169315,\n        0.010164537467062473,\n        0.014341088943183422,\n        -0.014819581061601639,\n        0.010759234428405762,\n        -0.01226306613534689,\n        0.01413602102547884,\n        0.01629607006907463,\n        0.019002968445420265,\n        0.0017892182804644108,\n        -0.011531657539308071,\n        -0.03620133921504021,\n        -0.003592107677832246,\n        0.0042859213426709175,\n        -0.028381410986185074,\n        -0.009528825990855694,\n        0.007840433157980442,\n        0.011627355590462685,\n        -0.022871917113661766,\n        -0.020452115684747696,\n        0.0321820043027401,\n        0.011367603205144405,\n        0.014040322043001652,\n        0.009843263775110245,\n        0.00572139723226428,\n        -0.001030466752126813,\n        0.023664847016334534,\n        0.014245389960706234,\n        -0.017786230891942978,\n        0.03786922246217728,\n        -0.008066007867455482,\n        0.012857763096690178,\n        0.004484153352677822,\n        -0.006145204417407513,\n        -0.016801904886960983,\n        0.014300075359642506,\n        0.023965613916516304,\n        0.02300862967967987,\n        -0.02403396926820278,\n        -0.008462472818791866,\n        0.0011406907578930259,\n        -0.017102671787142754,\n        -0.011880272999405861,\n        -0.025483116507530212,\n        0.018497133627533913,\n        0.015161360614001751,\n        0.03426002711057663,\n        0.03395926207304001,\n        -0.010506317019462585,\n        -0.010171372443437576,\n        -0.00060580502031371,\n        -0.0255788154900074,\n        0.008667540736496449,\n        -0.017909271642565727,\n        0.002712024375796318,\n        -0.006903956178575754,\n        -0.032400742173194885,\n        0.01868852972984314,\n        -0.001696083229035139,\n        0.0026111991610378027,\n        -0.014464129693806171,\n        -0.017458122223615646,\n        0.017786230891942978,\n        0.00887260865420103,\n        0.010889111086726189,\n        0.01959083043038845,\n        0.001661050831899047,\n        -0.0021908096969127655,\n        -0.04883352667093277,\n        0.043665811419487,\n        0.008066007867455482,\n        0.00551974680274725,\n        -0.02228405512869358,\n        -0.005639370065182447,\n        -0.004873782861977816,\n        0.00877007469534874,\n        0.036146651953458786,\n        -0.01896195486187935,\n        0.0021412516944110394,\n        -0.03978319093585014,\n        0.023869914934039116,\n        -0.0070816813968122005,\n        -0.019153350964188576,\n        0.009439963847398758,\n        -0.01401298027485609,\n        -0.010451632551848888,\n        -0.0013337964192032814,\n        -0.011634191498160362,\n        0.009098183363676071,\n        0.004309845622628927,\n        -0.008373609744012356,\n        0.010684043169021606,\n        -0.0029581058770418167,\n        -0.036173995584249496,\n        0.007177379913628101,\n        -0.005147206597030163,\n        -0.020903265103697777,\n        -0.03633804991841316,\n        0.020082993432879448,\n        0.012871434912085533,\n        -0.005577849689871073,\n        -0.002971776993945241,\n        -0.006944969762116671,\n        -0.01179140992462635,\n        -0.017676861956715584,\n        0.019700199365615845,\n        0.011941793374717236,\n        -0.01179140992462635,\n        0.008038665167987347,\n        -0.007273078430444002,\n        0.016760891303420067,\n        0.017047986388206482,\n        -0.011873437091708183,\n        -0.02639908716082573,\n        0.02123137377202511,\n        -0.02542843110859394,\n        -0.007143201772123575,\n        -0.03084222786128521,\n        -0.018770556896924973,\n        0.005666712298989296,\n        -0.01248864084482193,\n        -0.03450610861182213,\n        0.02428005076944828,\n        -0.018579160794615746,\n        -0.0011526530142873526,\n        -0.024608159437775612,\n        -0.008776910603046417,\n        -0.01200331375002861,\n        -0.03680286929011345,\n        0.004224400967359543,\n        0.014245389960706234,\n        -0.0037595799658447504,\n        -0.017772559076547623,\n        -0.024799557402729988,\n        -0.17531946301460266,\n        -0.015161360614001751,\n        0.03822467476129532,\n        -0.023664847016334534,\n        0.022147344425320625,\n        0.021450113505125046,\n        0.021149346604943275,\n        -0.002840191824361682,\n        -0.031006282195448875,\n        0.023637505248188972,\n        0.014327417127788067,\n        -0.010663536377251148,\n        -0.042380720376968384,\n        -0.0035579297691583633,\n        0.0025086652021855116,\n        -0.002946143504232168,\n        0.01077974122017622,\n        0.0316898413002491,\n        0.04943506047129631,\n        0.01756749115884304,\n        0.015940619632601738,\n        -0.01953614503145218,\n        -0.018223710358142853,\n        0.010226057842373848,\n        -0.0168429184705019,\n        0.0009005902684293687,\n        -0.021723536774516106,\n        0.005229233764111996,\n        0.014778567478060722,\n        -0.02627604641020298,\n        -0.00023283762857317924,\n        0.007785748224705458,\n        0.0036878061946481466,\n        -0.006985983345657587,\n        -0.0039373054169118404,\n        -0.03229137510061264,\n        0.0012731305323541164,\n        -0.02080756612122059,\n        -0.005406959448009729,\n        0.0031888072844594717,\n        0.018251052126288414,\n        0.01669253595173359,\n        0.0030538043938577175,\n        -0.0021327072754502296,\n        0.017034314572811127,\n        0.022940274327993393,\n        0.0037869224324822426,\n        0.0015004142187535763,\n        0.0037629976868629456,\n        0.0003041841846425086,\n        0.03311164677143097,\n        -0.004528584890067577,\n        -0.019754884764552116,\n        -0.006640785373747349,\n        0.00235828198492527,\n        -0.025961609557271004,\n        -0.013158529996871948,\n        0.027287714183330536,\n        0.0010484101949259639,\n        -0.02860015071928501,\n        0.010301249101758003,\n        -0.027561139315366745,\n        0.00029478524811565876,\n        -0.029584476724267006,\n        -0.02827204205095768,\n        -0.011196712963283062,\n        0.005420630797743797,\n        0.01674721948802471,\n        -0.03590057045221329,\n        0.005639370065182447,\n        0.006927880458533764,\n        -0.0010210677282884717,\n        -0.013596008531749249,\n        0.0036809705197811127,\n        -0.0034468513913452625,\n        0.000853595556691289,\n        -0.00920755323022604,\n        0.035818543285131454,\n        0.0016302906442433596,\n        0.001154361991211772,\n        0.007129530888050795,\n        0.06502022594213486,\n        -0.004644790198653936,\n        0.016651522368192673,\n        0.015393771231174469,\n        0.00843513011932373,\n        -0.002067768946290016,\n        0.0029017121996730566,\n        -0.0341779999434948,\n        -0.028053302317857742,\n        0.0027889248449355364,\n        0.005594938527792692,\n        -0.02467651665210724,\n        0.004884036257863045,\n        0.0007305547478608787,\n        0.007245736196637154,\n        0.016514809802174568,\n        -0.0069347163662314415,\n        0.019098665565252304,\n        0.0062409029342234135,\n        0.005782917607575655,\n        0.015708208084106445,\n        -0.04306428134441376,\n        0.019782226532697678,\n        0.03797859326004982,\n        0.006811675149947405,\n        0.009460470639169216,\n        0.02328205294907093,\n        0.03281088173389435,\n        -0.00685610668733716,\n        -0.010820754803717136,\n        0.019358418881893158,\n        0.005987985525280237,\n        0.034095972776412964,\n        -0.0001542282261652872,\n        0.02403396926820278,\n        -0.013520816341042519,\n        -0.026166677474975586,\n        0.008230062201619148,\n        0.0032657079864293337,\n        0.020301731303334236,\n        -0.008599184453487396,\n        -0.017102671787142754,\n        0.023774215951561928,\n        -0.028326725587248802,\n        -0.010390112176537514,\n        -0.1020418331027031,\n        -0.00406034616753459,\n        0.0007040667696855962,\n        0.03199060633778572,\n        0.009173375554382801,\n        0.015393771231174469,\n        -0.0013363597681745887,\n        0.02545577473938465,\n        -0.018128011375665665,\n        0.0074234614148736,\n        0.0031016534194350243,\n        -0.016952287405729294,\n        0.010882275179028511,\n        -0.011162534356117249,\n        -0.009884277358651161,\n        -0.013513981364667416,\n        -0.001104803872294724,\n        -0.0027256954926997423,\n        0.012222052551805973,\n        0.0258248969912529,\n        -0.022967616096138954,\n        -0.01868852972984314,\n        -0.013876267708837986,\n        -0.008701718412339687,\n        0.0054411375895142555,\n        0.00022044809884391725,\n        -0.006876613479107618,\n        0.0036741350777447224,\n        0.012105847708880901,\n        -0.004620865453034639,\n        0.004648208152502775,\n        -0.017006972804665565,\n        -0.0018080162117257714,\n        -0.0009834719821810722,\n        -0.017950285226106644,\n        0.0006788605242036283,\n        -0.02123137377202511,\n        -0.03379520773887634,\n        0.0144094442948699,\n        -0.033002275973558426,\n        0.0074644749984145164,\n        0.01428640354424715,\n        0.02403396926820278,\n        -0.009911620058119297,\n        -0.009474141523241997,\n        0.013637022115290165,\n        -0.0288188885897398,\n        0.036693502217531204,\n        0.002474487293511629,\n        -0.017553821206092834,\n        -0.006678381003439426,\n        0.014231719076633453,\n        -0.03573651611804962,\n        -0.014860594645142555,\n        0.0057384860701859,\n        -0.007977144792675972,\n        0.00470972852781415,\n        0.024567145854234695,\n        -0.01844244822859764,\n        -0.005789753049612045,\n        0.01953614503145218,\n        0.011060000397264957,\n        -0.004607194568961859,\n        0.004853276070207357,\n        0.012604846619069576,\n        -0.01617302931845188,\n        -0.0294477641582489,\n        -0.020301731303334236,\n        -0.004959227982908487,\n        -0.023117998614907265,\n        -0.033029619604349136,\n        -0.0020848580170422792,\n        -0.026344401761889458,\n        0.016255056485533714,\n        -0.010178208351135254,\n        -0.01527073048055172,\n        -0.005413795355707407,\n        -0.010889111086726189,\n        0.020028308033943176,\n        -0.008674376644194126,\n        -0.0165968369692564,\n        -0.013103845529258251,\n        0.011312917806208134,\n        -0.023323066532611847,\n        0.022338740527629852,\n        0.00041697159758768976,\n        -0.007669543381780386,\n        -0.002595819067209959,\n        0.010813918896019459,\n        -0.026440100744366646,\n        0.0014363304944708943,\n        0.028436096385121346,\n        -0.007238900288939476,\n        0.0006609170814044774,\n        -0.019098665565252304,\n        -0.010472139343619347,\n        -0.014915279112756252,\n        0.013062831945717335,\n        0.011811916716396809,\n        0.026891250163316727,\n        0.006709141191095114,\n        -0.00143034930806607,\n        -0.06053607165813446,\n        0.023965613916516304,\n        -0.007457639556378126,\n        -0.013213214464485645,\n        -0.011114685796201229,\n        -0.0015106676146388054,\n        0.00890678633004427,\n        0.0031101980712264776,\n        -0.009152868762612343,\n        0.010048331692814827,\n        -0.007649036590009928,\n        0.016774563118815422,\n        -0.02201063185930252,\n        0.0012799660908058286,\n        0.0031324136070907116,\n        -0.001912259147502482,\n        0.022639507427811623,\n        -0.01280307862907648,\n        -0.010772905312478542,\n        -0.005328350234776735,\n        -0.03275619447231293,\n        0.0006498091970570385,\n        0.003385330783203244,\n        0.020971620455384254,\n        0.003296468174085021,\n        -0.009446798823773861,\n        0.0005887160659767687,\n        0.0394277423620224,\n        -0.0039475588127970695,\n        -0.03491624444723129,\n        0.01100531592965126,\n        -0.015803907066583633,\n        0.009843263775110245,\n        0.027287714183330536,\n        0.009282744489610195,\n        -0.019249049946665764,\n        0.01581757888197899,\n        0.016952287405729294,\n        0.008660704828798771,\n        0.018647516146302223,\n        -0.005591520573943853,\n        -0.014792238362133503,\n        0.0019686527084559202,\n        -0.014327417127788067,\n        0.007690050173550844,\n        -0.003487864974886179,\n        0.012317751534283161,\n        -0.005393288563936949,\n        0.005622280761599541,\n        0.005991403479129076,\n        0.02073921076953411,\n        0.016501137986779213,\n        -0.009474141523241997,\n        -0.021750878542661667,\n        -0.014067664742469788,\n        -0.008694883435964584,\n        0.02283090353012085,\n        -0.018524475395679474,\n        -0.010089345276355743,\n        -0.033248357474803925,\n        0.05547773092985153,\n        0.011504314839839935,\n        0.002816267078742385,\n        -0.002638541627675295,\n        -0.0019447281956672668,\n        -0.006903956178575754,\n        0.0012440792052075267,\n        0.0021327072754502296,\n        0.012885105796158314,\n        -0.03024069406092167,\n        -0.002129289321601391,\n        -0.005813677795231342,\n        0.0018080162117257714,\n        0.00595722533762455,\n        -0.007341434247791767,\n        -0.0030623488128185272,\n        -0.008414623327553272,\n        -0.001274839392863214,\n        -0.008824759162962437,\n        0.013842090032994747,\n        0.01439577341079712,\n        -0.011333424597978592,\n        -0.015065662562847137,\n        0.009672373533248901,\n        0.041287023574113846,\n        0.03174452483654022,\n        -0.0035647654440253973,\n        0.003626285819336772,\n        -0.017376095056533813,\n        -0.016132015734910965,\n        0.0003838616539724171,\n        -0.0067945863120257854,\n        0.0037835044786334038,\n        0.001703773275949061,\n        0.023992955684661865,\n        0.035435751080513,\n        -0.015010977163910866,\n        0.0024061312433332205,\n        -0.01086860429495573,\n        -0.0027718357741832733,\n        -0.006729647982865572,\n        0.011729889549314976,\n        0.00763536524027586,\n        -0.02525070682168007,\n        -0.01723938249051571,\n        -0.0031119068153202534,\n        -0.0025342986918985844,\n        -0.009740729816257954,\n        0.015093004330992699,\n        0.02325471118092537,\n        -0.003105071373283863,\n        -0.01076607033610344,\n        0.006927880458533764,\n        0.012591174803674221,\n        -0.012105847708880901,\n        -0.012310915626585484,\n        -0.007232064846903086,\n        -0.029803216457366943,\n        -0.023774215951561928,\n        0.028627492487430573,\n        0.0159679614007473,\n        0.0015371555928140879,\n        0.007532831281423569,\n        -0.00964503176510334,\n        0.036693502217531204,\n        0.002694935305044055,\n        0.020424772053956985,\n        -0.018223710358142853,\n        0.014177034609019756,\n        -0.009911620058119297,\n        0.005222398322075605,\n        0.02587958239018917,\n        -0.0053488570265471935,\n        -0.004323516972362995,\n        -0.008004487492144108,\n        -0.014518814161419868,\n        -0.020780224353075027,\n        0.0011731598060578108,\n        0.011545328423380852,\n        0.09061271697282791,\n        0.040931571274995804,\n        -0.0016191827598959208,\n        0.015134017914533615,\n        0.007806255016475916,\n        0.03374052047729492,\n        0.015202374197542667,\n        -0.023774215951561928,\n        -0.024567145854234695,\n        -0.01641911081969738,\n        0.02917434088885784,\n        0.01099164504557848,\n        -0.01901663839817047,\n        -0.03311164677143097,\n        -0.0005280501209199429,\n        -0.02443043515086174,\n        0.006948387250304222,\n        0.019454117864370346,\n        -0.00039710564306005836,\n        0.014095007441937923,\n        0.03234605863690376,\n        0.03461547940969467,\n        0.03349443897604942,\n        0.027369743213057518,\n        -0.036420077085494995,\n        -0.02050679922103882,\n        0.045880548655986786,\n        -0.01801864244043827,\n        0.0014875974738970399,\n        -0.035435751080513,\n        0.02083490788936615,\n        -0.0001317989081144333,\n        -0.01929006353020668,\n        -0.017758889123797417,\n        -0.000527622876688838,\n        0.01717102713882923,\n        -0.002383915474638343,\n        -0.014368430711328983,\n        0.02572919800877571,\n        0.00013350781227927655,\n        -0.0074644749984145164,\n        -0.008565006777644157,\n        -0.03863481059670448,\n        -0.038935575634241104,\n        -0.021901262924075127,\n        0.019946280866861343,\n        0.007970309816300869,\n        -0.00807284377515316,\n        0.0011201839661225677\n      ],\n      \"index\": 0,\n      \"object\": \"embedding\"\n    }\n  ],\n  \"model\": \"ada\",\n  \"object\": \"list\",\n  \"usage\": {\n    \"prompt_tokens\": 10,\n    \"total_tokens\": 10\n  }\n}"}}],"links":[],"resource":{"attributes":{"service.name":"promptflow"},"schema_url":""}}],"modelversion":"default","collectdatatype":"pandas.core.frame.DataFrame","contentrange":"bytes 0-98858/98859","correlationid":"4f81ad4c-3ba2-4cbe-bf86-4cff67c20cb3","xrequestid":"4f81ad4c-3ba2-4cbe-bf86-4cff67c20cb3","agent":"azureml-ai-monitoring/0.1.0b4"}
{"specversion":"1.0","id":"15a463c7-da98-441e-995e-0879f07268fc","source":"/subscriptions/1aefdc5e-3a7c-4d71-a9f9-f5d3b03be19a/resourceGroups/yuachengtestrg/providers/Microsoft.MachineLearningServices/workspaces/ai-proj-eastus/onlineEndpoints/clone-vivi-log-test/deployments/clone-vivi-log-test-1","type":"azureml.inference.app_traces","datacontenttype":"application/json","time":"2024-04-11T18:08:11Z","data":[{"name":"lookup","context":{"trace_id":"0xa2f3f4f8267a482fa3bb96ad3e1f7f35","span_id":"0xdbbcc5b0e77864fb","trace_state":"[]"},"kind":"SpanKind.INTERNAL","parent_id":"0x22865871c42ca40c","start_time":"2024-04-11T18:08:05.437257Z","end_time":"2024-04-11T18:08:06.853768Z","status":{"status_code":"OK"},"attributes":{"framework":"promptflow","span_type":"Function","function":"search","node_name":"lookup","request_id":"8d0a7bf5-bd46-4c69-95b6-e2cc925bfa4c","line_run_id":"8d0a7bf5-bd46-4c69-95b6-e2cc925bfa4c","inputs":"{\n  \"mlindex_content\": \"embeddings:\\n  api_base: https:\/\/azureml-rag-auseast.openai.azure.com\/\\n  api_type: Azure\\n  api_version: 2023-07-01-preview\\n  batch_size: '16'\\n  connection:\\n    id: \\n      \/subscriptions\/1aefdc5e-3a7c-4d71-a9f9-f5d3b03be19a\/resourceGroups\/yuachengtestrg\/providers\/Microsoft.MachineLearningServices\/workspaces\/ai-proj-eastus\/connections\/Default_AzureOpenAI\\n  connection_type: workspace_connection\\n  deployment: text-embedding-ada-002\\n  dimension: 1536\\n  file_format_version: '2'\\n  kind: open_ai\\n  model: text-embedding-ada-002\\n  schema_version: '2'\\nindex:\\n  api_version: 2023-07-01-preview\\n  connection:\\n    id: \\n      \/subscriptions\/1aefdc5e-3a7c-4d71-a9f9-f5d3b03be19a\/resourceGroups\/yuachengtestrg\/providers\/Microsoft.MachineLearningServices\/workspaces\/ai-proj-eastus\/connections\/AzureAISearch\\n  connection_type: workspace_connection\\n  endpoint: https:\/\/yuacheng-aisearch-eastus.search.windows.net\\n  engine: azure-sdk\\n  field_mapping:\\n    content: content\\n    embedding: contentVector\\n    filename: filepath\\n    metadata: meta_json_string\\n    title: title\\n    url: url\\n  index: aml-rag-doc\\n  kind: acs\\n  semantic_configuration_name: azureml-default\\nself:\\n  path: \\n    azureml:\/\/subscriptions\/1aefdc5e-3a7c-4d71-a9f9-f5d3b03be19a\/resourcegroups\/yuachengtestrg\/workspaces\/ai-proj-eastus\/datastores\/workspaceblobstore\/paths\/azureml\/c258bd68-edde-4fbb-8333-d53f35698512\/index\/\\n  asset_id: \\n    azureml:\/\/locations\/eastus\/workspaces\/38bb01fe-e2e1-4e40-9af9-a9ff97fdcd6d\/data\/aml-rag-doc\/versions\/1\\n\",\n  \"queries\": \"What are the steps to create a Spark job?\",\n  \"query_type\": \"Hybrid (vector + keyword)\",\n  \"top_k\": 3\n}","output":"[\n  {\n    \"text\": \"# Configure Apache Spark jobs in Azure Machine Learning\\n\\n3. Under **Add tags**, provide **Name** and **Value**, then select **Add**. Adding tags is optional.\\n    4. Under the **Code** section:\\n        1. Select **Azure Machine Learning workspace default blob storage** from **Choose code location** dropdown.\\n        2. Under **Path to code file to upload**, select **Browse**.\\n        3. In the pop-up screen titled **Path selection**, select the path of code file `titanic.py` on the workspace default datastore `workspaceblobstore`.\\n        4. Select **Save**.\\n        5. Input `titanic.py` as the name of **Entry file** for the standalone job.\\n        6. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter **Input name** as `titanic_data`. The input should refer to this name later in the **Arguments**.\\n            2. Select **Input type** as **Data**.\\n            3. Select **Data type** as **File**.\\n            4. Select **Data source** as **URI**.\\n            5. Enter an Azure Data Lake Storage (ADLS) Gen 2 data URI for `titanic.csv` file in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here, `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        7.  To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter **Output name** as `wrangled_data`. The output should refer to this name later in the **Arguments**.\\n            2. Select **Output type** as **Folder**.\\n            3. For **Output URI destination**, enter an Azure Data Lake Storage (ADLS) Gen 2 folder URI in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        8.  Enter **Arguments**  as `--titanic_data ${{inputs.titanic_data}} --wrangled_data ${{outputs.wrangled_data}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** as 2 and executor **Memory (GB)** as 2.\\n            2. For **Dynamically allocated executors**, select **Disabled**.\\n            3. Enter the number of **Executor instances** as 2.\\n        2. For **Driver size**, enter number of driver **Cores** as 1 and driver **Memory (GB)** as 2.\\n    6. Select **Next**.\\n6. On the **Review** screen:\\n    1. Review the job specification before submitting it.\\n    2. Select **Create** to submit the standalone Spark job.\\n\\n\u003e [!NOTE]\\n\u003e A standalone job submitted from the Studio UI using an Azure Machine Learning serverless Spark compute defaults to user identity passthrough for data access.\\n\\n\\n---\\n\\n\u003e [!TIP]\\n\u003e You might have an existing Synapse Spark pool in your Azure Synapse workspace. To use an existing Synapse Spark pool, please follow the instructions to [attach a Synapse Spark pool in Azure Machine Learning workspace](.\/how-to-manage-synapse-spark-pool.md).\\n\\n## Next steps\\n- [Apache Spark in Azure Machine Learning](.\/apache-spark-azure-ml-concepts.md)\\n- [Quickstart: Interactive Data Wrangling with Apache Spark](.\/apache-spark-environment-configuration.md)\\n- [Attach and manage a Synapse Spark pool in Azure Machine Learning](.\/how-to-manage-synapse-spark-pool.md)\\n- [Interactive Data Wrangling with Apache Spark in Azure Machine Learning](.\/interactive-data-wrangling-with-apache-spark-azure-ml.md)\\n- [Submit Spark jobs in Azure Machine Learning](.\/how-to-submit-spark-jobs.md)\\n- [Code samples for Spark jobs using Azure Machine Learning CLI](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/cli\/jobs\/spark)\",\n    \"metadata\": {\n      \"id\": \"cXVpY2tzdGFydC1zcGFyay1qb2JzLm1kNA==\",\n      \"source\": {\n        \"title\": \"Configure Apache Spark jobs in Azure Machine Learning\",\n        \"filename\": \"quickstart-spark-jobs.md\",\n        \"url\": \"quickstart-spark-jobs.md\",\n        \"mtime\": 1710206171.0\n      },\n      \"stats\": {\n        \"tiktokens\": 901,\n        \"chars\": 3569,\n        \"lines\": 47\n      },\n      \"content_hash\": \"180236985807e2fb8630996332b1ac47df8c1aa7eda985ecb895df59c6ad2ec7\"\n    },\n    \"score\": 0.030751174315810204\n  },\n  {\n    \"text\": \"# Submit Spark jobs in Azure Machine Learning\\n\\n6. To add any Jar file(s) that the standalone job requires at runtime, select **+ Add file** under **Jars** and input the name of the `.jar` file to be included in the Spark driver. Also, add the executor `CLASSPATH` for successful job execution. Multiple files can be added.\\n        7. To add archive(s) that should be extracted into the working directory of each executor for successful job execution, select **+ Add file** under **Archives**, and input the name of the archive. Multiple archives can be added.\\n        8. Adding **Py files**, **Jars**, and **Archives** is optional.\\n        9. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter an **Input name**. The input should refer to this name later in the **Arguments**.\\n            2. Select an **Input type**.\\n            3. For type **Data**:\\n                1. Select **Data type** as **File** or **Folder**.\\n                2. Select **Data source** as **Upload from local**, **URI**, or **Datastore**.\\n                    - For **Upload from local**, select **Browse** under **Path to upload**, to choose the input file or folder.\\n                    - For **URI**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI), or enter a data asset `azureml:\/\/`.\\n                    - For **Datastore**:\\n                        1. **Select a datastore** from the dropdown menu.\\n                        2. Under **Path to data**, select **Browse**.\\n                        3. In the pop-up screen titled **Path selection**, select the path of the code files on the workspace default blob storage.\\n                        4. Select **Save**.\\n            4. For type **Integer**, enter an integer value as **Input value**.\\n            5. For type **Number**, enter a numeric value as **Input value**.\\n            6. For type **Boolean**, select **True** or **False** as **Input value**.\\n            7. For type **String**, enter a string as **Input value**.\\n        10. To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter an **Output name**. The output should refer to this name later to in the **Arguments**.\\n            2. Select **Output type** as **File** or **Folder**.\\n            3. For **Output URI destination**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI) or enter a data asset `azureml:\/\/`.\\n        11. Enter **Arguments** by using the names defined in the **Input name** and **Output name** fields in the earlier steps, and the names of input and output arguments used in the Python script **Entry file**. For example, if the **Input name** and **Output name** are defined as `job_input` and `job_output`, and the arguments are added in the **Entry file** as shown here\\n\\n            ``` python\\n            import argparse\\n\\n            parser = argparse.ArgumentParser()\\n            parser.add_argument(\\\"--input_param\\\")\\n            parser.add_argument(\\\"--output_param\\\")\\n            ```\\n\\n    then enter **Arguments** as `--input_param ${{inputs.job_input}} --output_param ${{outputs.job_output}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** and executor **Memory (GB)**, in gigabytes.\\n            2. For **Dynamically allocated executors**, select the **Disabled** or **Enabled** option.\\n        - If dynamic allocation of executors is **Disabled**, enter the number of **Executor instances**.\\n        - If dynamic allocation of executors is **Enabled**, use the slider to select the minimum and maximum number of executors.\\n        1. For **Driver size**:\\n            1. Enter number of driver **Cores** and driver **Memory (GB)**, in gigabytes.\\n            2. Enter **Name** and **Value** pairs for any **Additional configurations**, then select **Add**. Providing **Additional configurations** is optional.\\n    6. Select **Next**.\\n7. On the **Review** screen:\",\n    \"metadata\": {\n      \"id\": \"aG93LXRvLXN1Ym1pdC1zcGFyay1qb2JzLm1kNw==\",\n      \"source\": {\n        \"title\": \"Submit Spark jobs in Azure Machine Learning\",\n        \"filename\": \"how-to-submit-spark-jobs.md\",\n        \"url\": \"how-to-submit-spark-jobs.md\",\n        \"mtime\": 1710206154.0\n      },\n      \"stats\": {\n        \"tiktokens\": 933,\n        \"chars\": 3974,\n        \"lines\": 48\n      },\n      \"content_hash\": \"4d20509f3e7b887d13bf41c0ef760f486cc1b45615c33bca6825cd23643bd058\"\n    },\n    \"score\": 0.025739235803484917\n  },\n  {\n    \"text\": \"# Configure Apache Spark jobs in Azure Machine Learning\\n\\n- [Code samples for Spark jobs using Azure Machine Learning Python SDK](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/sdk\/python\/jobs\/spark)\",\n    \"metadata\": {\n      \"id\": \"cXVpY2tzdGFydC1zcGFyay1qb2JzLm1kNQ==\",\n      \"source\": {\n        \"title\": \"Configure Apache Spark jobs in Azure Machine Learning\",\n        \"filename\": \"quickstart-spark-jobs.md\",\n        \"url\": \"quickstart-spark-jobs.md\",\n        \"mtime\": 1710206171.0\n      },\n      \"stats\": {\n        \"tiktokens\": 44,\n        \"chars\": 203,\n        \"lines\": 3\n      },\n      \"content_hash\": \"9c6e5e25028d10af22f711dfc932d1c762f186375243340e341c3fe22463cf50\"\n    },\n    \"score\": 0.02253928780555725\n  }\n]"},"events":[{"name":"promptflow.function.inputs","timestamp":"2024-04-11T18:08:05.437911Z","attributes":{"payload":"{\n  \"mlindex_content\": \"embeddings:\\n  api_base: https:\/\/azureml-rag-auseast.openai.azure.com\/\\n  api_type: Azure\\n  api_version: 2023-07-01-preview\\n  batch_size: '16'\\n  connection:\\n    id: \\n      \/subscriptions\/1aefdc5e-3a7c-4d71-a9f9-f5d3b03be19a\/resourceGroups\/yuachengtestrg\/providers\/Microsoft.MachineLearningServices\/workspaces\/ai-proj-eastus\/connections\/Default_AzureOpenAI\\n  connection_type: workspace_connection\\n  deployment: text-embedding-ada-002\\n  dimension: 1536\\n  file_format_version: '2'\\n  kind: open_ai\\n  model: text-embedding-ada-002\\n  schema_version: '2'\\nindex:\\n  api_version: 2023-07-01-preview\\n  connection:\\n    id: \\n      \/subscriptions\/1aefdc5e-3a7c-4d71-a9f9-f5d3b03be19a\/resourceGroups\/yuachengtestrg\/providers\/Microsoft.MachineLearningServices\/workspaces\/ai-proj-eastus\/connections\/AzureAISearch\\n  connection_type: workspace_connection\\n  endpoint: https:\/\/yuacheng-aisearch-eastus.search.windows.net\\n  engine: azure-sdk\\n  field_mapping:\\n    content: content\\n    embedding: contentVector\\n    filename: filepath\\n    metadata: meta_json_string\\n    title: title\\n    url: url\\n  index: aml-rag-doc\\n  kind: acs\\n  semantic_configuration_name: azureml-default\\nself:\\n  path: \\n    azureml:\/\/subscriptions\/1aefdc5e-3a7c-4d71-a9f9-f5d3b03be19a\/resourcegroups\/yuachengtestrg\/workspaces\/ai-proj-eastus\/datastores\/workspaceblobstore\/paths\/azureml\/c258bd68-edde-4fbb-8333-d53f35698512\/index\/\\n  asset_id: \\n    azureml:\/\/locations\/eastus\/workspaces\/38bb01fe-e2e1-4e40-9af9-a9ff97fdcd6d\/data\/aml-rag-doc\/versions\/1\\n\",\n  \"queries\": \"What are the steps to create a Spark job?\",\n  \"query_type\": \"Hybrid (vector + keyword)\",\n  \"top_k\": 3\n}"}},{"name":"promptflow.function.output","timestamp":"2024-04-11T18:08:06.852412Z","attributes":{"payload":"[\n  {\n    \"text\": \"# Configure Apache Spark jobs in Azure Machine Learning\\n\\n3. Under **Add tags**, provide **Name** and **Value**, then select **Add**. Adding tags is optional.\\n    4. Under the **Code** section:\\n        1. Select **Azure Machine Learning workspace default blob storage** from **Choose code location** dropdown.\\n        2. Under **Path to code file to upload**, select **Browse**.\\n        3. In the pop-up screen titled **Path selection**, select the path of code file `titanic.py` on the workspace default datastore `workspaceblobstore`.\\n        4. Select **Save**.\\n        5. Input `titanic.py` as the name of **Entry file** for the standalone job.\\n        6. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter **Input name** as `titanic_data`. The input should refer to this name later in the **Arguments**.\\n            2. Select **Input type** as **Data**.\\n            3. Select **Data type** as **File**.\\n            4. Select **Data source** as **URI**.\\n            5. Enter an Azure Data Lake Storage (ADLS) Gen 2 data URI for `titanic.csv` file in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here, `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        7.  To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter **Output name** as `wrangled_data`. The output should refer to this name later in the **Arguments**.\\n            2. Select **Output type** as **Folder**.\\n            3. For **Output URI destination**, enter an Azure Data Lake Storage (ADLS) Gen 2 folder URI in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        8.  Enter **Arguments**  as `--titanic_data ${{inputs.titanic_data}} --wrangled_data ${{outputs.wrangled_data}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** as 2 and executor **Memory (GB)** as 2.\\n            2. For **Dynamically allocated executors**, select **Disabled**.\\n            3. Enter the number of **Executor instances** as 2.\\n        2. For **Driver size**, enter number of driver **Cores** as 1 and driver **Memory (GB)** as 2.\\n    6. Select **Next**.\\n6. On the **Review** screen:\\n    1. Review the job specification before submitting it.\\n    2. Select **Create** to submit the standalone Spark job.\\n\\n\u003e [!NOTE]\\n\u003e A standalone job submitted from the Studio UI using an Azure Machine Learning serverless Spark compute defaults to user identity passthrough for data access.\\n\\n\\n---\\n\\n\u003e [!TIP]\\n\u003e You might have an existing Synapse Spark pool in your Azure Synapse workspace. To use an existing Synapse Spark pool, please follow the instructions to [attach a Synapse Spark pool in Azure Machine Learning workspace](.\/how-to-manage-synapse-spark-pool.md).\\n\\n## Next steps\\n- [Apache Spark in Azure Machine Learning](.\/apache-spark-azure-ml-concepts.md)\\n- [Quickstart: Interactive Data Wrangling with Apache Spark](.\/apache-spark-environment-configuration.md)\\n- [Attach and manage a Synapse Spark pool in Azure Machine Learning](.\/how-to-manage-synapse-spark-pool.md)\\n- [Interactive Data Wrangling with Apache Spark in Azure Machine Learning](.\/interactive-data-wrangling-with-apache-spark-azure-ml.md)\\n- [Submit Spark jobs in Azure Machine Learning](.\/how-to-submit-spark-jobs.md)\\n- [Code samples for Spark jobs using Azure Machine Learning CLI](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/cli\/jobs\/spark)\",\n    \"metadata\": {\n      \"id\": \"cXVpY2tzdGFydC1zcGFyay1qb2JzLm1kNA==\",\n      \"source\": {\n        \"title\": \"Configure Apache Spark jobs in Azure Machine Learning\",\n        \"filename\": \"quickstart-spark-jobs.md\",\n        \"url\": \"quickstart-spark-jobs.md\",\n        \"mtime\": 1710206171.0\n      },\n      \"stats\": {\n        \"tiktokens\": 901,\n        \"chars\": 3569,\n        \"lines\": 47\n      },\n      \"content_hash\": \"180236985807e2fb8630996332b1ac47df8c1aa7eda985ecb895df59c6ad2ec7\"\n    },\n    \"score\": 0.030751174315810204\n  },\n  {\n    \"text\": \"# Submit Spark jobs in Azure Machine Learning\\n\\n6. To add any Jar file(s) that the standalone job requires at runtime, select **+ Add file** under **Jars** and input the name of the `.jar` file to be included in the Spark driver. Also, add the executor `CLASSPATH` for successful job execution. Multiple files can be added.\\n        7. To add archive(s) that should be extracted into the working directory of each executor for successful job execution, select **+ Add file** under **Archives**, and input the name of the archive. Multiple archives can be added.\\n        8. Adding **Py files**, **Jars**, and **Archives** is optional.\\n        9. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter an **Input name**. The input should refer to this name later in the **Arguments**.\\n            2. Select an **Input type**.\\n            3. For type **Data**:\\n                1. Select **Data type** as **File** or **Folder**.\\n                2. Select **Data source** as **Upload from local**, **URI**, or **Datastore**.\\n                    - For **Upload from local**, select **Browse** under **Path to upload**, to choose the input file or folder.\\n                    - For **URI**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI), or enter a data asset `azureml:\/\/`.\\n                    - For **Datastore**:\\n                        1. **Select a datastore** from the dropdown menu.\\n                        2. Under **Path to data**, select **Browse**.\\n                        3. In the pop-up screen titled **Path selection**, select the path of the code files on the workspace default blob storage.\\n                        4. Select **Save**.\\n            4. For type **Integer**, enter an integer value as **Input value**.\\n            5. For type **Number**, enter a numeric value as **Input value**.\\n            6. For type **Boolean**, select **True** or **False** as **Input value**.\\n            7. For type **String**, enter a string as **Input value**.\\n        10. To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter an **Output name**. The output should refer to this name later to in the **Arguments**.\\n            2. Select **Output type** as **File** or **Folder**.\\n            3. For **Output URI destination**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI) or enter a data asset `azureml:\/\/`.\\n        11. Enter **Arguments** by using the names defined in the **Input name** and **Output name** fields in the earlier steps, and the names of input and output arguments used in the Python script **Entry file**. For example, if the **Input name** and **Output name** are defined as `job_input` and `job_output`, and the arguments are added in the **Entry file** as shown here\\n\\n            ``` python\\n            import argparse\\n\\n            parser = argparse.ArgumentParser()\\n            parser.add_argument(\\\"--input_param\\\")\\n            parser.add_argument(\\\"--output_param\\\")\\n            ```\\n\\n    then enter **Arguments** as `--input_param ${{inputs.job_input}} --output_param ${{outputs.job_output}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** and executor **Memory (GB)**, in gigabytes.\\n            2. For **Dynamically allocated executors**, select the **Disabled** or **Enabled** option.\\n        - If dynamic allocation of executors is **Disabled**, enter the number of **Executor instances**.\\n        - If dynamic allocation of executors is **Enabled**, use the slider to select the minimum and maximum number of executors.\\n        1. For **Driver size**:\\n            1. Enter number of driver **Cores** and driver **Memory (GB)**, in gigabytes.\\n            2. Enter **Name** and **Value** pairs for any **Additional configurations**, then select **Add**. Providing **Additional configurations** is optional.\\n    6. Select **Next**.\\n7. On the **Review** screen:\",\n    \"metadata\": {\n      \"id\": \"aG93LXRvLXN1Ym1pdC1zcGFyay1qb2JzLm1kNw==\",\n      \"source\": {\n        \"title\": \"Submit Spark jobs in Azure Machine Learning\",\n        \"filename\": \"how-to-submit-spark-jobs.md\",\n        \"url\": \"how-to-submit-spark-jobs.md\",\n        \"mtime\": 1710206154.0\n      },\n      \"stats\": {\n        \"tiktokens\": 933,\n        \"chars\": 3974,\n        \"lines\": 48\n      },\n      \"content_hash\": \"4d20509f3e7b887d13bf41c0ef760f486cc1b45615c33bca6825cd23643bd058\"\n    },\n    \"score\": 0.025739235803484917\n  },\n  {\n    \"text\": \"# Configure Apache Spark jobs in Azure Machine Learning\\n\\n- [Code samples for Spark jobs using Azure Machine Learning Python SDK](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/sdk\/python\/jobs\/spark)\",\n    \"metadata\": {\n      \"id\": \"cXVpY2tzdGFydC1zcGFyay1qb2JzLm1kNQ==\",\n      \"source\": {\n        \"title\": \"Configure Apache Spark jobs in Azure Machine Learning\",\n        \"filename\": \"quickstart-spark-jobs.md\",\n        \"url\": \"quickstart-spark-jobs.md\",\n        \"mtime\": 1710206171.0\n      },\n      \"stats\": {\n        \"tiktokens\": 44,\n        \"chars\": 203,\n        \"lines\": 3\n      },\n      \"content_hash\": \"9c6e5e25028d10af22f711dfc932d1c762f186375243340e341c3fe22463cf50\"\n    },\n    \"score\": 0.02253928780555725\n  }\n]"}}],"links":[],"resource":{"attributes":{"service.name":"promptflow"},"schema_url":""}}],"xrequestid":"a6f2429b-9a8e-441e-8c92-5c4163072ed2","modelversion":"default","collectdatatype":"pandas.core.frame.DataFrame","agent":"azureml-ai-monitoring/0.1.0b4","contentrange":"bytes 0-23991/23992","correlationid":"a6f2429b-9a8e-441e-8c92-5c4163072ed2"}
{"specversion":"1.0","id":"104d9ebb-d264-4fe6-9787-d810dcc6f29f","source":"/subscriptions/1aefdc5e-3a7c-4d71-a9f9-f5d3b03be19a/resourceGroups/yuachengtestrg/providers/Microsoft.MachineLearningServices/workspaces/ai-proj-eastus/onlineEndpoints/clone-vivi-log-test/deployments/clone-vivi-log-test-1","type":"azureml.inference.app_traces","datacontenttype":"application/json","time":"2024-04-11T18:08:11Z","data":[{"name":"search","context":{"trace_id":"0xa2f3f4f8267a482fa3bb96ad3e1f7f35","span_id":"0xa265310d5ea11b31","trace_state":"[]"},"kind":"SpanKind.INTERNAL","parent_id":"0xdbbcc5b0e77864fb","start_time":"2024-04-11T18:08:05.438617Z","end_time":"2024-04-11T18:08:06.848616Z","status":{"status_code":"UNSET"},"attributes":{"span_type":"Retrieval","retrieval.query":"What are the steps to create a Spark job?","retrieval.documents":"[{\"document.content\": \"# Configure Apache Spark jobs in Azure Machine Learning\\n\\n3. Under **Add tags**, provide **Name** and **Value**, then select **Add**. Adding tags is optional.\\n    4. Under the **Code** section:\\n        1. Select **Azure Machine Learning workspace default blob storage** from **Choose code location** dropdown.\\n        2. Under **Path to code file to upload**, select **Browse**.\\n        3. In the pop-up screen titled **Path selection**, select the path of code file `titanic.py` on the workspace default datastore `workspaceblobstore`.\\n        4. Select **Save**.\\n        5. Input `titanic.py` as the name of **Entry file** for the standalone job.\\n        6. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter **Input name** as `titanic_data`. The input should refer to this name later in the **Arguments**.\\n            2. Select **Input type** as **Data**.\\n            3. Select **Data type** as **File**.\\n            4. Select **Data source** as **URI**.\\n            5. Enter an Azure Data Lake Storage (ADLS) Gen 2 data URI for `titanic.csv` file in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here, `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        7.  To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter **Output name** as `wrangled_data`. The output should refer to this name later in the **Arguments**.\\n            2. Select **Output type** as **Folder**.\\n            3. For **Output URI destination**, enter an Azure Data Lake Storage (ADLS) Gen 2 folder URI in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        8.  Enter **Arguments**  as `--titanic_data ${{inputs.titanic_data}} --wrangled_data ${{outputs.wrangled_data}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** as 2 and executor **Memory (GB)** as 2.\\n            2. For **Dynamically allocated executors**, select **Disabled**.\\n            3. Enter the number of **Executor instances** as 2.\\n        2. For **Driver size**, enter number of driver **Cores** as 1 and driver **Memory (GB)** as 2.\\n    6. Select **Next**.\\n6. On the **Review** screen:\\n    1. Review the job specification before submitting it.\\n    2. Select **Create** to submit the standalone Spark job.\\n\\n\u003e [!NOTE]\\n\u003e A standalone job submitted from the Studio UI using an Azure Machine Learning serverless Spark compute defaults to user identity passthrough for data access.\\n\\n\\n---\\n\\n\u003e [!TIP]\\n\u003e You might have an existing Synapse Spark pool in your Azure Synapse workspace. To use an existing Synapse Spark pool, please follow the instructions to [attach a Synapse Spark pool in Azure Machine Learning workspace](.\/how-to-manage-synapse-spark-pool.md).\\n\\n## Next steps\\n- [Apache Spark in Azure Machine Learning](.\/apache-spark-azure-ml-concepts.md)\\n- [Quickstart: Interactive Data Wrangling with Apache Spark](.\/apache-spark-environment-configuration.md)\\n- [Attach and manage a Synapse Spark pool in Azure Machine Learning](.\/how-to-manage-synapse-spark-pool.md)\\n- [Interactive Data Wrangling with Apache Spark in Azure Machine Learning](.\/interactive-data-wrangling-with-apache-spark-azure-ml.md)\\n- [Submit Spark jobs in Azure Machine Learning](.\/how-to-submit-spark-jobs.md)\\n- [Code samples for Spark jobs using Azure Machine Learning CLI](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/cli\/jobs\/spark)\", \"document.score\": 0.030751174315810204, \"document.metadata\": {\"id\": \"cXVpY2tzdGFydC1zcGFyay1qb2JzLm1kNA==\", \"source\": {\"title\": \"Configure Apache Spark jobs in Azure Machine Learning\", \"filename\": \"quickstart-spark-jobs.md\", \"url\": \"quickstart-spark-jobs.md\", \"mtime\": 1710206171.0}, \"stats\": {\"tiktokens\": 901, \"chars\": 3569, \"lines\": 47}, \"content_hash\": \"180236985807e2fb8630996332b1ac47df8c1aa7eda985ecb895df59c6ad2ec7\"}}, {\"document.content\": \"# Submit Spark jobs in Azure Machine Learning\\n\\n6. To add any Jar file(s) that the standalone job requires at runtime, select **+ Add file** under **Jars** and input the name of the `.jar` file to be included in the Spark driver. Also, add the executor `CLASSPATH` for successful job execution. Multiple files can be added.\\n        7. To add archive(s) that should be extracted into the working directory of each executor for successful job execution, select **+ Add file** under **Archives**, and input the name of the archive. Multiple archives can be added.\\n        8. Adding **Py files**, **Jars**, and **Archives** is optional.\\n        9. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter an **Input name**. The input should refer to this name later in the **Arguments**.\\n            2. Select an **Input type**.\\n            3. For type **Data**:\\n                1. Select **Data type** as **File** or **Folder**.\\n                2. Select **Data source** as **Upload from local**, **URI**, or **Datastore**.\\n                    - For **Upload from local**, select **Browse** under **Path to upload**, to choose the input file or folder.\\n                    - For **URI**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI), or enter a data asset `azureml:\/\/`.\\n                    - For **Datastore**:\\n                        1. **Select a datastore** from the dropdown menu.\\n                        2. Under **Path to data**, select **Browse**.\\n                        3. In the pop-up screen titled **Path selection**, select the path of the code files on the workspace default blob storage.\\n                        4. Select **Save**.\\n            4. For type **Integer**, enter an integer value as **Input value**.\\n            5. For type **Number**, enter a numeric value as **Input value**.\\n            6. For type **Boolean**, select **True** or **False** as **Input value**.\\n            7. For type **String**, enter a string as **Input value**.\\n        10. To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter an **Output name**. The output should refer to this name later to in the **Arguments**.\\n            2. Select **Output type** as **File** or **Folder**.\\n            3. For **Output URI destination**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI) or enter a data asset `azureml:\/\/`.\\n        11. Enter **Arguments** by using the names defined in the **Input name** and **Output name** fields in the earlier steps, and the names of input and output arguments used in the Python script **Entry file**. For example, if the **Input name** and **Output name** are defined as `job_input` and `job_output`, and the arguments are added in the **Entry file** as shown here\\n\\n            ``` python\\n            import argparse\\n\\n            parser = argparse.ArgumentParser()\\n            parser.add_argument(\\\"--input_param\\\")\\n            parser.add_argument(\\\"--output_param\\\")\\n            ```\\n\\n    then enter **Arguments** as `--input_param ${{inputs.job_input}} --output_param ${{outputs.job_output}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** and executor **Memory (GB)**, in gigabytes.\\n            2. For **Dynamically allocated executors**, select the **Disabled** or **Enabled** option.\\n        - If dynamic allocation of executors is **Disabled**, enter the number of **Executor instances**.\\n        - If dynamic allocation of executors is **Enabled**, use the slider to select the minimum and maximum number of executors.\\n        1. For **Driver size**:\\n            1. Enter number of driver **Cores** and driver **Memory (GB)**, in gigabytes.\\n            2. Enter **Name** and **Value** pairs for any **Additional configurations**, then select **Add**. Providing **Additional configurations** is optional.\\n    6. Select **Next**.\\n7. On the **Review** screen:\", \"document.score\": 0.025739235803484917, \"document.metadata\": {\"id\": \"aG93LXRvLXN1Ym1pdC1zcGFyay1qb2JzLm1kNw==\", \"source\": {\"title\": \"Submit Spark jobs in Azure Machine Learning\", \"filename\": \"how-to-submit-spark-jobs.md\", \"url\": \"how-to-submit-spark-jobs.md\", \"mtime\": 1710206154.0}, \"stats\": {\"tiktokens\": 933, \"chars\": 3974, \"lines\": 48}, \"content_hash\": \"4d20509f3e7b887d13bf41c0ef760f486cc1b45615c33bca6825cd23643bd058\"}}, {\"document.content\": \"# Configure Apache Spark jobs in Azure Machine Learning\\n\\n- [Code samples for Spark jobs using Azure Machine Learning Python SDK](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/sdk\/python\/jobs\/spark)\", \"document.score\": 0.02253928780555725, \"document.metadata\": {\"id\": \"cXVpY2tzdGFydC1zcGFyay1qb2JzLm1kNQ==\", \"source\": {\"title\": \"Configure Apache Spark jobs in Azure Machine Learning\", \"filename\": \"quickstart-spark-jobs.md\", \"url\": \"quickstart-spark-jobs.md\", \"mtime\": 1710206171.0}, \"stats\": {\"tiktokens\": 44, \"chars\": 203, \"lines\": 3}, \"content_hash\": \"9c6e5e25028d10af22f711dfc932d1c762f186375243340e341c3fe22463cf50\"}}]"},"events":[],"links":[],"resource":{"attributes":{"service.name":"promptflow"},"schema_url":""}}],"xrequestid":"423e940e-defe-4a66-bcba-06741fd93f5a","modelversion":"default","collectdatatype":"pandas.core.frame.DataFrame","agent":"azureml-ai-monitoring/0.1.0b4","contentrange":"bytes 0-9989/9990","correlationid":"423e940e-defe-4a66-bcba-06741fd93f5a"}
{"specversion":"1.0","id":"481174af-2280-4523-aa77-230e07e796de","source":"/subscriptions/1aefdc5e-3a7c-4d71-a9f9-f5d3b03be19a/resourceGroups/yuachengtestrg/providers/Microsoft.MachineLearningServices/workspaces/ai-proj-eastus/onlineEndpoints/clone-vivi-log-test/deployments/clone-vivi-log-test-1","type":"azureml.inference.app_traces","datacontenttype":"application/json","time":"2024-04-11T18:08:11Z","data":[{"name":"generate_prompt_context","context":{"trace_id":"0xa2f3f4f8267a482fa3bb96ad3e1f7f35","span_id":"0xb73a76f5294b3a3c","trace_state":"[]"},"kind":"SpanKind.INTERNAL","parent_id":"0x22865871c42ca40c","start_time":"2024-04-11T18:08:06.918370Z","end_time":"2024-04-11T18:08:06.922562Z","status":{"status_code":"OK"},"attributes":{"framework":"promptflow","span_type":"Function","function":"generate_prompt_context","node_name":"generate_prompt_context","request_id":"8d0a7bf5-bd46-4c69-95b6-e2cc925bfa4c","line_run_id":"8d0a7bf5-bd46-4c69-95b6-e2cc925bfa4c","inputs":"{\n  \"search_result\": [\n    {\n      \"text\": \"# Configure Apache Spark jobs in Azure Machine Learning\\n\\n3. Under **Add tags**, provide **Name** and **Value**, then select **Add**. Adding tags is optional.\\n    4. Under the **Code** section:\\n        1. Select **Azure Machine Learning workspace default blob storage** from **Choose code location** dropdown.\\n        2. Under **Path to code file to upload**, select **Browse**.\\n        3. In the pop-up screen titled **Path selection**, select the path of code file `titanic.py` on the workspace default datastore `workspaceblobstore`.\\n        4. Select **Save**.\\n        5. Input `titanic.py` as the name of **Entry file** for the standalone job.\\n        6. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter **Input name** as `titanic_data`. The input should refer to this name later in the **Arguments**.\\n            2. Select **Input type** as **Data**.\\n            3. Select **Data type** as **File**.\\n            4. Select **Data source** as **URI**.\\n            5. Enter an Azure Data Lake Storage (ADLS) Gen 2 data URI for `titanic.csv` file in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here, `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        7.  To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter **Output name** as `wrangled_data`. The output should refer to this name later in the **Arguments**.\\n            2. Select **Output type** as **Folder**.\\n            3. For **Output URI destination**, enter an Azure Data Lake Storage (ADLS) Gen 2 folder URI in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        8.  Enter **Arguments**  as `--titanic_data ${{inputs.titanic_data}} --wrangled_data ${{outputs.wrangled_data}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** as 2 and executor **Memory (GB)** as 2.\\n            2. For **Dynamically allocated executors**, select **Disabled**.\\n            3. Enter the number of **Executor instances** as 2.\\n        2. For **Driver size**, enter number of driver **Cores** as 1 and driver **Memory (GB)** as 2.\\n    6. Select **Next**.\\n6. On the **Review** screen:\\n    1. Review the job specification before submitting it.\\n    2. Select **Create** to submit the standalone Spark job.\\n\\n\u003e [!NOTE]\\n\u003e A standalone job submitted from the Studio UI using an Azure Machine Learning serverless Spark compute defaults to user identity passthrough for data access.\\n\\n\\n---\\n\\n\u003e [!TIP]\\n\u003e You might have an existing Synapse Spark pool in your Azure Synapse workspace. To use an existing Synapse Spark pool, please follow the instructions to [attach a Synapse Spark pool in Azure Machine Learning workspace](.\/how-to-manage-synapse-spark-pool.md).\\n\\n## Next steps\\n- [Apache Spark in Azure Machine Learning](.\/apache-spark-azure-ml-concepts.md)\\n- [Quickstart: Interactive Data Wrangling with Apache Spark](.\/apache-spark-environment-configuration.md)\\n- [Attach and manage a Synapse Spark pool in Azure Machine Learning](.\/how-to-manage-synapse-spark-pool.md)\\n- [Interactive Data Wrangling with Apache Spark in Azure Machine Learning](.\/interactive-data-wrangling-with-apache-spark-azure-ml.md)\\n- [Submit Spark jobs in Azure Machine Learning](.\/how-to-submit-spark-jobs.md)\\n- [Code samples for Spark jobs using Azure Machine Learning CLI](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/cli\/jobs\/spark)\",\n      \"metadata\": {\n        \"id\": \"cXVpY2tzdGFydC1zcGFyay1qb2JzLm1kNA==\",\n        \"source\": {\n          \"title\": \"Configure Apache Spark jobs in Azure Machine Learning\",\n          \"filename\": \"quickstart-spark-jobs.md\",\n          \"url\": \"quickstart-spark-jobs.md\",\n          \"mtime\": 1710206171.0\n        },\n        \"stats\": {\n          \"tiktokens\": 901,\n          \"chars\": 3569,\n          \"lines\": 47\n        },\n        \"content_hash\": \"180236985807e2fb8630996332b1ac47df8c1aa7eda985ecb895df59c6ad2ec7\"\n      },\n      \"score\": 0.030751174315810204\n    },\n    {\n      \"text\": \"# Submit Spark jobs in Azure Machine Learning\\n\\n6. To add any Jar file(s) that the standalone job requires at runtime, select **+ Add file** under **Jars** and input the name of the `.jar` file to be included in the Spark driver. Also, add the executor `CLASSPATH` for successful job execution. Multiple files can be added.\\n        7. To add archive(s) that should be extracted into the working directory of each executor for successful job execution, select **+ Add file** under **Archives**, and input the name of the archive. Multiple archives can be added.\\n        8. Adding **Py files**, **Jars**, and **Archives** is optional.\\n        9. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter an **Input name**. The input should refer to this name later in the **Arguments**.\\n            2. Select an **Input type**.\\n            3. For type **Data**:\\n                1. Select **Data type** as **File** or **Folder**.\\n                2. Select **Data source** as **Upload from local**, **URI**, or **Datastore**.\\n                    - For **Upload from local**, select **Browse** under **Path to upload**, to choose the input file or folder.\\n                    - For **URI**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI), or enter a data asset `azureml:\/\/`.\\n                    - For **Datastore**:\\n                        1. **Select a datastore** from the dropdown menu.\\n                        2. Under **Path to data**, select **Browse**.\\n                        3. In the pop-up screen titled **Path selection**, select the path of the code files on the workspace default blob storage.\\n                        4. Select **Save**.\\n            4. For type **Integer**, enter an integer value as **Input value**.\\n            5. For type **Number**, enter a numeric value as **Input value**.\\n            6. For type **Boolean**, select **True** or **False** as **Input value**.\\n            7. For type **String**, enter a string as **Input value**.\\n        10. To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter an **Output name**. The output should refer to this name later to in the **Arguments**.\\n            2. Select **Output type** as **File** or **Folder**.\\n            3. For **Output URI destination**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI) or enter a data asset `azureml:\/\/`.\\n        11. Enter **Arguments** by using the names defined in the **Input name** and **Output name** fields in the earlier steps, and the names of input and output arguments used in the Python script **Entry file**. For example, if the **Input name** and **Output name** are defined as `job_input` and `job_output`, and the arguments are added in the **Entry file** as shown here\\n\\n            ``` python\\n            import argparse\\n\\n            parser = argparse.ArgumentParser()\\n            parser.add_argument(\\\"--input_param\\\")\\n            parser.add_argument(\\\"--output_param\\\")\\n            ```\\n\\n    then enter **Arguments** as `--input_param ${{inputs.job_input}} --output_param ${{outputs.job_output}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** and executor **Memory (GB)**, in gigabytes.\\n            2. For **Dynamically allocated executors**, select the **Disabled** or **Enabled** option.\\n        - If dynamic allocation of executors is **Disabled**, enter the number of **Executor instances**.\\n        - If dynamic allocation of executors is **Enabled**, use the slider to select the minimum and maximum number of executors.\\n        1. For **Driver size**:\\n            1. Enter number of driver **Cores** and driver **Memory (GB)**, in gigabytes.\\n            2. Enter **Name** and **Value** pairs for any **Additional configurations**, then select **Add**. Providing **Additional configurations** is optional.\\n    6. Select **Next**.\\n7. On the **Review** screen:\",\n      \"metadata\": {\n        \"id\": \"aG93LXRvLXN1Ym1pdC1zcGFyay1qb2JzLm1kNw==\",\n        \"source\": {\n          \"title\": \"Submit Spark jobs in Azure Machine Learning\",\n          \"filename\": \"how-to-submit-spark-jobs.md\",\n          \"url\": \"how-to-submit-spark-jobs.md\",\n          \"mtime\": 1710206154.0\n        },\n        \"stats\": {\n          \"tiktokens\": 933,\n          \"chars\": 3974,\n          \"lines\": 48\n        },\n        \"content_hash\": \"4d20509f3e7b887d13bf41c0ef760f486cc1b45615c33bca6825cd23643bd058\"\n      },\n      \"score\": 0.025739235803484917\n    },\n    {\n      \"text\": \"# Configure Apache Spark jobs in Azure Machine Learning\\n\\n- [Code samples for Spark jobs using Azure Machine Learning Python SDK](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/sdk\/python\/jobs\/spark)\",\n      \"metadata\": {\n        \"id\": \"cXVpY2tzdGFydC1zcGFyay1qb2JzLm1kNQ==\",\n        \"source\": {\n          \"title\": \"Configure Apache Spark jobs in Azure Machine Learning\",\n          \"filename\": \"quickstart-spark-jobs.md\",\n          \"url\": \"quickstart-spark-jobs.md\",\n          \"mtime\": 1710206171.0\n        },\n        \"stats\": {\n          \"tiktokens\": 44,\n          \"chars\": 203,\n          \"lines\": 3\n        },\n        \"content_hash\": \"9c6e5e25028d10af22f711dfc932d1c762f186375243340e341c3fe22463cf50\"\n      },\n      \"score\": 0.02253928780555725\n    }\n  ]\n}","output":"\"Content: # Configure Apache Spark jobs in Azure Machine Learning\\n\\n3. Under **Add tags**, provide **Name** and **Value**, then select **Add**. Adding tags is optional.\\n    4. Under the **Code** section:\\n        1. Select **Azure Machine Learning workspace default blob storage** from **Choose code location** dropdown.\\n        2. Under **Path to code file to upload**, select **Browse**.\\n        3. In the pop-up screen titled **Path selection**, select the path of code file `titanic.py` on the workspace default datastore `workspaceblobstore`.\\n        4. Select **Save**.\\n        5. Input `titanic.py` as the name of **Entry file** for the standalone job.\\n        6. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter **Input name** as `titanic_data`. The input should refer to this name later in the **Arguments**.\\n            2. Select **Input type** as **Data**.\\n            3. Select **Data type** as **File**.\\n            4. Select **Data source** as **URI**.\\n            5. Enter an Azure Data Lake Storage (ADLS) Gen 2 data URI for `titanic.csv` file in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here, `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        7.  To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter **Output name** as `wrangled_data`. The output should refer to this name later in the **Arguments**.\\n            2. Select **Output type** as **Folder**.\\n            3. For **Output URI destination**, enter an Azure Data Lake Storage (ADLS) Gen 2 folder URI in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        8.  Enter **Arguments**  as `--titanic_data ${{inputs.titanic_data}} --wrangled_data ${{outputs.wrangled_data}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** as 2 and executor **Memory (GB)** as 2.\\n            2. For **Dynamically allocated executors**, select **Disabled**.\\n            3. Enter the number of **Executor instances** as 2.\\n        2. For **Driver size**, enter number of driver **Cores** as 1 and driver **Memory (GB)** as 2.\\n    6. Select **Next**.\\n6. On the **Review** screen:\\n    1. Review the job specification before submitting it.\\n    2. Select **Create** to submit the standalone Spark job.\\n\\n\u003e [!NOTE]\\n\u003e A standalone job submitted from the Studio UI using an Azure Machine Learning serverless Spark compute defaults to user identity passthrough for data access.\\n\\n\\n---\\n\\n\u003e [!TIP]\\n\u003e You might have an existing Synapse Spark pool in your Azure Synapse workspace. To use an existing Synapse Spark pool, please follow the instructions to [attach a Synapse Spark pool in Azure Machine Learning workspace](.\/how-to-manage-synapse-spark-pool.md).\\n\\n## Next steps\\n- [Apache Spark in Azure Machine Learning](.\/apache-spark-azure-ml-concepts.md)\\n- [Quickstart: Interactive Data Wrangling with Apache Spark](.\/apache-spark-environment-configuration.md)\\n- [Attach and manage a Synapse Spark pool in Azure Machine Learning](.\/how-to-manage-synapse-spark-pool.md)\\n- [Interactive Data Wrangling with Apache Spark in Azure Machine Learning](.\/interactive-data-wrangling-with-apache-spark-azure-ml.md)\\n- [Submit Spark jobs in Azure Machine Learning](.\/how-to-submit-spark-jobs.md)\\n- [Code samples for Spark jobs using Azure Machine Learning CLI](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/cli\/jobs\/spark)\\nSource: quickstart-spark-jobs.md\\n\\nContent: # Submit Spark jobs in Azure Machine Learning\\n\\n6. To add any Jar file(s) that the standalone job requires at runtime, select **+ Add file** under **Jars** and input the name of the `.jar` file to be included in the Spark driver. Also, add the executor `CLASSPATH` for successful job execution. Multiple files can be added.\\n        7. To add archive(s) that should be extracted into the working directory of each executor for successful job execution, select **+ Add file** under **Archives**, and input the name of the archive. Multiple archives can be added.\\n        8. Adding **Py files**, **Jars**, and **Archives** is optional.\\n        9. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter an **Input name**. The input should refer to this name later in the **Arguments**.\\n            2. Select an **Input type**.\\n            3. For type **Data**:\\n                1. Select **Data type** as **File** or **Folder**.\\n                2. Select **Data source** as **Upload from local**, **URI**, or **Datastore**.\\n                    - For **Upload from local**, select **Browse** under **Path to upload**, to choose the input file or folder.\\n                    - For **URI**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI), or enter a data asset `azureml:\/\/`.\\n                    - For **Datastore**:\\n                        1. **Select a datastore** from the dropdown menu.\\n                        2. Under **Path to data**, select **Browse**.\\n                        3. In the pop-up screen titled **Path selection**, select the path of the code files on the workspace default blob storage.\\n                        4. Select **Save**.\\n            4. For type **Integer**, enter an integer value as **Input value**.\\n            5. For type **Number**, enter a numeric value as **Input value**.\\n            6. For type **Boolean**, select **True** or **False** as **Input value**.\\n            7. For type **String**, enter a string as **Input value**.\\n        10. To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter an **Output name**. The output should refer to this name later to in the **Arguments**.\\n            2. Select **Output type** as **File** or **Folder**.\\n            3. For **Output URI destination**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI) or enter a data asset `azureml:\/\/`.\\n        11. Enter **Arguments** by using the names defined in the **Input name** and **Output name** fields in the earlier steps, and the names of input and output arguments used in the Python script **Entry file**. For example, if the **Input name** and **Output name** are defined as `job_input` and `job_output`, and the arguments are added in the **Entry file** as shown here\\n\\n            ``` python\\n            import argparse\\n\\n            parser = argparse.ArgumentParser()\\n            parser.add_argument(\\\"--input_param\\\")\\n            parser.add_argument(\\\"--output_param\\\")\\n            ```\\n\\n    then enter **Arguments** as `--input_param ${{inputs.job_input}} --output_param ${{outputs.job_output}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** and executor **Memory (GB)**, in gigabytes.\\n            2. For **Dynamically allocated executors**, select the **Disabled** or **Enabled** option.\\n        - If dynamic allocation of executors is **Disabled**, enter the number of **Executor instances**.\\n        - If dynamic allocation of executors is **Enabled**, use the slider to select the minimum and maximum number of executors.\\n        1. For **Driver size**:\\n            1. Enter number of driver **Cores** and driver **Memory (GB)**, in gigabytes.\\n            2. Enter **Name** and **Value** pairs for any **Additional configurations**, then select **Add**. Providing **Additional configurations** is optional.\\n    6. Select **Next**.\\n7. On the **Review** screen:\\nSource: how-to-submit-spark-jobs.md\\n\\nContent: # Configure Apache Spark jobs in Azure Machine Learning\\n\\n- [Code samples for Spark jobs using Azure Machine Learning Python SDK](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/sdk\/python\/jobs\/spark)\\nSource: quickstart-spark-jobs.md\""},"events":[{"name":"promptflow.function.inputs","timestamp":"2024-04-11T18:08:06.922230Z","attributes":{"payload":"{\n  \"search_result\": [\n    {\n      \"text\": \"# Configure Apache Spark jobs in Azure Machine Learning\\n\\n3. Under **Add tags**, provide **Name** and **Value**, then select **Add**. Adding tags is optional.\\n    4. Under the **Code** section:\\n        1. Select **Azure Machine Learning workspace default blob storage** from **Choose code location** dropdown.\\n        2. Under **Path to code file to upload**, select **Browse**.\\n        3. In the pop-up screen titled **Path selection**, select the path of code file `titanic.py` on the workspace default datastore `workspaceblobstore`.\\n        4. Select **Save**.\\n        5. Input `titanic.py` as the name of **Entry file** for the standalone job.\\n        6. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter **Input name** as `titanic_data`. The input should refer to this name later in the **Arguments**.\\n            2. Select **Input type** as **Data**.\\n            3. Select **Data type** as **File**.\\n            4. Select **Data source** as **URI**.\\n            5. Enter an Azure Data Lake Storage (ADLS) Gen 2 data URI for `titanic.csv` file in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here, `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        7.  To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter **Output name** as `wrangled_data`. The output should refer to this name later in the **Arguments**.\\n            2. Select **Output type** as **Folder**.\\n            3. For **Output URI destination**, enter an Azure Data Lake Storage (ADLS) Gen 2 folder URI in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        8.  Enter **Arguments**  as `--titanic_data ${{inputs.titanic_data}} --wrangled_data ${{outputs.wrangled_data}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** as 2 and executor **Memory (GB)** as 2.\\n            2. For **Dynamically allocated executors**, select **Disabled**.\\n            3. Enter the number of **Executor instances** as 2.\\n        2. For **Driver size**, enter number of driver **Cores** as 1 and driver **Memory (GB)** as 2.\\n    6. Select **Next**.\\n6. On the **Review** screen:\\n    1. Review the job specification before submitting it.\\n    2. Select **Create** to submit the standalone Spark job.\\n\\n\u003e [!NOTE]\\n\u003e A standalone job submitted from the Studio UI using an Azure Machine Learning serverless Spark compute defaults to user identity passthrough for data access.\\n\\n\\n---\\n\\n\u003e [!TIP]\\n\u003e You might have an existing Synapse Spark pool in your Azure Synapse workspace. To use an existing Synapse Spark pool, please follow the instructions to [attach a Synapse Spark pool in Azure Machine Learning workspace](.\/how-to-manage-synapse-spark-pool.md).\\n\\n## Next steps\\n- [Apache Spark in Azure Machine Learning](.\/apache-spark-azure-ml-concepts.md)\\n- [Quickstart: Interactive Data Wrangling with Apache Spark](.\/apache-spark-environment-configuration.md)\\n- [Attach and manage a Synapse Spark pool in Azure Machine Learning](.\/how-to-manage-synapse-spark-pool.md)\\n- [Interactive Data Wrangling with Apache Spark in Azure Machine Learning](.\/interactive-data-wrangling-with-apache-spark-azure-ml.md)\\n- [Submit Spark jobs in Azure Machine Learning](.\/how-to-submit-spark-jobs.md)\\n- [Code samples for Spark jobs using Azure Machine Learning CLI](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/cli\/jobs\/spark)\",\n      \"metadata\": {\n        \"id\": \"cXVpY2tzdGFydC1zcGFyay1qb2JzLm1kNA==\",\n        \"source\": {\n          \"title\": \"Configure Apache Spark jobs in Azure Machine Learning\",\n          \"filename\": \"quickstart-spark-jobs.md\",\n          \"url\": \"quickstart-spark-jobs.md\",\n          \"mtime\": 1710206171.0\n        },\n        \"stats\": {\n          \"tiktokens\": 901,\n          \"chars\": 3569,\n          \"lines\": 47\n        },\n        \"content_hash\": \"180236985807e2fb8630996332b1ac47df8c1aa7eda985ecb895df59c6ad2ec7\"\n      },\n      \"score\": 0.030751174315810204\n    },\n    {\n      \"text\": \"# Submit Spark jobs in Azure Machine Learning\\n\\n6. To add any Jar file(s) that the standalone job requires at runtime, select **+ Add file** under **Jars** and input the name of the `.jar` file to be included in the Spark driver. Also, add the executor `CLASSPATH` for successful job execution. Multiple files can be added.\\n        7. To add archive(s) that should be extracted into the working directory of each executor for successful job execution, select **+ Add file** under **Archives**, and input the name of the archive. Multiple archives can be added.\\n        8. Adding **Py files**, **Jars**, and **Archives** is optional.\\n        9. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter an **Input name**. The input should refer to this name later in the **Arguments**.\\n            2. Select an **Input type**.\\n            3. For type **Data**:\\n                1. Select **Data type** as **File** or **Folder**.\\n                2. Select **Data source** as **Upload from local**, **URI**, or **Datastore**.\\n                    - For **Upload from local**, select **Browse** under **Path to upload**, to choose the input file or folder.\\n                    - For **URI**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI), or enter a data asset `azureml:\/\/`.\\n                    - For **Datastore**:\\n                        1. **Select a datastore** from the dropdown menu.\\n                        2. Under **Path to data**, select **Browse**.\\n                        3. In the pop-up screen titled **Path selection**, select the path of the code files on the workspace default blob storage.\\n                        4. Select **Save**.\\n            4. For type **Integer**, enter an integer value as **Input value**.\\n            5. For type **Number**, enter a numeric value as **Input value**.\\n            6. For type **Boolean**, select **True** or **False** as **Input value**.\\n            7. For type **String**, enter a string as **Input value**.\\n        10. To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter an **Output name**. The output should refer to this name later to in the **Arguments**.\\n            2. Select **Output type** as **File** or **Folder**.\\n            3. For **Output URI destination**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI) or enter a data asset `azureml:\/\/`.\\n        11. Enter **Arguments** by using the names defined in the **Input name** and **Output name** fields in the earlier steps, and the names of input and output arguments used in the Python script **Entry file**. For example, if the **Input name** and **Output name** are defined as `job_input` and `job_output`, and the arguments are added in the **Entry file** as shown here\\n\\n            ``` python\\n            import argparse\\n\\n            parser = argparse.ArgumentParser()\\n            parser.add_argument(\\\"--input_param\\\")\\n            parser.add_argument(\\\"--output_param\\\")\\n            ```\\n\\n    then enter **Arguments** as `--input_param ${{inputs.job_input}} --output_param ${{outputs.job_output}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** and executor **Memory (GB)**, in gigabytes.\\n            2. For **Dynamically allocated executors**, select the **Disabled** or **Enabled** option.\\n        - If dynamic allocation of executors is **Disabled**, enter the number of **Executor instances**.\\n        - If dynamic allocation of executors is **Enabled**, use the slider to select the minimum and maximum number of executors.\\n        1. For **Driver size**:\\n            1. Enter number of driver **Cores** and driver **Memory (GB)**, in gigabytes.\\n            2. Enter **Name** and **Value** pairs for any **Additional configurations**, then select **Add**. Providing **Additional configurations** is optional.\\n    6. Select **Next**.\\n7. On the **Review** screen:\",\n      \"metadata\": {\n        \"id\": \"aG93LXRvLXN1Ym1pdC1zcGFyay1qb2JzLm1kNw==\",\n        \"source\": {\n          \"title\": \"Submit Spark jobs in Azure Machine Learning\",\n          \"filename\": \"how-to-submit-spark-jobs.md\",\n          \"url\": \"how-to-submit-spark-jobs.md\",\n          \"mtime\": 1710206154.0\n        },\n        \"stats\": {\n          \"tiktokens\": 933,\n          \"chars\": 3974,\n          \"lines\": 48\n        },\n        \"content_hash\": \"4d20509f3e7b887d13bf41c0ef760f486cc1b45615c33bca6825cd23643bd058\"\n      },\n      \"score\": 0.025739235803484917\n    },\n    {\n      \"text\": \"# Configure Apache Spark jobs in Azure Machine Learning\\n\\n- [Code samples for Spark jobs using Azure Machine Learning Python SDK](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/sdk\/python\/jobs\/spark)\",\n      \"metadata\": {\n        \"id\": \"cXVpY2tzdGFydC1zcGFyay1qb2JzLm1kNQ==\",\n        \"source\": {\n          \"title\": \"Configure Apache Spark jobs in Azure Machine Learning\",\n          \"filename\": \"quickstart-spark-jobs.md\",\n          \"url\": \"quickstart-spark-jobs.md\",\n          \"mtime\": 1710206171.0\n        },\n        \"stats\": {\n          \"tiktokens\": 44,\n          \"chars\": 203,\n          \"lines\": 3\n        },\n        \"content_hash\": \"9c6e5e25028d10af22f711dfc932d1c762f186375243340e341c3fe22463cf50\"\n      },\n      \"score\": 0.02253928780555725\n    }\n  ]\n}"}},{"name":"promptflow.function.output","timestamp":"2024-04-11T18:08:06.922444Z","attributes":{"payload":"\"Content: # Configure Apache Spark jobs in Azure Machine Learning\\n\\n3. Under **Add tags**, provide **Name** and **Value**, then select **Add**. Adding tags is optional.\\n    4. Under the **Code** section:\\n        1. Select **Azure Machine Learning workspace default blob storage** from **Choose code location** dropdown.\\n        2. Under **Path to code file to upload**, select **Browse**.\\n        3. In the pop-up screen titled **Path selection**, select the path of code file `titanic.py` on the workspace default datastore `workspaceblobstore`.\\n        4. Select **Save**.\\n        5. Input `titanic.py` as the name of **Entry file** for the standalone job.\\n        6. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter **Input name** as `titanic_data`. The input should refer to this name later in the **Arguments**.\\n            2. Select **Input type** as **Data**.\\n            3. Select **Data type** as **File**.\\n            4. Select **Data source** as **URI**.\\n            5. Enter an Azure Data Lake Storage (ADLS) Gen 2 data URI for `titanic.csv` file in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here, `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        7.  To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter **Output name** as `wrangled_data`. The output should refer to this name later in the **Arguments**.\\n            2. Select **Output type** as **Folder**.\\n            3. For **Output URI destination**, enter an Azure Data Lake Storage (ADLS) Gen 2 folder URI in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        8.  Enter **Arguments**  as `--titanic_data ${{inputs.titanic_data}} --wrangled_data ${{outputs.wrangled_data}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** as 2 and executor **Memory (GB)** as 2.\\n            2. For **Dynamically allocated executors**, select **Disabled**.\\n            3. Enter the number of **Executor instances** as 2.\\n        2. For **Driver size**, enter number of driver **Cores** as 1 and driver **Memory (GB)** as 2.\\n    6. Select **Next**.\\n6. On the **Review** screen:\\n    1. Review the job specification before submitting it.\\n    2. Select **Create** to submit the standalone Spark job.\\n\\n\u003e [!NOTE]\\n\u003e A standalone job submitted from the Studio UI using an Azure Machine Learning serverless Spark compute defaults to user identity passthrough for data access.\\n\\n\\n---\\n\\n\u003e [!TIP]\\n\u003e You might have an existing Synapse Spark pool in your Azure Synapse workspace. To use an existing Synapse Spark pool, please follow the instructions to [attach a Synapse Spark pool in Azure Machine Learning workspace](.\/how-to-manage-synapse-spark-pool.md).\\n\\n## Next steps\\n- [Apache Spark in Azure Machine Learning](.\/apache-spark-azure-ml-concepts.md)\\n- [Quickstart: Interactive Data Wrangling with Apache Spark](.\/apache-spark-environment-configuration.md)\\n- [Attach and manage a Synapse Spark pool in Azure Machine Learning](.\/how-to-manage-synapse-spark-pool.md)\\n- [Interactive Data Wrangling with Apache Spark in Azure Machine Learning](.\/interactive-data-wrangling-with-apache-spark-azure-ml.md)\\n- [Submit Spark jobs in Azure Machine Learning](.\/how-to-submit-spark-jobs.md)\\n- [Code samples for Spark jobs using Azure Machine Learning CLI](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/cli\/jobs\/spark)\\nSource: quickstart-spark-jobs.md\\n\\nContent: # Submit Spark jobs in Azure Machine Learning\\n\\n6. To add any Jar file(s) that the standalone job requires at runtime, select **+ Add file** under **Jars** and input the name of the `.jar` file to be included in the Spark driver. Also, add the executor `CLASSPATH` for successful job execution. Multiple files can be added.\\n        7. To add archive(s) that should be extracted into the working directory of each executor for successful job execution, select **+ Add file** under **Archives**, and input the name of the archive. Multiple archives can be added.\\n        8. Adding **Py files**, **Jars**, and **Archives** is optional.\\n        9. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter an **Input name**. The input should refer to this name later in the **Arguments**.\\n            2. Select an **Input type**.\\n            3. For type **Data**:\\n                1. Select **Data type** as **File** or **Folder**.\\n                2. Select **Data source** as **Upload from local**, **URI**, or **Datastore**.\\n                    - For **Upload from local**, select **Browse** under **Path to upload**, to choose the input file or folder.\\n                    - For **URI**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI), or enter a data asset `azureml:\/\/`.\\n                    - For **Datastore**:\\n                        1. **Select a datastore** from the dropdown menu.\\n                        2. Under **Path to data**, select **Browse**.\\n                        3. In the pop-up screen titled **Path selection**, select the path of the code files on the workspace default blob storage.\\n                        4. Select **Save**.\\n            4. For type **Integer**, enter an integer value as **Input value**.\\n            5. For type **Number**, enter a numeric value as **Input value**.\\n            6. For type **Boolean**, select **True** or **False** as **Input value**.\\n            7. For type **String**, enter a string as **Input value**.\\n        10. To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter an **Output name**. The output should refer to this name later to in the **Arguments**.\\n            2. Select **Output type** as **File** or **Folder**.\\n            3. For **Output URI destination**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI) or enter a data asset `azureml:\/\/`.\\n        11. Enter **Arguments** by using the names defined in the **Input name** and **Output name** fields in the earlier steps, and the names of input and output arguments used in the Python script **Entry file**. For example, if the **Input name** and **Output name** are defined as `job_input` and `job_output`, and the arguments are added in the **Entry file** as shown here\\n\\n            ``` python\\n            import argparse\\n\\n            parser = argparse.ArgumentParser()\\n            parser.add_argument(\\\"--input_param\\\")\\n            parser.add_argument(\\\"--output_param\\\")\\n            ```\\n\\n    then enter **Arguments** as `--input_param ${{inputs.job_input}} --output_param ${{outputs.job_output}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** and executor **Memory (GB)**, in gigabytes.\\n            2. For **Dynamically allocated executors**, select the **Disabled** or **Enabled** option.\\n        - If dynamic allocation of executors is **Disabled**, enter the number of **Executor instances**.\\n        - If dynamic allocation of executors is **Enabled**, use the slider to select the minimum and maximum number of executors.\\n        1. For **Driver size**:\\n            1. Enter number of driver **Cores** and driver **Memory (GB)**, in gigabytes.\\n            2. Enter **Name** and **Value** pairs for any **Additional configurations**, then select **Add**. Providing **Additional configurations** is optional.\\n    6. Select **Next**.\\n7. On the **Review** screen:\\nSource: how-to-submit-spark-jobs.md\\n\\nContent: # Configure Apache Spark jobs in Azure Machine Learning\\n\\n- [Code samples for Spark jobs using Azure Machine Learning Python SDK](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/sdk\/python\/jobs\/spark)\\nSource: quickstart-spark-jobs.md\""}}],"links":[],"resource":{"attributes":{"service.name":"promptflow"},"schema_url":""}}],"modelversion":"default","collectdatatype":"pandas.core.frame.DataFrame","agent":"azureml-ai-monitoring/0.1.0b4","contentrange":"bytes 0-37052/37053","correlationid":"c2f2a8dd-8c8d-41a5-9ef3-6efedbdc9ac4","xrequestid":"c2f2a8dd-8c8d-41a5-9ef3-6efedbdc9ac4"}
{"specversion":"1.0","id":"389e77d2-2ce6-40c3-9aa1-bc05b4d8d3d5","source":"/subscriptions/1aefdc5e-3a7c-4d71-a9f9-f5d3b03be19a/resourceGroups/yuachengtestrg/providers/Microsoft.MachineLearningServices/workspaces/ai-proj-eastus/onlineEndpoints/clone-vivi-log-test/deployments/clone-vivi-log-test-1","type":"azureml.inference.app_traces","datacontenttype":"application/json","time":"2024-04-11T18:08:11Z","data":[{"name":"Prompt_variants","context":{"trace_id":"0xa2f3f4f8267a482fa3bb96ad3e1f7f35","span_id":"0x9e656a78a51271b2","trace_state":"[]"},"kind":"SpanKind.INTERNAL","parent_id":"0x22865871c42ca40c","start_time":"2024-04-11T18:08:06.925315Z","end_time":"2024-04-11T18:08:06.928799Z","status":{"status_code":"OK"},"attributes":{"framework":"promptflow","span_type":"Function","function":"render_template_jinja2","node_name":"Prompt_variants","request_id":"8d0a7bf5-bd46-4c69-95b6-e2cc925bfa4c","line_run_id":"8d0a7bf5-bd46-4c69-95b6-e2cc925bfa4c","inputs":"{\n  \"template\": \"system: \\nYou are an AI assistant that helps users answer questions given a specific context and conversation history. You will be given a context and chat history, and then asked a question based on that context and history. Your answer should be as precise as possible, and should only come from the context.\\nPlease add citation after each sentence when possible in a form \\\"(Source: citation)\\\".\\n\\n user: \\n {{contexts}} \\n\\n chat history: \\n{% for item in chat_history %} user: \\n{{ item.inputs.question }} \\nassistant: \\n{{ item.outputs.output }} \\n{% endfor %}\\nuser: {{question}} \\nassistant:\",\n  \"chat_history\": [\n    {\n      \"inputs\": {\n        \"question\": \"what is aml?\"\n      },\n      \"outputs\": {\n        \"answer\": \"Azure Machine Learning (AML) is a cloud service used for accelerating and managing the machine learning project lifecycle. It is designed for ML professionals, data scientists, and engineers to facilitate their daily workflows in training and deploying models and managing machine learning operations (MLOps). You can create models in AML or use models built from open-source platforms like PyTorch, TensorFlow, or scikit-learn. Furthermore, Azure Machine Learning provides tools for monitoring, retraining, and redeploying models(Source: overview-what-is-azure-machine-learning.md).\"\n      }\n    },\n    {\n      \"inputs\": {\n        \"question\": \"how to create a spark job?\"\n      },\n      \"outputs\": {\n        \"answer\": \"To create a Spark job in Azure Machine Learning, you need to firstly provide a Name and optionally a Value under the **Add tags**. Then in the **Code** section, you need to choose the workspace's default blob storage for code location and select the path of the code file to upload. You then need to input the name of the `titanic.py` as the **Entry file**. \\n\\nNext, you add an input by selecting **+ Add input** under **Inputs** and filling up required fields such as **Input name**, **Input type**, and **Data type**. Similarly, you add an output by selecting **+ Add output** under **Outputs** and entering required information. \\n\\nThen you need to enter **Arguments** for the job. \\n\\nIn the **Spark configurations** section, you can configure parameters such as number of executor cores, memory, and instances. Similarly, configure the driver size. Then, you can add any additional optional configurations. \\n\\nOnce everything is set up, you can review the job specifications and select **Create** to submit the standalone Spark job (Source: quickstart-spark-jobs.md).\\n\\nBear in mind that you have the option to add any necessary Jar files, Py files or Archives for the job under the respective sections (Source: how-to-submit-spark-jobs.md). Also, please note that the job submitted defaults to user identity passthrough for data access (Source: quickstart-spark-jobs.md).\\n\"\n      }\n    }\n  ],\n  \"contexts\": \"Content: # Configure Apache Spark jobs in Azure Machine Learning\\n\\n3. Under **Add tags**, provide **Name** and **Value**, then select **Add**. Adding tags is optional.\\n    4. Under the **Code** section:\\n        1. Select **Azure Machine Learning workspace default blob storage** from **Choose code location** dropdown.\\n        2. Under **Path to code file to upload**, select **Browse**.\\n        3. In the pop-up screen titled **Path selection**, select the path of code file `titanic.py` on the workspace default datastore `workspaceblobstore`.\\n        4. Select **Save**.\\n        5. Input `titanic.py` as the name of **Entry file** for the standalone job.\\n        6. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter **Input name** as `titanic_data`. The input should refer to this name later in the **Arguments**.\\n            2. Select **Input type** as **Data**.\\n            3. Select **Data type** as **File**.\\n            4. Select **Data source** as **URI**.\\n            5. Enter an Azure Data Lake Storage (ADLS) Gen 2 data URI for `titanic.csv` file in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here, `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        7.  To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter **Output name** as `wrangled_data`. The output should refer to this name later in the **Arguments**.\\n            2. Select **Output type** as **Folder**.\\n            3. For **Output URI destination**, enter an Azure Data Lake Storage (ADLS) Gen 2 folder URI in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        8.  Enter **Arguments**  as `--titanic_data ${{inputs.titanic_data}} --wrangled_data ${{outputs.wrangled_data}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** as 2 and executor **Memory (GB)** as 2.\\n            2. For **Dynamically allocated executors**, select **Disabled**.\\n            3. Enter the number of **Executor instances** as 2.\\n        2. For **Driver size**, enter number of driver **Cores** as 1 and driver **Memory (GB)** as 2.\\n    6. Select **Next**.\\n6. On the **Review** screen:\\n    1. Review the job specification before submitting it.\\n    2. Select **Create** to submit the standalone Spark job.\\n\\n\u003e [!NOTE]\\n\u003e A standalone job submitted from the Studio UI using an Azure Machine Learning serverless Spark compute defaults to user identity passthrough for data access.\\n\\n\\n---\\n\\n\u003e [!TIP]\\n\u003e You might have an existing Synapse Spark pool in your Azure Synapse workspace. To use an existing Synapse Spark pool, please follow the instructions to [attach a Synapse Spark pool in Azure Machine Learning workspace](.\/how-to-manage-synapse-spark-pool.md).\\n\\n## Next steps\\n- [Apache Spark in Azure Machine Learning](.\/apache-spark-azure-ml-concepts.md)\\n- [Quickstart: Interactive Data Wrangling with Apache Spark](.\/apache-spark-environment-configuration.md)\\n- [Attach and manage a Synapse Spark pool in Azure Machine Learning](.\/how-to-manage-synapse-spark-pool.md)\\n- [Interactive Data Wrangling with Apache Spark in Azure Machine Learning](.\/interactive-data-wrangling-with-apache-spark-azure-ml.md)\\n- [Submit Spark jobs in Azure Machine Learning](.\/how-to-submit-spark-jobs.md)\\n- [Code samples for Spark jobs using Azure Machine Learning CLI](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/cli\/jobs\/spark)\\nSource: quickstart-spark-jobs.md\\n\\nContent: # Submit Spark jobs in Azure Machine Learning\\n\\n6. To add any Jar file(s) that the standalone job requires at runtime, select **+ Add file** under **Jars** and input the name of the `.jar` file to be included in the Spark driver. Also, add the executor `CLASSPATH` for successful job execution. Multiple files can be added.\\n        7. To add archive(s) that should be extracted into the working directory of each executor for successful job execution, select **+ Add file** under **Archives**, and input the name of the archive. Multiple archives can be added.\\n        8. Adding **Py files**, **Jars**, and **Archives** is optional.\\n        9. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter an **Input name**. The input should refer to this name later in the **Arguments**.\\n            2. Select an **Input type**.\\n            3. For type **Data**:\\n                1. Select **Data type** as **File** or **Folder**.\\n                2. Select **Data source** as **Upload from local**, **URI**, or **Datastore**.\\n                    - For **Upload from local**, select **Browse** under **Path to upload**, to choose the input file or folder.\\n                    - For **URI**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI), or enter a data asset `azureml:\/\/`.\\n                    - For **Datastore**:\\n                        1. **Select a datastore** from the dropdown menu.\\n                        2. Under **Path to data**, select **Browse**.\\n                        3. In the pop-up screen titled **Path selection**, select the path of the code files on the workspace default blob storage.\\n                        4. Select **Save**.\\n            4. For type **Integer**, enter an integer value as **Input value**.\\n            5. For type **Number**, enter a numeric value as **Input value**.\\n            6. For type **Boolean**, select **True** or **False** as **Input value**.\\n            7. For type **String**, enter a string as **Input value**.\\n        10. To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter an **Output name**. The output should refer to this name later to in the **Arguments**.\\n            2. Select **Output type** as **File** or **Folder**.\\n            3. For **Output URI destination**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI) or enter a data asset `azureml:\/\/`.\\n        11. Enter **Arguments** by using the names defined in the **Input name** and **Output name** fields in the earlier steps, and the names of input and output arguments used in the Python script **Entry file**. For example, if the **Input name** and **Output name** are defined as `job_input` and `job_output`, and the arguments are added in the **Entry file** as shown here\\n\\n            ``` python\\n            import argparse\\n\\n            parser = argparse.ArgumentParser()\\n            parser.add_argument(\\\"--input_param\\\")\\n            parser.add_argument(\\\"--output_param\\\")\\n            ```\\n\\n    then enter **Arguments** as `--input_param ${{inputs.job_input}} --output_param ${{outputs.job_output}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** and executor **Memory (GB)**, in gigabytes.\\n            2. For **Dynamically allocated executors**, select the **Disabled** or **Enabled** option.\\n        - If dynamic allocation of executors is **Disabled**, enter the number of **Executor instances**.\\n        - If dynamic allocation of executors is **Enabled**, use the slider to select the minimum and maximum number of executors.\\n        1. For **Driver size**:\\n            1. Enter number of driver **Cores** and driver **Memory (GB)**, in gigabytes.\\n            2. Enter **Name** and **Value** pairs for any **Additional configurations**, then select **Add**. Providing **Additional configurations** is optional.\\n    6. Select **Next**.\\n7. On the **Review** screen:\\nSource: how-to-submit-spark-jobs.md\\n\\nContent: # Configure Apache Spark jobs in Azure Machine Learning\\n\\n- [Code samples for Spark jobs using Azure Machine Learning Python SDK](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/sdk\/python\/jobs\/spark)\\nSource: quickstart-spark-jobs.md\",\n  \"question\": \"thank you\"\n}","output":"\"system: \\nYou are an AI assistant that helps users answer questions given a specific context and conversation history. You will be given a context and chat history, and then asked a question based on that context and history. Your answer should be as precise as possible, and should only come from the context.\\nPlease add citation after each sentence when possible in a form \\\"(Source: citation)\\\".\\n\\n user: \\n Content: # Configure Apache Spark jobs in Azure Machine Learning\\n\\n3. Under **Add tags**, provide **Name** and **Value**, then select **Add**. Adding tags is optional.\\n    4. Under the **Code** section:\\n        1. Select **Azure Machine Learning workspace default blob storage** from **Choose code location** dropdown.\\n        2. Under **Path to code file to upload**, select **Browse**.\\n        3. In the pop-up screen titled **Path selection**, select the path of code file `titanic.py` on the workspace default datastore `workspaceblobstore`.\\n        4. Select **Save**.\\n        5. Input `titanic.py` as the name of **Entry file** for the standalone job.\\n        6. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter **Input name** as `titanic_data`. The input should refer to this name later in the **Arguments**.\\n            2. Select **Input type** as **Data**.\\n            3. Select **Data type** as **File**.\\n            4. Select **Data source** as **URI**.\\n            5. Enter an Azure Data Lake Storage (ADLS) Gen 2 data URI for `titanic.csv` file in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here, `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        7.  To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter **Output name** as `wrangled_data`. The output should refer to this name later in the **Arguments**.\\n            2. Select **Output type** as **Folder**.\\n            3. For **Output URI destination**, enter an Azure Data Lake Storage (ADLS) Gen 2 folder URI in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        8.  Enter **Arguments**  as `--titanic_data ${{inputs.titanic_data}} --wrangled_data ${{outputs.wrangled_data}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** as 2 and executor **Memory (GB)** as 2.\\n            2. For **Dynamically allocated executors**, select **Disabled**.\\n            3. Enter the number of **Executor instances** as 2.\\n        2. For **Driver size**, enter number of driver **Cores** as 1 and driver **Memory (GB)** as 2.\\n    6. Select **Next**.\\n6. On the **Review** screen:\\n    1. Review the job specification before submitting it.\\n    2. Select **Create** to submit the standalone Spark job.\\n\\n\u003e [!NOTE]\\n\u003e A standalone job submitted from the Studio UI using an Azure Machine Learning serverless Spark compute defaults to user identity passthrough for data access.\\n\\n\\n---\\n\\n\u003e [!TIP]\\n\u003e You might have an existing Synapse Spark pool in your Azure Synapse workspace. To use an existing Synapse Spark pool, please follow the instructions to [attach a Synapse Spark pool in Azure Machine Learning workspace](.\/how-to-manage-synapse-spark-pool.md).\\n\\n## Next steps\\n- [Apache Spark in Azure Machine Learning](.\/apache-spark-azure-ml-concepts.md)\\n- [Quickstart: Interactive Data Wrangling with Apache Spark](.\/apache-spark-environment-configuration.md)\\n- [Attach and manage a Synapse Spark pool in Azure Machine Learning](.\/how-to-manage-synapse-spark-pool.md)\\n- [Interactive Data Wrangling with Apache Spark in Azure Machine Learning](.\/interactive-data-wrangling-with-apache-spark-azure-ml.md)\\n- [Submit Spark jobs in Azure Machine Learning](.\/how-to-submit-spark-jobs.md)\\n- [Code samples for Spark jobs using Azure Machine Learning CLI](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/cli\/jobs\/spark)\\nSource: quickstart-spark-jobs.md\\n\\nContent: # Submit Spark jobs in Azure Machine Learning\\n\\n6. To add any Jar file(s) that the standalone job requires at runtime, select **+ Add file** under **Jars** and input the name of the `.jar` file to be included in the Spark driver. Also, add the executor `CLASSPATH` for successful job execution. Multiple files can be added.\\n        7. To add archive(s) that should be extracted into the working directory of each executor for successful job execution, select **+ Add file** under **Archives**, and input the name of the archive. Multiple archives can be added.\\n        8. Adding **Py files**, **Jars**, and **Archives** is optional.\\n        9. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter an **Input name**. The input should refer to this name later in the **Arguments**.\\n            2. Select an **Input type**.\\n            3. For type **Data**:\\n                1. Select **Data type** as **File** or **Folder**.\\n                2. Select **Data source** as **Upload from local**, **URI**, or **Datastore**.\\n                    - For **Upload from local**, select **Browse** under **Path to upload**, to choose the input file or folder.\\n                    - For **URI**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI), or enter a data asset `azureml:\/\/`.\\n                    - For **Datastore**:\\n                        1. **Select a datastore** from the dropdown menu.\\n                        2. Under **Path to data**, select **Browse**.\\n                        3. In the pop-up screen titled **Path selection**, select the path of the code files on the workspace default blob storage.\\n                        4. Select **Save**.\\n            4. For type **Integer**, enter an integer value as **Input value**.\\n            5. For type **Number**, enter a numeric value as **Input value**.\\n            6. For type **Boolean**, select **True** or **False** as **Input value**.\\n            7. For type **String**, enter a string as **Input value**.\\n        10. To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter an **Output name**. The output should refer to this name later to in the **Arguments**.\\n            2. Select **Output type** as **File** or **Folder**.\\n            3. For **Output URI destination**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI) or enter a data asset `azureml:\/\/`.\\n        11. Enter **Arguments** by using the names defined in the **Input name** and **Output name** fields in the earlier steps, and the names of input and output arguments used in the Python script **Entry file**. For example, if the **Input name** and **Output name** are defined as `job_input` and `job_output`, and the arguments are added in the **Entry file** as shown here\\n\\n            ``` python\\n            import argparse\\n\\n            parser = argparse.ArgumentParser()\\n            parser.add_argument(\\\"--input_param\\\")\\n            parser.add_argument(\\\"--output_param\\\")\\n            ```\\n\\n    then enter **Arguments** as `--input_param ${{inputs.job_input}} --output_param ${{outputs.job_output}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** and executor **Memory (GB)**, in gigabytes.\\n            2. For **Dynamically allocated executors**, select the **Disabled** or **Enabled** option.\\n        - If dynamic allocation of executors is **Disabled**, enter the number of **Executor instances**.\\n        - If dynamic allocation of executors is **Enabled**, use the slider to select the minimum and maximum number of executors.\\n        1. For **Driver size**:\\n            1. Enter number of driver **Cores** and driver **Memory (GB)**, in gigabytes.\\n            2. Enter **Name** and **Value** pairs for any **Additional configurations**, then select **Add**. Providing **Additional configurations** is optional.\\n    6. Select **Next**.\\n7. On the **Review** screen:\\nSource: how-to-submit-spark-jobs.md\\n\\nContent: # Configure Apache Spark jobs in Azure Machine Learning\\n\\n- [Code samples for Spark jobs using Azure Machine Learning Python SDK](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/sdk\/python\/jobs\/spark)\\nSource: quickstart-spark-jobs.md \\n\\n chat history: \\n user: \\nwhat is aml? \\nassistant: \\n \\n user: \\nhow to create a spark job? \\nassistant: \\n \\nuser: thank you \\nassistant:\""},"events":[{"name":"promptflow.function.inputs","timestamp":"2024-04-11T18:08:06.926552Z","attributes":{"payload":"{\n  \"template\": \"system: \\nYou are an AI assistant that helps users answer questions given a specific context and conversation history. You will be given a context and chat history, and then asked a question based on that context and history. Your answer should be as precise as possible, and should only come from the context.\\nPlease add citation after each sentence when possible in a form \\\"(Source: citation)\\\".\\n\\n user: \\n {{contexts}} \\n\\n chat history: \\n{% for item in chat_history %} user: \\n{{ item.inputs.question }} \\nassistant: \\n{{ item.outputs.output }} \\n{% endfor %}\\nuser: {{question}} \\nassistant:\",\n  \"chat_history\": [\n    {\n      \"inputs\": {\n        \"question\": \"what is aml?\"\n      },\n      \"outputs\": {\n        \"answer\": \"Azure Machine Learning (AML) is a cloud service used for accelerating and managing the machine learning project lifecycle. It is designed for ML professionals, data scientists, and engineers to facilitate their daily workflows in training and deploying models and managing machine learning operations (MLOps). You can create models in AML or use models built from open-source platforms like PyTorch, TensorFlow, or scikit-learn. Furthermore, Azure Machine Learning provides tools for monitoring, retraining, and redeploying models(Source: overview-what-is-azure-machine-learning.md).\"\n      }\n    },\n    {\n      \"inputs\": {\n        \"question\": \"how to create a spark job?\"\n      },\n      \"outputs\": {\n        \"answer\": \"To create a Spark job in Azure Machine Learning, you need to firstly provide a Name and optionally a Value under the **Add tags**. Then in the **Code** section, you need to choose the workspace's default blob storage for code location and select the path of the code file to upload. You then need to input the name of the `titanic.py` as the **Entry file**. \\n\\nNext, you add an input by selecting **+ Add input** under **Inputs** and filling up required fields such as **Input name**, **Input type**, and **Data type**. Similarly, you add an output by selecting **+ Add output** under **Outputs** and entering required information. \\n\\nThen you need to enter **Arguments** for the job. \\n\\nIn the **Spark configurations** section, you can configure parameters such as number of executor cores, memory, and instances. Similarly, configure the driver size. Then, you can add any additional optional configurations. \\n\\nOnce everything is set up, you can review the job specifications and select **Create** to submit the standalone Spark job (Source: quickstart-spark-jobs.md).\\n\\nBear in mind that you have the option to add any necessary Jar files, Py files or Archives for the job under the respective sections (Source: how-to-submit-spark-jobs.md). Also, please note that the job submitted defaults to user identity passthrough for data access (Source: quickstart-spark-jobs.md).\\n\"\n      }\n    }\n  ],\n  \"contexts\": \"Content: # Configure Apache Spark jobs in Azure Machine Learning\\n\\n3. Under **Add tags**, provide **Name** and **Value**, then select **Add**. Adding tags is optional.\\n    4. Under the **Code** section:\\n        1. Select **Azure Machine Learning workspace default blob storage** from **Choose code location** dropdown.\\n        2. Under **Path to code file to upload**, select **Browse**.\\n        3. In the pop-up screen titled **Path selection**, select the path of code file `titanic.py` on the workspace default datastore `workspaceblobstore`.\\n        4. Select **Save**.\\n        5. Input `titanic.py` as the name of **Entry file** for the standalone job.\\n        6. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter **Input name** as `titanic_data`. The input should refer to this name later in the **Arguments**.\\n            2. Select **Input type** as **Data**.\\n            3. Select **Data type** as **File**.\\n            4. Select **Data source** as **URI**.\\n            5. Enter an Azure Data Lake Storage (ADLS) Gen 2 data URI for `titanic.csv` file in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here, `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        7.  To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter **Output name** as `wrangled_data`. The output should refer to this name later in the **Arguments**.\\n            2. Select **Output type** as **Folder**.\\n            3. For **Output URI destination**, enter an Azure Data Lake Storage (ADLS) Gen 2 folder URI in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        8.  Enter **Arguments**  as `--titanic_data ${{inputs.titanic_data}} --wrangled_data ${{outputs.wrangled_data}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** as 2 and executor **Memory (GB)** as 2.\\n            2. For **Dynamically allocated executors**, select **Disabled**.\\n            3. Enter the number of **Executor instances** as 2.\\n        2. For **Driver size**, enter number of driver **Cores** as 1 and driver **Memory (GB)** as 2.\\n    6. Select **Next**.\\n6. On the **Review** screen:\\n    1. Review the job specification before submitting it.\\n    2. Select **Create** to submit the standalone Spark job.\\n\\n\u003e [!NOTE]\\n\u003e A standalone job submitted from the Studio UI using an Azure Machine Learning serverless Spark compute defaults to user identity passthrough for data access.\\n\\n\\n---\\n\\n\u003e [!TIP]\\n\u003e You might have an existing Synapse Spark pool in your Azure Synapse workspace. To use an existing Synapse Spark pool, please follow the instructions to [attach a Synapse Spark pool in Azure Machine Learning workspace](.\/how-to-manage-synapse-spark-pool.md).\\n\\n## Next steps\\n- [Apache Spark in Azure Machine Learning](.\/apache-spark-azure-ml-concepts.md)\\n- [Quickstart: Interactive Data Wrangling with Apache Spark](.\/apache-spark-environment-configuration.md)\\n- [Attach and manage a Synapse Spark pool in Azure Machine Learning](.\/how-to-manage-synapse-spark-pool.md)\\n- [Interactive Data Wrangling with Apache Spark in Azure Machine Learning](.\/interactive-data-wrangling-with-apache-spark-azure-ml.md)\\n- [Submit Spark jobs in Azure Machine Learning](.\/how-to-submit-spark-jobs.md)\\n- [Code samples for Spark jobs using Azure Machine Learning CLI](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/cli\/jobs\/spark)\\nSource: quickstart-spark-jobs.md\\n\\nContent: # Submit Spark jobs in Azure Machine Learning\\n\\n6. To add any Jar file(s) that the standalone job requires at runtime, select **+ Add file** under **Jars** and input the name of the `.jar` file to be included in the Spark driver. Also, add the executor `CLASSPATH` for successful job execution. Multiple files can be added.\\n        7. To add archive(s) that should be extracted into the working directory of each executor for successful job execution, select **+ Add file** under **Archives**, and input the name of the archive. Multiple archives can be added.\\n        8. Adding **Py files**, **Jars**, and **Archives** is optional.\\n        9. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter an **Input name**. The input should refer to this name later in the **Arguments**.\\n            2. Select an **Input type**.\\n            3. For type **Data**:\\n                1. Select **Data type** as **File** or **Folder**.\\n                2. Select **Data source** as **Upload from local**, **URI**, or **Datastore**.\\n                    - For **Upload from local**, select **Browse** under **Path to upload**, to choose the input file or folder.\\n                    - For **URI**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI), or enter a data asset `azureml:\/\/`.\\n                    - For **Datastore**:\\n                        1. **Select a datastore** from the dropdown menu.\\n                        2. Under **Path to data**, select **Browse**.\\n                        3. In the pop-up screen titled **Path selection**, select the path of the code files on the workspace default blob storage.\\n                        4. Select **Save**.\\n            4. For type **Integer**, enter an integer value as **Input value**.\\n            5. For type **Number**, enter a numeric value as **Input value**.\\n            6. For type **Boolean**, select **True** or **False** as **Input value**.\\n            7. For type **String**, enter a string as **Input value**.\\n        10. To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter an **Output name**. The output should refer to this name later to in the **Arguments**.\\n            2. Select **Output type** as **File** or **Folder**.\\n            3. For **Output URI destination**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI) or enter a data asset `azureml:\/\/`.\\n        11. Enter **Arguments** by using the names defined in the **Input name** and **Output name** fields in the earlier steps, and the names of input and output arguments used in the Python script **Entry file**. For example, if the **Input name** and **Output name** are defined as `job_input` and `job_output`, and the arguments are added in the **Entry file** as shown here\\n\\n            ``` python\\n            import argparse\\n\\n            parser = argparse.ArgumentParser()\\n            parser.add_argument(\\\"--input_param\\\")\\n            parser.add_argument(\\\"--output_param\\\")\\n            ```\\n\\n    then enter **Arguments** as `--input_param ${{inputs.job_input}} --output_param ${{outputs.job_output}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** and executor **Memory (GB)**, in gigabytes.\\n            2. For **Dynamically allocated executors**, select the **Disabled** or **Enabled** option.\\n        - If dynamic allocation of executors is **Disabled**, enter the number of **Executor instances**.\\n        - If dynamic allocation of executors is **Enabled**, use the slider to select the minimum and maximum number of executors.\\n        1. For **Driver size**:\\n            1. Enter number of driver **Cores** and driver **Memory (GB)**, in gigabytes.\\n            2. Enter **Name** and **Value** pairs for any **Additional configurations**, then select **Add**. Providing **Additional configurations** is optional.\\n    6. Select **Next**.\\n7. On the **Review** screen:\\nSource: how-to-submit-spark-jobs.md\\n\\nContent: # Configure Apache Spark jobs in Azure Machine Learning\\n\\n- [Code samples for Spark jobs using Azure Machine Learning Python SDK](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/sdk\/python\/jobs\/spark)\\nSource: quickstart-spark-jobs.md\",\n  \"question\": \"thank you\"\n}"}},{"name":"promptflow.function.output","timestamp":"2024-04-11T18:08:06.928682Z","attributes":{"payload":"\"system: \\nYou are an AI assistant that helps users answer questions given a specific context and conversation history. You will be given a context and chat history, and then asked a question based on that context and history. Your answer should be as precise as possible, and should only come from the context.\\nPlease add citation after each sentence when possible in a form \\\"(Source: citation)\\\".\\n\\n user: \\n Content: # Configure Apache Spark jobs in Azure Machine Learning\\n\\n3. Under **Add tags**, provide **Name** and **Value**, then select **Add**. Adding tags is optional.\\n    4. Under the **Code** section:\\n        1. Select **Azure Machine Learning workspace default blob storage** from **Choose code location** dropdown.\\n        2. Under **Path to code file to upload**, select **Browse**.\\n        3. In the pop-up screen titled **Path selection**, select the path of code file `titanic.py` on the workspace default datastore `workspaceblobstore`.\\n        4. Select **Save**.\\n        5. Input `titanic.py` as the name of **Entry file** for the standalone job.\\n        6. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter **Input name** as `titanic_data`. The input should refer to this name later in the **Arguments**.\\n            2. Select **Input type** as **Data**.\\n            3. Select **Data type** as **File**.\\n            4. Select **Data source** as **URI**.\\n            5. Enter an Azure Data Lake Storage (ADLS) Gen 2 data URI for `titanic.csv` file in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here, `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        7.  To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter **Output name** as `wrangled_data`. The output should refer to this name later in the **Arguments**.\\n            2. Select **Output type** as **Folder**.\\n            3. For **Output URI destination**, enter an Azure Data Lake Storage (ADLS) Gen 2 folder URI in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        8.  Enter **Arguments**  as `--titanic_data ${{inputs.titanic_data}} --wrangled_data ${{outputs.wrangled_data}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** as 2 and executor **Memory (GB)** as 2.\\n            2. For **Dynamically allocated executors**, select **Disabled**.\\n            3. Enter the number of **Executor instances** as 2.\\n        2. For **Driver size**, enter number of driver **Cores** as 1 and driver **Memory (GB)** as 2.\\n    6. Select **Next**.\\n6. On the **Review** screen:\\n    1. Review the job specification before submitting it.\\n    2. Select **Create** to submit the standalone Spark job.\\n\\n\u003e [!NOTE]\\n\u003e A standalone job submitted from the Studio UI using an Azure Machine Learning serverless Spark compute defaults to user identity passthrough for data access.\\n\\n\\n---\\n\\n\u003e [!TIP]\\n\u003e You might have an existing Synapse Spark pool in your Azure Synapse workspace. To use an existing Synapse Spark pool, please follow the instructions to [attach a Synapse Spark pool in Azure Machine Learning workspace](.\/how-to-manage-synapse-spark-pool.md).\\n\\n## Next steps\\n- [Apache Spark in Azure Machine Learning](.\/apache-spark-azure-ml-concepts.md)\\n- [Quickstart: Interactive Data Wrangling with Apache Spark](.\/apache-spark-environment-configuration.md)\\n- [Attach and manage a Synapse Spark pool in Azure Machine Learning](.\/how-to-manage-synapse-spark-pool.md)\\n- [Interactive Data Wrangling with Apache Spark in Azure Machine Learning](.\/interactive-data-wrangling-with-apache-spark-azure-ml.md)\\n- [Submit Spark jobs in Azure Machine Learning](.\/how-to-submit-spark-jobs.md)\\n- [Code samples for Spark jobs using Azure Machine Learning CLI](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/cli\/jobs\/spark)\\nSource: quickstart-spark-jobs.md\\n\\nContent: # Submit Spark jobs in Azure Machine Learning\\n\\n6. To add any Jar file(s) that the standalone job requires at runtime, select **+ Add file** under **Jars** and input the name of the `.jar` file to be included in the Spark driver. Also, add the executor `CLASSPATH` for successful job execution. Multiple files can be added.\\n        7. To add archive(s) that should be extracted into the working directory of each executor for successful job execution, select **+ Add file** under **Archives**, and input the name of the archive. Multiple archives can be added.\\n        8. Adding **Py files**, **Jars**, and **Archives** is optional.\\n        9. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter an **Input name**. The input should refer to this name later in the **Arguments**.\\n            2. Select an **Input type**.\\n            3. For type **Data**:\\n                1. Select **Data type** as **File** or **Folder**.\\n                2. Select **Data source** as **Upload from local**, **URI**, or **Datastore**.\\n                    - For **Upload from local**, select **Browse** under **Path to upload**, to choose the input file or folder.\\n                    - For **URI**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI), or enter a data asset `azureml:\/\/`.\\n                    - For **Datastore**:\\n                        1. **Select a datastore** from the dropdown menu.\\n                        2. Under **Path to data**, select **Browse**.\\n                        3. In the pop-up screen titled **Path selection**, select the path of the code files on the workspace default blob storage.\\n                        4. Select **Save**.\\n            4. For type **Integer**, enter an integer value as **Input value**.\\n            5. For type **Number**, enter a numeric value as **Input value**.\\n            6. For type **Boolean**, select **True** or **False** as **Input value**.\\n            7. For type **String**, enter a string as **Input value**.\\n        10. To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter an **Output name**. The output should refer to this name later to in the **Arguments**.\\n            2. Select **Output type** as **File** or **Folder**.\\n            3. For **Output URI destination**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI) or enter a data asset `azureml:\/\/`.\\n        11. Enter **Arguments** by using the names defined in the **Input name** and **Output name** fields in the earlier steps, and the names of input and output arguments used in the Python script **Entry file**. For example, if the **Input name** and **Output name** are defined as `job_input` and `job_output`, and the arguments are added in the **Entry file** as shown here\\n\\n            ``` python\\n            import argparse\\n\\n            parser = argparse.ArgumentParser()\\n            parser.add_argument(\\\"--input_param\\\")\\n            parser.add_argument(\\\"--output_param\\\")\\n            ```\\n\\n    then enter **Arguments** as `--input_param ${{inputs.job_input}} --output_param ${{outputs.job_output}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** and executor **Memory (GB)**, in gigabytes.\\n            2. For **Dynamically allocated executors**, select the **Disabled** or **Enabled** option.\\n        - If dynamic allocation of executors is **Disabled**, enter the number of **Executor instances**.\\n        - If dynamic allocation of executors is **Enabled**, use the slider to select the minimum and maximum number of executors.\\n        1. For **Driver size**:\\n            1. Enter number of driver **Cores** and driver **Memory (GB)**, in gigabytes.\\n            2. Enter **Name** and **Value** pairs for any **Additional configurations**, then select **Add**. Providing **Additional configurations** is optional.\\n    6. Select **Next**.\\n7. On the **Review** screen:\\nSource: how-to-submit-spark-jobs.md\\n\\nContent: # Configure Apache Spark jobs in Azure Machine Learning\\n\\n- [Code samples for Spark jobs using Azure Machine Learning Python SDK](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/sdk\/python\/jobs\/spark)\\nSource: quickstart-spark-jobs.md \\n\\n chat history: \\n user: \\nwhat is aml? \\nassistant: \\n \\n user: \\nhow to create a spark job? \\nassistant: \\n \\nuser: thank you \\nassistant:\""}}],"links":[],"resource":{"attributes":{"service.name":"promptflow"},"schema_url":""}}],"modelversion":"default","collectdatatype":"pandas.core.frame.DataFrame","agent":"azureml-ai-monitoring/0.1.0b4","contentrange":"bytes 0-40605/40606","correlationid":"6605828a-3ac3-4eb1-940c-e712740c421f","xrequestid":"6605828a-3ac3-4eb1-940c-e712740c421f"}
{"specversion":"1.0","id":"8a4191bd-60f7-45ba-b388-c6a6d155a07b","source":"/subscriptions/1aefdc5e-3a7c-4d71-a9f9-f5d3b03be19a/resourceGroups/yuachengtestrg/providers/Microsoft.MachineLearningServices/workspaces/ai-proj-eastus/onlineEndpoints/clone-vivi-log-test/deployments/clone-vivi-log-test-1","type":"azureml.inference.app_traces","datacontenttype":"application/json","time":"2024-04-11T18:08:36Z","data":[{"name":"openai_chat","context":{"trace_id":"0xa2f3f4f8267a482fa3bb96ad3e1f7f35","span_id":"0x90f356b0423d403b","trace_state":"[]"},"kind":"SpanKind.INTERNAL","parent_id":"0x8458bbc98d74b531","start_time":"2024-04-11T18:08:06.934912Z","end_time":"2024-04-11T18:08:31.587840Z","status":{"status_code":"OK"},"attributes":{"framework":"promptflow","span_type":"LLM","function":"openai.resources.chat.completions.Completions.create","node_name":"answer_the_question_with_context","request_id":"8d0a7bf5-bd46-4c69-95b6-e2cc925bfa4c","line_run_id":"8d0a7bf5-bd46-4c69-95b6-e2cc925bfa4c","inputs":"{\n  \"model\": \"gpt-4-32k\",\n  \"messages\": [\n    {\n      \"role\": \"system\",\n      \"content\": \"You are an AI assistant that helps users answer questions given a specific context and conversation history. You will be given a context and chat history, and then asked a question based on that context and history. Your answer should be as precise as possible, and should only come from the context.\\nPlease add citation after each sentence when possible in a form \\\"(Source: citation)\\\".\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"Content: # Configure Apache Spark jobs in Azure Machine Learning\\n\\n3. Under **Add tags**, provide **Name** and **Value**, then select **Add**. Adding tags is optional.\\n    4. Under the **Code** section:\\n        1. Select **Azure Machine Learning workspace default blob storage** from **Choose code location** dropdown.\\n        2. Under **Path to code file to upload**, select **Browse**.\\n        3. In the pop-up screen titled **Path selection**, select the path of code file `titanic.py` on the workspace default datastore `workspaceblobstore`.\\n        4. Select **Save**.\\n        5. Input `titanic.py` as the name of **Entry file** for the standalone job.\\n        6. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter **Input name** as `titanic_data`. The input should refer to this name later in the **Arguments**.\\n            2. Select **Input type** as **Data**.\\n            3. Select **Data type** as **File**.\\n            4. Select **Data source** as **URI**.\\n            5. Enter an Azure Data Lake Storage (ADLS) Gen 2 data URI for `titanic.csv` file in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here, `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        7.  To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter **Output name** as `wrangled_data`. The output should refer to this name later in the **Arguments**.\\n            2. Select **Output type** as **Folder**.\\n            3. For **Output URI destination**, enter an Azure Data Lake Storage (ADLS) Gen 2 folder URI in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        8.  Enter **Arguments**  as `--titanic_data ${{inputs.titanic_data}} --wrangled_data ${{outputs.wrangled_data}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** as 2 and executor **Memory (GB)** as 2.\\n            2. For **Dynamically allocated executors**, select **Disabled**.\\n            3. Enter the number of **Executor instances** as 2.\\n        2. For **Driver size**, enter number of driver **Cores** as 1 and driver **Memory (GB)** as 2.\\n    6. Select **Next**.\\n6. On the **Review** screen:\\n    1. Review the job specification before submitting it.\\n    2. Select **Create** to submit the standalone Spark job.\\n\\n\u003e [!NOTE]\\n\u003e A standalone job submitted from the Studio UI using an Azure Machine Learning serverless Spark compute defaults to user identity passthrough for data access.\\n\\n\\n---\\n\\n\u003e [!TIP]\\n\u003e You might have an existing Synapse Spark pool in your Azure Synapse workspace. To use an existing Synapse Spark pool, please follow the instructions to [attach a Synapse Spark pool in Azure Machine Learning workspace](.\/how-to-manage-synapse-spark-pool.md).\\n\\n## Next steps\\n- [Apache Spark in Azure Machine Learning](.\/apache-spark-azure-ml-concepts.md)\\n- [Quickstart: Interactive Data Wrangling with Apache Spark](.\/apache-spark-environment-configuration.md)\\n- [Attach and manage a Synapse Spark pool in Azure Machine Learning](.\/how-to-manage-synapse-spark-pool.md)\\n- [Interactive Data Wrangling with Apache Spark in Azure Machine Learning](.\/interactive-data-wrangling-with-apache-spark-azure-ml.md)\\n- [Submit Spark jobs in Azure Machine Learning](.\/how-to-submit-spark-jobs.md)\\n- [Code samples for Spark jobs using Azure Machine Learning CLI](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/cli\/jobs\/spark)\\nSource: quickstart-spark-jobs.md\\n\\nContent: # Submit Spark jobs in Azure Machine Learning\\n\\n6. To add any Jar file(s) that the standalone job requires at runtime, select **+ Add file** under **Jars** and input the name of the `.jar` file to be included in the Spark driver. Also, add the executor `CLASSPATH` for successful job execution. Multiple files can be added.\\n        7. To add archive(s) that should be extracted into the working directory of each executor for successful job execution, select **+ Add file** under **Archives**, and input the name of the archive. Multiple archives can be added.\\n        8. Adding **Py files**, **Jars**, and **Archives** is optional.\\n        9. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter an **Input name**. The input should refer to this name later in the **Arguments**.\\n            2. Select an **Input type**.\\n            3. For type **Data**:\\n                1. Select **Data type** as **File** or **Folder**.\\n                2. Select **Data source** as **Upload from local**, **URI**, or **Datastore**.\\n                    - For **Upload from local**, select **Browse** under **Path to upload**, to choose the input file or folder.\\n                    - For **URI**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI), or enter a data asset `azureml:\/\/`.\\n                    - For **Datastore**:\\n                        1. **Select a datastore** from the dropdown menu.\\n                        2. Under **Path to data**, select **Browse**.\\n                        3. In the pop-up screen titled **Path selection**, select the path of the code files on the workspace default blob storage.\\n                        4. Select **Save**.\\n            4. For type **Integer**, enter an integer value as **Input value**.\\n            5. For type **Number**, enter a numeric value as **Input value**.\\n            6. For type **Boolean**, select **True** or **False** as **Input value**.\\n            7. For type **String**, enter a string as **Input value**.\\n        10. To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter an **Output name**. The output should refer to this name later to in the **Arguments**.\\n            2. Select **Output type** as **File** or **Folder**.\\n            3. For **Output URI destination**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI) or enter a data asset `azureml:\/\/`.\\n        11. Enter **Arguments** by using the names defined in the **Input name** and **Output name** fields in the earlier steps, and the names of input and output arguments used in the Python script **Entry file**. For example, if the **Input name** and **Output name** are defined as `job_input` and `job_output`, and the arguments are added in the **Entry file** as shown here\\n\\n            ``` python\\n            import argparse\\n\\n            parser = argparse.ArgumentParser()\\n            parser.add_argument(\\\"--input_param\\\")\\n            parser.add_argument(\\\"--output_param\\\")\\n            ```\\n\\n    then enter **Arguments** as `--input_param ${{inputs.job_input}} --output_param ${{outputs.job_output}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** and executor **Memory (GB)**, in gigabytes.\\n            2. For **Dynamically allocated executors**, select the **Disabled** or **Enabled** option.\\n        - If dynamic allocation of executors is **Disabled**, enter the number of **Executor instances**.\\n        - If dynamic allocation of executors is **Enabled**, use the slider to select the minimum and maximum number of executors.\\n        1. For **Driver size**:\\n            1. Enter number of driver **Cores** and driver **Memory (GB)**, in gigabytes.\\n            2. Enter **Name** and **Value** pairs for any **Additional configurations**, then select **Add**. Providing **Additional configurations** is optional.\\n    6. Select **Next**.\\n7. On the **Review** screen:\\nSource: how-to-submit-spark-jobs.md\\n\\nContent: # Configure Apache Spark jobs in Azure Machine Learning\\n\\n- [Code samples for Spark jobs using Azure Machine Learning Python SDK](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/sdk\/python\/jobs\/spark)\\nSource: quickstart-spark-jobs.md \\n\\n chat history:\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"what is aml?\"\n    },\n    {\n      \"role\": \"assistant\",\n      \"content\": \"\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"how to create a spark job?\"\n    },\n    {\n      \"role\": \"assistant\",\n      \"content\": \"user: thank you \\nassistant:\"\n    }\n  ],\n  \"temperature\": 1.0,\n  \"top_p\": 1.0,\n  \"n\": 1,\n  \"stream\": false,\n  \"presence_penalty\": 0.0,\n  \"frequency_penalty\": 0.0,\n  \"user\": \"\"\n}","llm.response.model":"gpt-4-32k","llm.generated_message":"{\n  \"content\": \"To create a Spark job in Azure Machine Learning, follow these steps:\\n\\n1. Provide a **Name** and optional **Tag** for your job.\\n2. In the **Code** section, you need to:\\n   1. Select **Azure Machine Learning workspace default blob storage** from **Choose code location** dropdown.\\n   2. Select **Browse** under **Path to code file to upload** and select the path to your file on the workspace default datastore.\\n   3. Input the name of your **Entry file** (e.g. `titanic.py`) for the standalone job.\\n3. To add an input, select **+ Add input** under **Inputs** and provide necessary details like **Input name**, **Input type**, **Data type**, **Data source**, and appropriate Azure Data Lake Storage (ADLS) Gen 2 data URI.\\n4. To add an output, select **+ Add output** under **Outputs** and provide necessary details like **Output name**, **Output type**, and an appropriate Azure Data Lake Storage (ADLS) Gen 2 folder URI.\\n5. Enter **Arguments** as `--titanic_data ${{inputs.titanic_data}} --wrangled_data ${{outputs.wrangled_data}}`.\\n6. For **Spark configurations**, adjust the **Executor size** and **Driver size** to fit your job's requirements.\\n7. Review the job specification in the **Review** screen, then select **Create** to submit the standalone Spark job (Source: quickstart-spark-jobs.md).\",\n  \"role\": \"assistant\",\n  \"function_call\": null,\n  \"tool_calls\": null\n}","__computed__.cumulative_token_count.completion":317,"__computed__.cumulative_token_count.prompt":2037,"__computed__.cumulative_token_count.total":2354,"llm.usage.completion_tokens":317,"llm.usage.prompt_tokens":2037,"llm.usage.total_tokens":2354,"output":"{\n  \"id\": \"chatcmpl-9Ct8B2qugJ7sWmJC4iHLH8eurQQOA\",\n  \"choices\": [\n    {\n      \"finish_reason\": \"stop\",\n      \"index\": 0,\n      \"logprobs\": null,\n      \"message\": {\n        \"content\": \"To create a Spark job in Azure Machine Learning, follow these steps:\\n\\n1. Provide a **Name** and optional **Tag** for your job.\\n2. In the **Code** section, you need to:\\n   1. Select **Azure Machine Learning workspace default blob storage** from **Choose code location** dropdown.\\n   2. Select **Browse** under **Path to code file to upload** and select the path to your file on the workspace default datastore.\\n   3. Input the name of your **Entry file** (e.g. `titanic.py`) for the standalone job.\\n3. To add an input, select **+ Add input** under **Inputs** and provide necessary details like **Input name**, **Input type**, **Data type**, **Data source**, and appropriate Azure Data Lake Storage (ADLS) Gen 2 data URI.\\n4. To add an output, select **+ Add output** under **Outputs** and provide necessary details like **Output name**, **Output type**, and an appropriate Azure Data Lake Storage (ADLS) Gen 2 folder URI.\\n5. Enter **Arguments** as `--titanic_data ${{inputs.titanic_data}} --wrangled_data ${{outputs.wrangled_data}}`.\\n6. For **Spark configurations**, adjust the **Executor size** and **Driver size** to fit your job's requirements.\\n7. Review the job specification in the **Review** screen, then select **Create** to submit the standalone Spark job (Source: quickstart-spark-jobs.md).\",\n        \"role\": \"assistant\",\n        \"function_call\": null,\n        \"tool_calls\": null\n      },\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ],\n  \"created\": 1712858887,\n  \"model\": \"gpt-4-32k\",\n  \"object\": \"chat.completion\",\n  \"system_fingerprint\": null,\n  \"usage\": {\n    \"completion_tokens\": 317,\n    \"prompt_tokens\": 2037,\n    \"total_tokens\": 2354\n  },\n  \"prompt_filter_results\": [\n    {\n      \"prompt_index\": 0,\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ]\n}"},"events":[{"name":"promptflow.function.inputs","timestamp":"2024-04-11T18:08:06.937324Z","attributes":{"payload":"{\n  \"model\": \"gpt-4-32k\",\n  \"messages\": [\n    {\n      \"role\": \"system\",\n      \"content\": \"You are an AI assistant that helps users answer questions given a specific context and conversation history. You will be given a context and chat history, and then asked a question based on that context and history. Your answer should be as precise as possible, and should only come from the context.\\nPlease add citation after each sentence when possible in a form \\\"(Source: citation)\\\".\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"Content: # Configure Apache Spark jobs in Azure Machine Learning\\n\\n3. Under **Add tags**, provide **Name** and **Value**, then select **Add**. Adding tags is optional.\\n    4. Under the **Code** section:\\n        1. Select **Azure Machine Learning workspace default blob storage** from **Choose code location** dropdown.\\n        2. Under **Path to code file to upload**, select **Browse**.\\n        3. In the pop-up screen titled **Path selection**, select the path of code file `titanic.py` on the workspace default datastore `workspaceblobstore`.\\n        4. Select **Save**.\\n        5. Input `titanic.py` as the name of **Entry file** for the standalone job.\\n        6. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter **Input name** as `titanic_data`. The input should refer to this name later in the **Arguments**.\\n            2. Select **Input type** as **Data**.\\n            3. Select **Data type** as **File**.\\n            4. Select **Data source** as **URI**.\\n            5. Enter an Azure Data Lake Storage (ADLS) Gen 2 data URI for `titanic.csv` file in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here, `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        7.  To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter **Output name** as `wrangled_data`. The output should refer to this name later in the **Arguments**.\\n            2. Select **Output type** as **Folder**.\\n            3. For **Output URI destination**, enter an Azure Data Lake Storage (ADLS) Gen 2 folder URI in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        8.  Enter **Arguments**  as `--titanic_data ${{inputs.titanic_data}} --wrangled_data ${{outputs.wrangled_data}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** as 2 and executor **Memory (GB)** as 2.\\n            2. For **Dynamically allocated executors**, select **Disabled**.\\n            3. Enter the number of **Executor instances** as 2.\\n        2. For **Driver size**, enter number of driver **Cores** as 1 and driver **Memory (GB)** as 2.\\n    6. Select **Next**.\\n6. On the **Review** screen:\\n    1. Review the job specification before submitting it.\\n    2. Select **Create** to submit the standalone Spark job.\\n\\n\u003e [!NOTE]\\n\u003e A standalone job submitted from the Studio UI using an Azure Machine Learning serverless Spark compute defaults to user identity passthrough for data access.\\n\\n\\n---\\n\\n\u003e [!TIP]\\n\u003e You might have an existing Synapse Spark pool in your Azure Synapse workspace. To use an existing Synapse Spark pool, please follow the instructions to [attach a Synapse Spark pool in Azure Machine Learning workspace](.\/how-to-manage-synapse-spark-pool.md).\\n\\n## Next steps\\n- [Apache Spark in Azure Machine Learning](.\/apache-spark-azure-ml-concepts.md)\\n- [Quickstart: Interactive Data Wrangling with Apache Spark](.\/apache-spark-environment-configuration.md)\\n- [Attach and manage a Synapse Spark pool in Azure Machine Learning](.\/how-to-manage-synapse-spark-pool.md)\\n- [Interactive Data Wrangling with Apache Spark in Azure Machine Learning](.\/interactive-data-wrangling-with-apache-spark-azure-ml.md)\\n- [Submit Spark jobs in Azure Machine Learning](.\/how-to-submit-spark-jobs.md)\\n- [Code samples for Spark jobs using Azure Machine Learning CLI](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/cli\/jobs\/spark)\\nSource: quickstart-spark-jobs.md\\n\\nContent: # Submit Spark jobs in Azure Machine Learning\\n\\n6. To add any Jar file(s) that the standalone job requires at runtime, select **+ Add file** under **Jars** and input the name of the `.jar` file to be included in the Spark driver. Also, add the executor `CLASSPATH` for successful job execution. Multiple files can be added.\\n        7. To add archive(s) that should be extracted into the working directory of each executor for successful job execution, select **+ Add file** under **Archives**, and input the name of the archive. Multiple archives can be added.\\n        8. Adding **Py files**, **Jars**, and **Archives** is optional.\\n        9. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter an **Input name**. The input should refer to this name later in the **Arguments**.\\n            2. Select an **Input type**.\\n            3. For type **Data**:\\n                1. Select **Data type** as **File** or **Folder**.\\n                2. Select **Data source** as **Upload from local**, **URI**, or **Datastore**.\\n                    - For **Upload from local**, select **Browse** under **Path to upload**, to choose the input file or folder.\\n                    - For **URI**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI), or enter a data asset `azureml:\/\/`.\\n                    - For **Datastore**:\\n                        1. **Select a datastore** from the dropdown menu.\\n                        2. Under **Path to data**, select **Browse**.\\n                        3. In the pop-up screen titled **Path selection**, select the path of the code files on the workspace default blob storage.\\n                        4. Select **Save**.\\n            4. For type **Integer**, enter an integer value as **Input value**.\\n            5. For type **Number**, enter a numeric value as **Input value**.\\n            6. For type **Boolean**, select **True** or **False** as **Input value**.\\n            7. For type **String**, enter a string as **Input value**.\\n        10. To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter an **Output name**. The output should refer to this name later to in the **Arguments**.\\n            2. Select **Output type** as **File** or **Folder**.\\n            3. For **Output URI destination**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI) or enter a data asset `azureml:\/\/`.\\n        11. Enter **Arguments** by using the names defined in the **Input name** and **Output name** fields in the earlier steps, and the names of input and output arguments used in the Python script **Entry file**. For example, if the **Input name** and **Output name** are defined as `job_input` and `job_output`, and the arguments are added in the **Entry file** as shown here\\n\\n            ``` python\\n            import argparse\\n\\n            parser = argparse.ArgumentParser()\\n            parser.add_argument(\\\"--input_param\\\")\\n            parser.add_argument(\\\"--output_param\\\")\\n            ```\\n\\n    then enter **Arguments** as `--input_param ${{inputs.job_input}} --output_param ${{outputs.job_output}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** and executor **Memory (GB)**, in gigabytes.\\n            2. For **Dynamically allocated executors**, select the **Disabled** or **Enabled** option.\\n        - If dynamic allocation of executors is **Disabled**, enter the number of **Executor instances**.\\n        - If dynamic allocation of executors is **Enabled**, use the slider to select the minimum and maximum number of executors.\\n        1. For **Driver size**:\\n            1. Enter number of driver **Cores** and driver **Memory (GB)**, in gigabytes.\\n            2. Enter **Name** and **Value** pairs for any **Additional configurations**, then select **Add**. Providing **Additional configurations** is optional.\\n    6. Select **Next**.\\n7. On the **Review** screen:\\nSource: how-to-submit-spark-jobs.md\\n\\nContent: # Configure Apache Spark jobs in Azure Machine Learning\\n\\n- [Code samples for Spark jobs using Azure Machine Learning Python SDK](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/sdk\/python\/jobs\/spark)\\nSource: quickstart-spark-jobs.md \\n\\n chat history:\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"what is aml?\"\n    },\n    {\n      \"role\": \"assistant\",\n      \"content\": \"\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"how to create a spark job?\"\n    },\n    {\n      \"role\": \"assistant\",\n      \"content\": \"user: thank you \\nassistant:\"\n    }\n  ],\n  \"temperature\": 1.0,\n  \"top_p\": 1.0,\n  \"n\": 1,\n  \"stream\": false,\n  \"presence_penalty\": 0.0,\n  \"frequency_penalty\": 0.0,\n  \"user\": \"\"\n}"}},{"name":"promptflow.llm.generated_message","timestamp":"2024-04-11T18:08:31.586194Z","attributes":{"payload":"{\n  \"content\": \"To create a Spark job in Azure Machine Learning, follow these steps:\\n\\n1. Provide a **Name** and optional **Tag** for your job.\\n2. In the **Code** section, you need to:\\n   1. Select **Azure Machine Learning workspace default blob storage** from **Choose code location** dropdown.\\n   2. Select **Browse** under **Path to code file to upload** and select the path to your file on the workspace default datastore.\\n   3. Input the name of your **Entry file** (e.g. `titanic.py`) for the standalone job.\\n3. To add an input, select **+ Add input** under **Inputs** and provide necessary details like **Input name**, **Input type**, **Data type**, **Data source**, and appropriate Azure Data Lake Storage (ADLS) Gen 2 data URI.\\n4. To add an output, select **+ Add output** under **Outputs** and provide necessary details like **Output name**, **Output type**, and an appropriate Azure Data Lake Storage (ADLS) Gen 2 folder URI.\\n5. Enter **Arguments** as `--titanic_data ${{inputs.titanic_data}} --wrangled_data ${{outputs.wrangled_data}}`.\\n6. For **Spark configurations**, adjust the **Executor size** and **Driver size** to fit your job's requirements.\\n7. Review the job specification in the **Review** screen, then select **Create** to submit the standalone Spark job (Source: quickstart-spark-jobs.md).\",\n  \"role\": \"assistant\",\n  \"function_call\": null,\n  \"tool_calls\": null\n}"}},{"name":"promptflow.function.output","timestamp":"2024-04-11T18:08:31.587637Z","attributes":{"payload":"{\n  \"id\": \"chatcmpl-9Ct8B2qugJ7sWmJC4iHLH8eurQQOA\",\n  \"choices\": [\n    {\n      \"finish_reason\": \"stop\",\n      \"index\": 0,\n      \"logprobs\": null,\n      \"message\": {\n        \"content\": \"To create a Spark job in Azure Machine Learning, follow these steps:\\n\\n1. Provide a **Name** and optional **Tag** for your job.\\n2. In the **Code** section, you need to:\\n   1. Select **Azure Machine Learning workspace default blob storage** from **Choose code location** dropdown.\\n   2. Select **Browse** under **Path to code file to upload** and select the path to your file on the workspace default datastore.\\n   3. Input the name of your **Entry file** (e.g. `titanic.py`) for the standalone job.\\n3. To add an input, select **+ Add input** under **Inputs** and provide necessary details like **Input name**, **Input type**, **Data type**, **Data source**, and appropriate Azure Data Lake Storage (ADLS) Gen 2 data URI.\\n4. To add an output, select **+ Add output** under **Outputs** and provide necessary details like **Output name**, **Output type**, and an appropriate Azure Data Lake Storage (ADLS) Gen 2 folder URI.\\n5. Enter **Arguments** as `--titanic_data ${{inputs.titanic_data}} --wrangled_data ${{outputs.wrangled_data}}`.\\n6. For **Spark configurations**, adjust the **Executor size** and **Driver size** to fit your job's requirements.\\n7. Review the job specification in the **Review** screen, then select **Create** to submit the standalone Spark job (Source: quickstart-spark-jobs.md).\",\n        \"role\": \"assistant\",\n        \"function_call\": null,\n        \"tool_calls\": null\n      },\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ],\n  \"created\": 1712858887,\n  \"model\": \"gpt-4-32k\",\n  \"object\": \"chat.completion\",\n  \"system_fingerprint\": null,\n  \"usage\": {\n    \"completion_tokens\": 317,\n    \"prompt_tokens\": 2037,\n    \"total_tokens\": 2354\n  },\n  \"prompt_filter_results\": [\n    {\n      \"prompt_index\": 0,\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ]\n}"}}],"links":[],"resource":{"attributes":{"service.name":"promptflow"},"schema_url":""}}],"collectdatatype":"pandas.core.frame.DataFrame","agent":"azureml-ai-monitoring/0.1.0b4","contentrange":"bytes 0-28446/28447","correlationid":"522eb493-93b7-4bbb-bf15-7c61aa09d1c8","xrequestid":"522eb493-93b7-4bbb-bf15-7c61aa09d1c8","modelversion":"default"}
{"specversion":"1.0","id":"885134b6-ea8b-4747-9cda-6ac41766e4b3","source":"/subscriptions/1aefdc5e-3a7c-4d71-a9f9-f5d3b03be19a/resourceGroups/yuachengtestrg/providers/Microsoft.MachineLearningServices/workspaces/ai-proj-eastus/onlineEndpoints/clone-vivi-log-test/deployments/clone-vivi-log-test-1","type":"azureml.inference.app_traces","datacontenttype":"application/json","time":"2024-04-11T18:08:36Z","data":[{"name":"answer_the_question_with_context","context":{"trace_id":"0xa2f3f4f8267a482fa3bb96ad3e1f7f35","span_id":"0x8458bbc98d74b531","trace_state":"[]"},"kind":"SpanKind.INTERNAL","parent_id":"0x22865871c42ca40c","start_time":"2024-04-11T18:08:06.930809Z","end_time":"2024-04-11T18:08:31.588113Z","status":{"status_code":"OK"},"attributes":{"framework":"promptflow","span_type":"Function","function":"AzureOpenAI.chat","node_name":"answer_the_question_with_context","request_id":"8d0a7bf5-bd46-4c69-95b6-e2cc925bfa4c","line_run_id":"8d0a7bf5-bd46-4c69-95b6-e2cc925bfa4c","prompt.template":"{{prompt_text}}","prompt.variables":"{\n  \"prompt_text\": \"system: \\nYou are an AI assistant that helps users answer questions given a specific context and conversation history. You will be given a context and chat history, and then asked a question based on that context and history. Your answer should be as precise as possible, and should only come from the context.\\nPlease add citation after each sentence when possible in a form \\\"(Source: citation)\\\".\\n\\n user: \\n Content: # Configure Apache Spark jobs in Azure Machine Learning\\n\\n3. Under **Add tags**, provide **Name** and **Value**, then select **Add**. Adding tags is optional.\\n    4. Under the **Code** section:\\n        1. Select **Azure Machine Learning workspace default blob storage** from **Choose code location** dropdown.\\n        2. Under **Path to code file to upload**, select **Browse**.\\n        3. In the pop-up screen titled **Path selection**, select the path of code file `titanic.py` on the workspace default datastore `workspaceblobstore`.\\n        4. Select **Save**.\\n        5. Input `titanic.py` as the name of **Entry file** for the standalone job.\\n        6. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter **Input name** as `titanic_data`. The input should refer to this name later in the **Arguments**.\\n            2. Select **Input type** as **Data**.\\n            3. Select **Data type** as **File**.\\n            4. Select **Data source** as **URI**.\\n            5. Enter an Azure Data Lake Storage (ADLS) Gen 2 data URI for `titanic.csv` file in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here, `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        7.  To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter **Output name** as `wrangled_data`. The output should refer to this name later in the **Arguments**.\\n            2. Select **Output type** as **Folder**.\\n            3. For **Output URI destination**, enter an Azure Data Lake Storage (ADLS) Gen 2 folder URI in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        8.  Enter **Arguments**  as `--titanic_data ${{inputs.titanic_data}} --wrangled_data ${{outputs.wrangled_data}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** as 2 and executor **Memory (GB)** as 2.\\n            2. For **Dynamically allocated executors**, select **Disabled**.\\n            3. Enter the number of **Executor instances** as 2.\\n        2. For **Driver size**, enter number of driver **Cores** as 1 and driver **Memory (GB)** as 2.\\n    6. Select **Next**.\\n6. On the **Review** screen:\\n    1. Review the job specification before submitting it.\\n    2. Select **Create** to submit the standalone Spark job.\\n\\n\u003e [!NOTE]\\n\u003e A standalone job submitted from the Studio UI using an Azure Machine Learning serverless Spark compute defaults to user identity passthrough for data access.\\n\\n\\n---\\n\\n\u003e [!TIP]\\n\u003e You might have an existing Synapse Spark pool in your Azure Synapse workspace. To use an existing Synapse Spark pool, please follow the instructions to [attach a Synapse Spark pool in Azure Machine Learning workspace](.\/how-to-manage-synapse-spark-pool.md).\\n\\n## Next steps\\n- [Apache Spark in Azure Machine Learning](.\/apache-spark-azure-ml-concepts.md)\\n- [Quickstart: Interactive Data Wrangling with Apache Spark](.\/apache-spark-environment-configuration.md)\\n- [Attach and manage a Synapse Spark pool in Azure Machine Learning](.\/how-to-manage-synapse-spark-pool.md)\\n- [Interactive Data Wrangling with Apache Spark in Azure Machine Learning](.\/interactive-data-wrangling-with-apache-spark-azure-ml.md)\\n- [Submit Spark jobs in Azure Machine Learning](.\/how-to-submit-spark-jobs.md)\\n- [Code samples for Spark jobs using Azure Machine Learning CLI](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/cli\/jobs\/spark)\\nSource: quickstart-spark-jobs.md\\n\\nContent: # Submit Spark jobs in Azure Machine Learning\\n\\n6. To add any Jar file(s) that the standalone job requires at runtime, select **+ Add file** under **Jars** and input the name of the `.jar` file to be included in the Spark driver. Also, add the executor `CLASSPATH` for successful job execution. Multiple files can be added.\\n        7. To add archive(s) that should be extracted into the working directory of each executor for successful job execution, select **+ Add file** under **Archives**, and input the name of the archive. Multiple archives can be added.\\n        8. Adding **Py files**, **Jars**, and **Archives** is optional.\\n        9. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter an **Input name**. The input should refer to this name later in the **Arguments**.\\n            2. Select an **Input type**.\\n            3. For type **Data**:\\n                1. Select **Data type** as **File** or **Folder**.\\n                2. Select **Data source** as **Upload from local**, **URI**, or **Datastore**.\\n                    - For **Upload from local**, select **Browse** under **Path to upload**, to choose the input file or folder.\\n                    - For **URI**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI), or enter a data asset `azureml:\/\/`.\\n                    - For **Datastore**:\\n                        1. **Select a datastore** from the dropdown menu.\\n                        2. Under **Path to data**, select **Browse**.\\n                        3. In the pop-up screen titled **Path selection**, select the path of the code files on the workspace default blob storage.\\n                        4. Select **Save**.\\n            4. For type **Integer**, enter an integer value as **Input value**.\\n            5. For type **Number**, enter a numeric value as **Input value**.\\n            6. For type **Boolean**, select **True** or **False** as **Input value**.\\n            7. For type **String**, enter a string as **Input value**.\\n        10. To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter an **Output name**. The output should refer to this name later to in the **Arguments**.\\n            2. Select **Output type** as **File** or **Folder**.\\n            3. For **Output URI destination**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI) or enter a data asset `azureml:\/\/`.\\n        11. Enter **Arguments** by using the names defined in the **Input name** and **Output name** fields in the earlier steps, and the names of input and output arguments used in the Python script **Entry file**. For example, if the **Input name** and **Output name** are defined as `job_input` and `job_output`, and the arguments are added in the **Entry file** as shown here\\n\\n            ``` python\\n            import argparse\\n\\n            parser = argparse.ArgumentParser()\\n            parser.add_argument(\\\"--input_param\\\")\\n            parser.add_argument(\\\"--output_param\\\")\\n            ```\\n\\n    then enter **Arguments** as `--input_param ${{inputs.job_input}} --output_param ${{outputs.job_output}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** and executor **Memory (GB)**, in gigabytes.\\n            2. For **Dynamically allocated executors**, select the **Disabled** or **Enabled** option.\\n        - If dynamic allocation of executors is **Disabled**, enter the number of **Executor instances**.\\n        - If dynamic allocation of executors is **Enabled**, use the slider to select the minimum and maximum number of executors.\\n        1. For **Driver size**:\\n            1. Enter number of driver **Cores** and driver **Memory (GB)**, in gigabytes.\\n            2. Enter **Name** and **Value** pairs for any **Additional configurations**, then select **Add**. Providing **Additional configurations** is optional.\\n    6. Select **Next**.\\n7. On the **Review** screen:\\nSource: how-to-submit-spark-jobs.md\\n\\nContent: # Configure Apache Spark jobs in Azure Machine Learning\\n\\n- [Code samples for Spark jobs using Azure Machine Learning Python SDK](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/sdk\/python\/jobs\/spark)\\nSource: quickstart-spark-jobs.md \\n\\n chat history: \\n user: \\nwhat is aml? \\nassistant: \\n \\n user: \\nhow to create a spark job? \\nassistant: \\n \\nuser: thank you \\nassistant:\"\n}","inputs":"{\n  \"prompt\": \"{{prompt_text}}\",\n  \"deployment_name\": \"gpt-4-32k\",\n  \"temperature\": 1.0,\n  \"top_p\": 1.0,\n  \"presence_penalty\": 0.0,\n  \"frequency_penalty\": 0.0,\n  \"prompt_text\": \"system: \\nYou are an AI assistant that helps users answer questions given a specific context and conversation history. You will be given a context and chat history, and then asked a question based on that context and history. Your answer should be as precise as possible, and should only come from the context.\\nPlease add citation after each sentence when possible in a form \\\"(Source: citation)\\\".\\n\\n user: \\n Content: # Configure Apache Spark jobs in Azure Machine Learning\\n\\n3. Under **Add tags**, provide **Name** and **Value**, then select **Add**. Adding tags is optional.\\n    4. Under the **Code** section:\\n        1. Select **Azure Machine Learning workspace default blob storage** from **Choose code location** dropdown.\\n        2. Under **Path to code file to upload**, select **Browse**.\\n        3. In the pop-up screen titled **Path selection**, select the path of code file `titanic.py` on the workspace default datastore `workspaceblobstore`.\\n        4. Select **Save**.\\n        5. Input `titanic.py` as the name of **Entry file** for the standalone job.\\n        6. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter **Input name** as `titanic_data`. The input should refer to this name later in the **Arguments**.\\n            2. Select **Input type** as **Data**.\\n            3. Select **Data type** as **File**.\\n            4. Select **Data source** as **URI**.\\n            5. Enter an Azure Data Lake Storage (ADLS) Gen 2 data URI for `titanic.csv` file in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here, `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        7.  To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter **Output name** as `wrangled_data`. The output should refer to this name later in the **Arguments**.\\n            2. Select **Output type** as **Folder**.\\n            3. For **Output URI destination**, enter an Azure Data Lake Storage (ADLS) Gen 2 folder URI in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        8.  Enter **Arguments**  as `--titanic_data ${{inputs.titanic_data}} --wrangled_data ${{outputs.wrangled_data}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** as 2 and executor **Memory (GB)** as 2.\\n            2. For **Dynamically allocated executors**, select **Disabled**.\\n            3. Enter the number of **Executor instances** as 2.\\n        2. For **Driver size**, enter number of driver **Cores** as 1 and driver **Memory (GB)** as 2.\\n    6. Select **Next**.\\n6. On the **Review** screen:\\n    1. Review the job specification before submitting it.\\n    2. Select **Create** to submit the standalone Spark job.\\n\\n\u003e [!NOTE]\\n\u003e A standalone job submitted from the Studio UI using an Azure Machine Learning serverless Spark compute defaults to user identity passthrough for data access.\\n\\n\\n---\\n\\n\u003e [!TIP]\\n\u003e You might have an existing Synapse Spark pool in your Azure Synapse workspace. To use an existing Synapse Spark pool, please follow the instructions to [attach a Synapse Spark pool in Azure Machine Learning workspace](.\/how-to-manage-synapse-spark-pool.md).\\n\\n## Next steps\\n- [Apache Spark in Azure Machine Learning](.\/apache-spark-azure-ml-concepts.md)\\n- [Quickstart: Interactive Data Wrangling with Apache Spark](.\/apache-spark-environment-configuration.md)\\n- [Attach and manage a Synapse Spark pool in Azure Machine Learning](.\/how-to-manage-synapse-spark-pool.md)\\n- [Interactive Data Wrangling with Apache Spark in Azure Machine Learning](.\/interactive-data-wrangling-with-apache-spark-azure-ml.md)\\n- [Submit Spark jobs in Azure Machine Learning](.\/how-to-submit-spark-jobs.md)\\n- [Code samples for Spark jobs using Azure Machine Learning CLI](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/cli\/jobs\/spark)\\nSource: quickstart-spark-jobs.md\\n\\nContent: # Submit Spark jobs in Azure Machine Learning\\n\\n6. To add any Jar file(s) that the standalone job requires at runtime, select **+ Add file** under **Jars** and input the name of the `.jar` file to be included in the Spark driver. Also, add the executor `CLASSPATH` for successful job execution. Multiple files can be added.\\n        7. To add archive(s) that should be extracted into the working directory of each executor for successful job execution, select **+ Add file** under **Archives**, and input the name of the archive. Multiple archives can be added.\\n        8. Adding **Py files**, **Jars**, and **Archives** is optional.\\n        9. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter an **Input name**. The input should refer to this name later in the **Arguments**.\\n            2. Select an **Input type**.\\n            3. For type **Data**:\\n                1. Select **Data type** as **File** or **Folder**.\\n                2. Select **Data source** as **Upload from local**, **URI**, or **Datastore**.\\n                    - For **Upload from local**, select **Browse** under **Path to upload**, to choose the input file or folder.\\n                    - For **URI**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI), or enter a data asset `azureml:\/\/`.\\n                    - For **Datastore**:\\n                        1. **Select a datastore** from the dropdown menu.\\n                        2. Under **Path to data**, select **Browse**.\\n                        3. In the pop-up screen titled **Path selection**, select the path of the code files on the workspace default blob storage.\\n                        4. Select **Save**.\\n            4. For type **Integer**, enter an integer value as **Input value**.\\n            5. For type **Number**, enter a numeric value as **Input value**.\\n            6. For type **Boolean**, select **True** or **False** as **Input value**.\\n            7. For type **String**, enter a string as **Input value**.\\n        10. To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter an **Output name**. The output should refer to this name later to in the **Arguments**.\\n            2. Select **Output type** as **File** or **Folder**.\\n            3. For **Output URI destination**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI) or enter a data asset `azureml:\/\/`.\\n        11. Enter **Arguments** by using the names defined in the **Input name** and **Output name** fields in the earlier steps, and the names of input and output arguments used in the Python script **Entry file**. For example, if the **Input name** and **Output name** are defined as `job_input` and `job_output`, and the arguments are added in the **Entry file** as shown here\\n\\n            ``` python\\n            import argparse\\n\\n            parser = argparse.ArgumentParser()\\n            parser.add_argument(\\\"--input_param\\\")\\n            parser.add_argument(\\\"--output_param\\\")\\n            ```\\n\\n    then enter **Arguments** as `--input_param ${{inputs.job_input}} --output_param ${{outputs.job_output}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** and executor **Memory (GB)**, in gigabytes.\\n            2. For **Dynamically allocated executors**, select the **Disabled** or **Enabled** option.\\n        - If dynamic allocation of executors is **Disabled**, enter the number of **Executor instances**.\\n        - If dynamic allocation of executors is **Enabled**, use the slider to select the minimum and maximum number of executors.\\n        1. For **Driver size**:\\n            1. Enter number of driver **Cores** and driver **Memory (GB)**, in gigabytes.\\n            2. Enter **Name** and **Value** pairs for any **Additional configurations**, then select **Add**. Providing **Additional configurations** is optional.\\n    6. Select **Next**.\\n7. On the **Review** screen:\\nSource: how-to-submit-spark-jobs.md\\n\\nContent: # Configure Apache Spark jobs in Azure Machine Learning\\n\\n- [Code samples for Spark jobs using Azure Machine Learning Python SDK](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/sdk\/python\/jobs\/spark)\\nSource: quickstart-spark-jobs.md \\n\\n chat history: \\n user: \\nwhat is aml? \\nassistant: \\n \\n user: \\nhow to create a spark job? \\nassistant: \\n \\nuser: thank you \\nassistant:\",\n  \"stream\": false\n}","__computed__.cumulative_token_count.completion":317,"__computed__.cumulative_token_count.prompt":2037,"__computed__.cumulative_token_count.total":2354,"output":"\"To create a Spark job in Azure Machine Learning, follow these steps:\\n\\n1. Provide a **Name** and optional **Tag** for your job.\\n2. In the **Code** section, you need to:\\n   1. Select **Azure Machine Learning workspace default blob storage** from **Choose code location** dropdown.\\n   2. Select **Browse** under **Path to code file to upload** and select the path to your file on the workspace default datastore.\\n   3. Input the name of your **Entry file** (e.g. `titanic.py`) for the standalone job.\\n3. To add an input, select **+ Add input** under **Inputs** and provide necessary details like **Input name**, **Input type**, **Data type**, **Data source**, and appropriate Azure Data Lake Storage (ADLS) Gen 2 data URI.\\n4. To add an output, select **+ Add output** under **Outputs** and provide necessary details like **Output name**, **Output type**, and an appropriate Azure Data Lake Storage (ADLS) Gen 2 folder URI.\\n5. Enter **Arguments** as `--titanic_data ${{inputs.titanic_data}} --wrangled_data ${{outputs.wrangled_data}}`.\\n6. For **Spark configurations**, adjust the **Executor size** and **Driver size** to fit your job's requirements.\\n7. Review the job specification in the **Review** screen, then select **Create** to submit the standalone Spark job (Source: quickstart-spark-jobs.md).\""},"events":[{"name":"promptflow.prompt.template","timestamp":"2024-04-11T18:08:06.931726Z","attributes":{"payload":"{\n  \"prompt.template\": \"{{prompt_text}}\",\n  \"prompt.variables\": \"{\\n  \\\"prompt_text\\\": \\\"system: \\\\nYou are an AI assistant that helps users answer questions given a specific context and conversation history. You will be given a context and chat history, and then asked a question based on that context and history. Your answer should be as precise as possible, and should only come from the context.\\\\nPlease add citation after each sentence when possible in a form \\\\\\\"(Source: citation)\\\\\\\".\\\\n\\\\n user: \\\\n Content: # Configure Apache Spark jobs in Azure Machine Learning\\\\n\\\\n3. Under **Add tags**, provide **Name** and **Value**, then select **Add**. Adding tags is optional.\\\\n    4. Under the **Code** section:\\\\n        1. Select **Azure Machine Learning workspace default blob storage** from **Choose code location** dropdown.\\\\n        2. Under **Path to code file to upload**, select **Browse**.\\\\n        3. In the pop-up screen titled **Path selection**, select the path of code file `titanic.py` on the workspace default datastore `workspaceblobstore`.\\\\n        4. Select **Save**.\\\\n        5. Input `titanic.py` as the name of **Entry file** for the standalone job.\\\\n        6. To add an input, select **+ Add input** under **Inputs** and\\\\n            1. Enter **Input name** as `titanic_data`. The input should refer to this name later in the **Arguments**.\\\\n            2. Select **Input type** as **Data**.\\\\n            3. Select **Data type** as **File**.\\\\n            4. Select **Data source** as **URI**.\\\\n            5. Enter an Azure Data Lake Storage (ADLS) Gen 2 data URI for `titanic.csv` file in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here, `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\\\n        7.  To add an input, select **+ Add output** under **Outputs** and\\\\n            1. Enter **Output name** as `wrangled_data`. The output should refer to this name later in the **Arguments**.\\\\n            2. Select **Output type** as **Folder**.\\\\n            3. For **Output URI destination**, enter an Azure Data Lake Storage (ADLS) Gen 2 folder URI in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\\\n        8.  Enter **Arguments**  as `--titanic_data ${{inputs.titanic_data}} --wrangled_data ${{outputs.wrangled_data}}`.\\\\n    5. Under the **Spark configurations** section:\\\\n        1. For **Executor size**:\\\\n            1. Enter the number of executor **Cores** as 2 and executor **Memory (GB)** as 2.\\\\n            2. For **Dynamically allocated executors**, select **Disabled**.\\\\n            3. Enter the number of **Executor instances** as 2.\\\\n        2. For **Driver size**, enter number of driver **Cores** as 1 and driver **Memory (GB)** as 2.\\\\n    6. Select **Next**.\\\\n6. On the **Review** screen:\\\\n    1. Review the job specification before submitting it.\\\\n    2. Select **Create** to submit the standalone Spark job.\\\\n\\\\n\u003e [!NOTE]\\\\n\u003e A standalone job submitted from the Studio UI using an Azure Machine Learning serverless Spark compute defaults to user identity passthrough for data access.\\\\n\\\\n\\\\n---\\\\n\\\\n\u003e [!TIP]\\\\n\u003e You might have an existing Synapse Spark pool in your Azure Synapse workspace. To use an existing Synapse Spark pool, please follow the instructions to [attach a Synapse Spark pool in Azure Machine Learning workspace](.\/how-to-manage-synapse-spark-pool.md).\\\\n\\\\n## Next steps\\\\n- [Apache Spark in Azure Machine Learning](.\/apache-spark-azure-ml-concepts.md)\\\\n- [Quickstart: Interactive Data Wrangling with Apache Spark](.\/apache-spark-environment-configuration.md)\\\\n- [Attach and manage a Synapse Spark pool in Azure Machine Learning](.\/how-to-manage-synapse-spark-pool.md)\\\\n- [Interactive Data Wrangling with Apache Spark in Azure Machine Learning](.\/interactive-data-wrangling-with-apache-spark-azure-ml.md)\\\\n- [Submit Spark jobs in Azure Machine Learning](.\/how-to-submit-spark-jobs.md)\\\\n- [Code samples for Spark jobs using Azure Machine Learning CLI](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/cli\/jobs\/spark)\\\\nSource: quickstart-spark-jobs.md\\\\n\\\\nContent: # Submit Spark jobs in Azure Machine Learning\\\\n\\\\n6. To add any Jar file(s) that the standalone job requires at runtime, select **+ Add file** under **Jars** and input the name of the `.jar` file to be included in the Spark driver. Also, add the executor `CLASSPATH` for successful job execution. Multiple files can be added.\\\\n        7. To add archive(s) that should be extracted into the working directory of each executor for successful job execution, select **+ Add file** under **Archives**, and input the name of the archive. Multiple archives can be added.\\\\n        8. Adding **Py files**, **Jars**, and **Archives** is optional.\\\\n        9. To add an input, select **+ Add input** under **Inputs** and\\\\n            1. Enter an **Input name**. The input should refer to this name later in the **Arguments**.\\\\n            2. Select an **Input type**.\\\\n            3. For type **Data**:\\\\n                1. Select **Data type** as **File** or **Folder**.\\\\n                2. Select **Data source** as **Upload from local**, **URI**, or **Datastore**.\\\\n                    - For **Upload from local**, select **Browse** under **Path to upload**, to choose the input file or folder.\\\\n                    - For **URI**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI), or enter a data asset `azureml:\/\/`.\\\\n                    - For **Datastore**:\\\\n                        1. **Select a datastore** from the dropdown menu.\\\\n                        2. Under **Path to data**, select **Browse**.\\\\n                        3. In the pop-up screen titled **Path selection**, select the path of the code files on the workspace default blob storage.\\\\n                        4. Select **Save**.\\\\n            4. For type **Integer**, enter an integer value as **Input value**.\\\\n            5. For type **Number**, enter a numeric value as **Input value**.\\\\n            6. For type **Boolean**, select **True** or **False** as **Input value**.\\\\n            7. For type **String**, enter a string as **Input value**.\\\\n        10. To add an input, select **+ Add output** under **Outputs** and\\\\n            1. Enter an **Output name**. The output should refer to this name later to in the **Arguments**.\\\\n            2. Select **Output type** as **File** or **Folder**.\\\\n            3. For **Output URI destination**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI) or enter a data asset `azureml:\/\/`.\\\\n        11. Enter **Arguments** by using the names defined in the **Input name** and **Output name** fields in the earlier steps, and the names of input and output arguments used in the Python script **Entry file**. For example, if the **Input name** and **Output name** are defined as `job_input` and `job_output`, and the arguments are added in the **Entry file** as shown here\\\\n\\\\n            ``` python\\\\n            import argparse\\\\n\\\\n            parser = argparse.ArgumentParser()\\\\n            parser.add_argument(\\\\\\\"--input_param\\\\\\\")\\\\n            parser.add_argument(\\\\\\\"--output_param\\\\\\\")\\\\n            ```\\\\n\\\\n    then enter **Arguments** as `--input_param ${{inputs.job_input}} --output_param ${{outputs.job_output}}`.\\\\n    5. Under the **Spark configurations** section:\\\\n        1. For **Executor size**:\\\\n            1. Enter the number of executor **Cores** and executor **Memory (GB)**, in gigabytes.\\\\n            2. For **Dynamically allocated executors**, select the **Disabled** or **Enabled** option.\\\\n        - If dynamic allocation of executors is **Disabled**, enter the number of **Executor instances**.\\\\n        - If dynamic allocation of executors is **Enabled**, use the slider to select the minimum and maximum number of executors.\\\\n        1. For **Driver size**:\\\\n            1. Enter number of driver **Cores** and driver **Memory (GB)**, in gigabytes.\\\\n            2. Enter **Name** and **Value** pairs for any **Additional configurations**, then select **Add**. Providing **Additional configurations** is optional.\\\\n    6. Select **Next**.\\\\n7. On the **Review** screen:\\\\nSource: how-to-submit-spark-jobs.md\\\\n\\\\nContent: # Configure Apache Spark jobs in Azure Machine Learning\\\\n\\\\n- [Code samples for Spark jobs using Azure Machine Learning Python SDK](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/sdk\/python\/jobs\/spark)\\\\nSource: quickstart-spark-jobs.md \\\\n\\\\n chat history: \\\\n user: \\\\nwhat is aml? \\\\nassistant: \\\\n \\\\n user: \\\\nhow to create a spark job? \\\\nassistant: \\\\n \\\\nuser: thank you \\\\nassistant:\\\"\\n}\"\n}"}},{"name":"promptflow.function.inputs","timestamp":"2024-04-11T18:08:06.932784Z","attributes":{"payload":"{\n  \"prompt\": \"{{prompt_text}}\",\n  \"deployment_name\": \"gpt-4-32k\",\n  \"temperature\": 1.0,\n  \"top_p\": 1.0,\n  \"presence_penalty\": 0.0,\n  \"frequency_penalty\": 0.0,\n  \"prompt_text\": \"system: \\nYou are an AI assistant that helps users answer questions given a specific context and conversation history. You will be given a context and chat history, and then asked a question based on that context and history. Your answer should be as precise as possible, and should only come from the context.\\nPlease add citation after each sentence when possible in a form \\\"(Source: citation)\\\".\\n\\n user: \\n Content: # Configure Apache Spark jobs in Azure Machine Learning\\n\\n3. Under **Add tags**, provide **Name** and **Value**, then select **Add**. Adding tags is optional.\\n    4. Under the **Code** section:\\n        1. Select **Azure Machine Learning workspace default blob storage** from **Choose code location** dropdown.\\n        2. Under **Path to code file to upload**, select **Browse**.\\n        3. In the pop-up screen titled **Path selection**, select the path of code file `titanic.py` on the workspace default datastore `workspaceblobstore`.\\n        4. Select **Save**.\\n        5. Input `titanic.py` as the name of **Entry file** for the standalone job.\\n        6. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter **Input name** as `titanic_data`. The input should refer to this name later in the **Arguments**.\\n            2. Select **Input type** as **Data**.\\n            3. Select **Data type** as **File**.\\n            4. Select **Data source** as **URI**.\\n            5. Enter an Azure Data Lake Storage (ADLS) Gen 2 data URI for `titanic.csv` file in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here, `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        7.  To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter **Output name** as `wrangled_data`. The output should refer to this name later in the **Arguments**.\\n            2. Select **Output type** as **Folder**.\\n            3. For **Output URI destination**, enter an Azure Data Lake Storage (ADLS) Gen 2 folder URI in the `abfss:\/\/\u003cFILE_SYSTEM_NAME\u003e@\u003cSTORAGE_ACCOUNT_NAME\u003e.dfs.core.windows.net\/\u003cPATH_TO_DATA\u003e` format. Here `\u003cFILE_SYSTEM_NAME\u003e` matches the container name.\\n        8.  Enter **Arguments**  as `--titanic_data ${{inputs.titanic_data}} --wrangled_data ${{outputs.wrangled_data}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** as 2 and executor **Memory (GB)** as 2.\\n            2. For **Dynamically allocated executors**, select **Disabled**.\\n            3. Enter the number of **Executor instances** as 2.\\n        2. For **Driver size**, enter number of driver **Cores** as 1 and driver **Memory (GB)** as 2.\\n    6. Select **Next**.\\n6. On the **Review** screen:\\n    1. Review the job specification before submitting it.\\n    2. Select **Create** to submit the standalone Spark job.\\n\\n\u003e [!NOTE]\\n\u003e A standalone job submitted from the Studio UI using an Azure Machine Learning serverless Spark compute defaults to user identity passthrough for data access.\\n\\n\\n---\\n\\n\u003e [!TIP]\\n\u003e You might have an existing Synapse Spark pool in your Azure Synapse workspace. To use an existing Synapse Spark pool, please follow the instructions to [attach a Synapse Spark pool in Azure Machine Learning workspace](.\/how-to-manage-synapse-spark-pool.md).\\n\\n## Next steps\\n- [Apache Spark in Azure Machine Learning](.\/apache-spark-azure-ml-concepts.md)\\n- [Quickstart: Interactive Data Wrangling with Apache Spark](.\/apache-spark-environment-configuration.md)\\n- [Attach and manage a Synapse Spark pool in Azure Machine Learning](.\/how-to-manage-synapse-spark-pool.md)\\n- [Interactive Data Wrangling with Apache Spark in Azure Machine Learning](.\/interactive-data-wrangling-with-apache-spark-azure-ml.md)\\n- [Submit Spark jobs in Azure Machine Learning](.\/how-to-submit-spark-jobs.md)\\n- [Code samples for Spark jobs using Azure Machine Learning CLI](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/cli\/jobs\/spark)\\nSource: quickstart-spark-jobs.md\\n\\nContent: # Submit Spark jobs in Azure Machine Learning\\n\\n6. To add any Jar file(s) that the standalone job requires at runtime, select **+ Add file** under **Jars** and input the name of the `.jar` file to be included in the Spark driver. Also, add the executor `CLASSPATH` for successful job execution. Multiple files can be added.\\n        7. To add archive(s) that should be extracted into the working directory of each executor for successful job execution, select **+ Add file** under **Archives**, and input the name of the archive. Multiple archives can be added.\\n        8. Adding **Py files**, **Jars**, and **Archives** is optional.\\n        9. To add an input, select **+ Add input** under **Inputs** and\\n            1. Enter an **Input name**. The input should refer to this name later in the **Arguments**.\\n            2. Select an **Input type**.\\n            3. For type **Data**:\\n                1. Select **Data type** as **File** or **Folder**.\\n                2. Select **Data source** as **Upload from local**, **URI**, or **Datastore**.\\n                    - For **Upload from local**, select **Browse** under **Path to upload**, to choose the input file or folder.\\n                    - For **URI**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI), or enter a data asset `azureml:\/\/`.\\n                    - For **Datastore**:\\n                        1. **Select a datastore** from the dropdown menu.\\n                        2. Under **Path to data**, select **Browse**.\\n                        3. In the pop-up screen titled **Path selection**, select the path of the code files on the workspace default blob storage.\\n                        4. Select **Save**.\\n            4. For type **Integer**, enter an integer value as **Input value**.\\n            5. For type **Number**, enter a numeric value as **Input value**.\\n            6. For type **Boolean**, select **True** or **False** as **Input value**.\\n            7. For type **String**, enter a string as **Input value**.\\n        10. To add an input, select **+ Add output** under **Outputs** and\\n            1. Enter an **Output name**. The output should refer to this name later to in the **Arguments**.\\n            2. Select **Output type** as **File** or **Folder**.\\n            3. For **Output URI destination**, enter a storage data URI (for example, `abfss:\/\/` or `wasbs:\/\/` URI) or enter a data asset `azureml:\/\/`.\\n        11. Enter **Arguments** by using the names defined in the **Input name** and **Output name** fields in the earlier steps, and the names of input and output arguments used in the Python script **Entry file**. For example, if the **Input name** and **Output name** are defined as `job_input` and `job_output`, and the arguments are added in the **Entry file** as shown here\\n\\n            ``` python\\n            import argparse\\n\\n            parser = argparse.ArgumentParser()\\n            parser.add_argument(\\\"--input_param\\\")\\n            parser.add_argument(\\\"--output_param\\\")\\n            ```\\n\\n    then enter **Arguments** as `--input_param ${{inputs.job_input}} --output_param ${{outputs.job_output}}`.\\n    5. Under the **Spark configurations** section:\\n        1. For **Executor size**:\\n            1. Enter the number of executor **Cores** and executor **Memory (GB)**, in gigabytes.\\n            2. For **Dynamically allocated executors**, select the **Disabled** or **Enabled** option.\\n        - If dynamic allocation of executors is **Disabled**, enter the number of **Executor instances**.\\n        - If dynamic allocation of executors is **Enabled**, use the slider to select the minimum and maximum number of executors.\\n        1. For **Driver size**:\\n            1. Enter number of driver **Cores** and driver **Memory (GB)**, in gigabytes.\\n            2. Enter **Name** and **Value** pairs for any **Additional configurations**, then select **Add**. Providing **Additional configurations** is optional.\\n    6. Select **Next**.\\n7. On the **Review** screen:\\nSource: how-to-submit-spark-jobs.md\\n\\nContent: # Configure Apache Spark jobs in Azure Machine Learning\\n\\n- [Code samples for Spark jobs using Azure Machine Learning Python SDK](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/sdk\/python\/jobs\/spark)\\nSource: quickstart-spark-jobs.md \\n\\n chat history: \\n user: \\nwhat is aml? \\nassistant: \\n \\n user: \\nhow to create a spark job? \\nassistant: \\n \\nuser: thank you \\nassistant:\",\n  \"stream\": false\n}"}},{"name":"promptflow.function.output","timestamp":"2024-04-11T18:08:31.588041Z","attributes":{"payload":"\"To create a Spark job in Azure Machine Learning, follow these steps:\\n\\n1. Provide a **Name** and optional **Tag** for your job.\\n2. In the **Code** section, you need to:\\n   1. Select **Azure Machine Learning workspace default blob storage** from **Choose code location** dropdown.\\n   2. Select **Browse** under **Path to code file to upload** and select the path to your file on the workspace default datastore.\\n   3. Input the name of your **Entry file** (e.g. `titanic.py`) for the standalone job.\\n3. To add an input, select **+ Add input** under **Inputs** and provide necessary details like **Input name**, **Input type**, **Data type**, **Data source**, and appropriate Azure Data Lake Storage (ADLS) Gen 2 data URI.\\n4. To add an output, select **+ Add output** under **Outputs** and provide necessary details like **Output name**, **Output type**, and an appropriate Azure Data Lake Storage (ADLS) Gen 2 folder URI.\\n5. Enter **Arguments** as `--titanic_data ${{inputs.titanic_data}} --wrangled_data ${{outputs.wrangled_data}}`.\\n6. For **Spark configurations**, adjust the **Executor size** and **Driver size** to fit your job's requirements.\\n7. Review the job specification in the **Review** screen, then select **Create** to submit the standalone Spark job (Source: quickstart-spark-jobs.md).\""}}],"links":[],"resource":{"attributes":{"service.name":"promptflow"},"schema_url":""}}],"contentrange":"bytes 0-39606/39607","correlationid":"564b7033-13f4-47c3-a656-69589807c152","xrequestid":"564b7033-13f4-47c3-a656-69589807c152","modelversion":"default","collectdatatype":"pandas.core.frame.DataFrame","agent":"azureml-ai-monitoring/0.1.0b4"}
{"specversion":"1.0","id":"fc3757da-244e-4337-a425-3414dc4eaa96","source":"/subscriptions/1aefdc5e-3a7c-4d71-a9f9-f5d3b03be19a/resourceGroups/yuachengtestrg/providers/Microsoft.MachineLearningServices/workspaces/ai-proj-eastus/onlineEndpoints/clone-vivi-log-test/deployments/clone-vivi-log-test-1","type":"azureml.inference.app_traces","datacontenttype":"application/json","time":"2024-04-11T18:08:36Z","data":[{"name":"model","context":{"trace_id":"0xa2f3f4f8267a482fa3bb96ad3e1f7f35","span_id":"0x22865871c42ca40c","trace_state":"[]"},"kind":"SpanKind.INTERNAL","parent_id":"0x20e9e9b852633643","start_time":"2024-04-11T18:08:03.666551Z","end_time":"2024-04-11T18:08:31.592058Z","status":{"status_code":"OK"},"attributes":{"framework":"promptflow","span_type":"Flow","request_id":"8d0a7bf5-bd46-4c69-95b6-e2cc925bfa4c","line_run_id":"8d0a7bf5-bd46-4c69-95b6-e2cc925bfa4c","inputs":"{\n  \"question\": \"thank you\",\n  \"chat_history\": [\n    {\n      \"inputs\": {\n        \"question\": \"what is aml?\"\n      },\n      \"outputs\": {\n        \"answer\": \"Azure Machine Learning (AML) is a cloud service used for accelerating and managing the machine learning project lifecycle. It is designed for ML professionals, data scientists, and engineers to facilitate their daily workflows in training and deploying models and managing machine learning operations (MLOps). You can create models in AML or use models built from open-source platforms like PyTorch, TensorFlow, or scikit-learn. Furthermore, Azure Machine Learning provides tools for monitoring, retraining, and redeploying models(Source: overview-what-is-azure-machine-learning.md).\"\n      }\n    },\n    {\n      \"inputs\": {\n        \"question\": \"how to create a spark job?\"\n      },\n      \"outputs\": {\n        \"answer\": \"To create a Spark job in Azure Machine Learning, you need to firstly provide a Name and optionally a Value under the **Add tags**. Then in the **Code** section, you need to choose the workspace's default blob storage for code location and select the path of the code file to upload. You then need to input the name of the `titanic.py` as the **Entry file**. \\n\\nNext, you add an input by selecting **+ Add input** under **Inputs** and filling up required fields such as **Input name**, **Input type**, and **Data type**. Similarly, you add an output by selecting **+ Add output** under **Outputs** and entering required information. \\n\\nThen you need to enter **Arguments** for the job. \\n\\nIn the **Spark configurations** section, you can configure parameters such as number of executor cores, memory, and instances. Similarly, configure the driver size. Then, you can add any additional optional configurations. \\n\\nOnce everything is set up, you can review the job specifications and select **Create** to submit the standalone Spark job (Source: quickstart-spark-jobs.md).\\n\\nBear in mind that you have the option to add any necessary Jar files, Py files or Archives for the job under the respective sections (Source: how-to-submit-spark-jobs.md). Also, please note that the job submitted defaults to user identity passthrough for data access (Source: quickstart-spark-jobs.md).\\n\"\n      }\n    }\n  ]\n}","__computed__.cumulative_token_count.prompt":2139,"__computed__.cumulative_token_count.completion":327,"__computed__.cumulative_token_count.total":2466,"output":"{\n  \"answer\": \"To create a Spark job in Azure Machine Learning, follow these steps:\\n\\n1. Provide a **Name** and optional **Tag** for your job.\\n2. In the **Code** section, you need to:\\n   1. Select **Azure Machine Learning workspace default blob storage** from **Choose code location** dropdown.\\n   2. Select **Browse** under **Path to code file to upload** and select the path to your file on the workspace default datastore.\\n   3. Input the name of your **Entry file** (e.g. `titanic.py`) for the standalone job.\\n3. To add an input, select **+ Add input** under **Inputs** and provide necessary details like **Input name**, **Input type**, **Data type**, **Data source**, and appropriate Azure Data Lake Storage (ADLS) Gen 2 data URI.\\n4. To add an output, select **+ Add output** under **Outputs** and provide necessary details like **Output name**, **Output type**, and an appropriate Azure Data Lake Storage (ADLS) Gen 2 folder URI.\\n5. Enter **Arguments** as `--titanic_data ${{inputs.titanic_data}} --wrangled_data ${{outputs.wrangled_data}}`.\\n6. For **Spark configurations**, adjust the **Executor size** and **Driver size** to fit your job's requirements.\\n7. Review the job specification in the **Review** screen, then select **Create** to submit the standalone Spark job (Source: quickstart-spark-jobs.md).\"\n}"},"events":[{"name":"promptflow.function.inputs","timestamp":"2024-04-11T18:08:03.667660Z","attributes":{"payload":"{\n  \"question\": \"thank you\",\n  \"chat_history\": [\n    {\n      \"inputs\": {\n        \"question\": \"what is aml?\"\n      },\n      \"outputs\": {\n        \"answer\": \"Azure Machine Learning (AML) is a cloud service used for accelerating and managing the machine learning project lifecycle. It is designed for ML professionals, data scientists, and engineers to facilitate their daily workflows in training and deploying models and managing machine learning operations (MLOps). You can create models in AML or use models built from open-source platforms like PyTorch, TensorFlow, or scikit-learn. Furthermore, Azure Machine Learning provides tools for monitoring, retraining, and redeploying models(Source: overview-what-is-azure-machine-learning.md).\"\n      }\n    },\n    {\n      \"inputs\": {\n        \"question\": \"how to create a spark job?\"\n      },\n      \"outputs\": {\n        \"answer\": \"To create a Spark job in Azure Machine Learning, you need to firstly provide a Name and optionally a Value under the **Add tags**. Then in the **Code** section, you need to choose the workspace's default blob storage for code location and select the path of the code file to upload. You then need to input the name of the `titanic.py` as the **Entry file**. \\n\\nNext, you add an input by selecting **+ Add input** under **Inputs** and filling up required fields such as **Input name**, **Input type**, and **Data type**. Similarly, you add an output by selecting **+ Add output** under **Outputs** and entering required information. \\n\\nThen you need to enter **Arguments** for the job. \\n\\nIn the **Spark configurations** section, you can configure parameters such as number of executor cores, memory, and instances. Similarly, configure the driver size. Then, you can add any additional optional configurations. \\n\\nOnce everything is set up, you can review the job specifications and select **Create** to submit the standalone Spark job (Source: quickstart-spark-jobs.md).\\n\\nBear in mind that you have the option to add any necessary Jar files, Py files or Archives for the job under the respective sections (Source: how-to-submit-spark-jobs.md). Also, please note that the job submitted defaults to user identity passthrough for data access (Source: quickstart-spark-jobs.md).\\n\"\n      }\n    }\n  ]\n}"}},{"name":"promptflow.function.output","timestamp":"2024-04-11T18:08:31.592017Z","attributes":{"payload":"{\n  \"answer\": \"To create a Spark job in Azure Machine Learning, follow these steps:\\n\\n1. Provide a **Name** and optional **Tag** for your job.\\n2. In the **Code** section, you need to:\\n   1. Select **Azure Machine Learning workspace default blob storage** from **Choose code location** dropdown.\\n   2. Select **Browse** under **Path to code file to upload** and select the path to your file on the workspace default datastore.\\n   3. Input the name of your **Entry file** (e.g. `titanic.py`) for the standalone job.\\n3. To add an input, select **+ Add input** under **Inputs** and provide necessary details like **Input name**, **Input type**, **Data type**, **Data source**, and appropriate Azure Data Lake Storage (ADLS) Gen 2 data URI.\\n4. To add an output, select **+ Add output** under **Outputs** and provide necessary details like **Output name**, **Output type**, and an appropriate Azure Data Lake Storage (ADLS) Gen 2 folder URI.\\n5. Enter **Arguments** as `--titanic_data ${{inputs.titanic_data}} --wrangled_data ${{outputs.wrangled_data}}`.\\n6. For **Spark configurations**, adjust the **Executor size** and **Driver size** to fit your job's requirements.\\n7. Review the job specification in the **Review** screen, then select **Create** to submit the standalone Spark job (Source: quickstart-spark-jobs.md).\"\n}"}}],"links":[],"resource":{"attributes":{"service.name":"promptflow"},"schema_url":""}}],"correlationid":"c2d7f791-3c4d-4fc8-92e1-6fed74b5bd48","xrequestid":"c2d7f791-3c4d-4fc8-92e1-6fed74b5bd48","modelversion":"default","collectdatatype":"pandas.core.frame.DataFrame","agent":"azureml-ai-monitoring/0.1.0b4","contentrange":"bytes 0-8317/8318"}
{"specversion":"1.0","id":"cb625bc6-3636-4274-b225-3c2c1e98ae60","source":"/subscriptions/1aefdc5e-3a7c-4d71-a9f9-f5d3b03be19a/resourceGroups/yuachengtestrg/providers/Microsoft.MachineLearningServices/workspaces/ai-proj-eastus/onlineEndpoints/clone-vivi-log-test/deployments/clone-vivi-log-test-1","type":"azureml.inference.app_traces","datacontenttype":"application/json","time":"2024-04-11T18:08:56Z","data":[{"name":"openai_chat","context":{"trace_id":"0xa2f3f4f8267a482fa3bb96ad3e1f7f35","span_id":"0x41a7fa8fa703dfeb","trace_state":"[]"},"kind":"SpanKind.INTERNAL","parent_id":"0x908eb2abd9baf9aa","start_time":"2024-04-11T18:08:54.522296Z","end_time":"2024-04-11T18:08:56.182446Z","status":{"status_code":"OK"},"attributes":{"framework":"promptflow","span_type":"LLM","function":"openai.resources.chat.completions.Completions.create","node_name":"modify_query_with_history","request_id":"de58ac2b-f07e-4e0a-89f1-509849ed2737","line_run_id":"de58ac2b-f07e-4e0a-89f1-509849ed2737","inputs":"{\n  \"model\": \"gpt-4-32k\",\n  \"messages\": [\n    {\n      \"role\": \"system\",\n      \"content\": \"Given the following conversation history and the users next question,rephrase the question to be a stand alone question.\\nIf the conversation is irrelevant or empty, just restate the original question.\\nDo not add more details than necessary to the question.\\nconversation:\\n\\n chat history:\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"what is aml?\"\n    },\n    {\n      \"role\": \"assistant\",\n      \"content\": \"\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"how to create a spark job?\"\n    },\n    {\n      \"role\": \"assistant\",\n      \"content\": \"\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"thank you\"\n    },\n    {\n      \"role\": \"assistant\",\n      \"content\": \"\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"Follow up Input: can you share a link to the examle? \\nStandalone Question:\"\n    }\n  ],\n  \"temperature\": 1.0,\n  \"top_p\": 1.0,\n  \"n\": 1,\n  \"stream\": false,\n  \"presence_penalty\": 0.0,\n  \"frequency_penalty\": 0.0,\n  \"user\": \"\",\n  \"max_tokens\": 16\n}","llm.response.model":"gpt-4-32k","llm.generated_message":"{\n  \"content\": \"Could you provide a link to an example?\",\n  \"role\": \"assistant\",\n  \"function_call\": null,\n  \"tool_calls\": null\n}","__computed__.cumulative_token_count.completion":9,"__computed__.cumulative_token_count.prompt":120,"__computed__.cumulative_token_count.total":129,"llm.usage.completion_tokens":9,"llm.usage.prompt_tokens":120,"llm.usage.total_tokens":129,"output":"{\n  \"id\": \"chatcmpl-9Ct8x9gFCJyEEB37dH9oiu8UhH69r\",\n  \"choices\": [\n    {\n      \"finish_reason\": \"stop\",\n      \"index\": 0,\n      \"logprobs\": null,\n      \"message\": {\n        \"content\": \"Could you provide a link to an example?\",\n        \"role\": \"assistant\",\n        \"function_call\": null,\n        \"tool_calls\": null\n      },\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ],\n  \"created\": 1712858935,\n  \"model\": \"gpt-4-32k\",\n  \"object\": \"chat.completion\",\n  \"system_fingerprint\": null,\n  \"usage\": {\n    \"completion_tokens\": 9,\n    \"prompt_tokens\": 120,\n    \"total_tokens\": 129\n  },\n  \"prompt_filter_results\": [\n    {\n      \"prompt_index\": 0,\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ]\n}"},"events":[{"name":"promptflow.function.inputs","timestamp":"2024-04-11T18:08:54.525166Z","attributes":{"payload":"{\n  \"model\": \"gpt-4-32k\",\n  \"messages\": [\n    {\n      \"role\": \"system\",\n      \"content\": \"Given the following conversation history and the users next question,rephrase the question to be a stand alone question.\\nIf the conversation is irrelevant or empty, just restate the original question.\\nDo not add more details than necessary to the question.\\nconversation:\\n\\n chat history:\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"what is aml?\"\n    },\n    {\n      \"role\": \"assistant\",\n      \"content\": \"\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"how to create a spark job?\"\n    },\n    {\n      \"role\": \"assistant\",\n      \"content\": \"\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"thank you\"\n    },\n    {\n      \"role\": \"assistant\",\n      \"content\": \"\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"Follow up Input: can you share a link to the examle? \\nStandalone Question:\"\n    }\n  ],\n  \"temperature\": 1.0,\n  \"top_p\": 1.0,\n  \"n\": 1,\n  \"stream\": false,\n  \"presence_penalty\": 0.0,\n  \"frequency_penalty\": 0.0,\n  \"user\": \"\",\n  \"max_tokens\": 16\n}"}},{"name":"promptflow.llm.generated_message","timestamp":"2024-04-11T18:08:56.178736Z","attributes":{"payload":"{\n  \"content\": \"Could you provide a link to an example?\",\n  \"role\": \"assistant\",\n  \"function_call\": null,\n  \"tool_calls\": null\n}"}},{"name":"promptflow.function.output","timestamp":"2024-04-11T18:08:56.182151Z","attributes":{"payload":"{\n  \"id\": \"chatcmpl-9Ct8x9gFCJyEEB37dH9oiu8UhH69r\",\n  \"choices\": [\n    {\n      \"finish_reason\": \"stop\",\n      \"index\": 0,\n      \"logprobs\": null,\n      \"message\": {\n        \"content\": \"Could you provide a link to an example?\",\n        \"role\": \"assistant\",\n        \"function_call\": null,\n        \"tool_calls\": null\n      },\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ],\n  \"created\": 1712858935,\n  \"model\": \"gpt-4-32k\",\n  \"object\": \"chat.completion\",\n  \"system_fingerprint\": null,\n  \"usage\": {\n    \"completion_tokens\": 9,\n    \"prompt_tokens\": 120,\n    \"total_tokens\": 129\n  },\n  \"prompt_filter_results\": [\n    {\n      \"prompt_index\": 0,\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ]\n}"}}],"links":[],"resource":{"attributes":{"service.name":"promptflow"},"schema_url":""}}],"contentrange":"bytes 0-7225/7226","correlationid":"cdd6a5d4-0b07-4f0e-b394-587db84bce11","xrequestid":"cdd6a5d4-0b07-4f0e-b394-587db84bce11","modelversion":"default","collectdatatype":"pandas.core.frame.DataFrame","agent":"azureml-ai-monitoring/0.1.0b4"}
{"specversion":"1.0","id":"2ca26521-5f4b-4c0d-80b4-b471b0a4a903","source":"/subscriptions/1aefdc5e-3a7c-4d71-a9f9-f5d3b03be19a/resourceGroups/yuachengtestrg/providers/Microsoft.MachineLearningServices/workspaces/ai-proj-eastus/onlineEndpoints/clone-vivi-log-test/deployments/clone-vivi-log-test-1","type":"azureml.inference.app_traces","datacontenttype":"application/json","time":"2024-04-11T18:08:56Z","data":[{"name":"modify_query_with_history","context":{"trace_id":"0xa2f3f4f8267a482fa3bb96ad3e1f7f35","span_id":"0x908eb2abd9baf9aa","trace_state":"[]"},"kind":"SpanKind.INTERNAL","parent_id":"0x38853fe3b7d18b15","start_time":"2024-04-11T18:08:54.515801Z","end_time":"2024-04-11T18:08:56.182844Z","status":{"status_code":"OK"},"attributes":{"framework":"promptflow","span_type":"Function","function":"AzureOpenAI.chat","node_name":"modify_query_with_history","request_id":"de58ac2b-f07e-4e0a-89f1-509849ed2737","line_run_id":"de58ac2b-f07e-4e0a-89f1-509849ed2737","prompt.template":"system: \nGiven the following conversation history and the users next question,rephrase the question to be a stand alone question.\nIf the conversation is irrelevant or empty, just restate the original question.\nDo not add more details than necessary to the question.\nconversation:\n\n chat history: \n{% for item in chat_history %} user: \n{{ item.inputs.question }} \nassistant: \n{{ item.outputs.output }} \n{% endfor %}\n\nuser:\nFollow up Input: {{question}} \nStandalone Question:","prompt.variables":"{\n  \"question\": \"can you share a link to the examle?\",\n  \"chat_history\": [\n    {\n      \"inputs\": {\n        \"question\": \"what is aml?\"\n      },\n      \"outputs\": {\n        \"answer\": \"Azure Machine Learning (AML) is a cloud service used for accelerating and managing the machine learning project lifecycle. It is designed for ML professionals, data scientists, and engineers to facilitate their daily workflows in training and deploying models and managing machine learning operations (MLOps). You can create models in AML or use models built from open-source platforms like PyTorch, TensorFlow, or scikit-learn. Furthermore, Azure Machine Learning provides tools for monitoring, retraining, and redeploying models(Source: overview-what-is-azure-machine-learning.md).\"\n      }\n    },\n    {\n      \"inputs\": {\n        \"question\": \"how to create a spark job?\"\n      },\n      \"outputs\": {\n        \"answer\": \"To create a Spark job in Azure Machine Learning, you need to firstly provide a Name and optionally a Value under the **Add tags**. Then in the **Code** section, you need to choose the workspace's default blob storage for code location and select the path of the code file to upload. You then need to input the name of the `titanic.py` as the **Entry file**. \\n\\nNext, you add an input by selecting **+ Add input** under **Inputs** and filling up required fields such as **Input name**, **Input type**, and **Data type**. Similarly, you add an output by selecting **+ Add output** under **Outputs** and entering required information. \\n\\nThen you need to enter **Arguments** for the job. \\n\\nIn the **Spark configurations** section, you can configure parameters such as number of executor cores, memory, and instances. Similarly, configure the driver size. Then, you can add any additional optional configurations. \\n\\nOnce everything is set up, you can review the job specifications and select **Create** to submit the standalone Spark job (Source: quickstart-spark-jobs.md).\\n\\nBear in mind that you have the option to add any necessary Jar files, Py files or Archives for the job under the respective sections (Source: how-to-submit-spark-jobs.md). Also, please note that the job submitted defaults to user identity passthrough for data access (Source: quickstart-spark-jobs.md).\\n\"\n      }\n    },\n    {\n      \"inputs\": {\n        \"question\": \"thank you\"\n      },\n      \"outputs\": {\n        \"answer\": \"To create a Spark job in Azure Machine Learning, follow these steps:\\n\\n1. Provide a **Name** and optional **Tag** for your job.\\n2. In the **Code** section, you need to:\\n   1. Select **Azure Machine Learning workspace default blob storage** from **Choose code location** dropdown.\\n   2. Select **Browse** under **Path to code file to upload** and select the path to your file on the workspace default datastore.\\n   3. Input the name of your **Entry file** (e.g. `titanic.py`) for the standalone job.\\n3. To add an input, select **+ Add input** under **Inputs** and provide necessary details like **Input name**, **Input type**, **Data type**, **Data source**, and appropriate Azure Data Lake Storage (ADLS) Gen 2 data URI.\\n4. To add an output, select **+ Add output** under **Outputs** and provide necessary details like **Output name**, **Output type**, and an appropriate Azure Data Lake Storage (ADLS) Gen 2 folder URI.\\n5. Enter **Arguments** as `--titanic_data ${{inputs.titanic_data}} --wrangled_data ${{outputs.wrangled_data}}`.\\n6. For **Spark configurations**, adjust the **Executor size** and **Driver size** to fit your job's requirements.\\n7. Review the job specification in the **Review** screen, then select **Create** to submit the standalone Spark job (Source: quickstart-spark-jobs.md).\"\n      }\n    }\n  ]\n}","inputs":"{\n  \"prompt\": \"system: \\nGiven the following conversation history and the users next question,rephrase the question to be a stand alone question.\\nIf the conversation is irrelevant or empty, just restate the original question.\\nDo not add more details than necessary to the question.\\nconversation:\\n\\n chat history: \\n{% for item in chat_history %} user: \\n{{ item.inputs.question }} \\nassistant: \\n{{ item.outputs.output }} \\n{% endfor %}\\n\\nuser:\\nFollow up Input: {{question}} \\nStandalone Question:\",\n  \"deployment_name\": \"gpt-4-32k\",\n  \"temperature\": 1.0,\n  \"top_p\": 1.0,\n  \"max_tokens\": 16,\n  \"presence_penalty\": 0.0,\n  \"frequency_penalty\": 0.0,\n  \"chat_history\": [\n    {\n      \"inputs\": {\n        \"question\": \"what is aml?\"\n      },\n      \"outputs\": {\n        \"answer\": \"Azure Machine Learning (AML) is a cloud service used for accelerating and managing the machine learning project lifecycle. It is designed for ML professionals, data scientists, and engineers to facilitate their daily workflows in training and deploying models and managing machine learning operations (MLOps). You can create models in AML or use models built from open-source platforms like PyTorch, TensorFlow, or scikit-learn. Furthermore, Azure Machine Learning provides tools for monitoring, retraining, and redeploying models(Source: overview-what-is-azure-machine-learning.md).\"\n      }\n    },\n    {\n      \"inputs\": {\n        \"question\": \"how to create a spark job?\"\n      },\n      \"outputs\": {\n        \"answer\": \"To create a Spark job in Azure Machine Learning, you need to firstly provide a Name and optionally a Value under the **Add tags**. Then in the **Code** section, you need to choose the workspace's default blob storage for code location and select the path of the code file to upload. You then need to input the name of the `titanic.py` as the **Entry file**. \\n\\nNext, you add an input by selecting **+ Add input** under **Inputs** and filling up required fields such as **Input name**, **Input type**, and **Data type**. Similarly, you add an output by selecting **+ Add output** under **Outputs** and entering required information. \\n\\nThen you need to enter **Arguments** for the job. \\n\\nIn the **Spark configurations** section, you can configure parameters such as number of executor cores, memory, and instances. Similarly, configure the driver size. Then, you can add any additional optional configurations. \\n\\nOnce everything is set up, you can review the job specifications and select **Create** to submit the standalone Spark job (Source: quickstart-spark-jobs.md).\\n\\nBear in mind that you have the option to add any necessary Jar files, Py files or Archives for the job under the respective sections (Source: how-to-submit-spark-jobs.md). Also, please note that the job submitted defaults to user identity passthrough for data access (Source: quickstart-spark-jobs.md).\\n\"\n      }\n    },\n    {\n      \"inputs\": {\n        \"question\": \"thank you\"\n      },\n      \"outputs\": {\n        \"answer\": \"To create a Spark job in Azure Machine Learning, follow these steps:\\n\\n1. Provide a **Name** and optional **Tag** for your job.\\n2. In the **Code** section, you need to:\\n   1. Select **Azure Machine Learning workspace default blob storage** from **Choose code location** dropdown.\\n   2. Select **Browse** under **Path to code file to upload** and select the path to your file on the workspace default datastore.\\n   3. Input the name of your **Entry file** (e.g. `titanic.py`) for the standalone job.\\n3. To add an input, select **+ Add input** under **Inputs** and provide necessary details like **Input name**, **Input type**, **Data type**, **Data source**, and appropriate Azure Data Lake Storage (ADLS) Gen 2 data URI.\\n4. To add an output, select **+ Add output** under **Outputs** and provide necessary details like **Output name**, **Output type**, and an appropriate Azure Data Lake Storage (ADLS) Gen 2 folder URI.\\n5. Enter **Arguments** as `--titanic_data ${{inputs.titanic_data}} --wrangled_data ${{outputs.wrangled_data}}`.\\n6. For **Spark configurations**, adjust the **Executor size** and **Driver size** to fit your job's requirements.\\n7. Review the job specification in the **Review** screen, then select **Create** to submit the standalone Spark job (Source: quickstart-spark-jobs.md).\"\n      }\n    }\n  ],\n  \"question\": \"can you share a link to the examle?\"\n}","__computed__.cumulative_token_count.completion":9,"__computed__.cumulative_token_count.prompt":120,"__computed__.cumulative_token_count.total":129,"output":"\"Could you provide a link to an example?\""},"events":[{"name":"promptflow.prompt.template","timestamp":"2024-04-11T18:08:54.518389Z","attributes":{"payload":"{\n  \"prompt.template\": \"system: \\nGiven the following conversation history and the users next question,rephrase the question to be a stand alone question.\\nIf the conversation is irrelevant or empty, just restate the original question.\\nDo not add more details than necessary to the question.\\nconversation:\\n\\n chat history: \\n{% for item in chat_history %} user: \\n{{ item.inputs.question }} \\nassistant: \\n{{ item.outputs.output }} \\n{% endfor %}\\n\\nuser:\\nFollow up Input: {{question}} \\nStandalone Question:\",\n  \"prompt.variables\": \"{\\n  \\\"question\\\": \\\"can you share a link to the examle?\\\",\\n  \\\"chat_history\\\": [\\n    {\\n      \\\"inputs\\\": {\\n        \\\"question\\\": \\\"what is aml?\\\"\\n      },\\n      \\\"outputs\\\": {\\n        \\\"answer\\\": \\\"Azure Machine Learning (AML) is a cloud service used for accelerating and managing the machine learning project lifecycle. It is designed for ML professionals, data scientists, and engineers to facilitate their daily workflows in training and deploying models and managing machine learning operations (MLOps). You can create models in AML or use models built from open-source platforms like PyTorch, TensorFlow, or scikit-learn. Furthermore, Azure Machine Learning provides tools for monitoring, retraining, and redeploying models(Source: overview-what-is-azure-machine-learning.md).\\\"\\n      }\\n    },\\n    {\\n      \\\"inputs\\\": {\\n        \\\"question\\\": \\\"how to create a spark job?\\\"\\n      },\\n      \\\"outputs\\\": {\\n        \\\"answer\\\": \\\"To create a Spark job in Azure Machine Learning, you need to firstly provide a Name and optionally a Value under the **Add tags**. Then in the **Code** section, you need to choose the workspace's default blob storage for code location and select the path of the code file to upload. You then need to input the name of the `titanic.py` as the **Entry file**. \\\\n\\\\nNext, you add an input by selecting **+ Add input** under **Inputs** and filling up required fields such as **Input name**, **Input type**, and **Data type**. Similarly, you add an output by selecting **+ Add output** under **Outputs** and entering required information. \\\\n\\\\nThen you need to enter **Arguments** for the job. \\\\n\\\\nIn the **Spark configurations** section, you can configure parameters such as number of executor cores, memory, and instances. Similarly, configure the driver size. Then, you can add any additional optional configurations. \\\\n\\\\nOnce everything is set up, you can review the job specifications and select **Create** to submit the standalone Spark job (Source: quickstart-spark-jobs.md).\\\\n\\\\nBear in mind that you have the option to add any necessary Jar files, Py files or Archives for the job under the respective sections (Source: how-to-submit-spark-jobs.md). Also, please note that the job submitted defaults to user identity passthrough for data access (Source: quickstart-spark-jobs.md).\\\\n\\\"\\n      }\\n    },\\n    {\\n      \\\"inputs\\\": {\\n        \\\"question\\\": \\\"thank you\\\"\\n      },\\n      \\\"outputs\\\": {\\n        \\\"answer\\\": \\\"To create a Spark job in Azure Machine Learning, follow these steps:\\\\n\\\\n1. Provide a **Name** and optional **Tag** for your job.\\\\n2. In the **Code** section, you need to:\\\\n   1. Select **Azure Machine Learning workspace default blob storage** from **Choose code location** dropdown.\\\\n   2. Select **Browse** under **Path to code file to upload** and select the path to your file on the workspace default datastore.\\\\n   3. Input the name of your **Entry file** (e.g. `titanic.py`) for the standalone job.\\\\n3. To add an input, select **+ Add input** under **Inputs** and provide necessary details like **Input name**, **Input type**, **Data type**, **Data source**, and appropriate Azure Data Lake Storage (ADLS) Gen 2 data URI.\\\\n4. To add an output, select **+ Add output** under **Outputs** and provide necessary details like **Output name**, **Output type**, and an appropriate Azure Data Lake Storage (ADLS) Gen 2 folder URI.\\\\n5. Enter **Arguments** as `--titanic_data ${{inputs.titanic_data}} --wrangled_data ${{outputs.wrangled_data}}`.\\\\n6. For **Spark configurations**, adjust the **Executor size** and **Driver size** to fit your job's requirements.\\\\n7. Review the job specification in the **Review** screen, then select **Create** to submit the standalone Spark job (Source: quickstart-spark-jobs.md).\\\"\\n      }\\n    }\\n  ]\\n}\"\n}"}},{"name":"promptflow.function.inputs","timestamp":"2024-04-11T18:08:54.520233Z","attributes":{"payload":"{\n  \"prompt\": \"system: \\nGiven the following conversation history and the users next question,rephrase the question to be a stand alone question.\\nIf the conversation is irrelevant or empty, just restate the original question.\\nDo not add more details than necessary to the question.\\nconversation:\\n\\n chat history: \\n{% for item in chat_history %} user: \\n{{ item.inputs.question }} \\nassistant: \\n{{ item.outputs.output }} \\n{% endfor %}\\n\\nuser:\\nFollow up Input: {{question}} \\nStandalone Question:\",\n  \"deployment_name\": \"gpt-4-32k\",\n  \"temperature\": 1.0,\n  \"top_p\": 1.0,\n  \"max_tokens\": 16,\n  \"presence_penalty\": 0.0,\n  \"frequency_penalty\": 0.0,\n  \"chat_history\": [\n    {\n      \"inputs\": {\n        \"question\": \"what is aml?\"\n      },\n      \"outputs\": {\n        \"answer\": \"Azure Machine Learning (AML) is a cloud service used for accelerating and managing the machine learning project lifecycle. It is designed for ML professionals, data scientists, and engineers to facilitate their daily workflows in training and deploying models and managing machine learning operations (MLOps). You can create models in AML or use models built from open-source platforms like PyTorch, TensorFlow, or scikit-learn. Furthermore, Azure Machine Learning provides tools for monitoring, retraining, and redeploying models(Source: overview-what-is-azure-machine-learning.md).\"\n      }\n    },\n    {\n      \"inputs\": {\n        \"question\": \"how to create a spark job?\"\n      },\n      \"outputs\": {\n        \"answer\": \"To create a Spark job in Azure Machine Learning, you need to firstly provide a Name and optionally a Value under the **Add tags**. Then in the **Code** section, you need to choose the workspace's default blob storage for code location and select the path of the code file to upload. You then need to input the name of the `titanic.py` as the **Entry file**. \\n\\nNext, you add an input by selecting **+ Add input** under **Inputs** and filling up required fields such as **Input name**, **Input type**, and **Data type**. Similarly, you add an output by selecting **+ Add output** under **Outputs** and entering required information. \\n\\nThen you need to enter **Arguments** for the job. \\n\\nIn the **Spark configurations** section, you can configure parameters such as number of executor cores, memory, and instances. Similarly, configure the driver size. Then, you can add any additional optional configurations. \\n\\nOnce everything is set up, you can review the job specifications and select **Create** to submit the standalone Spark job (Source: quickstart-spark-jobs.md).\\n\\nBear in mind that you have the option to add any necessary Jar files, Py files or Archives for the job under the respective sections (Source: how-to-submit-spark-jobs.md). Also, please note that the job submitted defaults to user identity passthrough for data access (Source: quickstart-spark-jobs.md).\\n\"\n      }\n    },\n    {\n      \"inputs\": {\n        \"question\": \"thank you\"\n      },\n      \"outputs\": {\n        \"answer\": \"To create a Spark job in Azure Machine Learning, follow these steps:\\n\\n1. Provide a **Name** and optional **Tag** for your job.\\n2. In the **Code** section, you need to:\\n   1. Select **Azure Machine Learning workspace default blob storage** from **Choose code location** dropdown.\\n   2. Select **Browse** under **Path to code file to upload** and select the path to your file on the workspace default datastore.\\n   3. Input the name of your **Entry file** (e.g. `titanic.py`) for the standalone job.\\n3. To add an input, select **+ Add input** under **Inputs** and provide necessary details like **Input name**, **Input type**, **Data type**, **Data source**, and appropriate Azure Data Lake Storage (ADLS) Gen 2 data URI.\\n4. To add an output, select **+ Add output** under **Outputs** and provide necessary details like **Output name**, **Output type**, and an appropriate Azure Data Lake Storage (ADLS) Gen 2 folder URI.\\n5. Enter **Arguments** as `--titanic_data ${{inputs.titanic_data}} --wrangled_data ${{outputs.wrangled_data}}`.\\n6. For **Spark configurations**, adjust the **Executor size** and **Driver size** to fit your job's requirements.\\n7. Review the job specification in the **Review** screen, then select **Create** to submit the standalone Spark job (Source: quickstart-spark-jobs.md).\"\n      }\n    }\n  ],\n  \"question\": \"can you share a link to the examle?\"\n}"}},{"name":"promptflow.function.output","timestamp":"2024-04-11T18:08:56.182729Z","attributes":{"payload":"\"Could you provide a link to an example?\""}}],"links":[],"resource":{"attributes":{"service.name":"promptflow"},"schema_url":""}}],"contentrange":"bytes 0-19171/19172","correlationid":"7bad0035-c827-441f-9e94-4d8276fa9354","xrequestid":"7bad0035-c827-441f-9e94-4d8276fa9354","modelversion":"default","collectdatatype":"pandas.core.frame.DataFrame","agent":"azureml-ai-monitoring/0.1.0b4"}
{"specversion":"1.0","id":"565ebb6f-47b6-4688-86e9-9cca6504be45","source":"/subscriptions/1aefdc5e-3a7c-4d71-a9f9-f5d3b03be19a/resourceGroups/yuachengtestrg/providers/Microsoft.MachineLearningServices/workspaces/ai-proj-eastus/onlineEndpoints/clone-vivi-log-test/deployments/clone-vivi-log-test-1","type":"azureml.inference.app_traces","datacontenttype":"application/json","time":"2024-04-11T18:09:01Z","data":[{"name":"openai_embeddings","context":{"trace_id":"0xa2f3f4f8267a482fa3bb96ad3e1f7f35","span_id":"0xcddc04b705e1691c","trace_state":"[]"},"kind":"SpanKind.INTERNAL","parent_id":"0x76d5b46d668f8735","start_time":"2024-04-11T18:08:56.190346Z","end_time":"2024-04-11T18:08:57.194818Z","status":{"status_code":"OK"},"attributes":{"framework":"promptflow","span_type":"Embedding","function":"openai.resources.embeddings.Embeddings.create","node_name":"lookup","request_id":"de58ac2b-f07e-4e0a-89f1-509849ed2737","line_run_id":"de58ac2b-f07e-4e0a-89f1-509849ed2737","inputs":"{\n  \"input\": [\n    [\n      13191,\n      499,\n      3493,\n      264,\n      2723,\n      311,\n      459,\n      3187,\n      30\n    ]\n  ],\n  \"model\": \"text-embedding-ada-002\"\n}","llm.response.model":"ada","embedding.embeddings":"[\n  {\n    \"embedding.vector\": \"\u003c1536 dimensional vector\u003e\",\n    \"embedding.text\": \"\u003c9 dimensional token\u003e\"\n  }\n]","__computed__.cumulative_token_count.prompt":9,"__computed__.cumulative_token_count.total":9,"llm.usage.prompt_tokens":9,"llm.usage.total_tokens":9,"output":"{\n  \"data\": [\n    {\n      \"embedding\": [\n        -0.008503426797688007,\n        0.023497147485613823,\n        0.016994154080748558,\n        -0.0233447328209877,\n        0.014441220089793205,\n        -0.010757883079349995,\n        -0.0006747491424903274,\n        0.014047483913600445,\n        -0.01742599345743656,\n        -0.0034674168564379215,\n        0.004908998496830463,\n        0.019890017807483673,\n        0.0030736809130758047,\n        -0.0034737675450742245,\n        -0.029466692358255386,\n        0.01844208501279354,\n        0.022595364600419998,\n        0.0011954967631027102,\n        0.008255754597485065,\n        -0.014809553511440754,\n        -0.022862089797854424,\n        0.004086598288267851,\n        -0.021909503266215324,\n        -0.0010867430828511715,\n        -0.024779964238405228,\n        0.016790933907032013,\n        0.016841739416122437,\n        -0.019559787586331367,\n        -0.007220610044896603,\n        -0.010992854833602905,\n        0.038611527532339096,\n        -0.010294291190803051,\n        -0.03271818906068802,\n        -0.03287060558795929,\n        -0.011126216500997543,\n        -0.002781554125249386,\n        0.00756989186629653,\n        4.74433022645826e-07,\n        0.021172834560275078,\n        -0.025643642991781235,\n        0.009716387838125229,\n        0.00950681883841753,\n        0.020766397938132286,\n        -0.029974739998579025,\n        -0.004045319743454456,\n        0.01247889082878828,\n        -0.01121512521058321,\n        -0.008204950019717216,\n        -0.01469524297863245,\n        -0.003791296621784568,\n        0.017095763236284256,\n        0.0007156310020945966,\n        -0.046841882169246674,\n        -0.02309071086347103,\n        -0.00017940389807336032,\n        0.020004328340291977,\n        0.001987731782719493,\n        -0.0032896006014198065,\n        0.004458107519894838,\n        -0.00819224864244461,\n        0.009011473506689072,\n        0.010935699567198753,\n        -0.01165966596454382,\n        -0.01284722425043583,\n        -0.014847656711935997,\n        -0.012745615094900131,\n        -0.010903946124017239,\n        0.02873002551496029,\n        0.007468282710760832,\n        -0.02215082384645939,\n        0.024322722107172012,\n        -0.002600562758743763,\n        -0.01901363767683506,\n        -0.0014574582455679774,\n        0.02495778165757656,\n        -0.018391281366348267,\n        -0.005810780916363001,\n        0.0053852922283113,\n        -0.011043659411370754,\n        0.0056488411501049995,\n        0.008617737330496311,\n        -0.006706213112920523,\n        -0.001276466646231711,\n        0.03269278630614281,\n        0.021998411044478416,\n        0.010008514858782291,\n        0.0022274660877883434,\n        0.006315652281045914,\n        -0.00394688593223691,\n        -0.013704552315175533,\n        0.007385725155472755,\n        0.017692716792225838,\n        -0.008452622219920158,\n        0.01165966596454382,\n        0.0022052391432225704,\n        0.015673233196139336,\n        -0.02480536699295044,\n        0.03972923010587692,\n        -0.002108392771333456,\n        -0.01676553301513195,\n        0.00831926055252552,\n        -0.005585335660725832,\n        -0.04191382974386215,\n        -0.0026021504309028387,\n        -0.005410694517195225,\n        -0.0043215700425207615,\n        0.025732552632689476,\n        0.0009740202804096043,\n        0.014085587114095688,\n        -0.00816049613058567,\n        -0.022227032110095024,\n        0.00871299672871828,\n        0.012345528230071068,\n        -0.030355773866176605,\n        -0.00937980692833662,\n        0.010205382481217384,\n        0.01197719480842352,\n        -0.020448869094252586,\n        0.008338311687111855,\n        -0.009182939305901527,\n        0.012732913717627525,\n        0.025237206369638443,\n        0.016054267063736916,\n        -0.02552933245897293,\n        0.010561015456914902,\n        -0.013158402405679226,\n        -0.01977570727467537,\n        -0.008408168330788612,\n        -0.010179980657994747,\n        -0.018264269456267357,\n        0.03502980247139931,\n        0.02682485245168209,\n        0.007881070487201214,\n        0.015050875954329967,\n        -0.01600346341729164,\n        0.0502965971827507,\n        -0.037824057042598724,\n        0.012631304562091827,\n        -0.028679221868515015,\n        -0.02824738249182701,\n        0.013336218893527985,\n        0.010707078501582146,\n        0.01642260141670704,\n        -0.00871299672871828,\n        -0.014174495823681355,\n        0.02113473229110241,\n        0.0360712967813015,\n        -0.016943348571658134,\n        0.00023596375831402838,\n        -0.0014074473874643445,\n        0.01780702732503414,\n        0.03094002790749073,\n        0.00811604131013155,\n        0.015520818531513214,\n        0.010561015456914902,\n        0.014136391691863537,\n        0.004791513085365295,\n        0.014441220089793205,\n        -0.0015130258398130536,\n        -0.0206901915371418,\n        0.012974236160516739,\n        -0.0009446488111279905,\n        0.033200833946466446,\n        -0.01848018914461136,\n        -0.003626181511208415,\n        0.01879771798849106,\n        0.009652881883084774,\n        -0.016054267063736916,\n        -0.006585551891475916,\n        -0.009964060969650745,\n        -0.019318465143442154,\n        0.01160886138677597,\n        -0.026494622230529785,\n        0.022887492552399635,\n        0.02423381432890892,\n        0.010199031792581081,\n        0.01686714217066765,\n        -0.0047280071303248405,\n        -0.0023497147485613823,\n        -0.036553941667079926,\n        -0.00259421207010746,\n        -0.0018257919000461698,\n        0.015038174577057362,\n        0.01089759636670351,\n        -0.016625819727778435,\n        -0.006293425336480141,\n        -0.0028402970638126135,\n        -0.01425070222467184,\n        -0.004499386064708233,\n        -0.015203289687633514,\n        0.013463230803608894,\n        -0.005299559328705072,\n        0.0103450957685709,\n        -0.021490363404154778,\n        -0.6608667969703674,\n        -0.044784292578697205,\n        -0.004769285675138235,\n        0.0004084217071067542,\n        0.025986574590206146,\n        0.06995799392461777,\n        -0.00892256572842598,\n        -0.004432705231010914,\n        -0.045038316398859024,\n        0.02682485245168209,\n        0.004524788353592157,\n        0.011653315275907516,\n        0.010764233767986298,\n        0.012701161205768585,\n        -0.009227393195033073,\n        -0.03683336824178696,\n        0.021401455625891685,\n        0.00517254788428545,\n        0.0028768128249794245,\n        0.0024910152424126863,\n        -0.021617375314235687,\n        0.006814172957092524,\n        0.0031768777407705784,\n        -0.008522478863596916,\n        -0.011621561832726002,\n        -0.01167236641049385,\n        -0.004261239431798458,\n        -0.026520023122429848,\n        0.011951792053878307,\n        0.016689324751496315,\n        -0.025961171835660934,\n        0.006334703881293535,\n        0.0009898967109620571,\n        -0.005620263516902924,\n        0.041329577565193176,\n        -0.03825589641928673,\n        -0.01875961385667324,\n        0.006636356469243765,\n        -0.008096990175545216,\n        0.02860301360487938,\n        -0.009144836105406284,\n        0.014225300401449203,\n        0.002794255269691348,\n        0.002822832902893424,\n        -0.01752760261297226,\n        -0.019242258742451668,\n        0.007398426067084074,\n        0.00863678939640522,\n        0.012059751898050308,\n        0.017768923193216324,\n        -0.004172331187874079,\n        -0.0077921622432768345,\n        -0.03261658176779747,\n        -0.00223857956007123,\n        0.010719779878854752,\n        0.01606696844100952,\n        0.03541083633899689,\n        -0.027282092720270157,\n        -0.0004108031571377069,\n        -0.0008081113337539136,\n        0.003934184554964304,\n        0.020296454429626465,\n        -0.005201125517487526,\n        -0.005426570773124695,\n        0.0161304734647274,\n        0.008268455974757671,\n        -0.016981452703475952,\n        -0.004153279587626457,\n        0.0018416682723909616,\n        -0.014415817335247993,\n        0.014746047556400299,\n        -0.002759327180683613,\n        -0.03584267571568489,\n        -0.0053154355846345425,\n        -0.010287940502166748,\n        0.008224002085626125,\n        0.0015154072316363454,\n        0.0008493901113979518,\n        -0.009481417015194893,\n        -0.001461427309550345,\n        0.015965359285473824,\n        -0.015177886933088303,\n        -0.024195712059736252,\n        -0.0039151329547166824,\n        0.027510713785886765,\n        0.020207546651363373,\n        -0.03482658416032791,\n        0.00634422991424799,\n        -0.012567798607051373,\n        0.0019210505997762084,\n        0.0401102676987648,\n        0.019191453233361244,\n        0.009163887239992619,\n        -0.017578406259417534,\n        -0.024094102904200554,\n        0.04727372154593468,\n        0.012701161205768585,\n        -0.012389982119202614,\n        0.0215411689132452,\n        -0.009392508305609226,\n        -0.013971276581287384,\n        -0.0117231709882617,\n        -0.01705765910446644,\n        -0.003172114957123995,\n        0.018594499677419662,\n        0.011748573742806911,\n        0.018276970833539963,\n        0.039246585220098495,\n        0.03337864950299263,\n        -0.004521613474935293,\n        -0.020207546651363373,\n        -0.0043723746202886105,\n        0.0012081979075446725,\n        -0.010160928592085838,\n        -0.008630438707768917,\n        -0.02954290062189102,\n        0.010192682035267353,\n        0.019978925585746765,\n        -0.017629211768507957,\n        -0.00223857956007123,\n        0.01587645150721073,\n        0.03287060558795929,\n        0.025326114147901535,\n        -0.005340838339179754,\n        0.013831564225256443,\n        0.01526679564267397,\n        -0.0013701376738026738,\n        -0.04430164769291878,\n        0.011157969944179058,\n        0.009494117461144924,\n        -0.0013145701959729195,\n        0.004969329107552767,\n        0.015571623109281063,\n        -0.004235837142914534,\n        0.03853532299399376,\n        0.008846358396112919,\n        -0.005874286871403456,\n        -0.020664788782596588,\n        0.006852276157587767,\n        -0.010872193612158298,\n        -0.004045319743454456,\n        -0.013209206983447075,\n        0.016092371195554733,\n        -0.014669841155409813,\n        -0.01251064334064722,\n        0.00908133015036583,\n        -0.029085658490657806,\n        0.01295518409460783,\n        -0.005664717871695757,\n        0.01686714217066765,\n        -0.01948358118534088,\n        -0.015393806621432304,\n        0.0027625025250017643,\n        0.0006902287132106721,\n        -0.0103450957685709,\n        -0.000833513680845499,\n        -0.02397979237139225,\n        -0.02730749547481537,\n        0.002044886816293001,\n        -0.009176588617265224,\n        0.014199897646903992,\n        0.014085587114095688,\n        -0.009252795949578285,\n        0.011831131763756275,\n        1.609971332072746e-05,\n        -0.004064371343702078,\n        0.01644800417125225,\n        0.025948472321033478,\n        -0.01733708381652832,\n        -0.02667243778705597,\n        0.005328136961907148,\n        -0.019102545455098152,\n        -0.0033372300677001476,\n        0.03200692683458328,\n        -0.0032260948792099953,\n        0.015165186487138271,\n        -0.006299775559455156,\n        0.0037150895223021507,\n        0.003950060810893774,\n        -0.011881936341524124,\n        -5.497221354744397e-05,\n        0.020652087405323982,\n        -0.008757450617849827,\n        0.0072777653113007545,\n        0.03579187020659447,\n        0.010783285833895206,\n        -0.006445839069783688,\n        0.004718481097370386,\n        -0.0056488411501049995,\n        0.006166413426399231,\n        0.01759110763669014,\n        0.018149958923459053,\n        -0.004286641720682383,\n        0.014441220089793205,\n        0.0023338382598012686,\n        0.005223352462053299,\n        0.0038166989106684923,\n        0.009138485416769981,\n        0.022138122469186783,\n        0.013691850937902927,\n        0.02072829380631447,\n        -0.00882730633020401,\n        -0.0055313557386398315,\n        -0.027917152270674706,\n        -0.00044930356671102345,\n        -0.024729160591959953,\n        -0.0021703108213841915,\n        -0.011742223054170609,\n        0.022925594821572304,\n        0.024500539526343346,\n        0.021934904158115387,\n        -0.009690986014902592,\n        0.0005814750329591334,\n        -0.028145773336291313,\n        -0.00487089529633522,\n        0.005934617482125759,\n        0.0011947029270231724,\n        -0.00018337300571147352,\n        -0.01308219600468874,\n        0.00776675995439291,\n        -0.009449663572013378,\n        0.024208413437008858,\n        0.03843371197581291,\n        -0.006693511735647917,\n        -0.0043437969870865345,\n        -0.00803348422050476,\n        0.014746047556400299,\n        0.0341661237180233,\n        0.010383198969066143,\n        -0.04407302662730217,\n        -0.017108462750911713,\n        -0.007849317044019699,\n        -0.007366673089563847,\n        0.002244930248707533,\n        0.018772315233945847,\n        0.03198152408003807,\n        -0.026901058852672577,\n        -0.007353972177952528,\n        0.01406018529087305,\n        -0.021210938692092896,\n        0.0011304033687338233,\n        0.012167711742222309,\n        0.01980111002922058,\n        -0.02315421588718891,\n        0.031219452619552612,\n        0.016397198662161827,\n        0.034978996962308884,\n        0.02834899164736271,\n        -0.02486887201666832,\n        -0.0057059964165091515,\n        -0.005963195115327835,\n        0.012898028828203678,\n        0.0038166989106684923,\n        -0.0020020203664898872,\n        0.0032467341516166925,\n        0.0032165690790861845,\n        -0.010713429190218449,\n        0.0079572768881917,\n        0.01064357254654169,\n        0.0013701376738026738,\n        0.014098288491368294,\n        0.0002609691582620144,\n        0.007080897223204374,\n        -0.005442447494715452,\n        0.0203726626932621,\n        -0.001881359494291246,\n        -0.022125422954559326,\n        -0.006071154959499836,\n        0.0007731831865385175,\n        0.002706934930756688,\n        -0.011424694210290909,\n        -0.015381106175482273,\n        -0.007550840266048908,\n        -0.012002596631646156,\n        0.01635909453034401,\n        -0.019293062388896942,\n        0.01676553301513195,\n        0.008967019617557526,\n        0.007169805467128754,\n        0.010795986279845238,\n        -0.046079810708761215,\n        -0.02745991013944149,\n        0.020042432472109795,\n        0.0013812512625008821,\n        -0.011208774521946907,\n        -0.03388669714331627,\n        -0.010954751633107662,\n        0.03469957038760185,\n        -0.008751099929213524,\n        0.009468715637922287,\n        0.002837121719494462,\n        0.009595726616680622,\n        0.007119000423699617,\n        -0.009049576707184315,\n        0.001667027361690998,\n        0.020080534741282463,\n        0.03520761802792549,\n        -0.00840181764215231,\n        -0.008389117196202278,\n        0.0004703398735728115,\n        0.014542829245328903,\n        0.02417030930519104,\n        -0.003419787622988224,\n        0.011418343521654606,\n        0.016587715595960617,\n        0.017222773283720016,\n        0.015711335465312004,\n        -0.005725048016756773,\n        -0.0141109898686409,\n        -0.02603738009929657,\n        -0.0012812295462936163,\n        -0.019470879808068275,\n        0.0009914843831211329,\n        -0.005918740760535002,\n        0.009754491969943047,\n        -0.007639748044312,\n        -0.0015765315620228648,\n        8.55343823786825e-05,\n        0.02277318201959133,\n        0.005350363906472921,\n        -0.009875152260065079,\n        -0.029060255736112595,\n        -0.01450472604483366,\n        0.010967452079057693,\n        0.06889109313488007,\n        -0.004038969054818153,\n        0.020131340250372887,\n        -0.005277332384139299,\n        0.001632099156267941,\n        -0.021160133183002472,\n        -0.02321772277355194,\n        -0.003972288221120834,\n        0.014669841155409813,\n        -0.007201557978987694,\n        0.01642260141670704,\n        -0.012821821495890617,\n        0.005712347105145454,\n        0.001924225827679038,\n        0.01600346341729164,\n        -0.008408168330788612,\n        0.024779964238405228,\n        -0.012917080894112587,\n        -0.0036865118891000748,\n        -0.001746409572660923,\n        -0.004759760107845068,\n        0.010211733169853687,\n        0.027612322941422462,\n        0.022722376510500908,\n        0.022798582911491394,\n        0.014085587114095688,\n        0.007404776755720377,\n        0.017946740612387657,\n        0.014949265867471695,\n        -0.01822616532444954,\n        0.016473405063152313,\n        -0.017768923193216324,\n        0.019559787586331367,\n        0.03040657937526703,\n        0.02103312313556671,\n        0.029619107022881508,\n        -0.0030324021354317665,\n        -0.022455653175711632,\n        0.007563541177660227,\n        -0.023865481838583946,\n        -0.0016368620563298464,\n        0.007538138888776302,\n        0.010008514858782291,\n        0.004486685153096914,\n        0.00311972270719707,\n        -0.00400086585432291,\n        -0.016409900039434433,\n        0.025478528812527657,\n        0.008096990175545216,\n        0.009703686460852623,\n        0.014492024667561054,\n        -0.0059663704596459866,\n        0.005556758027523756,\n        -0.014326909556984901,\n        0.0159145537763834,\n        0.0023259001318365335,\n        -0.020639386028051376,\n        -0.008776501752436161,\n        -0.0016559138894081116,\n        -0.014733346179127693,\n        -0.027790140360593796,\n        0.02385278046131134,\n        0.005804430693387985,\n        -0.00022901780903339386,\n        -0.014466621913015842,\n        -0.005947318393737078,\n        -0.027612322941422462,\n        -0.0020417117048054934,\n        -0.022404847666621208,\n        0.005423395894467831,\n        0.014441220089793205,\n        -0.012091505341231823,\n        -0.04353957995772362,\n        0.0006354549550451338,\n        0.013526735827326775,\n        0.015190588310360909,\n        0.01164061389863491,\n        0.02043616771697998,\n        0.015939956530928612,\n        -0.002359240548685193,\n        -0.005839358549565077,\n        -0.023395538330078125,\n        -0.004169155843555927,\n        -0.025948472321033478,\n        0.024449734017252922,\n        -0.019381972029805183,\n        0.01227567158639431,\n        0.0024703757371753454,\n        -0.0048232655972242355,\n        0.03259117901325226,\n        0.00821130070835352,\n        0.009716387838125229,\n        0.007353972177952528,\n        -0.04315854609012604,\n        -0.004235837142914534,\n        0.0017273578559979796,\n        0.009024174883961678,\n        0.0354362390935421,\n        -0.014072886668145657,\n        -0.01708306185901165,\n        0.012167711742222309,\n        -0.0384083092212677,\n        -0.0060235257260501385,\n        -0.02569444850087166,\n        -0.014174495823681355,\n        0.019089844077825546,\n        0.007417478132992983,\n        0.0013653747737407684,\n        -0.01635909453034401,\n        -0.006277548614889383,\n        0.008198599331080914,\n        -0.026494622230529785,\n        0.005712347105145454,\n        0.009195640683174133,\n        0.014923864044249058,\n        0.014365012757480145,\n        0.021299846470355988,\n        0.01774352230131626,\n        0.003657934255897999,\n        -0.03411531820893288,\n        0.0077921622432768345,\n        -0.031524281948804855,\n        0.009938658215105534,\n        0.0038611527998000383,\n        -0.010573716834187508,\n        0.009201991371810436,\n        -0.025986574590206146,\n        -0.05121108144521713,\n        -0.010834090411663055,\n        -0.006833224557340145,\n        -0.000206592318136245,\n        0.016409900039434433,\n        -0.018937431275844574,\n        -0.006903080735355616,\n        -0.030838418751955032,\n        -0.012288372963666916,\n        0.0037119141779839993,\n        0.0008382766391150653,\n        -0.032819800078868866,\n        -0.007563541177660227,\n        0.0012597964378073812,\n        0.0012955183628946543,\n        -0.01771811954677105,\n        -0.021376052871346474,\n        -0.02423381432890892,\n        -0.04346337169408798,\n        -0.01085314154624939,\n        0.027231289073824883,\n        0.0055535826832056046,\n        0.022519158199429512,\n        0.005629789549857378,\n        0.01430150680243969,\n        -0.03015255555510521,\n        -0.012027999386191368,\n        -0.0008962256833910942,\n        -0.005817131604999304,\n        -0.034750375896692276,\n        0.014758748933672905,\n        0.018200762569904327,\n        3.398552871658467e-05,\n        0.032565776258707047,\n        -0.017502199858427048,\n        0.020855305716395378,\n        0.019216855987906456,\n        0.013729955069720745,\n        -0.005721873138099909,\n        0.019039040431380272,\n        0.012834522873163223,\n        -0.00446128286421299,\n        -0.01425070222467184,\n        0.024081401526927948,\n        -0.0008708233362995088,\n        0.024335423484444618,\n        0.028450600802898407,\n        0.017070360481739044,\n        0.015508117154240608,\n        -0.0006191816064529121,\n        -0.022138122469186783,\n        -0.015609726309776306,\n        -0.026977265253663063,\n        0.005921916104853153,\n        0.013247311115264893,\n        -0.026774046942591667,\n        0.009170237928628922,\n        -0.024767262861132622,\n        -0.01150090154260397,\n        0.004385075997561216,\n        -0.013882368803024292,\n        0.003670635400339961,\n        -0.013971276581287384,\n        -0.009456014260649681,\n        0.01477145031094551,\n        0.016435302793979645,\n        -0.022696973755955696,\n        0.04071992263197899,\n        -0.027688531205058098,\n        -0.00821130070835352,\n        0.0005354332970455289,\n        0.009557623416185379,\n        0.02198570966720581,\n        0.004924875218421221,\n        0.004759760107845068,\n        0.008833657018840313,\n        0.009703686460852623,\n        -0.002406870014965534,\n        0.015393806621432304,\n        -0.01009107194840908,\n        0.0007902503712102771,\n        -0.014453921467065811,\n        0.004912173841148615,\n        -0.022417549043893814,\n        -0.040669117122888565,\n        -0.008135093376040459,\n        0.01682903803884983,\n        0.005080464296042919,\n        0.030711406841874123,\n        -0.02603738009929657,\n        0.009417911060154438,\n        -0.019051741808652878,\n        -0.01765461266040802,\n        -0.014453921467065811,\n        -0.02644381672143936,\n        0.017222773283720016,\n        0.014339610934257507,\n        0.009443312883377075,\n        0.018467487767338753,\n        -0.0008287507225759327,\n        -0.012237568385899067,\n        -0.008833657018840313,\n        0.002722811419516802,\n        0.016943348571658134,\n        0.0014304682845249772,\n        0.014187196269631386,\n        -0.018594499677419662,\n        -0.02977152168750763,\n        -0.010065670125186443,\n        0.0022830336820334196,\n        -0.02353525161743164,\n        -0.011793027631938457,\n        0.0021766615100204945,\n        0.03393750265240669,\n        0.00487089529633522,\n        0.0012026411714032292,\n        -0.00011371508298907429,\n        -0.015203289687633514,\n        0.01327271293848753,\n        -0.008363714441657066,\n        0.005201125517487526,\n        -0.010122825391590595,\n        0.0065093450248241425,\n        -0.012440786696970463,\n        0.021591972559690475,\n        -0.014923864044249058,\n        0.04978854954242706,\n        -0.0006092588300816715,\n        0.013387023471295834,\n        -0.013298115693032742,\n        -0.006877678446471691,\n        -0.012936132028698921,\n        0.016752831637859344,\n        0.007804863154888153,\n        0.027409104630351067,\n        0.020334558561444283,\n        0.004493035841733217,\n        0.007817564532160759,\n        0.0019401023164391518,\n        -0.011335786432027817,\n        -0.01835317723453045,\n        -0.010548314079642296,\n        0.015622427687048912,\n        -0.005940968170762062,\n        0.010211733169853687,\n        -0.003476942889392376,\n        -0.0077858115546405315,\n        0.012301074340939522,\n        0.005109041929244995,\n        0.001077217166312039,\n        -0.013412426225841045,\n        -0.02002973109483719,\n        0.009964060969650745,\n        0.027917152270674706,\n        -0.005826657637953758,\n        -0.008141444064676762,\n        0.0011224651243537664,\n        0.007588943466544151,\n        -0.0047121308743953705,\n        -0.017184671014547348,\n        -0.0032514971680939198,\n        0.011399291455745697,\n        -0.025097493082284927,\n        -0.03442014753818512,\n        -0.01322190836071968,\n        0.012821821495890617,\n        0.024411631748080254,\n        0.029339682310819626,\n        -0.014631737023591995,\n        0.00856058206409216,\n        0.020715592429041862,\n        -0.044682685285806656,\n        0.005950493738055229,\n        0.008738398551940918,\n        -0.013729955069720745,\n        -0.02081720344722271,\n        0.009246445260941982,\n        0.0010502272052690387,\n        -0.012605901807546616,\n        -0.006226744037121534,\n        -0.02022024802863598,\n        -0.03322623670101166,\n        -0.016219383105635643,\n        0.011545355431735516,\n        -0.012840873561799526,\n        0.015927255153656006,\n        -0.015343002043664455,\n        -0.023141514509916306,\n        -0.0006850688369013369,\n        0.0014360250206664205,\n        -0.015050875954329967,\n        -0.010243486613035202,\n        0.007449230644851923,\n        -0.012440786696970463,\n        0.01680363528430462,\n        0.027815543115139008,\n        -0.006442663725465536,\n        -0.009462364949285984,\n        -0.007919173687696457,\n        -0.014161794446408749,\n        0.013958576135337353,\n        -0.00586158549413085,\n        0.000983546138741076,\n        -0.01371725369244814,\n        0.007982679642736912,\n        0.0027704406529664993,\n        -0.021503064781427383,\n        -0.014009380713105202,\n        0.003727790666744113,\n        -0.03248956799507141,\n        0.03053359128534794,\n        0.020652087405323982,\n        -0.010211733169853687,\n        -0.016219383105635643,\n        0.01948358118534088,\n        0.00890351366251707,\n        0.02043616771697998,\n        -0.008471674285829067,\n        -0.013298115693032742,\n        -0.018200762569904327,\n        -0.01371725369244814,\n        0.005598036572337151,\n        -0.013653747737407684,\n        -0.013920472003519535,\n        0.05451338365674019,\n        0.005534530617296696,\n        -0.04224406182765961,\n        -0.013526735827326775,\n        -0.008649490773677826,\n        -0.035893481224775314,\n        -0.014796852134168148,\n        0.014085587114095688,\n        -0.01339972484856844,\n        -0.01695604994893074,\n        0.0016162226675078273,\n        -0.010465756990015507,\n        0.03701118379831314,\n        0.0012232805602252483,\n        0.020918812602758408,\n        0.0077858115546405315,\n        -0.0047280071303248405,\n        -0.005979071371257305,\n        0.003356281667947769,\n        0.010878544300794601,\n        0.009976761415600777,\n        -0.0335310660302639,\n        -0.007544489577412605,\n        0.01945817843079567,\n        -0.0010549902217462659,\n        0.0012907554628327489,\n        0.026393013074994087,\n        -0.013133000582456589,\n        -0.034750375896692276,\n        -0.02359875664114952,\n        -0.022950997576117516,\n        0.010002164170145988,\n        0.013450529426336288,\n        0.0015773253981024027,\n        -0.02784094400703907,\n        -0.013818862847983837,\n        0.0030371651519089937,\n        0.00294984458014369,\n        -0.014593633823096752,\n        0.015927255153656006,\n        0.010237135924398899,\n        -0.004146928898990154,\n        -0.011316734366118908,\n        -0.039754632860422134,\n        -0.00725236302241683,\n        0.009684635326266289,\n        -0.015241392888128757,\n        -0.003784945933148265,\n        -0.01295518409460783,\n        0.001254239585250616,\n        0.005178898107260466,\n        -0.015939956530928612,\n        -0.006725264713168144,\n        -0.025033988058567047,\n        0.028196576982736588,\n        -0.025033988058567047,\n        0.020398063585162163,\n        0.015254094265401363,\n        -0.003842101199552417,\n        -0.03439474478363991,\n        -0.01882312074303627,\n        0.029085658490657806,\n        -0.021426858380436897,\n        -0.0009382982389070094,\n        -0.00760799553245306,\n        0.018149958923459053,\n        0.008814605884253979,\n        0.011316734366118908,\n        -0.023687664419412613,\n        -0.018810419365763664,\n        -0.006757017690688372,\n        0.005429746117442846,\n        -0.01712116412818432,\n        -0.018175361678004265,\n        -0.0006580788758583367,\n        0.025961171835660934,\n        0.005201125517487526,\n        -0.0039532361552119255,\n        0.007265063934028149,\n        -0.01221216656267643,\n        -0.036274515092372894,\n        0.01831507310271263,\n        0.0013439415488392115,\n        -0.014530127868056297,\n        0.004362848587334156,\n        0.21419237554073334,\n        -0.009906905703246593,\n        0.007950927130877972,\n        0.04148199036717415,\n        -0.00979259517043829,\n        -0.005156671162694693,\n        0.016879843547940254,\n        0.007093598134815693,\n        -0.018658004701137543,\n        0.02357335388660431,\n        -0.013933173380792141,\n        0.0003203073865734041,\n        -0.031778305768966675,\n        0.0019512157887220383,\n        0.01774352230131626,\n        -0.03909417241811752,\n        -0.017286280170083046,\n        -0.011145268566906452,\n        -0.018340475857257843,\n        -0.003162589157000184,\n        -0.00789377186447382,\n        0.013514035381376743,\n        0.004810564685612917,\n        -0.029238073155283928,\n        0.0394752062857151,\n        0.019877316430211067,\n        -0.008255754597485065,\n        0.006661758758127689,\n        0.018772315233945847,\n        0.010516561567783356,\n        -0.024779964238405228,\n        0.0021496715489774942,\n        0.015317600220441818,\n        0.007233310956507921,\n        -0.021630076691508293,\n        -0.013514035381376743,\n        0.0034483652561903,\n        0.001973442966118455,\n        0.021934904158115387,\n        0.019153350964188576,\n        0.004896297585219145,\n        -0.026469219475984573,\n        -0.010916647501289845,\n        -0.014263403601944447,\n        0.019661396741867065,\n        0.024119503796100616,\n        -0.02837439253926277,\n        -0.038992565125226974,\n        0.017514901235699654,\n        0.01661311835050583,\n        -0.0015122320037335157,\n        -0.0016940173227339983,\n        0.039627622812986374,\n        0.013107597827911377,\n        -0.013831564225256443,\n        -0.005340838339179754,\n        -0.0005163815803825855,\n        0.01778162457048893,\n        0.033962905406951904,\n        0.022163525223731995,\n        -0.00151064433157444,\n        0.027739334851503372,\n        -0.03429313376545906,\n        0.011081762611865997,\n        -0.013679150491952896,\n        0.011742223054170609,\n        -0.02277318201959133,\n        -0.020664788782596588,\n        -0.008522478863596916,\n        -0.004473983775824308,\n        0.00010170851601287723,\n        -0.008535180240869522,\n        0.030609797686338425,\n        0.01026888843625784,\n        -0.02771393209695816,\n        -0.022442951798439026,\n        0.01901363767683506,\n        0.023776572197675705,\n        0.04064371436834335,\n        0.039017967879772186,\n        -0.005420220550149679,\n        0.021337950602173805,\n        0.005975896026939154,\n        0.003540448611602187,\n        -0.015558921732008457,\n        -0.04353957995772362,\n        0.0011947029270231724,\n        0.014479323290288448,\n        -0.01533030066639185,\n        -0.0014868295984342694,\n        -0.024437032639980316,\n        0.0031816407572478056,\n        -0.027764737606048584,\n        -0.0034039111342281103,\n        0.021744387224316597,\n        -0.004092948976904154,\n        0.014530127868056297,\n        0.03160048648715019,\n        0.003391209989786148,\n        -0.022214330732822418,\n        -0.012193114496767521,\n        0.05314165726304054,\n        0.03528382629156113,\n        0.00982434768229723,\n        0.004261239431798458,\n        -0.0010232372442260385,\n        0.0015662119258195162,\n        0.01961059309542179,\n        -0.0048232655972242355,\n        -0.004232661798596382,\n        -0.0026100885588675737,\n        -0.028069565072655678,\n        -0.0038802046328783035,\n        -0.01663852110505104,\n        0.00513444421812892,\n        0.02306530810892582,\n        0.0013082196237519383,\n        -0.027536116540431976,\n        0.0011304033687338233,\n        0.011583458632230759,\n        -0.02423381432890892,\n        -0.02243025042116642,\n        0.005483726039528847,\n        -0.0109801534563303,\n        0.015419209375977516,\n        -0.0033467558678239584,\n        -0.016206681728363037,\n        0.002524355659261346,\n        0.004429529886692762,\n        -0.0064807673916220665,\n        -0.0036801614332944155,\n        -0.022709675133228302,\n        0.010891245678067207,\n        -0.013488632626831532,\n        -0.013958576135337353,\n        -0.0006501406896859407,\n        -0.0027482137084007263,\n        -0.029847728088498116,\n        0.01164061389863491,\n        0.0017130690393969417,\n        -0.003613480366766453,\n        -0.009456014260649681,\n        -0.017603809013962746,\n        0.000527098192833364,\n        0.001559861353598535,\n        -0.02094421349465847,\n        -0.003114959690719843,\n        -0.007563541177660227,\n        -0.013196506537497044,\n        -0.021439559757709503,\n        0.0007418271852657199,\n        0.006375982891768217,\n        -0.008331961929798126,\n        -0.014923864044249058,\n        -0.0012851987266913056,\n        -0.010084721259772778,\n        0.003249909495934844,\n        -0.025732552632689476,\n        0.00725236302241683,\n        0.013387023471295834,\n        -0.022811284288764,\n        -0.004197733476758003,\n        0.02591036818921566,\n        0.006423612125217915,\n        -0.020601283758878708,\n        -0.02357335388660431,\n        -0.15962818264961243,\n        0.01263765525072813,\n        0.004791513085365295,\n        -0.021083926782011986,\n        0.011024607345461845,\n        0.020652087405323982,\n        0.00850977748632431,\n        -0.012739264406263828,\n        -0.024055998772382736,\n        0.008008081465959549,\n        0.01818806305527687,\n        -0.03624911233782768,\n        -0.02192220278084278,\n        -0.00025184021797031164,\n        -0.01224391907453537,\n        0.0022481053601950407,\n        0.013183805160224438,\n        0.00129710603505373,\n        0.019597891718149185,\n        0.015762140974402428,\n        0.016181278973817825,\n        -0.009570324793457985,\n        0.033988308161497116,\n        0.013933173380792141,\n        -0.01314570102840662,\n        0.0275869220495224,\n        -0.016346393153071404,\n        0.022722376510500908,\n        0.0012518581934273243,\n        -0.01629558950662613,\n        -0.0013995091430842876,\n        0.006814172957092524,\n        0.018594499677419662,\n        -0.03119405172765255,\n        -0.005074113607406616,\n        -0.0035372732672840357,\n        0.01661311835050583,\n        -0.03751922771334648,\n        0.00010944828682113439,\n        0.016727428883314133,\n        0.012155011296272278,\n        0.02467835508286953,\n        -0.01298693660646677,\n        -0.0063791582360863686,\n        -0.03015255555510521,\n        0.00605845358222723,\n        0.037290606647729874,\n        -0.01287897676229477,\n        0.012840873561799526,\n        -0.012802770361304283,\n        0.021820593625307083,\n        -0.007868369109928608,\n        0.001025618752464652,\n        -0.00497567979618907,\n        0.010713429190218449,\n        0.020423466339707375,\n        0.008389117196202278,\n        0.0288570374250412,\n        0.006194991059601307,\n        -0.006934833712875843,\n        0.002821245463564992,\n        -0.033327847719192505,\n        -0.012091505341231823,\n        -0.004766110796481371,\n        -0.002187774982303381,\n        -0.00012939306907355785,\n        -0.01952168345451355,\n        -0.001416973304003477,\n        -0.015546221286058426,\n        -0.005998123437166214,\n        -0.0032245072070509195,\n        -0.029161864891648293,\n        0.009684635326266289,\n        0.02192220278084278,\n        0.009354405105113983,\n        -0.007982679642736912,\n        9.897974814521149e-05,\n        0.0069094314239919186,\n        -0.008611386641860008,\n        -0.01221216656267643,\n        -0.014149093069136143,\n        0.051236484199762344,\n        -0.013107597827911377,\n        0.05339568108320236,\n        -0.03838290646672249,\n        -0.011157969944179058,\n        -0.0300255436450243,\n        0.008363714441657066,\n        -0.013247311115264893,\n        -0.01644800417125225,\n        0.02370036579668522,\n        -0.02138875424861908,\n        -0.016054267063736916,\n        -0.005251930095255375,\n        0.00669986242428422,\n        0.007398426067084074,\n        0.009881502948701382,\n        8.439325756626204e-05,\n        0.002044886816293001,\n        -0.011348486877977848,\n        0.00273710023611784,\n        -0.028018761426210403,\n        0.008408168330788612,\n        0.021210938692092896,\n        0.029187267646193504,\n        0.047502342611551285,\n        -0.01854369416832924,\n        0.0026243773754686117,\n        0.026647035032510757,\n        -0.0016940173227339983,\n        -0.014936565421521664,\n        0.00294984458014369,\n        0.03424232825636864,\n        0.006953885778784752,\n        0.005693295504897833,\n        0.014555530622601509,\n        0.0056774187833070755,\n        0.0033816839568316936,\n        -0.0073349205777049065,\n        -0.016270186752080917,\n        0.041431184858083725,\n        0.009843399748206139,\n        0.0029180916026234627,\n        0.007950927130877972,\n        0.001597170950844884,\n        -0.02151576615869999,\n        -0.08474214375019073,\n        0.0051979501731693745,\n        0.011335786432027817,\n        0.015127082355320454,\n        -0.024030596017837524,\n        0.012891678139567375,\n        -0.009055927395820618,\n        0.006744316313415766,\n        -0.007747707888484001,\n        0.016663923859596252,\n        -0.01721007376909256,\n        -0.027231289073824883,\n        0.00037329504266381264,\n        -0.021426858380436897,\n        0.012453488074243069,\n        0.0009303600527346134,\n        0.00018337300571147352,\n        0.008058886975049973,\n        -0.016778234392404556,\n        0.015165186487138271,\n        -0.0043215700425207615,\n        -0.003315002890303731,\n        0.007849317044019699,\n        -0.018708810210227966,\n        0.007106299512088299,\n        0.012161361053586006,\n        -0.017832430079579353,\n        -0.005940968170762062,\n        0.013094896450638771,\n        -0.00015221547801047564,\n        0.0023957565426826477,\n        -0.04115176200866699,\n        -0.0012804358266294003,\n        -0.019064443185925484,\n        -0.005598036572337151,\n        -0.0144285187125206,\n        -0.017362486571073532,\n        -0.0016765532782301307,\n        0.01854369416832924,\n        -0.019877316430211067,\n        -0.004874070640653372,\n        0.008643140085041523,\n        0.024843471124768257,\n        -0.04173601418733597,\n        0.008141444064676762,\n        -0.006099732592701912,\n        0.0018607201054692268,\n        0.02556743659079075,\n        0.012339177541434765,\n        -0.01526679564267397,\n        -0.020868007093667984,\n        0.03751922771334648,\n        -0.010427652858197689,\n        -0.019039040431380272,\n        0.04064371436834335,\n        -0.005302734673023224,\n        -0.004213610198348761,\n        0.013425126671791077,\n        -0.00835101306438446,\n        -0.019229557365179062,\n        0.00330547709017992,\n        -0.011869234964251518,\n        -0.018721511587500572,\n        0.0034102615900337696,\n        0.013171103782951832,\n        -0.0018273795722052455,\n        -0.027409104630351067,\n        -0.008293857797980309,\n        0.002643429208546877,\n        -0.02376387268304825,\n        -0.0010057731997221708,\n        0.018200762569904327,\n        -0.005274157039821148,\n        0.014187196269631386,\n        -0.01812455616891384,\n        0.006036226637661457,\n        -0.0300255436450243,\n        -0.0009946596110239625,\n        0.008522478863596916,\n        -0.005483726039528847,\n        0.0005358302150852978,\n        -0.01064357254654169,\n        -0.00016908420366235077,\n        -0.0011462797410786152,\n        0.002908565802499652,\n        -0.010097422637045383,\n        0.00010086507973028347,\n        -0.0006513313855975866,\n        0.0025322940200567245,\n        -0.0365031361579895,\n        0.002257631393149495,\n        0.032413363456726074,\n        -0.009322651661932468,\n        -0.03172750025987625,\n        -0.021172834560275078,\n        -0.012199465185403824,\n        0.0028895142022520304,\n        0.01176762580871582,\n        0.009748141281306744,\n        0.014987369999289513,\n        0.002421158831566572,\n        0.020804502069950104,\n        -0.0330992266535759,\n        0.023078009486198425,\n        -0.010459406301379204,\n        -0.011183371767401695,\n        0.005613913293927908,\n        0.0011010318994522095,\n        0.009017824195325375,\n        -0.003492819145321846,\n        0.007061845622956753,\n        0.01121512521058321,\n        -0.012809121049940586,\n        -0.001567799597978592,\n        -0.01430150680243969,\n        0.00017057261720765382,\n        -0.005775853060185909,\n        -0.015584324486553669,\n        0.018658004701137543,\n        0.001490004942752421,\n        0.019089844077825546,\n        -0.03833210468292236,\n        0.0028768128249794245,\n        -0.010275239124894142,\n        -0.004521613474935293,\n        0.02720588631927967,\n        -0.031092442572116852,\n        0.03866233304142952,\n        -0.016536911949515343,\n        0.027155082672834396,\n        -0.0007846935768611729,\n        -0.03579187020659447,\n        0.025935770943760872,\n        -0.03876394405961037,\n        0.014009380713105202,\n        0.015571623109281063,\n        0.008497077040374279,\n        -0.024538643658161163,\n        0.02486887201666832,\n        0.02518640272319317,\n        0.027002668008208275,\n        0.022849388420581818,\n        0.004273940809071064,\n        -0.00725236302241683,\n        -0.01616857759654522,\n        -0.03561405465006828,\n        -0.014263403601944447,\n        0.01701955497264862,\n        -0.00621721800416708,\n        0.0012844048906117678,\n        0.00856058206409216,\n        0.013615644536912441,\n        0.024462435394525528,\n        0.015368404798209667,\n        -0.018327774479985237,\n        -0.006179114803671837,\n        -0.001624954747967422,\n        -0.02157927304506302,\n        0.0020115463994443417,\n        -0.0030451032798737288,\n        0.029034852981567383,\n        0.0014137979596853256,\n        0.03566486015915871,\n        0.018937431275844574,\n        0.02128714509308338,\n        -0.001895648310892284,\n        0.020995019003748894,\n        -0.0015114381676539779,\n        0.00805253628641367,\n        0.03129566088318825,\n        0.037316009402275085,\n        -0.04061831161379814,\n        -0.05791729316115379,\n        0.017857832834124565,\n        -0.0023909935262054205,\n        0.009837049059569836,\n        0.030127152800559998,\n        -0.013323517516255379,\n        -0.0023544777650386095,\n        -0.013691850937902927,\n        -0.005185248795896769,\n        0.013285414315760136,\n        0.002894276985898614,\n        0.011583458632230759,\n        -0.02606278285384178,\n        0.01841668412089348,\n        0.02606278285384178,\n        0.01841668412089348,\n        -0.011005556210875511,\n        0.0014336435124278069,\n        -0.013336218893527985,\n        0.001917875255458057,\n        0.009652881883084774,\n        -0.0007584974518977106,\n        -0.02034725993871689,\n        -0.012307425029575825,\n        -0.007487334311008453,\n        -0.00856058206409216,\n        -0.0029101534746587276,\n        0.021503064781427383,\n        0.010084721259772778,\n        -0.010910296812653542,\n        0.03594428673386574,\n        -0.002622789703309536,\n        0.005480550695210695,\n        -0.02571985125541687,\n        -0.03944980725646019,\n        0.00216713547706604,\n        -0.010910296812653542,\n        -0.013463230803608894,\n        0.010364146903157234,\n        0.023078009486198425,\n        -0.00950681883841753,\n        0.009132134728133678,\n        0.0007751677185297012,\n        0.005734574049711227,\n        -0.019153350964188576,\n        0.020131340250372887,\n        0.00979259517043829,\n        -0.04173601418733597,\n        -0.026088183745741844,\n        0.03132106363773346,\n        0.011354837566614151,\n        0.02357335388660431,\n        -0.004296167753636837,\n        0.0052709816955029964,\n        0.012053401209414005,\n        0.01879771798849106,\n        0.006322002969682217,\n        -0.002702171914279461,\n        0.023713067173957825,\n        0.023611458018422127,\n        -0.01540650799870491,\n        -0.011894636787474155,\n        -0.006598253268748522,\n        -0.0008390704169869423,\n        -0.022671572864055634,\n        -0.012174062430858612,\n        0.00939885899424553,\n        0.008820956572890282,\n        -0.034623365849256516,\n        0.05989867448806763,\n        0.007804863154888153,\n        -0.029847728088498116,\n        0.004731182474642992,\n        -0.016460703685879707,\n        0.030863821506500244,\n        0.01553351990878582,\n        -0.003064155112951994,\n        0.0002816085470840335,\n        -0.01164061389863491,\n        -0.000274067249847576,\n        0.004162805620580912,\n        0.02898404933512211,\n        -0.009551272727549076,\n        -0.0037309660110622644,\n        0.0077921622432768345,\n        -0.014339610934257507,\n        0.010992854833602905,\n        -0.0012875802349299192,\n        0.012574149295687675,\n        0.0003691274905577302,\n        0.016879843547940254,\n        0.009309951215982437,\n        0.010700727812945843,\n        0.0015932018868625164,\n        -0.012682109139859676,\n        -0.014873059466481209,\n        -0.03749382495880127,\n        -0.012917080894112587,\n        0.0013375909766182303,\n        0.004508912097662687,\n        -0.006287074647843838,\n        -0.018365878611803055,\n        -0.031778305768966675,\n        -0.004007216077297926,\n        0.004610521253198385,\n        -0.003165764268487692,\n        -0.012516994029283524,\n        0.022760480642318726,\n        -0.004804213996976614,\n        0.022722376510500908,\n        0.017895935103297234,\n        -0.019940823316574097,\n        -0.027688531205058098,\n        -0.029314279556274414,\n        -0.00661095418035984,\n        -0.024259217083454132,\n        -0.01243443600833416,\n        -0.02799335867166519\n      ],\n      \"index\": 0,\n      \"object\": \"embedding\"\n    }\n  ],\n  \"model\": \"ada\",\n  \"object\": \"list\",\n  \"usage\": {\n    \"prompt_tokens\": 9,\n    \"total_tokens\": 9\n  }\n}"},"events":[{"name":"promptflow.function.inputs","timestamp":"2024-04-11T18:08:56.191845Z","attributes":{"payload":"{\n  \"input\": [\n    [\n      13191,\n      499,\n      3493,\n      264,\n      2723,\n      311,\n      459,\n      3187,\n      30\n    ]\n  ],\n  \"model\": \"text-embedding-ada-002\"\n}"}},{"name":"promptflow.embedding.embeddings","timestamp":"2024-04-11T18:08:57.080863Z","attributes":{"payload":"[\n  {\n    \"embedding.vector\": \"\u003c1536 dimensional vector\u003e\",\n    \"embedding.text\": \"\u003c9 dimensional token\u003e\"\n  }\n]"}},{"name":"promptflow.function.output","timestamp":"2024-04-11T18:08:57.192106Z","attributes":{"payload":"{\n  \"data\": [\n    {\n      \"embedding\": [\n        -0.008503426797688007,\n        0.023497147485613823,\n        0.016994154080748558,\n        -0.0233447328209877,\n        0.014441220089793205,\n        -0.010757883079349995,\n        -0.0006747491424903274,\n        0.014047483913600445,\n        -0.01742599345743656,\n        -0.0034674168564379215,\n        0.004908998496830463,\n        0.019890017807483673,\n        0.0030736809130758047,\n        -0.0034737675450742245,\n        -0.029466692358255386,\n        0.01844208501279354,\n        0.022595364600419998,\n        0.0011954967631027102,\n        0.008255754597485065,\n        -0.014809553511440754,\n        -0.022862089797854424,\n        0.004086598288267851,\n        -0.021909503266215324,\n        -0.0010867430828511715,\n        -0.024779964238405228,\n        0.016790933907032013,\n        0.016841739416122437,\n        -0.019559787586331367,\n        -0.007220610044896603,\n        -0.010992854833602905,\n        0.038611527532339096,\n        -0.010294291190803051,\n        -0.03271818906068802,\n        -0.03287060558795929,\n        -0.011126216500997543,\n        -0.002781554125249386,\n        0.00756989186629653,\n        4.74433022645826e-07,\n        0.021172834560275078,\n        -0.025643642991781235,\n        0.009716387838125229,\n        0.00950681883841753,\n        0.020766397938132286,\n        -0.029974739998579025,\n        -0.004045319743454456,\n        0.01247889082878828,\n        -0.01121512521058321,\n        -0.008204950019717216,\n        -0.01469524297863245,\n        -0.003791296621784568,\n        0.017095763236284256,\n        0.0007156310020945966,\n        -0.046841882169246674,\n        -0.02309071086347103,\n        -0.00017940389807336032,\n        0.020004328340291977,\n        0.001987731782719493,\n        -0.0032896006014198065,\n        0.004458107519894838,\n        -0.00819224864244461,\n        0.009011473506689072,\n        0.010935699567198753,\n        -0.01165966596454382,\n        -0.01284722425043583,\n        -0.014847656711935997,\n        -0.012745615094900131,\n        -0.010903946124017239,\n        0.02873002551496029,\n        0.007468282710760832,\n        -0.02215082384645939,\n        0.024322722107172012,\n        -0.002600562758743763,\n        -0.01901363767683506,\n        -0.0014574582455679774,\n        0.02495778165757656,\n        -0.018391281366348267,\n        -0.005810780916363001,\n        0.0053852922283113,\n        -0.011043659411370754,\n        0.0056488411501049995,\n        0.008617737330496311,\n        -0.006706213112920523,\n        -0.001276466646231711,\n        0.03269278630614281,\n        0.021998411044478416,\n        0.010008514858782291,\n        0.0022274660877883434,\n        0.006315652281045914,\n        -0.00394688593223691,\n        -0.013704552315175533,\n        0.007385725155472755,\n        0.017692716792225838,\n        -0.008452622219920158,\n        0.01165966596454382,\n        0.0022052391432225704,\n        0.015673233196139336,\n        -0.02480536699295044,\n        0.03972923010587692,\n        -0.002108392771333456,\n        -0.01676553301513195,\n        0.00831926055252552,\n        -0.005585335660725832,\n        -0.04191382974386215,\n        -0.0026021504309028387,\n        -0.005410694517195225,\n        -0.0043215700425207615,\n        0.025732552632689476,\n        0.0009740202804096043,\n        0.014085587114095688,\n        -0.00816049613058567,\n        -0.022227032110095024,\n        0.00871299672871828,\n        0.012345528230071068,\n        -0.030355773866176605,\n        -0.00937980692833662,\n        0.010205382481217384,\n        0.01197719480842352,\n        -0.020448869094252586,\n        0.008338311687111855,\n        -0.009182939305901527,\n        0.012732913717627525,\n        0.025237206369638443,\n        0.016054267063736916,\n        -0.02552933245897293,\n        0.010561015456914902,\n        -0.013158402405679226,\n        -0.01977570727467537,\n        -0.008408168330788612,\n        -0.010179980657994747,\n        -0.018264269456267357,\n        0.03502980247139931,\n        0.02682485245168209,\n        0.007881070487201214,\n        0.015050875954329967,\n        -0.01600346341729164,\n        0.0502965971827507,\n        -0.037824057042598724,\n        0.012631304562091827,\n        -0.028679221868515015,\n        -0.02824738249182701,\n        0.013336218893527985,\n        0.010707078501582146,\n        0.01642260141670704,\n        -0.00871299672871828,\n        -0.014174495823681355,\n        0.02113473229110241,\n        0.0360712967813015,\n        -0.016943348571658134,\n        0.00023596375831402838,\n        -0.0014074473874643445,\n        0.01780702732503414,\n        0.03094002790749073,\n        0.00811604131013155,\n        0.015520818531513214,\n        0.010561015456914902,\n        0.014136391691863537,\n        0.004791513085365295,\n        0.014441220089793205,\n        -0.0015130258398130536,\n        -0.0206901915371418,\n        0.012974236160516739,\n        -0.0009446488111279905,\n        0.033200833946466446,\n        -0.01848018914461136,\n        -0.003626181511208415,\n        0.01879771798849106,\n        0.009652881883084774,\n        -0.016054267063736916,\n        -0.006585551891475916,\n        -0.009964060969650745,\n        -0.019318465143442154,\n        0.01160886138677597,\n        -0.026494622230529785,\n        0.022887492552399635,\n        0.02423381432890892,\n        0.010199031792581081,\n        0.01686714217066765,\n        -0.0047280071303248405,\n        -0.0023497147485613823,\n        -0.036553941667079926,\n        -0.00259421207010746,\n        -0.0018257919000461698,\n        0.015038174577057362,\n        0.01089759636670351,\n        -0.016625819727778435,\n        -0.006293425336480141,\n        -0.0028402970638126135,\n        -0.01425070222467184,\n        -0.004499386064708233,\n        -0.015203289687633514,\n        0.013463230803608894,\n        -0.005299559328705072,\n        0.0103450957685709,\n        -0.021490363404154778,\n        -0.6608667969703674,\n        -0.044784292578697205,\n        -0.004769285675138235,\n        0.0004084217071067542,\n        0.025986574590206146,\n        0.06995799392461777,\n        -0.00892256572842598,\n        -0.004432705231010914,\n        -0.045038316398859024,\n        0.02682485245168209,\n        0.004524788353592157,\n        0.011653315275907516,\n        0.010764233767986298,\n        0.012701161205768585,\n        -0.009227393195033073,\n        -0.03683336824178696,\n        0.021401455625891685,\n        0.00517254788428545,\n        0.0028768128249794245,\n        0.0024910152424126863,\n        -0.021617375314235687,\n        0.006814172957092524,\n        0.0031768777407705784,\n        -0.008522478863596916,\n        -0.011621561832726002,\n        -0.01167236641049385,\n        -0.004261239431798458,\n        -0.026520023122429848,\n        0.011951792053878307,\n        0.016689324751496315,\n        -0.025961171835660934,\n        0.006334703881293535,\n        0.0009898967109620571,\n        -0.005620263516902924,\n        0.041329577565193176,\n        -0.03825589641928673,\n        -0.01875961385667324,\n        0.006636356469243765,\n        -0.008096990175545216,\n        0.02860301360487938,\n        -0.009144836105406284,\n        0.014225300401449203,\n        0.002794255269691348,\n        0.002822832902893424,\n        -0.01752760261297226,\n        -0.019242258742451668,\n        0.007398426067084074,\n        0.00863678939640522,\n        0.012059751898050308,\n        0.017768923193216324,\n        -0.004172331187874079,\n        -0.0077921622432768345,\n        -0.03261658176779747,\n        -0.00223857956007123,\n        0.010719779878854752,\n        0.01606696844100952,\n        0.03541083633899689,\n        -0.027282092720270157,\n        -0.0004108031571377069,\n        -0.0008081113337539136,\n        0.003934184554964304,\n        0.020296454429626465,\n        -0.005201125517487526,\n        -0.005426570773124695,\n        0.0161304734647274,\n        0.008268455974757671,\n        -0.016981452703475952,\n        -0.004153279587626457,\n        0.0018416682723909616,\n        -0.014415817335247993,\n        0.014746047556400299,\n        -0.002759327180683613,\n        -0.03584267571568489,\n        -0.0053154355846345425,\n        -0.010287940502166748,\n        0.008224002085626125,\n        0.0015154072316363454,\n        0.0008493901113979518,\n        -0.009481417015194893,\n        -0.001461427309550345,\n        0.015965359285473824,\n        -0.015177886933088303,\n        -0.024195712059736252,\n        -0.0039151329547166824,\n        0.027510713785886765,\n        0.020207546651363373,\n        -0.03482658416032791,\n        0.00634422991424799,\n        -0.012567798607051373,\n        0.0019210505997762084,\n        0.0401102676987648,\n        0.019191453233361244,\n        0.009163887239992619,\n        -0.017578406259417534,\n        -0.024094102904200554,\n        0.04727372154593468,\n        0.012701161205768585,\n        -0.012389982119202614,\n        0.0215411689132452,\n        -0.009392508305609226,\n        -0.013971276581287384,\n        -0.0117231709882617,\n        -0.01705765910446644,\n        -0.003172114957123995,\n        0.018594499677419662,\n        0.011748573742806911,\n        0.018276970833539963,\n        0.039246585220098495,\n        0.03337864950299263,\n        -0.004521613474935293,\n        -0.020207546651363373,\n        -0.0043723746202886105,\n        0.0012081979075446725,\n        -0.010160928592085838,\n        -0.008630438707768917,\n        -0.02954290062189102,\n        0.010192682035267353,\n        0.019978925585746765,\n        -0.017629211768507957,\n        -0.00223857956007123,\n        0.01587645150721073,\n        0.03287060558795929,\n        0.025326114147901535,\n        -0.005340838339179754,\n        0.013831564225256443,\n        0.01526679564267397,\n        -0.0013701376738026738,\n        -0.04430164769291878,\n        0.011157969944179058,\n        0.009494117461144924,\n        -0.0013145701959729195,\n        0.004969329107552767,\n        0.015571623109281063,\n        -0.004235837142914534,\n        0.03853532299399376,\n        0.008846358396112919,\n        -0.005874286871403456,\n        -0.020664788782596588,\n        0.006852276157587767,\n        -0.010872193612158298,\n        -0.004045319743454456,\n        -0.013209206983447075,\n        0.016092371195554733,\n        -0.014669841155409813,\n        -0.01251064334064722,\n        0.00908133015036583,\n        -0.029085658490657806,\n        0.01295518409460783,\n        -0.005664717871695757,\n        0.01686714217066765,\n        -0.01948358118534088,\n        -0.015393806621432304,\n        0.0027625025250017643,\n        0.0006902287132106721,\n        -0.0103450957685709,\n        -0.000833513680845499,\n        -0.02397979237139225,\n        -0.02730749547481537,\n        0.002044886816293001,\n        -0.009176588617265224,\n        0.014199897646903992,\n        0.014085587114095688,\n        -0.009252795949578285,\n        0.011831131763756275,\n        1.609971332072746e-05,\n        -0.004064371343702078,\n        0.01644800417125225,\n        0.025948472321033478,\n        -0.01733708381652832,\n        -0.02667243778705597,\n        0.005328136961907148,\n        -0.019102545455098152,\n        -0.0033372300677001476,\n        0.03200692683458328,\n        -0.0032260948792099953,\n        0.015165186487138271,\n        -0.006299775559455156,\n        0.0037150895223021507,\n        0.003950060810893774,\n        -0.011881936341524124,\n        -5.497221354744397e-05,\n        0.020652087405323982,\n        -0.008757450617849827,\n        0.0072777653113007545,\n        0.03579187020659447,\n        0.010783285833895206,\n        -0.006445839069783688,\n        0.004718481097370386,\n        -0.0056488411501049995,\n        0.006166413426399231,\n        0.01759110763669014,\n        0.018149958923459053,\n        -0.004286641720682383,\n        0.014441220089793205,\n        0.0023338382598012686,\n        0.005223352462053299,\n        0.0038166989106684923,\n        0.009138485416769981,\n        0.022138122469186783,\n        0.013691850937902927,\n        0.02072829380631447,\n        -0.00882730633020401,\n        -0.0055313557386398315,\n        -0.027917152270674706,\n        -0.00044930356671102345,\n        -0.024729160591959953,\n        -0.0021703108213841915,\n        -0.011742223054170609,\n        0.022925594821572304,\n        0.024500539526343346,\n        0.021934904158115387,\n        -0.009690986014902592,\n        0.0005814750329591334,\n        -0.028145773336291313,\n        -0.00487089529633522,\n        0.005934617482125759,\n        0.0011947029270231724,\n        -0.00018337300571147352,\n        -0.01308219600468874,\n        0.00776675995439291,\n        -0.009449663572013378,\n        0.024208413437008858,\n        0.03843371197581291,\n        -0.006693511735647917,\n        -0.0043437969870865345,\n        -0.00803348422050476,\n        0.014746047556400299,\n        0.0341661237180233,\n        0.010383198969066143,\n        -0.04407302662730217,\n        -0.017108462750911713,\n        -0.007849317044019699,\n        -0.007366673089563847,\n        0.002244930248707533,\n        0.018772315233945847,\n        0.03198152408003807,\n        -0.026901058852672577,\n        -0.007353972177952528,\n        0.01406018529087305,\n        -0.021210938692092896,\n        0.0011304033687338233,\n        0.012167711742222309,\n        0.01980111002922058,\n        -0.02315421588718891,\n        0.031219452619552612,\n        0.016397198662161827,\n        0.034978996962308884,\n        0.02834899164736271,\n        -0.02486887201666832,\n        -0.0057059964165091515,\n        -0.005963195115327835,\n        0.012898028828203678,\n        0.0038166989106684923,\n        -0.0020020203664898872,\n        0.0032467341516166925,\n        0.0032165690790861845,\n        -0.010713429190218449,\n        0.0079572768881917,\n        0.01064357254654169,\n        0.0013701376738026738,\n        0.014098288491368294,\n        0.0002609691582620144,\n        0.007080897223204374,\n        -0.005442447494715452,\n        0.0203726626932621,\n        -0.001881359494291246,\n        -0.022125422954559326,\n        -0.006071154959499836,\n        0.0007731831865385175,\n        0.002706934930756688,\n        -0.011424694210290909,\n        -0.015381106175482273,\n        -0.007550840266048908,\n        -0.012002596631646156,\n        0.01635909453034401,\n        -0.019293062388896942,\n        0.01676553301513195,\n        0.008967019617557526,\n        0.007169805467128754,\n        0.010795986279845238,\n        -0.046079810708761215,\n        -0.02745991013944149,\n        0.020042432472109795,\n        0.0013812512625008821,\n        -0.011208774521946907,\n        -0.03388669714331627,\n        -0.010954751633107662,\n        0.03469957038760185,\n        -0.008751099929213524,\n        0.009468715637922287,\n        0.002837121719494462,\n        0.009595726616680622,\n        0.007119000423699617,\n        -0.009049576707184315,\n        0.001667027361690998,\n        0.020080534741282463,\n        0.03520761802792549,\n        -0.00840181764215231,\n        -0.008389117196202278,\n        0.0004703398735728115,\n        0.014542829245328903,\n        0.02417030930519104,\n        -0.003419787622988224,\n        0.011418343521654606,\n        0.016587715595960617,\n        0.017222773283720016,\n        0.015711335465312004,\n        -0.005725048016756773,\n        -0.0141109898686409,\n        -0.02603738009929657,\n        -0.0012812295462936163,\n        -0.019470879808068275,\n        0.0009914843831211329,\n        -0.005918740760535002,\n        0.009754491969943047,\n        -0.007639748044312,\n        -0.0015765315620228648,\n        8.55343823786825e-05,\n        0.02277318201959133,\n        0.005350363906472921,\n        -0.009875152260065079,\n        -0.029060255736112595,\n        -0.01450472604483366,\n        0.010967452079057693,\n        0.06889109313488007,\n        -0.004038969054818153,\n        0.020131340250372887,\n        -0.005277332384139299,\n        0.001632099156267941,\n        -0.021160133183002472,\n        -0.02321772277355194,\n        -0.003972288221120834,\n        0.014669841155409813,\n        -0.007201557978987694,\n        0.01642260141670704,\n        -0.012821821495890617,\n        0.005712347105145454,\n        0.001924225827679038,\n        0.01600346341729164,\n        -0.008408168330788612,\n        0.024779964238405228,\n        -0.012917080894112587,\n        -0.0036865118891000748,\n        -0.001746409572660923,\n        -0.004759760107845068,\n        0.010211733169853687,\n        0.027612322941422462,\n        0.022722376510500908,\n        0.022798582911491394,\n        0.014085587114095688,\n        0.007404776755720377,\n        0.017946740612387657,\n        0.014949265867471695,\n        -0.01822616532444954,\n        0.016473405063152313,\n        -0.017768923193216324,\n        0.019559787586331367,\n        0.03040657937526703,\n        0.02103312313556671,\n        0.029619107022881508,\n        -0.0030324021354317665,\n        -0.022455653175711632,\n        0.007563541177660227,\n        -0.023865481838583946,\n        -0.0016368620563298464,\n        0.007538138888776302,\n        0.010008514858782291,\n        0.004486685153096914,\n        0.00311972270719707,\n        -0.00400086585432291,\n        -0.016409900039434433,\n        0.025478528812527657,\n        0.008096990175545216,\n        0.009703686460852623,\n        0.014492024667561054,\n        -0.0059663704596459866,\n        0.005556758027523756,\n        -0.014326909556984901,\n        0.0159145537763834,\n        0.0023259001318365335,\n        -0.020639386028051376,\n        -0.008776501752436161,\n        -0.0016559138894081116,\n        -0.014733346179127693,\n        -0.027790140360593796,\n        0.02385278046131134,\n        0.005804430693387985,\n        -0.00022901780903339386,\n        -0.014466621913015842,\n        -0.005947318393737078,\n        -0.027612322941422462,\n        -0.0020417117048054934,\n        -0.022404847666621208,\n        0.005423395894467831,\n        0.014441220089793205,\n        -0.012091505341231823,\n        -0.04353957995772362,\n        0.0006354549550451338,\n        0.013526735827326775,\n        0.015190588310360909,\n        0.01164061389863491,\n        0.02043616771697998,\n        0.015939956530928612,\n        -0.002359240548685193,\n        -0.005839358549565077,\n        -0.023395538330078125,\n        -0.004169155843555927,\n        -0.025948472321033478,\n        0.024449734017252922,\n        -0.019381972029805183,\n        0.01227567158639431,\n        0.0024703757371753454,\n        -0.0048232655972242355,\n        0.03259117901325226,\n        0.00821130070835352,\n        0.009716387838125229,\n        0.007353972177952528,\n        -0.04315854609012604,\n        -0.004235837142914534,\n        0.0017273578559979796,\n        0.009024174883961678,\n        0.0354362390935421,\n        -0.014072886668145657,\n        -0.01708306185901165,\n        0.012167711742222309,\n        -0.0384083092212677,\n        -0.0060235257260501385,\n        -0.02569444850087166,\n        -0.014174495823681355,\n        0.019089844077825546,\n        0.007417478132992983,\n        0.0013653747737407684,\n        -0.01635909453034401,\n        -0.006277548614889383,\n        0.008198599331080914,\n        -0.026494622230529785,\n        0.005712347105145454,\n        0.009195640683174133,\n        0.014923864044249058,\n        0.014365012757480145,\n        0.021299846470355988,\n        0.01774352230131626,\n        0.003657934255897999,\n        -0.03411531820893288,\n        0.0077921622432768345,\n        -0.031524281948804855,\n        0.009938658215105534,\n        0.0038611527998000383,\n        -0.010573716834187508,\n        0.009201991371810436,\n        -0.025986574590206146,\n        -0.05121108144521713,\n        -0.010834090411663055,\n        -0.006833224557340145,\n        -0.000206592318136245,\n        0.016409900039434433,\n        -0.018937431275844574,\n        -0.006903080735355616,\n        -0.030838418751955032,\n        -0.012288372963666916,\n        0.0037119141779839993,\n        0.0008382766391150653,\n        -0.032819800078868866,\n        -0.007563541177660227,\n        0.0012597964378073812,\n        0.0012955183628946543,\n        -0.01771811954677105,\n        -0.021376052871346474,\n        -0.02423381432890892,\n        -0.04346337169408798,\n        -0.01085314154624939,\n        0.027231289073824883,\n        0.0055535826832056046,\n        0.022519158199429512,\n        0.005629789549857378,\n        0.01430150680243969,\n        -0.03015255555510521,\n        -0.012027999386191368,\n        -0.0008962256833910942,\n        -0.005817131604999304,\n        -0.034750375896692276,\n        0.014758748933672905,\n        0.018200762569904327,\n        3.398552871658467e-05,\n        0.032565776258707047,\n        -0.017502199858427048,\n        0.020855305716395378,\n        0.019216855987906456,\n        0.013729955069720745,\n        -0.005721873138099909,\n        0.019039040431380272,\n        0.012834522873163223,\n        -0.00446128286421299,\n        -0.01425070222467184,\n        0.024081401526927948,\n        -0.0008708233362995088,\n        0.024335423484444618,\n        0.028450600802898407,\n        0.017070360481739044,\n        0.015508117154240608,\n        -0.0006191816064529121,\n        -0.022138122469186783,\n        -0.015609726309776306,\n        -0.026977265253663063,\n        0.005921916104853153,\n        0.013247311115264893,\n        -0.026774046942591667,\n        0.009170237928628922,\n        -0.024767262861132622,\n        -0.01150090154260397,\n        0.004385075997561216,\n        -0.013882368803024292,\n        0.003670635400339961,\n        -0.013971276581287384,\n        -0.009456014260649681,\n        0.01477145031094551,\n        0.016435302793979645,\n        -0.022696973755955696,\n        0.04071992263197899,\n        -0.027688531205058098,\n        -0.00821130070835352,\n        0.0005354332970455289,\n        0.009557623416185379,\n        0.02198570966720581,\n        0.004924875218421221,\n        0.004759760107845068,\n        0.008833657018840313,\n        0.009703686460852623,\n        -0.002406870014965534,\n        0.015393806621432304,\n        -0.01009107194840908,\n        0.0007902503712102771,\n        -0.014453921467065811,\n        0.004912173841148615,\n        -0.022417549043893814,\n        -0.040669117122888565,\n        -0.008135093376040459,\n        0.01682903803884983,\n        0.005080464296042919,\n        0.030711406841874123,\n        -0.02603738009929657,\n        0.009417911060154438,\n        -0.019051741808652878,\n        -0.01765461266040802,\n        -0.014453921467065811,\n        -0.02644381672143936,\n        0.017222773283720016,\n        0.014339610934257507,\n        0.009443312883377075,\n        0.018467487767338753,\n        -0.0008287507225759327,\n        -0.012237568385899067,\n        -0.008833657018840313,\n        0.002722811419516802,\n        0.016943348571658134,\n        0.0014304682845249772,\n        0.014187196269631386,\n        -0.018594499677419662,\n        -0.02977152168750763,\n        -0.010065670125186443,\n        0.0022830336820334196,\n        -0.02353525161743164,\n        -0.011793027631938457,\n        0.0021766615100204945,\n        0.03393750265240669,\n        0.00487089529633522,\n        0.0012026411714032292,\n        -0.00011371508298907429,\n        -0.015203289687633514,\n        0.01327271293848753,\n        -0.008363714441657066,\n        0.005201125517487526,\n        -0.010122825391590595,\n        0.0065093450248241425,\n        -0.012440786696970463,\n        0.021591972559690475,\n        -0.014923864044249058,\n        0.04978854954242706,\n        -0.0006092588300816715,\n        0.013387023471295834,\n        -0.013298115693032742,\n        -0.006877678446471691,\n        -0.012936132028698921,\n        0.016752831637859344,\n        0.007804863154888153,\n        0.027409104630351067,\n        0.020334558561444283,\n        0.004493035841733217,\n        0.007817564532160759,\n        0.0019401023164391518,\n        -0.011335786432027817,\n        -0.01835317723453045,\n        -0.010548314079642296,\n        0.015622427687048912,\n        -0.005940968170762062,\n        0.010211733169853687,\n        -0.003476942889392376,\n        -0.0077858115546405315,\n        0.012301074340939522,\n        0.005109041929244995,\n        0.001077217166312039,\n        -0.013412426225841045,\n        -0.02002973109483719,\n        0.009964060969650745,\n        0.027917152270674706,\n        -0.005826657637953758,\n        -0.008141444064676762,\n        0.0011224651243537664,\n        0.007588943466544151,\n        -0.0047121308743953705,\n        -0.017184671014547348,\n        -0.0032514971680939198,\n        0.011399291455745697,\n        -0.025097493082284927,\n        -0.03442014753818512,\n        -0.01322190836071968,\n        0.012821821495890617,\n        0.024411631748080254,\n        0.029339682310819626,\n        -0.014631737023591995,\n        0.00856058206409216,\n        0.020715592429041862,\n        -0.044682685285806656,\n        0.005950493738055229,\n        0.008738398551940918,\n        -0.013729955069720745,\n        -0.02081720344722271,\n        0.009246445260941982,\n        0.0010502272052690387,\n        -0.012605901807546616,\n        -0.006226744037121534,\n        -0.02022024802863598,\n        -0.03322623670101166,\n        -0.016219383105635643,\n        0.011545355431735516,\n        -0.012840873561799526,\n        0.015927255153656006,\n        -0.015343002043664455,\n        -0.023141514509916306,\n        -0.0006850688369013369,\n        0.0014360250206664205,\n        -0.015050875954329967,\n        -0.010243486613035202,\n        0.007449230644851923,\n        -0.012440786696970463,\n        0.01680363528430462,\n        0.027815543115139008,\n        -0.006442663725465536,\n        -0.009462364949285984,\n        -0.007919173687696457,\n        -0.014161794446408749,\n        0.013958576135337353,\n        -0.00586158549413085,\n        0.000983546138741076,\n        -0.01371725369244814,\n        0.007982679642736912,\n        0.0027704406529664993,\n        -0.021503064781427383,\n        -0.014009380713105202,\n        0.003727790666744113,\n        -0.03248956799507141,\n        0.03053359128534794,\n        0.020652087405323982,\n        -0.010211733169853687,\n        -0.016219383105635643,\n        0.01948358118534088,\n        0.00890351366251707,\n        0.02043616771697998,\n        -0.008471674285829067,\n        -0.013298115693032742,\n        -0.018200762569904327,\n        -0.01371725369244814,\n        0.005598036572337151,\n        -0.013653747737407684,\n        -0.013920472003519535,\n        0.05451338365674019,\n        0.005534530617296696,\n        -0.04224406182765961,\n        -0.013526735827326775,\n        -0.008649490773677826,\n        -0.035893481224775314,\n        -0.014796852134168148,\n        0.014085587114095688,\n        -0.01339972484856844,\n        -0.01695604994893074,\n        0.0016162226675078273,\n        -0.010465756990015507,\n        0.03701118379831314,\n        0.0012232805602252483,\n        0.020918812602758408,\n        0.0077858115546405315,\n        -0.0047280071303248405,\n        -0.005979071371257305,\n        0.003356281667947769,\n        0.010878544300794601,\n        0.009976761415600777,\n        -0.0335310660302639,\n        -0.007544489577412605,\n        0.01945817843079567,\n        -0.0010549902217462659,\n        0.0012907554628327489,\n        0.026393013074994087,\n        -0.013133000582456589,\n        -0.034750375896692276,\n        -0.02359875664114952,\n        -0.022950997576117516,\n        0.010002164170145988,\n        0.013450529426336288,\n        0.0015773253981024027,\n        -0.02784094400703907,\n        -0.013818862847983837,\n        0.0030371651519089937,\n        0.00294984458014369,\n        -0.014593633823096752,\n        0.015927255153656006,\n        0.010237135924398899,\n        -0.004146928898990154,\n        -0.011316734366118908,\n        -0.039754632860422134,\n        -0.00725236302241683,\n        0.009684635326266289,\n        -0.015241392888128757,\n        -0.003784945933148265,\n        -0.01295518409460783,\n        0.001254239585250616,\n        0.005178898107260466,\n        -0.015939956530928612,\n        -0.006725264713168144,\n        -0.025033988058567047,\n        0.028196576982736588,\n        -0.025033988058567047,\n        0.020398063585162163,\n        0.015254094265401363,\n        -0.003842101199552417,\n        -0.03439474478363991,\n        -0.01882312074303627,\n        0.029085658490657806,\n        -0.021426858380436897,\n        -0.0009382982389070094,\n        -0.00760799553245306,\n        0.018149958923459053,\n        0.008814605884253979,\n        0.011316734366118908,\n        -0.023687664419412613,\n        -0.018810419365763664,\n        -0.006757017690688372,\n        0.005429746117442846,\n        -0.01712116412818432,\n        -0.018175361678004265,\n        -0.0006580788758583367,\n        0.025961171835660934,\n        0.005201125517487526,\n        -0.0039532361552119255,\n        0.007265063934028149,\n        -0.01221216656267643,\n        -0.036274515092372894,\n        0.01831507310271263,\n        0.0013439415488392115,\n        -0.014530127868056297,\n        0.004362848587334156,\n        0.21419237554073334,\n        -0.009906905703246593,\n        0.007950927130877972,\n        0.04148199036717415,\n        -0.00979259517043829,\n        -0.005156671162694693,\n        0.016879843547940254,\n        0.007093598134815693,\n        -0.018658004701137543,\n        0.02357335388660431,\n        -0.013933173380792141,\n        0.0003203073865734041,\n        -0.031778305768966675,\n        0.0019512157887220383,\n        0.01774352230131626,\n        -0.03909417241811752,\n        -0.017286280170083046,\n        -0.011145268566906452,\n        -0.018340475857257843,\n        -0.003162589157000184,\n        -0.00789377186447382,\n        0.013514035381376743,\n        0.004810564685612917,\n        -0.029238073155283928,\n        0.0394752062857151,\n        0.019877316430211067,\n        -0.008255754597485065,\n        0.006661758758127689,\n        0.018772315233945847,\n        0.010516561567783356,\n        -0.024779964238405228,\n        0.0021496715489774942,\n        0.015317600220441818,\n        0.007233310956507921,\n        -0.021630076691508293,\n        -0.013514035381376743,\n        0.0034483652561903,\n        0.001973442966118455,\n        0.021934904158115387,\n        0.019153350964188576,\n        0.004896297585219145,\n        -0.026469219475984573,\n        -0.010916647501289845,\n        -0.014263403601944447,\n        0.019661396741867065,\n        0.024119503796100616,\n        -0.02837439253926277,\n        -0.038992565125226974,\n        0.017514901235699654,\n        0.01661311835050583,\n        -0.0015122320037335157,\n        -0.0016940173227339983,\n        0.039627622812986374,\n        0.013107597827911377,\n        -0.013831564225256443,\n        -0.005340838339179754,\n        -0.0005163815803825855,\n        0.01778162457048893,\n        0.033962905406951904,\n        0.022163525223731995,\n        -0.00151064433157444,\n        0.027739334851503372,\n        -0.03429313376545906,\n        0.011081762611865997,\n        -0.013679150491952896,\n        0.011742223054170609,\n        -0.02277318201959133,\n        -0.020664788782596588,\n        -0.008522478863596916,\n        -0.004473983775824308,\n        0.00010170851601287723,\n        -0.008535180240869522,\n        0.030609797686338425,\n        0.01026888843625784,\n        -0.02771393209695816,\n        -0.022442951798439026,\n        0.01901363767683506,\n        0.023776572197675705,\n        0.04064371436834335,\n        0.039017967879772186,\n        -0.005420220550149679,\n        0.021337950602173805,\n        0.005975896026939154,\n        0.003540448611602187,\n        -0.015558921732008457,\n        -0.04353957995772362,\n        0.0011947029270231724,\n        0.014479323290288448,\n        -0.01533030066639185,\n        -0.0014868295984342694,\n        -0.024437032639980316,\n        0.0031816407572478056,\n        -0.027764737606048584,\n        -0.0034039111342281103,\n        0.021744387224316597,\n        -0.004092948976904154,\n        0.014530127868056297,\n        0.03160048648715019,\n        0.003391209989786148,\n        -0.022214330732822418,\n        -0.012193114496767521,\n        0.05314165726304054,\n        0.03528382629156113,\n        0.00982434768229723,\n        0.004261239431798458,\n        -0.0010232372442260385,\n        0.0015662119258195162,\n        0.01961059309542179,\n        -0.0048232655972242355,\n        -0.004232661798596382,\n        -0.0026100885588675737,\n        -0.028069565072655678,\n        -0.0038802046328783035,\n        -0.01663852110505104,\n        0.00513444421812892,\n        0.02306530810892582,\n        0.0013082196237519383,\n        -0.027536116540431976,\n        0.0011304033687338233,\n        0.011583458632230759,\n        -0.02423381432890892,\n        -0.02243025042116642,\n        0.005483726039528847,\n        -0.0109801534563303,\n        0.015419209375977516,\n        -0.0033467558678239584,\n        -0.016206681728363037,\n        0.002524355659261346,\n        0.004429529886692762,\n        -0.0064807673916220665,\n        -0.0036801614332944155,\n        -0.022709675133228302,\n        0.010891245678067207,\n        -0.013488632626831532,\n        -0.013958576135337353,\n        -0.0006501406896859407,\n        -0.0027482137084007263,\n        -0.029847728088498116,\n        0.01164061389863491,\n        0.0017130690393969417,\n        -0.003613480366766453,\n        -0.009456014260649681,\n        -0.017603809013962746,\n        0.000527098192833364,\n        0.001559861353598535,\n        -0.02094421349465847,\n        -0.003114959690719843,\n        -0.007563541177660227,\n        -0.013196506537497044,\n        -0.021439559757709503,\n        0.0007418271852657199,\n        0.006375982891768217,\n        -0.008331961929798126,\n        -0.014923864044249058,\n        -0.0012851987266913056,\n        -0.010084721259772778,\n        0.003249909495934844,\n        -0.025732552632689476,\n        0.00725236302241683,\n        0.013387023471295834,\n        -0.022811284288764,\n        -0.004197733476758003,\n        0.02591036818921566,\n        0.006423612125217915,\n        -0.020601283758878708,\n        -0.02357335388660431,\n        -0.15962818264961243,\n        0.01263765525072813,\n        0.004791513085365295,\n        -0.021083926782011986,\n        0.011024607345461845,\n        0.020652087405323982,\n        0.00850977748632431,\n        -0.012739264406263828,\n        -0.024055998772382736,\n        0.008008081465959549,\n        0.01818806305527687,\n        -0.03624911233782768,\n        -0.02192220278084278,\n        -0.00025184021797031164,\n        -0.01224391907453537,\n        0.0022481053601950407,\n        0.013183805160224438,\n        0.00129710603505373,\n        0.019597891718149185,\n        0.015762140974402428,\n        0.016181278973817825,\n        -0.009570324793457985,\n        0.033988308161497116,\n        0.013933173380792141,\n        -0.01314570102840662,\n        0.0275869220495224,\n        -0.016346393153071404,\n        0.022722376510500908,\n        0.0012518581934273243,\n        -0.01629558950662613,\n        -0.0013995091430842876,\n        0.006814172957092524,\n        0.018594499677419662,\n        -0.03119405172765255,\n        -0.005074113607406616,\n        -0.0035372732672840357,\n        0.01661311835050583,\n        -0.03751922771334648,\n        0.00010944828682113439,\n        0.016727428883314133,\n        0.012155011296272278,\n        0.02467835508286953,\n        -0.01298693660646677,\n        -0.0063791582360863686,\n        -0.03015255555510521,\n        0.00605845358222723,\n        0.037290606647729874,\n        -0.01287897676229477,\n        0.012840873561799526,\n        -0.012802770361304283,\n        0.021820593625307083,\n        -0.007868369109928608,\n        0.001025618752464652,\n        -0.00497567979618907,\n        0.010713429190218449,\n        0.020423466339707375,\n        0.008389117196202278,\n        0.0288570374250412,\n        0.006194991059601307,\n        -0.006934833712875843,\n        0.002821245463564992,\n        -0.033327847719192505,\n        -0.012091505341231823,\n        -0.004766110796481371,\n        -0.002187774982303381,\n        -0.00012939306907355785,\n        -0.01952168345451355,\n        -0.001416973304003477,\n        -0.015546221286058426,\n        -0.005998123437166214,\n        -0.0032245072070509195,\n        -0.029161864891648293,\n        0.009684635326266289,\n        0.02192220278084278,\n        0.009354405105113983,\n        -0.007982679642736912,\n        9.897974814521149e-05,\n        0.0069094314239919186,\n        -0.008611386641860008,\n        -0.01221216656267643,\n        -0.014149093069136143,\n        0.051236484199762344,\n        -0.013107597827911377,\n        0.05339568108320236,\n        -0.03838290646672249,\n        -0.011157969944179058,\n        -0.0300255436450243,\n        0.008363714441657066,\n        -0.013247311115264893,\n        -0.01644800417125225,\n        0.02370036579668522,\n        -0.02138875424861908,\n        -0.016054267063736916,\n        -0.005251930095255375,\n        0.00669986242428422,\n        0.007398426067084074,\n        0.009881502948701382,\n        8.439325756626204e-05,\n        0.002044886816293001,\n        -0.011348486877977848,\n        0.00273710023611784,\n        -0.028018761426210403,\n        0.008408168330788612,\n        0.021210938692092896,\n        0.029187267646193504,\n        0.047502342611551285,\n        -0.01854369416832924,\n        0.0026243773754686117,\n        0.026647035032510757,\n        -0.0016940173227339983,\n        -0.014936565421521664,\n        0.00294984458014369,\n        0.03424232825636864,\n        0.006953885778784752,\n        0.005693295504897833,\n        0.014555530622601509,\n        0.0056774187833070755,\n        0.0033816839568316936,\n        -0.0073349205777049065,\n        -0.016270186752080917,\n        0.041431184858083725,\n        0.009843399748206139,\n        0.0029180916026234627,\n        0.007950927130877972,\n        0.001597170950844884,\n        -0.02151576615869999,\n        -0.08474214375019073,\n        0.0051979501731693745,\n        0.011335786432027817,\n        0.015127082355320454,\n        -0.024030596017837524,\n        0.012891678139567375,\n        -0.009055927395820618,\n        0.006744316313415766,\n        -0.007747707888484001,\n        0.016663923859596252,\n        -0.01721007376909256,\n        -0.027231289073824883,\n        0.00037329504266381264,\n        -0.021426858380436897,\n        0.012453488074243069,\n        0.0009303600527346134,\n        0.00018337300571147352,\n        0.008058886975049973,\n        -0.016778234392404556,\n        0.015165186487138271,\n        -0.0043215700425207615,\n        -0.003315002890303731,\n        0.007849317044019699,\n        -0.018708810210227966,\n        0.007106299512088299,\n        0.012161361053586006,\n        -0.017832430079579353,\n        -0.005940968170762062,\n        0.013094896450638771,\n        -0.00015221547801047564,\n        0.0023957565426826477,\n        -0.04115176200866699,\n        -0.0012804358266294003,\n        -0.019064443185925484,\n        -0.005598036572337151,\n        -0.0144285187125206,\n        -0.017362486571073532,\n        -0.0016765532782301307,\n        0.01854369416832924,\n        -0.019877316430211067,\n        -0.004874070640653372,\n        0.008643140085041523,\n        0.024843471124768257,\n        -0.04173601418733597,\n        0.008141444064676762,\n        -0.006099732592701912,\n        0.0018607201054692268,\n        0.02556743659079075,\n        0.012339177541434765,\n        -0.01526679564267397,\n        -0.020868007093667984,\n        0.03751922771334648,\n        -0.010427652858197689,\n        -0.019039040431380272,\n        0.04064371436834335,\n        -0.005302734673023224,\n        -0.004213610198348761,\n        0.013425126671791077,\n        -0.00835101306438446,\n        -0.019229557365179062,\n        0.00330547709017992,\n        -0.011869234964251518,\n        -0.018721511587500572,\n        0.0034102615900337696,\n        0.013171103782951832,\n        -0.0018273795722052455,\n        -0.027409104630351067,\n        -0.008293857797980309,\n        0.002643429208546877,\n        -0.02376387268304825,\n        -0.0010057731997221708,\n        0.018200762569904327,\n        -0.005274157039821148,\n        0.014187196269631386,\n        -0.01812455616891384,\n        0.006036226637661457,\n        -0.0300255436450243,\n        -0.0009946596110239625,\n        0.008522478863596916,\n        -0.005483726039528847,\n        0.0005358302150852978,\n        -0.01064357254654169,\n        -0.00016908420366235077,\n        -0.0011462797410786152,\n        0.002908565802499652,\n        -0.010097422637045383,\n        0.00010086507973028347,\n        -0.0006513313855975866,\n        0.0025322940200567245,\n        -0.0365031361579895,\n        0.002257631393149495,\n        0.032413363456726074,\n        -0.009322651661932468,\n        -0.03172750025987625,\n        -0.021172834560275078,\n        -0.012199465185403824,\n        0.0028895142022520304,\n        0.01176762580871582,\n        0.009748141281306744,\n        0.014987369999289513,\n        0.002421158831566572,\n        0.020804502069950104,\n        -0.0330992266535759,\n        0.023078009486198425,\n        -0.010459406301379204,\n        -0.011183371767401695,\n        0.005613913293927908,\n        0.0011010318994522095,\n        0.009017824195325375,\n        -0.003492819145321846,\n        0.007061845622956753,\n        0.01121512521058321,\n        -0.012809121049940586,\n        -0.001567799597978592,\n        -0.01430150680243969,\n        0.00017057261720765382,\n        -0.005775853060185909,\n        -0.015584324486553669,\n        0.018658004701137543,\n        0.001490004942752421,\n        0.019089844077825546,\n        -0.03833210468292236,\n        0.0028768128249794245,\n        -0.010275239124894142,\n        -0.004521613474935293,\n        0.02720588631927967,\n        -0.031092442572116852,\n        0.03866233304142952,\n        -0.016536911949515343,\n        0.027155082672834396,\n        -0.0007846935768611729,\n        -0.03579187020659447,\n        0.025935770943760872,\n        -0.03876394405961037,\n        0.014009380713105202,\n        0.015571623109281063,\n        0.008497077040374279,\n        -0.024538643658161163,\n        0.02486887201666832,\n        0.02518640272319317,\n        0.027002668008208275,\n        0.022849388420581818,\n        0.004273940809071064,\n        -0.00725236302241683,\n        -0.01616857759654522,\n        -0.03561405465006828,\n        -0.014263403601944447,\n        0.01701955497264862,\n        -0.00621721800416708,\n        0.0012844048906117678,\n        0.00856058206409216,\n        0.013615644536912441,\n        0.024462435394525528,\n        0.015368404798209667,\n        -0.018327774479985237,\n        -0.006179114803671837,\n        -0.001624954747967422,\n        -0.02157927304506302,\n        0.0020115463994443417,\n        -0.0030451032798737288,\n        0.029034852981567383,\n        0.0014137979596853256,\n        0.03566486015915871,\n        0.018937431275844574,\n        0.02128714509308338,\n        -0.001895648310892284,\n        0.020995019003748894,\n        -0.0015114381676539779,\n        0.00805253628641367,\n        0.03129566088318825,\n        0.037316009402275085,\n        -0.04061831161379814,\n        -0.05791729316115379,\n        0.017857832834124565,\n        -0.0023909935262054205,\n        0.009837049059569836,\n        0.030127152800559998,\n        -0.013323517516255379,\n        -0.0023544777650386095,\n        -0.013691850937902927,\n        -0.005185248795896769,\n        0.013285414315760136,\n        0.002894276985898614,\n        0.011583458632230759,\n        -0.02606278285384178,\n        0.01841668412089348,\n        0.02606278285384178,\n        0.01841668412089348,\n        -0.011005556210875511,\n        0.0014336435124278069,\n        -0.013336218893527985,\n        0.001917875255458057,\n        0.009652881883084774,\n        -0.0007584974518977106,\n        -0.02034725993871689,\n        -0.012307425029575825,\n        -0.007487334311008453,\n        -0.00856058206409216,\n        -0.0029101534746587276,\n        0.021503064781427383,\n        0.010084721259772778,\n        -0.010910296812653542,\n        0.03594428673386574,\n        -0.002622789703309536,\n        0.005480550695210695,\n        -0.02571985125541687,\n        -0.03944980725646019,\n        0.00216713547706604,\n        -0.010910296812653542,\n        -0.013463230803608894,\n        0.010364146903157234,\n        0.023078009486198425,\n        -0.00950681883841753,\n        0.009132134728133678,\n        0.0007751677185297012,\n        0.005734574049711227,\n        -0.019153350964188576,\n        0.020131340250372887,\n        0.00979259517043829,\n        -0.04173601418733597,\n        -0.026088183745741844,\n        0.03132106363773346,\n        0.011354837566614151,\n        0.02357335388660431,\n        -0.004296167753636837,\n        0.0052709816955029964,\n        0.012053401209414005,\n        0.01879771798849106,\n        0.006322002969682217,\n        -0.002702171914279461,\n        0.023713067173957825,\n        0.023611458018422127,\n        -0.01540650799870491,\n        -0.011894636787474155,\n        -0.006598253268748522,\n        -0.0008390704169869423,\n        -0.022671572864055634,\n        -0.012174062430858612,\n        0.00939885899424553,\n        0.008820956572890282,\n        -0.034623365849256516,\n        0.05989867448806763,\n        0.007804863154888153,\n        -0.029847728088498116,\n        0.004731182474642992,\n        -0.016460703685879707,\n        0.030863821506500244,\n        0.01553351990878582,\n        -0.003064155112951994,\n        0.0002816085470840335,\n        -0.01164061389863491,\n        -0.000274067249847576,\n        0.004162805620580912,\n        0.02898404933512211,\n        -0.009551272727549076,\n        -0.0037309660110622644,\n        0.0077921622432768345,\n        -0.014339610934257507,\n        0.010992854833602905,\n        -0.0012875802349299192,\n        0.012574149295687675,\n        0.0003691274905577302,\n        0.016879843547940254,\n        0.009309951215982437,\n        0.010700727812945843,\n        0.0015932018868625164,\n        -0.012682109139859676,\n        -0.014873059466481209,\n        -0.03749382495880127,\n        -0.012917080894112587,\n        0.0013375909766182303,\n        0.004508912097662687,\n        -0.006287074647843838,\n        -0.018365878611803055,\n        -0.031778305768966675,\n        -0.004007216077297926,\n        0.004610521253198385,\n        -0.003165764268487692,\n        -0.012516994029283524,\n        0.022760480642318726,\n        -0.004804213996976614,\n        0.022722376510500908,\n        0.017895935103297234,\n        -0.019940823316574097,\n        -0.027688531205058098,\n        -0.029314279556274414,\n        -0.00661095418035984,\n        -0.024259217083454132,\n        -0.01243443600833416,\n        -0.02799335867166519\n      ],\n      \"index\": 0,\n      \"object\": \"embedding\"\n    }\n  ],\n  \"model\": \"ada\",\n  \"object\": \"list\",\n  \"usage\": {\n    \"prompt_tokens\": 9,\n    \"total_tokens\": 9\n  }\n}"}}],"links":[],"resource":{"attributes":{"service.name":"promptflow"},"schema_url":""}}],"modelversion":"default","collectdatatype":"pandas.core.frame.DataFrame","agent":"azureml-ai-monitoring/0.1.0b4","contentrange":"bytes 0-98780/98781","correlationid":"23d71538-416a-44f7-a687-5773c7c377b9","xrequestid":"23d71538-416a-44f7-a687-5773c7c377b9"}
{"specversion":"1.0","id":"b8d2e685-1d87-48a8-b9d0-b07d8a1bc107","source":"/subscriptions/1aefdc5e-3a7c-4d71-a9f9-f5d3b03be19a/resourceGroups/yuachengtestrg/providers/Microsoft.MachineLearningServices/workspaces/ai-proj-eastus/onlineEndpoints/clone-vivi-log-test/deployments/clone-vivi-log-test-1","type":"azureml.inference.app_traces","datacontenttype":"application/json","time":"2024-04-11T18:09:01Z","data":[{"name":"Prompt_variants","context":{"trace_id":"0xa2f3f4f8267a482fa3bb96ad3e1f7f35","span_id":"0xd2076fd4915c298e","trace_state":"[]"},"kind":"SpanKind.INTERNAL","parent_id":"0x38853fe3b7d18b15","start_time":"2024-04-11T18:08:57.734287Z","end_time":"2024-04-11T18:08:57.746423Z","status":{"status_code":"OK"},"attributes":{"framework":"promptflow","span_type":"Function","function":"render_template_jinja2","node_name":"Prompt_variants","request_id":"de58ac2b-f07e-4e0a-89f1-509849ed2737","line_run_id":"de58ac2b-f07e-4e0a-89f1-509849ed2737","inputs":"{\n  \"template\": \"system: \\nYou are an AI assistant that helps users answer questions given a specific context and conversation history. You will be given a context and chat history, and then asked a question based on that context and history. Your answer should be as precise as possible, and should only come from the context.\\nPlease add citation after each sentence when possible in a form \\\"(Source: citation)\\\".\\n\\n user: \\n {{contexts}} \\n\\n chat history: \\n{% for item in chat_history %} user: \\n{{ item.inputs.question }} \\nassistant: \\n{{ item.outputs.output }} \\n{% endfor %}\\nuser: {{question}} \\nassistant:\",\n  \"chat_history\": [\n    {\n      \"inputs\": {\n        \"question\": \"what is aml?\"\n      },\n      \"outputs\": {\n        \"answer\": \"Azure Machine Learning (AML) is a cloud service used for accelerating and managing the machine learning project lifecycle. It is designed for ML professionals, data scientists, and engineers to facilitate their daily workflows in training and deploying models and managing machine learning operations (MLOps). You can create models in AML or use models built from open-source platforms like PyTorch, TensorFlow, or scikit-learn. Furthermore, Azure Machine Learning provides tools for monitoring, retraining, and redeploying models(Source: overview-what-is-azure-machine-learning.md).\"\n      }\n    },\n    {\n      \"inputs\": {\n        \"question\": \"how to create a spark job?\"\n      },\n      \"outputs\": {\n        \"answer\": \"To create a Spark job in Azure Machine Learning, you need to firstly provide a Name and optionally a Value under the **Add tags**. Then in the **Code** section, you need to choose the workspace's default blob storage for code location and select the path of the code file to upload. You then need to input the name of the `titanic.py` as the **Entry file**. \\n\\nNext, you add an input by selecting **+ Add input** under **Inputs** and filling up required fields such as **Input name**, **Input type**, and **Data type**. Similarly, you add an output by selecting **+ Add output** under **Outputs** and entering required information. \\n\\nThen you need to enter **Arguments** for the job. \\n\\nIn the **Spark configurations** section, you can configure parameters such as number of executor cores, memory, and instances. Similarly, configure the driver size. Then, you can add any additional optional configurations. \\n\\nOnce everything is set up, you can review the job specifications and select **Create** to submit the standalone Spark job (Source: quickstart-spark-jobs.md).\\n\\nBear in mind that you have the option to add any necessary Jar files, Py files or Archives for the job under the respective sections (Source: how-to-submit-spark-jobs.md). Also, please note that the job submitted defaults to user identity passthrough for data access (Source: quickstart-spark-jobs.md).\\n\"\n      }\n    },\n    {\n      \"inputs\": {\n        \"question\": \"thank you\"\n      },\n      \"outputs\": {\n        \"answer\": \"To create a Spark job in Azure Machine Learning, follow these steps:\\n\\n1. Provide a **Name** and optional **Tag** for your job.\\n2. In the **Code** section, you need to:\\n   1. Select **Azure Machine Learning workspace default blob storage** from **Choose code location** dropdown.\\n   2. Select **Browse** under **Path to code file to upload** and select the path to your file on the workspace default datastore.\\n   3. Input the name of your **Entry file** (e.g. `titanic.py`) for the standalone job.\\n3. To add an input, select **+ Add input** under **Inputs** and provide necessary details like **Input name**, **Input type**, **Data type**, **Data source**, and appropriate Azure Data Lake Storage (ADLS) Gen 2 data URI.\\n4. To add an output, select **+ Add output** under **Outputs** and provide necessary details like **Output name**, **Output type**, and an appropriate Azure Data Lake Storage (ADLS) Gen 2 folder URI.\\n5. Enter **Arguments** as `--titanic_data ${{inputs.titanic_data}} --wrangled_data ${{outputs.wrangled_data}}`.\\n6. For **Spark configurations**, adjust the **Executor size** and **Driver size** to fit your job's requirements.\\n7. Review the job specification in the **Review** screen, then select **Create** to submit the standalone Spark job (Source: quickstart-spark-jobs.md).\"\n      }\n    }\n  ],\n  \"contexts\": \"Content: # Tutorial: Create resources you need to get started\\n\\n| [Upload, access and explore your data in Azure Machine Learning](tutorial-explore-data.md)     |  Store large data in the cloud and retrieve it from notebooks and scripts |\\n| [Model development on a cloud workstation](tutorial-cloud-workstation.md) | Start prototyping and developing machine learning models |\\n| [Train a model in Azure Machine Learning](tutorial-train-model.md) |    Dive in to the details of training a model     |\\n| [Deploy a model as an online endpoint](tutorial-deploy-model.md)  |   Dive in to the details of deploying a model      |\\n| [Create production machine learning pipelines](tutorial-pipeline-python-sdk.md) | Split a complete machine learning task into a multistep workflow. |\\nSource: quickstart-create-resources.md\\n\\nContent: # Configure a private endpoint for an Azure Machine Learning workspace\\n\\n* When using a workspace with multiple private endpoints, one of the private endpoints must be in the same VNet as the following dependency services:\\n\\n    * Azure Storage Account that provides the default storage for the workspace\\n    * Azure Key Vault for the workspace\\n    * Azure Container Registry for the workspace.\\n\\n    For example, one VNet ('services' VNet) would contain a private endpoint for the dependency services and the workspace. This configuration allows the workspace to communicate with the services. Another VNet ('clients') might only contain a private endpoint for the workspace, and be used only for communication between client development machines and the workspace.\\n\\n## Create a workspace that uses a private endpoint\\n\\nUse one of the following methods to create a workspace with a private endpoint. Each of these methods __requires an existing virtual network__:\\n\\n\u003e [!TIP]\\n\u003e If you'd like to create a workspace, private endpoint, and virtual network at the same time, see [Use an Azure Resource Manager template to create a workspace for Azure Machine Learning](how-to-create-workspace-template.md).\\n\\n# [Azure CLI](#tab\/cli)\\n[!INCLUDE [cli v2](includes\/machine-learning-cli-v2.md)]\\n\\nWhen using the Azure CLI [extension 2.0 CLI for machine learning](how-to-configure-cli.md), a YAML document is used to configure the workspace. The following example demonstrates creating a new workspace using a YAML configuration:\\n\\n\u003e [!TIP]\\n\u003e When using private link, your workspace cannot use Azure Container Registry tasks compute for image building. The `image_build_compute` property in this configuration specifies a CPU compute cluster name to use for Docker image environment building. You can also specify whether the private link workspace should be accessible over the internet using the `public_network_access` property.\\n\u003e\\n\u003e In this example, the compute referenced by `image_build_compute` will need to be created before building images.\\n\\n:::code language=\\\"YAML\\\" source=\\\"~\/azureml-examples-main\/cli\/resources\/workspace\/privatelink.yml\\\":::\\n\\n```azurecli-interactive\\naz ml workspace create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --file privatelink.yml\\n```\\n\\nAfter creating the workspace, use the [Azure networking CLI commands](\/cli\/azure\/network\/private-endpoint#az-network-private-endpoint-create) to create a private link endpoint for the workspace.\\n\\n```azurecli-interactive\\naz network private-endpoint create \\\\\\n    --name \u003cprivate-endpoint-name\u003e \\\\\\n    --vnet-name \u003cvnet-name\u003e \\\\\\n    --subnet \u003csubnet-name\u003e \\\\\\n    --private-connection-resource-id \\\"\/subscriptions\/\u003csubscription\u003e\/resourceGroups\/\u003cresource-group-name\u003e\/providers\/Microsoft.MachineLearningServices\/workspaces\/\u003cworkspace-name\u003e\\\" \\\\\\n    --group-id amlworkspace \\\\\\n    --connection-name workspace -l \u003clocation\u003e\\n```\\n\\nTo create the private DNS zone entries for the workspace, use the following commands:\\n\\n```azurecli-interactive\\n# Add privatelink.api.azureml.ms\\naz network private-dns zone create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --name privatelink.api.azureml.ms\\n\\naz network private-dns link vnet create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --zone-name privatelink.api.azureml.ms \\\\\\n    --name \u003clink-name\u003e \\\\\\n    --virtual-network \u003cvnet-name\u003e \\\\\\n    --registration-enabled false\\n\\naz network private-endpoint dns-zone-group create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --endpoint-name \u003cprivate-endpoint-name\u003e \\\\\\n    --name myzonegroup \\\\\\n    --private-dns-zone privatelink.api.azureml.ms \\\\\\n    --zone-name privatelink.api.azureml.ms\\n\\n# Add privatelink.notebooks.azure.net\\naz network private-dns zone create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --name privatelink.notebooks.azure.net\\n\\naz network private-dns link vnet create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --zone-name privatelink.notebooks.azure.net \\\\\\n    --name \u003clink-name\u003e \\\\\\n    --virtual-network \u003cvnet-name\u003e \\\\\\n    --registration-enabled false\\n\\naz network private-endpoint dns-zone-group add \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\nSource: how-to-configure-private-link.md\\n\\nContent: # Model performance and fairness\\n\\n- Learn how to use the components by checking out Fairlearn's [GitHub repository](https:\/\/github.com\/fairlearn\/fairlearn\/), [user guide](https:\/\/fairlearn.github.io\/main\/user_guide\/index.html), [examples](https:\/\/fairlearn.github.io\/main\/auto_examples\/index.html), and [sample notebooks](https:\/\/github.com\/fairlearn\/fairlearn\/blob\/main\/docs\/contributor_guide\/contributing_example_notebooks.rst).\\nSource: concept-fairness-ml.md\",\n  \"question\": \"can you share a link to the examle?\"\n}","output":"\"system: \\nYou are an AI assistant that helps users answer questions given a specific context and conversation history. You will be given a context and chat history, and then asked a question based on that context and history. Your answer should be as precise as possible, and should only come from the context.\\nPlease add citation after each sentence when possible in a form \\\"(Source: citation)\\\".\\n\\n user: \\n Content: # Tutorial: Create resources you need to get started\\n\\n| [Upload, access and explore your data in Azure Machine Learning](tutorial-explore-data.md)     |  Store large data in the cloud and retrieve it from notebooks and scripts |\\n| [Model development on a cloud workstation](tutorial-cloud-workstation.md) | Start prototyping and developing machine learning models |\\n| [Train a model in Azure Machine Learning](tutorial-train-model.md) |    Dive in to the details of training a model     |\\n| [Deploy a model as an online endpoint](tutorial-deploy-model.md)  |   Dive in to the details of deploying a model      |\\n| [Create production machine learning pipelines](tutorial-pipeline-python-sdk.md) | Split a complete machine learning task into a multistep workflow. |\\nSource: quickstart-create-resources.md\\n\\nContent: # Configure a private endpoint for an Azure Machine Learning workspace\\n\\n* When using a workspace with multiple private endpoints, one of the private endpoints must be in the same VNet as the following dependency services:\\n\\n    * Azure Storage Account that provides the default storage for the workspace\\n    * Azure Key Vault for the workspace\\n    * Azure Container Registry for the workspace.\\n\\n    For example, one VNet ('services' VNet) would contain a private endpoint for the dependency services and the workspace. This configuration allows the workspace to communicate with the services. Another VNet ('clients') might only contain a private endpoint for the workspace, and be used only for communication between client development machines and the workspace.\\n\\n## Create a workspace that uses a private endpoint\\n\\nUse one of the following methods to create a workspace with a private endpoint. Each of these methods __requires an existing virtual network__:\\n\\n\u003e [!TIP]\\n\u003e If you'd like to create a workspace, private endpoint, and virtual network at the same time, see [Use an Azure Resource Manager template to create a workspace for Azure Machine Learning](how-to-create-workspace-template.md).\\n\\n# [Azure CLI](#tab\/cli)\\n[!INCLUDE [cli v2](includes\/machine-learning-cli-v2.md)]\\n\\nWhen using the Azure CLI [extension 2.0 CLI for machine learning](how-to-configure-cli.md), a YAML document is used to configure the workspace. The following example demonstrates creating a new workspace using a YAML configuration:\\n\\n\u003e [!TIP]\\n\u003e When using private link, your workspace cannot use Azure Container Registry tasks compute for image building. The `image_build_compute` property in this configuration specifies a CPU compute cluster name to use for Docker image environment building. You can also specify whether the private link workspace should be accessible over the internet using the `public_network_access` property.\\n\u003e\\n\u003e In this example, the compute referenced by `image_build_compute` will need to be created before building images.\\n\\n:::code language=\\\"YAML\\\" source=\\\"~\/azureml-examples-main\/cli\/resources\/workspace\/privatelink.yml\\\":::\\n\\n```azurecli-interactive\\naz ml workspace create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --file privatelink.yml\\n```\\n\\nAfter creating the workspace, use the [Azure networking CLI commands](\/cli\/azure\/network\/private-endpoint#az-network-private-endpoint-create) to create a private link endpoint for the workspace.\\n\\n```azurecli-interactive\\naz network private-endpoint create \\\\\\n    --name \u003cprivate-endpoint-name\u003e \\\\\\n    --vnet-name \u003cvnet-name\u003e \\\\\\n    --subnet \u003csubnet-name\u003e \\\\\\n    --private-connection-resource-id \\\"\/subscriptions\/\u003csubscription\u003e\/resourceGroups\/\u003cresource-group-name\u003e\/providers\/Microsoft.MachineLearningServices\/workspaces\/\u003cworkspace-name\u003e\\\" \\\\\\n    --group-id amlworkspace \\\\\\n    --connection-name workspace -l \u003clocation\u003e\\n```\\n\\nTo create the private DNS zone entries for the workspace, use the following commands:\\n\\n```azurecli-interactive\\n# Add privatelink.api.azureml.ms\\naz network private-dns zone create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --name privatelink.api.azureml.ms\\n\\naz network private-dns link vnet create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --zone-name privatelink.api.azureml.ms \\\\\\n    --name \u003clink-name\u003e \\\\\\n    --virtual-network \u003cvnet-name\u003e \\\\\\n    --registration-enabled false\\n\\naz network private-endpoint dns-zone-group create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --endpoint-name \u003cprivate-endpoint-name\u003e \\\\\\n    --name myzonegroup \\\\\\n    --private-dns-zone privatelink.api.azureml.ms \\\\\\n    --zone-name privatelink.api.azureml.ms\\n\\n# Add privatelink.notebooks.azure.net\\naz network private-dns zone create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --name privatelink.notebooks.azure.net\\n\\naz network private-dns link vnet create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --zone-name privatelink.notebooks.azure.net \\\\\\n    --name \u003clink-name\u003e \\\\\\n    --virtual-network \u003cvnet-name\u003e \\\\\\n    --registration-enabled false\\n\\naz network private-endpoint dns-zone-group add \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\nSource: how-to-configure-private-link.md\\n\\nContent: # Model performance and fairness\\n\\n- Learn how to use the components by checking out Fairlearn's [GitHub repository](https:\/\/github.com\/fairlearn\/fairlearn\/), [user guide](https:\/\/fairlearn.github.io\/main\/user_guide\/index.html), [examples](https:\/\/fairlearn.github.io\/main\/auto_examples\/index.html), and [sample notebooks](https:\/\/github.com\/fairlearn\/fairlearn\/blob\/main\/docs\/contributor_guide\/contributing_example_notebooks.rst).\\nSource: concept-fairness-ml.md \\n\\n chat history: \\n user: \\nwhat is aml? \\nassistant: \\n \\n user: \\nhow to create a spark job? \\nassistant: \\n \\n user: \\nthank you \\nassistant: \\n \\nuser: can you share a link to the examle? \\nassistant:\""},"events":[{"name":"promptflow.function.inputs","timestamp":"2024-04-11T18:08:57.742348Z","attributes":{"payload":"{\n  \"template\": \"system: \\nYou are an AI assistant that helps users answer questions given a specific context and conversation history. You will be given a context and chat history, and then asked a question based on that context and history. Your answer should be as precise as possible, and should only come from the context.\\nPlease add citation after each sentence when possible in a form \\\"(Source: citation)\\\".\\n\\n user: \\n {{contexts}} \\n\\n chat history: \\n{% for item in chat_history %} user: \\n{{ item.inputs.question }} \\nassistant: \\n{{ item.outputs.output }} \\n{% endfor %}\\nuser: {{question}} \\nassistant:\",\n  \"chat_history\": [\n    {\n      \"inputs\": {\n        \"question\": \"what is aml?\"\n      },\n      \"outputs\": {\n        \"answer\": \"Azure Machine Learning (AML) is a cloud service used for accelerating and managing the machine learning project lifecycle. It is designed for ML professionals, data scientists, and engineers to facilitate their daily workflows in training and deploying models and managing machine learning operations (MLOps). You can create models in AML or use models built from open-source platforms like PyTorch, TensorFlow, or scikit-learn. Furthermore, Azure Machine Learning provides tools for monitoring, retraining, and redeploying models(Source: overview-what-is-azure-machine-learning.md).\"\n      }\n    },\n    {\n      \"inputs\": {\n        \"question\": \"how to create a spark job?\"\n      },\n      \"outputs\": {\n        \"answer\": \"To create a Spark job in Azure Machine Learning, you need to firstly provide a Name and optionally a Value under the **Add tags**. Then in the **Code** section, you need to choose the workspace's default blob storage for code location and select the path of the code file to upload. You then need to input the name of the `titanic.py` as the **Entry file**. \\n\\nNext, you add an input by selecting **+ Add input** under **Inputs** and filling up required fields such as **Input name**, **Input type**, and **Data type**. Similarly, you add an output by selecting **+ Add output** under **Outputs** and entering required information. \\n\\nThen you need to enter **Arguments** for the job. \\n\\nIn the **Spark configurations** section, you can configure parameters such as number of executor cores, memory, and instances. Similarly, configure the driver size. Then, you can add any additional optional configurations. \\n\\nOnce everything is set up, you can review the job specifications and select **Create** to submit the standalone Spark job (Source: quickstart-spark-jobs.md).\\n\\nBear in mind that you have the option to add any necessary Jar files, Py files or Archives for the job under the respective sections (Source: how-to-submit-spark-jobs.md). Also, please note that the job submitted defaults to user identity passthrough for data access (Source: quickstart-spark-jobs.md).\\n\"\n      }\n    },\n    {\n      \"inputs\": {\n        \"question\": \"thank you\"\n      },\n      \"outputs\": {\n        \"answer\": \"To create a Spark job in Azure Machine Learning, follow these steps:\\n\\n1. Provide a **Name** and optional **Tag** for your job.\\n2. In the **Code** section, you need to:\\n   1. Select **Azure Machine Learning workspace default blob storage** from **Choose code location** dropdown.\\n   2. Select **Browse** under **Path to code file to upload** and select the path to your file on the workspace default datastore.\\n   3. Input the name of your **Entry file** (e.g. `titanic.py`) for the standalone job.\\n3. To add an input, select **+ Add input** under **Inputs** and provide necessary details like **Input name**, **Input type**, **Data type**, **Data source**, and appropriate Azure Data Lake Storage (ADLS) Gen 2 data URI.\\n4. To add an output, select **+ Add output** under **Outputs** and provide necessary details like **Output name**, **Output type**, and an appropriate Azure Data Lake Storage (ADLS) Gen 2 folder URI.\\n5. Enter **Arguments** as `--titanic_data ${{inputs.titanic_data}} --wrangled_data ${{outputs.wrangled_data}}`.\\n6. For **Spark configurations**, adjust the **Executor size** and **Driver size** to fit your job's requirements.\\n7. Review the job specification in the **Review** screen, then select **Create** to submit the standalone Spark job (Source: quickstart-spark-jobs.md).\"\n      }\n    }\n  ],\n  \"contexts\": \"Content: # Tutorial: Create resources you need to get started\\n\\n| [Upload, access and explore your data in Azure Machine Learning](tutorial-explore-data.md)     |  Store large data in the cloud and retrieve it from notebooks and scripts |\\n| [Model development on a cloud workstation](tutorial-cloud-workstation.md) | Start prototyping and developing machine learning models |\\n| [Train a model in Azure Machine Learning](tutorial-train-model.md) |    Dive in to the details of training a model     |\\n| [Deploy a model as an online endpoint](tutorial-deploy-model.md)  |   Dive in to the details of deploying a model      |\\n| [Create production machine learning pipelines](tutorial-pipeline-python-sdk.md) | Split a complete machine learning task into a multistep workflow. |\\nSource: quickstart-create-resources.md\\n\\nContent: # Configure a private endpoint for an Azure Machine Learning workspace\\n\\n* When using a workspace with multiple private endpoints, one of the private endpoints must be in the same VNet as the following dependency services:\\n\\n    * Azure Storage Account that provides the default storage for the workspace\\n    * Azure Key Vault for the workspace\\n    * Azure Container Registry for the workspace.\\n\\n    For example, one VNet ('services' VNet) would contain a private endpoint for the dependency services and the workspace. This configuration allows the workspace to communicate with the services. Another VNet ('clients') might only contain a private endpoint for the workspace, and be used only for communication between client development machines and the workspace.\\n\\n## Create a workspace that uses a private endpoint\\n\\nUse one of the following methods to create a workspace with a private endpoint. Each of these methods __requires an existing virtual network__:\\n\\n\u003e [!TIP]\\n\u003e If you'd like to create a workspace, private endpoint, and virtual network at the same time, see [Use an Azure Resource Manager template to create a workspace for Azure Machine Learning](how-to-create-workspace-template.md).\\n\\n# [Azure CLI](#tab\/cli)\\n[!INCLUDE [cli v2](includes\/machine-learning-cli-v2.md)]\\n\\nWhen using the Azure CLI [extension 2.0 CLI for machine learning](how-to-configure-cli.md), a YAML document is used to configure the workspace. The following example demonstrates creating a new workspace using a YAML configuration:\\n\\n\u003e [!TIP]\\n\u003e When using private link, your workspace cannot use Azure Container Registry tasks compute for image building. The `image_build_compute` property in this configuration specifies a CPU compute cluster name to use for Docker image environment building. You can also specify whether the private link workspace should be accessible over the internet using the `public_network_access` property.\\n\u003e\\n\u003e In this example, the compute referenced by `image_build_compute` will need to be created before building images.\\n\\n:::code language=\\\"YAML\\\" source=\\\"~\/azureml-examples-main\/cli\/resources\/workspace\/privatelink.yml\\\":::\\n\\n```azurecli-interactive\\naz ml workspace create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --file privatelink.yml\\n```\\n\\nAfter creating the workspace, use the [Azure networking CLI commands](\/cli\/azure\/network\/private-endpoint#az-network-private-endpoint-create) to create a private link endpoint for the workspace.\\n\\n```azurecli-interactive\\naz network private-endpoint create \\\\\\n    --name \u003cprivate-endpoint-name\u003e \\\\\\n    --vnet-name \u003cvnet-name\u003e \\\\\\n    --subnet \u003csubnet-name\u003e \\\\\\n    --private-connection-resource-id \\\"\/subscriptions\/\u003csubscription\u003e\/resourceGroups\/\u003cresource-group-name\u003e\/providers\/Microsoft.MachineLearningServices\/workspaces\/\u003cworkspace-name\u003e\\\" \\\\\\n    --group-id amlworkspace \\\\\\n    --connection-name workspace -l \u003clocation\u003e\\n```\\n\\nTo create the private DNS zone entries for the workspace, use the following commands:\\n\\n```azurecli-interactive\\n# Add privatelink.api.azureml.ms\\naz network private-dns zone create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --name privatelink.api.azureml.ms\\n\\naz network private-dns link vnet create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --zone-name privatelink.api.azureml.ms \\\\\\n    --name \u003clink-name\u003e \\\\\\n    --virtual-network \u003cvnet-name\u003e \\\\\\n    --registration-enabled false\\n\\naz network private-endpoint dns-zone-group create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --endpoint-name \u003cprivate-endpoint-name\u003e \\\\\\n    --name myzonegroup \\\\\\n    --private-dns-zone privatelink.api.azureml.ms \\\\\\n    --zone-name privatelink.api.azureml.ms\\n\\n# Add privatelink.notebooks.azure.net\\naz network private-dns zone create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --name privatelink.notebooks.azure.net\\n\\naz network private-dns link vnet create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --zone-name privatelink.notebooks.azure.net \\\\\\n    --name \u003clink-name\u003e \\\\\\n    --virtual-network \u003cvnet-name\u003e \\\\\\n    --registration-enabled false\\n\\naz network private-endpoint dns-zone-group add \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\nSource: how-to-configure-private-link.md\\n\\nContent: # Model performance and fairness\\n\\n- Learn how to use the components by checking out Fairlearn's [GitHub repository](https:\/\/github.com\/fairlearn\/fairlearn\/), [user guide](https:\/\/fairlearn.github.io\/main\/user_guide\/index.html), [examples](https:\/\/fairlearn.github.io\/main\/auto_examples\/index.html), and [sample notebooks](https:\/\/github.com\/fairlearn\/fairlearn\/blob\/main\/docs\/contributor_guide\/contributing_example_notebooks.rst).\\nSource: concept-fairness-ml.md\",\n  \"question\": \"can you share a link to the examle?\"\n}"}},{"name":"promptflow.function.output","timestamp":"2024-04-11T18:08:57.746132Z","attributes":{"payload":"\"system: \\nYou are an AI assistant that helps users answer questions given a specific context and conversation history. You will be given a context and chat history, and then asked a question based on that context and history. Your answer should be as precise as possible, and should only come from the context.\\nPlease add citation after each sentence when possible in a form \\\"(Source: citation)\\\".\\n\\n user: \\n Content: # Tutorial: Create resources you need to get started\\n\\n| [Upload, access and explore your data in Azure Machine Learning](tutorial-explore-data.md)     |  Store large data in the cloud and retrieve it from notebooks and scripts |\\n| [Model development on a cloud workstation](tutorial-cloud-workstation.md) | Start prototyping and developing machine learning models |\\n| [Train a model in Azure Machine Learning](tutorial-train-model.md) |    Dive in to the details of training a model     |\\n| [Deploy a model as an online endpoint](tutorial-deploy-model.md)  |   Dive in to the details of deploying a model      |\\n| [Create production machine learning pipelines](tutorial-pipeline-python-sdk.md) | Split a complete machine learning task into a multistep workflow. |\\nSource: quickstart-create-resources.md\\n\\nContent: # Configure a private endpoint for an Azure Machine Learning workspace\\n\\n* When using a workspace with multiple private endpoints, one of the private endpoints must be in the same VNet as the following dependency services:\\n\\n    * Azure Storage Account that provides the default storage for the workspace\\n    * Azure Key Vault for the workspace\\n    * Azure Container Registry for the workspace.\\n\\n    For example, one VNet ('services' VNet) would contain a private endpoint for the dependency services and the workspace. This configuration allows the workspace to communicate with the services. Another VNet ('clients') might only contain a private endpoint for the workspace, and be used only for communication between client development machines and the workspace.\\n\\n## Create a workspace that uses a private endpoint\\n\\nUse one of the following methods to create a workspace with a private endpoint. Each of these methods __requires an existing virtual network__:\\n\\n\u003e [!TIP]\\n\u003e If you'd like to create a workspace, private endpoint, and virtual network at the same time, see [Use an Azure Resource Manager template to create a workspace for Azure Machine Learning](how-to-create-workspace-template.md).\\n\\n# [Azure CLI](#tab\/cli)\\n[!INCLUDE [cli v2](includes\/machine-learning-cli-v2.md)]\\n\\nWhen using the Azure CLI [extension 2.0 CLI for machine learning](how-to-configure-cli.md), a YAML document is used to configure the workspace. The following example demonstrates creating a new workspace using a YAML configuration:\\n\\n\u003e [!TIP]\\n\u003e When using private link, your workspace cannot use Azure Container Registry tasks compute for image building. The `image_build_compute` property in this configuration specifies a CPU compute cluster name to use for Docker image environment building. You can also specify whether the private link workspace should be accessible over the internet using the `public_network_access` property.\\n\u003e\\n\u003e In this example, the compute referenced by `image_build_compute` will need to be created before building images.\\n\\n:::code language=\\\"YAML\\\" source=\\\"~\/azureml-examples-main\/cli\/resources\/workspace\/privatelink.yml\\\":::\\n\\n```azurecli-interactive\\naz ml workspace create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --file privatelink.yml\\n```\\n\\nAfter creating the workspace, use the [Azure networking CLI commands](\/cli\/azure\/network\/private-endpoint#az-network-private-endpoint-create) to create a private link endpoint for the workspace.\\n\\n```azurecli-interactive\\naz network private-endpoint create \\\\\\n    --name \u003cprivate-endpoint-name\u003e \\\\\\n    --vnet-name \u003cvnet-name\u003e \\\\\\n    --subnet \u003csubnet-name\u003e \\\\\\n    --private-connection-resource-id \\\"\/subscriptions\/\u003csubscription\u003e\/resourceGroups\/\u003cresource-group-name\u003e\/providers\/Microsoft.MachineLearningServices\/workspaces\/\u003cworkspace-name\u003e\\\" \\\\\\n    --group-id amlworkspace \\\\\\n    --connection-name workspace -l \u003clocation\u003e\\n```\\n\\nTo create the private DNS zone entries for the workspace, use the following commands:\\n\\n```azurecli-interactive\\n# Add privatelink.api.azureml.ms\\naz network private-dns zone create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --name privatelink.api.azureml.ms\\n\\naz network private-dns link vnet create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --zone-name privatelink.api.azureml.ms \\\\\\n    --name \u003clink-name\u003e \\\\\\n    --virtual-network \u003cvnet-name\u003e \\\\\\n    --registration-enabled false\\n\\naz network private-endpoint dns-zone-group create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --endpoint-name \u003cprivate-endpoint-name\u003e \\\\\\n    --name myzonegroup \\\\\\n    --private-dns-zone privatelink.api.azureml.ms \\\\\\n    --zone-name privatelink.api.azureml.ms\\n\\n# Add privatelink.notebooks.azure.net\\naz network private-dns zone create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --name privatelink.notebooks.azure.net\\n\\naz network private-dns link vnet create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --zone-name privatelink.notebooks.azure.net \\\\\\n    --name \u003clink-name\u003e \\\\\\n    --virtual-network \u003cvnet-name\u003e \\\\\\n    --registration-enabled false\\n\\naz network private-endpoint dns-zone-group add \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\nSource: how-to-configure-private-link.md\\n\\nContent: # Model performance and fairness\\n\\n- Learn how to use the components by checking out Fairlearn's [GitHub repository](https:\/\/github.com\/fairlearn\/fairlearn\/), [user guide](https:\/\/fairlearn.github.io\/main\/user_guide\/index.html), [examples](https:\/\/fairlearn.github.io\/main\/auto_examples\/index.html), and [sample notebooks](https:\/\/github.com\/fairlearn\/fairlearn\/blob\/main\/docs\/contributor_guide\/contributing_example_notebooks.rst).\\nSource: concept-fairness-ml.md \\n\\n chat history: \\n user: \\nwhat is aml? \\nassistant: \\n \\n user: \\nhow to create a spark job? \\nassistant: \\n \\n user: \\nthank you \\nassistant: \\n \\nuser: can you share a link to the examle? \\nassistant:\""}}],"links":[],"resource":{"attributes":{"service.name":"promptflow"},"schema_url":""}}],"xrequestid":"c23421a7-8673-4dcf-89e5-f0332ee718c1","modelversion":"default","collectdatatype":"pandas.core.frame.DataFrame","agent":"azureml-ai-monitoring/0.1.0b4","contentrange":"bytes 0-33945/33946","correlationid":"c23421a7-8673-4dcf-89e5-f0332ee718c1"}
{"specversion":"1.0","id":"f25b6676-42bc-43bd-a4c7-36dcb111ecf2","source":"/subscriptions/1aefdc5e-3a7c-4d71-a9f9-f5d3b03be19a/resourceGroups/yuachengtestrg/providers/Microsoft.MachineLearningServices/workspaces/ai-proj-eastus/onlineEndpoints/clone-vivi-log-test/deployments/clone-vivi-log-test-1","type":"azureml.inference.app_traces","datacontenttype":"application/json","time":"2024-04-11T18:09:01Z","data":[{"name":"search","context":{"trace_id":"0xa2f3f4f8267a482fa3bb96ad3e1f7f35","span_id":"0x76d5b46d668f8735","trace_state":"[]"},"kind":"SpanKind.INTERNAL","parent_id":"0x962ff815307a1061","start_time":"2024-04-11T18:08:56.189462Z","end_time":"2024-04-11T18:08:57.638864Z","status":{"status_code":"UNSET"},"attributes":{"span_type":"Retrieval","retrieval.query":"Could you provide a link to an example?","retrieval.documents":"[{\"document.content\": \"# Tutorial: Create resources you need to get started\\n\\n| [Upload, access and explore your data in Azure Machine Learning](tutorial-explore-data.md)     |  Store large data in the cloud and retrieve it from notebooks and scripts |\\n| [Model development on a cloud workstation](tutorial-cloud-workstation.md) | Start prototyping and developing machine learning models |\\n| [Train a model in Azure Machine Learning](tutorial-train-model.md) |    Dive in to the details of training a model     |\\n| [Deploy a model as an online endpoint](tutorial-deploy-model.md)  |   Dive in to the details of deploying a model      |\\n| [Create production machine learning pipelines](tutorial-pipeline-python-sdk.md) | Split a complete machine learning task into a multistep workflow. |\", \"document.score\": 0.02364782989025116, \"document.metadata\": {\"id\": \"cXVpY2tzdGFydC1jcmVhdGUtcmVzb3VyY2VzLm1kMg==\", \"source\": {\"title\": \"Tutorial: Create resources you need to get started\", \"filename\": \"quickstart-create-resources.md\", \"url\": \"quickstart-create-resources.md\", \"mtime\": 1710206171.0}, \"stats\": {\"tiktokens\": 162, \"chars\": 763, \"lines\": 7}, \"content_hash\": \"120bcf54a5162e37efb991db28b8fbdfa4718a161cb35be2d4baa921fefbf7eb\"}}, {\"document.content\": \"# Configure a private endpoint for an Azure Machine Learning workspace\\n\\n* When using a workspace with multiple private endpoints, one of the private endpoints must be in the same VNet as the following dependency services:\\n\\n    * Azure Storage Account that provides the default storage for the workspace\\n    * Azure Key Vault for the workspace\\n    * Azure Container Registry for the workspace.\\n\\n    For example, one VNet ('services' VNet) would contain a private endpoint for the dependency services and the workspace. This configuration allows the workspace to communicate with the services. Another VNet ('clients') might only contain a private endpoint for the workspace, and be used only for communication between client development machines and the workspace.\\n\\n## Create a workspace that uses a private endpoint\\n\\nUse one of the following methods to create a workspace with a private endpoint. Each of these methods __requires an existing virtual network__:\\n\\n\u003e [!TIP]\\n\u003e If you'd like to create a workspace, private endpoint, and virtual network at the same time, see [Use an Azure Resource Manager template to create a workspace for Azure Machine Learning](how-to-create-workspace-template.md).\\n\\n# [Azure CLI](#tab\/cli)\\n[!INCLUDE [cli v2](includes\/machine-learning-cli-v2.md)]\\n\\nWhen using the Azure CLI [extension 2.0 CLI for machine learning](how-to-configure-cli.md), a YAML document is used to configure the workspace. The following example demonstrates creating a new workspace using a YAML configuration:\\n\\n\u003e [!TIP]\\n\u003e When using private link, your workspace cannot use Azure Container Registry tasks compute for image building. The `image_build_compute` property in this configuration specifies a CPU compute cluster name to use for Docker image environment building. You can also specify whether the private link workspace should be accessible over the internet using the `public_network_access` property.\\n\u003e\\n\u003e In this example, the compute referenced by `image_build_compute` will need to be created before building images.\\n\\n:::code language=\\\"YAML\\\" source=\\\"~\/azureml-examples-main\/cli\/resources\/workspace\/privatelink.yml\\\":::\\n\\n```azurecli-interactive\\naz ml workspace create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --file privatelink.yml\\n```\\n\\nAfter creating the workspace, use the [Azure networking CLI commands](\/cli\/azure\/network\/private-endpoint#az-network-private-endpoint-create) to create a private link endpoint for the workspace.\\n\\n```azurecli-interactive\\naz network private-endpoint create \\\\\\n    --name \u003cprivate-endpoint-name\u003e \\\\\\n    --vnet-name \u003cvnet-name\u003e \\\\\\n    --subnet \u003csubnet-name\u003e \\\\\\n    --private-connection-resource-id \\\"\/subscriptions\/\u003csubscription\u003e\/resourceGroups\/\u003cresource-group-name\u003e\/providers\/Microsoft.MachineLearningServices\/workspaces\/\u003cworkspace-name\u003e\\\" \\\\\\n    --group-id amlworkspace \\\\\\n    --connection-name workspace -l \u003clocation\u003e\\n```\\n\\nTo create the private DNS zone entries for the workspace, use the following commands:\\n\\n```azurecli-interactive\\n# Add privatelink.api.azureml.ms\\naz network private-dns zone create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --name privatelink.api.azureml.ms\\n\\naz network private-dns link vnet create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --zone-name privatelink.api.azureml.ms \\\\\\n    --name \u003clink-name\u003e \\\\\\n    --virtual-network \u003cvnet-name\u003e \\\\\\n    --registration-enabled false\\n\\naz network private-endpoint dns-zone-group create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --endpoint-name \u003cprivate-endpoint-name\u003e \\\\\\n    --name myzonegroup \\\\\\n    --private-dns-zone privatelink.api.azureml.ms \\\\\\n    --zone-name privatelink.api.azureml.ms\\n\\n# Add privatelink.notebooks.azure.net\\naz network private-dns zone create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --name privatelink.notebooks.azure.net\\n\\naz network private-dns link vnet create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --zone-name privatelink.notebooks.azure.net \\\\\\n    --name \u003clink-name\u003e \\\\\\n    --virtual-network \u003cvnet-name\u003e \\\\\\n    --registration-enabled false\\n\\naz network private-endpoint dns-zone-group add \\\\\\n    -g \u003cresource-group-name\u003e \\\\\", \"document.score\": 0.01666666753590107, \"document.metadata\": {\"id\": \"aG93LXRvLWNvbmZpZ3VyZS1wcml2YXRlLWxpbmsubWQx\", \"source\": {\"title\": \"Configure a private endpoint for an Azure Machine Learning workspace\", \"filename\": \"how-to-configure-private-link.md\", \"url\": \"how-to-configure-private-link.md\", \"mtime\": 1710206126.0}, \"stats\": {\"tiktokens\": 878, \"chars\": 4020, \"lines\": 83}, \"content_hash\": \"6defa15776349ba683025232d021517cd3cb8325d3ec94681700ec7bab908ce2\"}}, {\"document.content\": \"# Model performance and fairness\\n\\n- Learn how to use the components by checking out Fairlearn's [GitHub repository](https:\/\/github.com\/fairlearn\/fairlearn\/), [user guide](https:\/\/fairlearn.github.io\/main\/user_guide\/index.html), [examples](https:\/\/fairlearn.github.io\/main\/auto_examples\/index.html), and [sample notebooks](https:\/\/github.com\/fairlearn\/fairlearn\/blob\/main\/docs\/contributor_guide\/contributing_example_notebooks.rst).\", \"document.score\": 0.01666666753590107, \"document.metadata\": {\"id\": \"Y29uY2VwdC1mYWlybmVzcy1tbC5tZDI=\", \"source\": {\"title\": \"Model performance and fairness\", \"filename\": \"concept-fairness-ml.md\", \"url\": \"concept-fairness-ml.md\", \"mtime\": 1710206114.0}, \"stats\": {\"tiktokens\": 97, \"chars\": 430, \"lines\": 3}, \"content_hash\": \"81513a84c2eb0f6235b7846f9612571b7cfbdd32f55af511cc1aad4f3f7111a3\"}}]"},"events":[],"links":[],"resource":{"attributes":{"service.name":"promptflow"},"schema_url":""}}],"correlationid":"16ac851b-cacf-4dff-9186-b3b4375b380d","xrequestid":"16ac851b-cacf-4dff-9186-b3b4375b380d","modelversion":"default","collectdatatype":"pandas.core.frame.DataFrame","agent":"azureml-ai-monitoring/0.1.0b4","contentrange":"bytes 0-7558/7559"}
{"specversion":"1.0","id":"8fbe27cf-3b26-4583-8eac-c14c294463ef","source":"/subscriptions/1aefdc5e-3a7c-4d71-a9f9-f5d3b03be19a/resourceGroups/yuachengtestrg/providers/Microsoft.MachineLearningServices/workspaces/ai-proj-eastus/onlineEndpoints/clone-vivi-log-test/deployments/clone-vivi-log-test-1","type":"azureml.inference.app_traces","datacontenttype":"application/json","time":"2024-04-11T18:09:01Z","data":[{"name":"openai_chat","context":{"trace_id":"0xa2f3f4f8267a482fa3bb96ad3e1f7f35","span_id":"0x6e83fd7654455e34","trace_state":"[]"},"kind":"SpanKind.INTERNAL","parent_id":"0x9842e675f27242d6","start_time":"2024-04-11T18:08:57.757021Z","end_time":"2024-04-11T18:09:00.985182Z","status":{"status_code":"OK"},"attributes":{"framework":"promptflow","span_type":"LLM","function":"openai.resources.chat.completions.Completions.create","node_name":"answer_the_question_with_context","request_id":"de58ac2b-f07e-4e0a-89f1-509849ed2737","line_run_id":"de58ac2b-f07e-4e0a-89f1-509849ed2737","inputs":"{\n  \"model\": \"gpt-4-32k\",\n  \"messages\": [\n    {\n      \"role\": \"system\",\n      \"content\": \"You are an AI assistant that helps users answer questions given a specific context and conversation history. You will be given a context and chat history, and then asked a question based on that context and history. Your answer should be as precise as possible, and should only come from the context.\\nPlease add citation after each sentence when possible in a form \\\"(Source: citation)\\\".\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"Content: # Tutorial: Create resources you need to get started\\n\\n| [Upload, access and explore your data in Azure Machine Learning](tutorial-explore-data.md)     |  Store large data in the cloud and retrieve it from notebooks and scripts |\\n| [Model development on a cloud workstation](tutorial-cloud-workstation.md) | Start prototyping and developing machine learning models |\\n| [Train a model in Azure Machine Learning](tutorial-train-model.md) |    Dive in to the details of training a model     |\\n| [Deploy a model as an online endpoint](tutorial-deploy-model.md)  |   Dive in to the details of deploying a model      |\\n| [Create production machine learning pipelines](tutorial-pipeline-python-sdk.md) | Split a complete machine learning task into a multistep workflow. |\\nSource: quickstart-create-resources.md\\n\\nContent: # Configure a private endpoint for an Azure Machine Learning workspace\\n\\n* When using a workspace with multiple private endpoints, one of the private endpoints must be in the same VNet as the following dependency services:\\n\\n    * Azure Storage Account that provides the default storage for the workspace\\n    * Azure Key Vault for the workspace\\n    * Azure Container Registry for the workspace.\\n\\n    For example, one VNet ('services' VNet) would contain a private endpoint for the dependency services and the workspace. This configuration allows the workspace to communicate with the services. Another VNet ('clients') might only contain a private endpoint for the workspace, and be used only for communication between client development machines and the workspace.\\n\\n## Create a workspace that uses a private endpoint\\n\\nUse one of the following methods to create a workspace with a private endpoint. Each of these methods __requires an existing virtual network__:\\n\\n\u003e [!TIP]\\n\u003e If you'd like to create a workspace, private endpoint, and virtual network at the same time, see [Use an Azure Resource Manager template to create a workspace for Azure Machine Learning](how-to-create-workspace-template.md).\\n\\n# [Azure CLI](#tab\/cli)\\n[!INCLUDE [cli v2](includes\/machine-learning-cli-v2.md)]\\n\\nWhen using the Azure CLI [extension 2.0 CLI for machine learning](how-to-configure-cli.md), a YAML document is used to configure the workspace. The following example demonstrates creating a new workspace using a YAML configuration:\\n\\n\u003e [!TIP]\\n\u003e When using private link, your workspace cannot use Azure Container Registry tasks compute for image building. The `image_build_compute` property in this configuration specifies a CPU compute cluster name to use for Docker image environment building. You can also specify whether the private link workspace should be accessible over the internet using the `public_network_access` property.\\n\u003e\\n\u003e In this example, the compute referenced by `image_build_compute` will need to be created before building images.\\n\\n:::code language=\\\"YAML\\\" source=\\\"~\/azureml-examples-main\/cli\/resources\/workspace\/privatelink.yml\\\":::\\n\\n```azurecli-interactive\\naz ml workspace create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --file privatelink.yml\\n```\\n\\nAfter creating the workspace, use the [Azure networking CLI commands](\/cli\/azure\/network\/private-endpoint#az-network-private-endpoint-create) to create a private link endpoint for the workspace.\\n\\n```azurecli-interactive\\naz network private-endpoint create \\\\\\n    --name \u003cprivate-endpoint-name\u003e \\\\\\n    --vnet-name \u003cvnet-name\u003e \\\\\\n    --subnet \u003csubnet-name\u003e \\\\\\n    --private-connection-resource-id \\\"\/subscriptions\/\u003csubscription\u003e\/resourceGroups\/\u003cresource-group-name\u003e\/providers\/Microsoft.MachineLearningServices\/workspaces\/\u003cworkspace-name\u003e\\\" \\\\\\n    --group-id amlworkspace \\\\\\n    --connection-name workspace -l \u003clocation\u003e\\n```\\n\\nTo create the private DNS zone entries for the workspace, use the following commands:\\n\\n```azurecli-interactive\\n# Add privatelink.api.azureml.ms\\naz network private-dns zone create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --name privatelink.api.azureml.ms\\n\\naz network private-dns link vnet create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --zone-name privatelink.api.azureml.ms \\\\\\n    --name \u003clink-name\u003e \\\\\\n    --virtual-network \u003cvnet-name\u003e \\\\\\n    --registration-enabled false\\n\\naz network private-endpoint dns-zone-group create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --endpoint-name \u003cprivate-endpoint-name\u003e \\\\\\n    --name myzonegroup \\\\\\n    --private-dns-zone privatelink.api.azureml.ms \\\\\\n    --zone-name privatelink.api.azureml.ms\\n\\n# Add privatelink.notebooks.azure.net\\naz network private-dns zone create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --name privatelink.notebooks.azure.net\\n\\naz network private-dns link vnet create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --zone-name privatelink.notebooks.azure.net \\\\\\n    --name \u003clink-name\u003e \\\\\\n    --virtual-network \u003cvnet-name\u003e \\\\\\n    --registration-enabled false\\n\\naz network private-endpoint dns-zone-group add \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\nSource: how-to-configure-private-link.md\\n\\nContent: # Model performance and fairness\\n\\n- Learn how to use the components by checking out Fairlearn's [GitHub repository](https:\/\/github.com\/fairlearn\/fairlearn\/), [user guide](https:\/\/fairlearn.github.io\/main\/user_guide\/index.html), [examples](https:\/\/fairlearn.github.io\/main\/auto_examples\/index.html), and [sample notebooks](https:\/\/github.com\/fairlearn\/fairlearn\/blob\/main\/docs\/contributor_guide\/contributing_example_notebooks.rst).\\nSource: concept-fairness-ml.md \\n\\n chat history:\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"what is aml?\"\n    },\n    {\n      \"role\": \"assistant\",\n      \"content\": \"\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"how to create a spark job?\"\n    },\n    {\n      \"role\": \"assistant\",\n      \"content\": \"\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"thank you\"\n    },\n    {\n      \"role\": \"assistant\",\n      \"content\": \"user: can you share a link to the examle? \\nassistant:\"\n    }\n  ],\n  \"temperature\": 1.0,\n  \"top_p\": 1.0,\n  \"n\": 1,\n  \"stream\": false,\n  \"presence_penalty\": 0.0,\n  \"frequency_penalty\": 0.0,\n  \"user\": \"\"\n}","llm.response.model":"gpt-4-32k","llm.generated_message":"{\n  \"content\": \"I'm sorry for any confusion, but the provided contexts don't include a direct link to an example for creating a spark job.\",\n  \"role\": \"assistant\",\n  \"function_call\": null,\n  \"tool_calls\": null\n}","__computed__.cumulative_token_count.completion":26,"__computed__.cumulative_token_count.prompt":1311,"__computed__.cumulative_token_count.total":1337,"llm.usage.completion_tokens":26,"llm.usage.prompt_tokens":1311,"llm.usage.total_tokens":1337,"output":"{\n  \"id\": \"chatcmpl-9Ct90yfAXVaYpa26p78NS1M0qSnk1\",\n  \"choices\": [\n    {\n      \"finish_reason\": \"stop\",\n      \"index\": 0,\n      \"logprobs\": null,\n      \"message\": {\n        \"content\": \"I'm sorry for any confusion, but the provided contexts don't include a direct link to an example for creating a spark job.\",\n        \"role\": \"assistant\",\n        \"function_call\": null,\n        \"tool_calls\": null\n      },\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ],\n  \"created\": 1712858938,\n  \"model\": \"gpt-4-32k\",\n  \"object\": \"chat.completion\",\n  \"system_fingerprint\": null,\n  \"usage\": {\n    \"completion_tokens\": 26,\n    \"prompt_tokens\": 1311,\n    \"total_tokens\": 1337\n  },\n  \"prompt_filter_results\": [\n    {\n      \"prompt_index\": 0,\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ]\n}"},"events":[{"name":"promptflow.function.inputs","timestamp":"2024-04-11T18:08:57.763986Z","attributes":{"payload":"{\n  \"model\": \"gpt-4-32k\",\n  \"messages\": [\n    {\n      \"role\": \"system\",\n      \"content\": \"You are an AI assistant that helps users answer questions given a specific context and conversation history. You will be given a context and chat history, and then asked a question based on that context and history. Your answer should be as precise as possible, and should only come from the context.\\nPlease add citation after each sentence when possible in a form \\\"(Source: citation)\\\".\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"Content: # Tutorial: Create resources you need to get started\\n\\n| [Upload, access and explore your data in Azure Machine Learning](tutorial-explore-data.md)     |  Store large data in the cloud and retrieve it from notebooks and scripts |\\n| [Model development on a cloud workstation](tutorial-cloud-workstation.md) | Start prototyping and developing machine learning models |\\n| [Train a model in Azure Machine Learning](tutorial-train-model.md) |    Dive in to the details of training a model     |\\n| [Deploy a model as an online endpoint](tutorial-deploy-model.md)  |   Dive in to the details of deploying a model      |\\n| [Create production machine learning pipelines](tutorial-pipeline-python-sdk.md) | Split a complete machine learning task into a multistep workflow. |\\nSource: quickstart-create-resources.md\\n\\nContent: # Configure a private endpoint for an Azure Machine Learning workspace\\n\\n* When using a workspace with multiple private endpoints, one of the private endpoints must be in the same VNet as the following dependency services:\\n\\n    * Azure Storage Account that provides the default storage for the workspace\\n    * Azure Key Vault for the workspace\\n    * Azure Container Registry for the workspace.\\n\\n    For example, one VNet ('services' VNet) would contain a private endpoint for the dependency services and the workspace. This configuration allows the workspace to communicate with the services. Another VNet ('clients') might only contain a private endpoint for the workspace, and be used only for communication between client development machines and the workspace.\\n\\n## Create a workspace that uses a private endpoint\\n\\nUse one of the following methods to create a workspace with a private endpoint. Each of these methods __requires an existing virtual network__:\\n\\n\u003e [!TIP]\\n\u003e If you'd like to create a workspace, private endpoint, and virtual network at the same time, see [Use an Azure Resource Manager template to create a workspace for Azure Machine Learning](how-to-create-workspace-template.md).\\n\\n# [Azure CLI](#tab\/cli)\\n[!INCLUDE [cli v2](includes\/machine-learning-cli-v2.md)]\\n\\nWhen using the Azure CLI [extension 2.0 CLI for machine learning](how-to-configure-cli.md), a YAML document is used to configure the workspace. The following example demonstrates creating a new workspace using a YAML configuration:\\n\\n\u003e [!TIP]\\n\u003e When using private link, your workspace cannot use Azure Container Registry tasks compute for image building. The `image_build_compute` property in this configuration specifies a CPU compute cluster name to use for Docker image environment building. You can also specify whether the private link workspace should be accessible over the internet using the `public_network_access` property.\\n\u003e\\n\u003e In this example, the compute referenced by `image_build_compute` will need to be created before building images.\\n\\n:::code language=\\\"YAML\\\" source=\\\"~\/azureml-examples-main\/cli\/resources\/workspace\/privatelink.yml\\\":::\\n\\n```azurecli-interactive\\naz ml workspace create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --file privatelink.yml\\n```\\n\\nAfter creating the workspace, use the [Azure networking CLI commands](\/cli\/azure\/network\/private-endpoint#az-network-private-endpoint-create) to create a private link endpoint for the workspace.\\n\\n```azurecli-interactive\\naz network private-endpoint create \\\\\\n    --name \u003cprivate-endpoint-name\u003e \\\\\\n    --vnet-name \u003cvnet-name\u003e \\\\\\n    --subnet \u003csubnet-name\u003e \\\\\\n    --private-connection-resource-id \\\"\/subscriptions\/\u003csubscription\u003e\/resourceGroups\/\u003cresource-group-name\u003e\/providers\/Microsoft.MachineLearningServices\/workspaces\/\u003cworkspace-name\u003e\\\" \\\\\\n    --group-id amlworkspace \\\\\\n    --connection-name workspace -l \u003clocation\u003e\\n```\\n\\nTo create the private DNS zone entries for the workspace, use the following commands:\\n\\n```azurecli-interactive\\n# Add privatelink.api.azureml.ms\\naz network private-dns zone create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --name privatelink.api.azureml.ms\\n\\naz network private-dns link vnet create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --zone-name privatelink.api.azureml.ms \\\\\\n    --name \u003clink-name\u003e \\\\\\n    --virtual-network \u003cvnet-name\u003e \\\\\\n    --registration-enabled false\\n\\naz network private-endpoint dns-zone-group create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --endpoint-name \u003cprivate-endpoint-name\u003e \\\\\\n    --name myzonegroup \\\\\\n    --private-dns-zone privatelink.api.azureml.ms \\\\\\n    --zone-name privatelink.api.azureml.ms\\n\\n# Add privatelink.notebooks.azure.net\\naz network private-dns zone create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --name privatelink.notebooks.azure.net\\n\\naz network private-dns link vnet create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --zone-name privatelink.notebooks.azure.net \\\\\\n    --name \u003clink-name\u003e \\\\\\n    --virtual-network \u003cvnet-name\u003e \\\\\\n    --registration-enabled false\\n\\naz network private-endpoint dns-zone-group add \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\nSource: how-to-configure-private-link.md\\n\\nContent: # Model performance and fairness\\n\\n- Learn how to use the components by checking out Fairlearn's [GitHub repository](https:\/\/github.com\/fairlearn\/fairlearn\/), [user guide](https:\/\/fairlearn.github.io\/main\/user_guide\/index.html), [examples](https:\/\/fairlearn.github.io\/main\/auto_examples\/index.html), and [sample notebooks](https:\/\/github.com\/fairlearn\/fairlearn\/blob\/main\/docs\/contributor_guide\/contributing_example_notebooks.rst).\\nSource: concept-fairness-ml.md \\n\\n chat history:\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"what is aml?\"\n    },\n    {\n      \"role\": \"assistant\",\n      \"content\": \"\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"how to create a spark job?\"\n    },\n    {\n      \"role\": \"assistant\",\n      \"content\": \"\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"thank you\"\n    },\n    {\n      \"role\": \"assistant\",\n      \"content\": \"user: can you share a link to the examle? \\nassistant:\"\n    }\n  ],\n  \"temperature\": 1.0,\n  \"top_p\": 1.0,\n  \"n\": 1,\n  \"stream\": false,\n  \"presence_penalty\": 0.0,\n  \"frequency_penalty\": 0.0,\n  \"user\": \"\"\n}"}},{"name":"promptflow.llm.generated_message","timestamp":"2024-04-11T18:09:00.981558Z","attributes":{"payload":"{\n  \"content\": \"I'm sorry for any confusion, but the provided contexts don't include a direct link to an example for creating a spark job.\",\n  \"role\": \"assistant\",\n  \"function_call\": null,\n  \"tool_calls\": null\n}"}},{"name":"promptflow.function.output","timestamp":"2024-04-11T18:09:00.984683Z","attributes":{"payload":"{\n  \"id\": \"chatcmpl-9Ct90yfAXVaYpa26p78NS1M0qSnk1\",\n  \"choices\": [\n    {\n      \"finish_reason\": \"stop\",\n      \"index\": 0,\n      \"logprobs\": null,\n      \"message\": {\n        \"content\": \"I'm sorry for any confusion, but the provided contexts don't include a direct link to an example for creating a spark job.\",\n        \"role\": \"assistant\",\n        \"function_call\": null,\n        \"tool_calls\": null\n      },\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ],\n  \"created\": 1712858938,\n  \"model\": \"gpt-4-32k\",\n  \"object\": \"chat.completion\",\n  \"system_fingerprint\": null,\n  \"usage\": {\n    \"completion_tokens\": 26,\n    \"prompt_tokens\": 1311,\n    \"total_tokens\": 1337\n  },\n  \"prompt_filter_results\": [\n    {\n      \"prompt_index\": 0,\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ]\n}"}}],"links":[],"resource":{"attributes":{"service.name":"promptflow"},"schema_url":""}}],"contentrange":"bytes 0-19120/19121","correlationid":"6b4dabf0-4449-4a7b-ae60-217652129db8","xrequestid":"6b4dabf0-4449-4a7b-ae60-217652129db8","modelversion":"default","collectdatatype":"pandas.core.frame.DataFrame","agent":"azureml-ai-monitoring/0.1.0b4"}
{"specversion":"1.0","id":"3a0f0417-5969-42e1-8c5b-e1762d848bb1","source":"/subscriptions/1aefdc5e-3a7c-4d71-a9f9-f5d3b03be19a/resourceGroups/yuachengtestrg/providers/Microsoft.MachineLearningServices/workspaces/ai-proj-eastus/onlineEndpoints/clone-vivi-log-test/deployments/clone-vivi-log-test-1","type":"azureml.inference.app_traces","datacontenttype":"application/json","time":"2024-04-11T18:09:01Z","data":[{"name":"lookup","context":{"trace_id":"0xa2f3f4f8267a482fa3bb96ad3e1f7f35","span_id":"0x962ff815307a1061","trace_state":"[]"},"kind":"SpanKind.INTERNAL","parent_id":"0x38853fe3b7d18b15","start_time":"2024-04-11T18:08:56.187991Z","end_time":"2024-04-11T18:08:57.649184Z","status":{"status_code":"OK"},"attributes":{"framework":"promptflow","span_type":"Function","function":"search","node_name":"lookup","request_id":"de58ac2b-f07e-4e0a-89f1-509849ed2737","line_run_id":"de58ac2b-f07e-4e0a-89f1-509849ed2737","inputs":"{\n  \"mlindex_content\": \"embeddings:\\n  api_base: https:\/\/azureml-rag-auseast.openai.azure.com\/\\n  api_type: Azure\\n  api_version: 2023-07-01-preview\\n  batch_size: '16'\\n  connection:\\n    id: \\n      \/subscriptions\/1aefdc5e-3a7c-4d71-a9f9-f5d3b03be19a\/resourceGroups\/yuachengtestrg\/providers\/Microsoft.MachineLearningServices\/workspaces\/ai-proj-eastus\/connections\/Default_AzureOpenAI\\n  connection_type: workspace_connection\\n  deployment: text-embedding-ada-002\\n  dimension: 1536\\n  file_format_version: '2'\\n  kind: open_ai\\n  model: text-embedding-ada-002\\n  schema_version: '2'\\nindex:\\n  api_version: 2023-07-01-preview\\n  connection:\\n    id: \\n      \/subscriptions\/1aefdc5e-3a7c-4d71-a9f9-f5d3b03be19a\/resourceGroups\/yuachengtestrg\/providers\/Microsoft.MachineLearningServices\/workspaces\/ai-proj-eastus\/connections\/AzureAISearch\\n  connection_type: workspace_connection\\n  endpoint: https:\/\/yuacheng-aisearch-eastus.search.windows.net\\n  engine: azure-sdk\\n  field_mapping:\\n    content: content\\n    embedding: contentVector\\n    filename: filepath\\n    metadata: meta_json_string\\n    title: title\\n    url: url\\n  index: aml-rag-doc\\n  kind: acs\\n  semantic_configuration_name: azureml-default\\nself:\\n  path: \\n    azureml:\/\/subscriptions\/1aefdc5e-3a7c-4d71-a9f9-f5d3b03be19a\/resourcegroups\/yuachengtestrg\/workspaces\/ai-proj-eastus\/datastores\/workspaceblobstore\/paths\/azureml\/c258bd68-edde-4fbb-8333-d53f35698512\/index\/\\n  asset_id: \\n    azureml:\/\/locations\/eastus\/workspaces\/38bb01fe-e2e1-4e40-9af9-a9ff97fdcd6d\/data\/aml-rag-doc\/versions\/1\\n\",\n  \"queries\": \"Could you provide a link to an example?\",\n  \"query_type\": \"Hybrid (vector + keyword)\",\n  \"top_k\": 3\n}","output":"[\n  {\n    \"text\": \"# Tutorial: Create resources you need to get started\\n\\n| [Upload, access and explore your data in Azure Machine Learning](tutorial-explore-data.md)     |  Store large data in the cloud and retrieve it from notebooks and scripts |\\n| [Model development on a cloud workstation](tutorial-cloud-workstation.md) | Start prototyping and developing machine learning models |\\n| [Train a model in Azure Machine Learning](tutorial-train-model.md) |    Dive in to the details of training a model     |\\n| [Deploy a model as an online endpoint](tutorial-deploy-model.md)  |   Dive in to the details of deploying a model      |\\n| [Create production machine learning pipelines](tutorial-pipeline-python-sdk.md) | Split a complete machine learning task into a multistep workflow. |\",\n    \"metadata\": {\n      \"id\": \"cXVpY2tzdGFydC1jcmVhdGUtcmVzb3VyY2VzLm1kMg==\",\n      \"source\": {\n        \"title\": \"Tutorial: Create resources you need to get started\",\n        \"filename\": \"quickstart-create-resources.md\",\n        \"url\": \"quickstart-create-resources.md\",\n        \"mtime\": 1710206171.0\n      },\n      \"stats\": {\n        \"tiktokens\": 162,\n        \"chars\": 763,\n        \"lines\": 7\n      },\n      \"content_hash\": \"120bcf54a5162e37efb991db28b8fbdfa4718a161cb35be2d4baa921fefbf7eb\"\n    },\n    \"score\": 0.02364782989025116\n  },\n  {\n    \"text\": \"# Configure a private endpoint for an Azure Machine Learning workspace\\n\\n* When using a workspace with multiple private endpoints, one of the private endpoints must be in the same VNet as the following dependency services:\\n\\n    * Azure Storage Account that provides the default storage for the workspace\\n    * Azure Key Vault for the workspace\\n    * Azure Container Registry for the workspace.\\n\\n    For example, one VNet ('services' VNet) would contain a private endpoint for the dependency services and the workspace. This configuration allows the workspace to communicate with the services. Another VNet ('clients') might only contain a private endpoint for the workspace, and be used only for communication between client development machines and the workspace.\\n\\n## Create a workspace that uses a private endpoint\\n\\nUse one of the following methods to create a workspace with a private endpoint. Each of these methods __requires an existing virtual network__:\\n\\n\u003e [!TIP]\\n\u003e If you'd like to create a workspace, private endpoint, and virtual network at the same time, see [Use an Azure Resource Manager template to create a workspace for Azure Machine Learning](how-to-create-workspace-template.md).\\n\\n# [Azure CLI](#tab\/cli)\\n[!INCLUDE [cli v2](includes\/machine-learning-cli-v2.md)]\\n\\nWhen using the Azure CLI [extension 2.0 CLI for machine learning](how-to-configure-cli.md), a YAML document is used to configure the workspace. The following example demonstrates creating a new workspace using a YAML configuration:\\n\\n\u003e [!TIP]\\n\u003e When using private link, your workspace cannot use Azure Container Registry tasks compute for image building. The `image_build_compute` property in this configuration specifies a CPU compute cluster name to use for Docker image environment building. You can also specify whether the private link workspace should be accessible over the internet using the `public_network_access` property.\\n\u003e\\n\u003e In this example, the compute referenced by `image_build_compute` will need to be created before building images.\\n\\n:::code language=\\\"YAML\\\" source=\\\"~\/azureml-examples-main\/cli\/resources\/workspace\/privatelink.yml\\\":::\\n\\n```azurecli-interactive\\naz ml workspace create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --file privatelink.yml\\n```\\n\\nAfter creating the workspace, use the [Azure networking CLI commands](\/cli\/azure\/network\/private-endpoint#az-network-private-endpoint-create) to create a private link endpoint for the workspace.\\n\\n```azurecli-interactive\\naz network private-endpoint create \\\\\\n    --name \u003cprivate-endpoint-name\u003e \\\\\\n    --vnet-name \u003cvnet-name\u003e \\\\\\n    --subnet \u003csubnet-name\u003e \\\\\\n    --private-connection-resource-id \\\"\/subscriptions\/\u003csubscription\u003e\/resourceGroups\/\u003cresource-group-name\u003e\/providers\/Microsoft.MachineLearningServices\/workspaces\/\u003cworkspace-name\u003e\\\" \\\\\\n    --group-id amlworkspace \\\\\\n    --connection-name workspace -l \u003clocation\u003e\\n```\\n\\nTo create the private DNS zone entries for the workspace, use the following commands:\\n\\n```azurecli-interactive\\n# Add privatelink.api.azureml.ms\\naz network private-dns zone create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --name privatelink.api.azureml.ms\\n\\naz network private-dns link vnet create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --zone-name privatelink.api.azureml.ms \\\\\\n    --name \u003clink-name\u003e \\\\\\n    --virtual-network \u003cvnet-name\u003e \\\\\\n    --registration-enabled false\\n\\naz network private-endpoint dns-zone-group create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --endpoint-name \u003cprivate-endpoint-name\u003e \\\\\\n    --name myzonegroup \\\\\\n    --private-dns-zone privatelink.api.azureml.ms \\\\\\n    --zone-name privatelink.api.azureml.ms\\n\\n# Add privatelink.notebooks.azure.net\\naz network private-dns zone create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --name privatelink.notebooks.azure.net\\n\\naz network private-dns link vnet create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --zone-name privatelink.notebooks.azure.net \\\\\\n    --name \u003clink-name\u003e \\\\\\n    --virtual-network \u003cvnet-name\u003e \\\\\\n    --registration-enabled false\\n\\naz network private-endpoint dns-zone-group add \\\\\\n    -g \u003cresource-group-name\u003e \\\\\",\n    \"metadata\": {\n      \"id\": \"aG93LXRvLWNvbmZpZ3VyZS1wcml2YXRlLWxpbmsubWQx\",\n      \"source\": {\n        \"title\": \"Configure a private endpoint for an Azure Machine Learning workspace\",\n        \"filename\": \"how-to-configure-private-link.md\",\n        \"url\": \"how-to-configure-private-link.md\",\n        \"mtime\": 1710206126.0\n      },\n      \"stats\": {\n        \"tiktokens\": 878,\n        \"chars\": 4020,\n        \"lines\": 83\n      },\n      \"content_hash\": \"6defa15776349ba683025232d021517cd3cb8325d3ec94681700ec7bab908ce2\"\n    },\n    \"score\": 0.01666666753590107\n  },\n  {\n    \"text\": \"# Model performance and fairness\\n\\n- Learn how to use the components by checking out Fairlearn's [GitHub repository](https:\/\/github.com\/fairlearn\/fairlearn\/), [user guide](https:\/\/fairlearn.github.io\/main\/user_guide\/index.html), [examples](https:\/\/fairlearn.github.io\/main\/auto_examples\/index.html), and [sample notebooks](https:\/\/github.com\/fairlearn\/fairlearn\/blob\/main\/docs\/contributor_guide\/contributing_example_notebooks.rst).\",\n    \"metadata\": {\n      \"id\": \"Y29uY2VwdC1mYWlybmVzcy1tbC5tZDI=\",\n      \"source\": {\n        \"title\": \"Model performance and fairness\",\n        \"filename\": \"concept-fairness-ml.md\",\n        \"url\": \"concept-fairness-ml.md\",\n        \"mtime\": 1710206114.0\n      },\n      \"stats\": {\n        \"tiktokens\": 97,\n        \"chars\": 430,\n        \"lines\": 3\n      },\n      \"content_hash\": \"81513a84c2eb0f6235b7846f9612571b7cfbdd32f55af511cc1aad4f3f7111a3\"\n    },\n    \"score\": 0.01666666753590107\n  }\n]"},"events":[{"name":"promptflow.function.inputs","timestamp":"2024-04-11T18:08:56.188685Z","attributes":{"payload":"{\n  \"mlindex_content\": \"embeddings:\\n  api_base: https:\/\/azureml-rag-auseast.openai.azure.com\/\\n  api_type: Azure\\n  api_version: 2023-07-01-preview\\n  batch_size: '16'\\n  connection:\\n    id: \\n      \/subscriptions\/1aefdc5e-3a7c-4d71-a9f9-f5d3b03be19a\/resourceGroups\/yuachengtestrg\/providers\/Microsoft.MachineLearningServices\/workspaces\/ai-proj-eastus\/connections\/Default_AzureOpenAI\\n  connection_type: workspace_connection\\n  deployment: text-embedding-ada-002\\n  dimension: 1536\\n  file_format_version: '2'\\n  kind: open_ai\\n  model: text-embedding-ada-002\\n  schema_version: '2'\\nindex:\\n  api_version: 2023-07-01-preview\\n  connection:\\n    id: \\n      \/subscriptions\/1aefdc5e-3a7c-4d71-a9f9-f5d3b03be19a\/resourceGroups\/yuachengtestrg\/providers\/Microsoft.MachineLearningServices\/workspaces\/ai-proj-eastus\/connections\/AzureAISearch\\n  connection_type: workspace_connection\\n  endpoint: https:\/\/yuacheng-aisearch-eastus.search.windows.net\\n  engine: azure-sdk\\n  field_mapping:\\n    content: content\\n    embedding: contentVector\\n    filename: filepath\\n    metadata: meta_json_string\\n    title: title\\n    url: url\\n  index: aml-rag-doc\\n  kind: acs\\n  semantic_configuration_name: azureml-default\\nself:\\n  path: \\n    azureml:\/\/subscriptions\/1aefdc5e-3a7c-4d71-a9f9-f5d3b03be19a\/resourcegroups\/yuachengtestrg\/workspaces\/ai-proj-eastus\/datastores\/workspaceblobstore\/paths\/azureml\/c258bd68-edde-4fbb-8333-d53f35698512\/index\/\\n  asset_id: \\n    azureml:\/\/locations\/eastus\/workspaces\/38bb01fe-e2e1-4e40-9af9-a9ff97fdcd6d\/data\/aml-rag-doc\/versions\/1\\n\",\n  \"queries\": \"Could you provide a link to an example?\",\n  \"query_type\": \"Hybrid (vector + keyword)\",\n  \"top_k\": 3\n}"}},{"name":"promptflow.function.output","timestamp":"2024-04-11T18:08:57.647926Z","attributes":{"payload":"[\n  {\n    \"text\": \"# Tutorial: Create resources you need to get started\\n\\n| [Upload, access and explore your data in Azure Machine Learning](tutorial-explore-data.md)     |  Store large data in the cloud and retrieve it from notebooks and scripts |\\n| [Model development on a cloud workstation](tutorial-cloud-workstation.md) | Start prototyping and developing machine learning models |\\n| [Train a model in Azure Machine Learning](tutorial-train-model.md) |    Dive in to the details of training a model     |\\n| [Deploy a model as an online endpoint](tutorial-deploy-model.md)  |   Dive in to the details of deploying a model      |\\n| [Create production machine learning pipelines](tutorial-pipeline-python-sdk.md) | Split a complete machine learning task into a multistep workflow. |\",\n    \"metadata\": {\n      \"id\": \"cXVpY2tzdGFydC1jcmVhdGUtcmVzb3VyY2VzLm1kMg==\",\n      \"source\": {\n        \"title\": \"Tutorial: Create resources you need to get started\",\n        \"filename\": \"quickstart-create-resources.md\",\n        \"url\": \"quickstart-create-resources.md\",\n        \"mtime\": 1710206171.0\n      },\n      \"stats\": {\n        \"tiktokens\": 162,\n        \"chars\": 763,\n        \"lines\": 7\n      },\n      \"content_hash\": \"120bcf54a5162e37efb991db28b8fbdfa4718a161cb35be2d4baa921fefbf7eb\"\n    },\n    \"score\": 0.02364782989025116\n  },\n  {\n    \"text\": \"# Configure a private endpoint for an Azure Machine Learning workspace\\n\\n* When using a workspace with multiple private endpoints, one of the private endpoints must be in the same VNet as the following dependency services:\\n\\n    * Azure Storage Account that provides the default storage for the workspace\\n    * Azure Key Vault for the workspace\\n    * Azure Container Registry for the workspace.\\n\\n    For example, one VNet ('services' VNet) would contain a private endpoint for the dependency services and the workspace. This configuration allows the workspace to communicate with the services. Another VNet ('clients') might only contain a private endpoint for the workspace, and be used only for communication between client development machines and the workspace.\\n\\n## Create a workspace that uses a private endpoint\\n\\nUse one of the following methods to create a workspace with a private endpoint. Each of these methods __requires an existing virtual network__:\\n\\n\u003e [!TIP]\\n\u003e If you'd like to create a workspace, private endpoint, and virtual network at the same time, see [Use an Azure Resource Manager template to create a workspace for Azure Machine Learning](how-to-create-workspace-template.md).\\n\\n# [Azure CLI](#tab\/cli)\\n[!INCLUDE [cli v2](includes\/machine-learning-cli-v2.md)]\\n\\nWhen using the Azure CLI [extension 2.0 CLI for machine learning](how-to-configure-cli.md), a YAML document is used to configure the workspace. The following example demonstrates creating a new workspace using a YAML configuration:\\n\\n\u003e [!TIP]\\n\u003e When using private link, your workspace cannot use Azure Container Registry tasks compute for image building. The `image_build_compute` property in this configuration specifies a CPU compute cluster name to use for Docker image environment building. You can also specify whether the private link workspace should be accessible over the internet using the `public_network_access` property.\\n\u003e\\n\u003e In this example, the compute referenced by `image_build_compute` will need to be created before building images.\\n\\n:::code language=\\\"YAML\\\" source=\\\"~\/azureml-examples-main\/cli\/resources\/workspace\/privatelink.yml\\\":::\\n\\n```azurecli-interactive\\naz ml workspace create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --file privatelink.yml\\n```\\n\\nAfter creating the workspace, use the [Azure networking CLI commands](\/cli\/azure\/network\/private-endpoint#az-network-private-endpoint-create) to create a private link endpoint for the workspace.\\n\\n```azurecli-interactive\\naz network private-endpoint create \\\\\\n    --name \u003cprivate-endpoint-name\u003e \\\\\\n    --vnet-name \u003cvnet-name\u003e \\\\\\n    --subnet \u003csubnet-name\u003e \\\\\\n    --private-connection-resource-id \\\"\/subscriptions\/\u003csubscription\u003e\/resourceGroups\/\u003cresource-group-name\u003e\/providers\/Microsoft.MachineLearningServices\/workspaces\/\u003cworkspace-name\u003e\\\" \\\\\\n    --group-id amlworkspace \\\\\\n    --connection-name workspace -l \u003clocation\u003e\\n```\\n\\nTo create the private DNS zone entries for the workspace, use the following commands:\\n\\n```azurecli-interactive\\n# Add privatelink.api.azureml.ms\\naz network private-dns zone create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --name privatelink.api.azureml.ms\\n\\naz network private-dns link vnet create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --zone-name privatelink.api.azureml.ms \\\\\\n    --name \u003clink-name\u003e \\\\\\n    --virtual-network \u003cvnet-name\u003e \\\\\\n    --registration-enabled false\\n\\naz network private-endpoint dns-zone-group create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --endpoint-name \u003cprivate-endpoint-name\u003e \\\\\\n    --name myzonegroup \\\\\\n    --private-dns-zone privatelink.api.azureml.ms \\\\\\n    --zone-name privatelink.api.azureml.ms\\n\\n# Add privatelink.notebooks.azure.net\\naz network private-dns zone create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --name privatelink.notebooks.azure.net\\n\\naz network private-dns link vnet create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --zone-name privatelink.notebooks.azure.net \\\\\\n    --name \u003clink-name\u003e \\\\\\n    --virtual-network \u003cvnet-name\u003e \\\\\\n    --registration-enabled false\\n\\naz network private-endpoint dns-zone-group add \\\\\\n    -g \u003cresource-group-name\u003e \\\\\",\n    \"metadata\": {\n      \"id\": \"aG93LXRvLWNvbmZpZ3VyZS1wcml2YXRlLWxpbmsubWQx\",\n      \"source\": {\n        \"title\": \"Configure a private endpoint for an Azure Machine Learning workspace\",\n        \"filename\": \"how-to-configure-private-link.md\",\n        \"url\": \"how-to-configure-private-link.md\",\n        \"mtime\": 1710206126.0\n      },\n      \"stats\": {\n        \"tiktokens\": 878,\n        \"chars\": 4020,\n        \"lines\": 83\n      },\n      \"content_hash\": \"6defa15776349ba683025232d021517cd3cb8325d3ec94681700ec7bab908ce2\"\n    },\n    \"score\": 0.01666666753590107\n  },\n  {\n    \"text\": \"# Model performance and fairness\\n\\n- Learn how to use the components by checking out Fairlearn's [GitHub repository](https:\/\/github.com\/fairlearn\/fairlearn\/), [user guide](https:\/\/fairlearn.github.io\/main\/user_guide\/index.html), [examples](https:\/\/fairlearn.github.io\/main\/auto_examples\/index.html), and [sample notebooks](https:\/\/github.com\/fairlearn\/fairlearn\/blob\/main\/docs\/contributor_guide\/contributing_example_notebooks.rst).\",\n    \"metadata\": {\n      \"id\": \"Y29uY2VwdC1mYWlybmVzcy1tbC5tZDI=\",\n      \"source\": {\n        \"title\": \"Model performance and fairness\",\n        \"filename\": \"concept-fairness-ml.md\",\n        \"url\": \"concept-fairness-ml.md\",\n        \"mtime\": 1710206114.0\n      },\n      \"stats\": {\n        \"tiktokens\": 97,\n        \"chars\": 430,\n        \"lines\": 3\n      },\n      \"content_hash\": \"81513a84c2eb0f6235b7846f9612571b7cfbdd32f55af511cc1aad4f3f7111a3\"\n    },\n    \"score\": 0.01666666753590107\n  }\n]"}}],"links":[],"resource":{"attributes":{"service.name":"promptflow"},"schema_url":""}}],"contentrange":"bytes 0-19129/19130","correlationid":"5ba4b873-5901-45e2-988d-a4fcb5fc0fdb","xrequestid":"5ba4b873-5901-45e2-988d-a4fcb5fc0fdb","modelversion":"default","collectdatatype":"pandas.core.frame.DataFrame","agent":"azureml-ai-monitoring/0.1.0b4"}
{"specversion":"1.0","id":"d1b2d541-0e17-4e58-a160-44e3ff7f37c9","source":"/subscriptions/1aefdc5e-3a7c-4d71-a9f9-f5d3b03be19a/resourceGroups/yuachengtestrg/providers/Microsoft.MachineLearningServices/workspaces/ai-proj-eastus/onlineEndpoints/clone-vivi-log-test/deployments/clone-vivi-log-test-1","type":"azureml.inference.app_traces","datacontenttype":"application/json","time":"2024-04-11T18:09:01Z","data":[{"name":"answer_the_question_with_context","context":{"trace_id":"0xa2f3f4f8267a482fa3bb96ad3e1f7f35","span_id":"0x9842e675f27242d6","trace_state":"[]"},"kind":"SpanKind.INTERNAL","parent_id":"0x38853fe3b7d18b15","start_time":"2024-04-11T18:08:57.750327Z","end_time":"2024-04-11T18:09:00.985614Z","status":{"status_code":"OK"},"attributes":{"framework":"promptflow","span_type":"Function","function":"AzureOpenAI.chat","node_name":"answer_the_question_with_context","request_id":"de58ac2b-f07e-4e0a-89f1-509849ed2737","line_run_id":"de58ac2b-f07e-4e0a-89f1-509849ed2737","prompt.template":"{{prompt_text}}","prompt.variables":"{\n  \"prompt_text\": \"system: \\nYou are an AI assistant that helps users answer questions given a specific context and conversation history. You will be given a context and chat history, and then asked a question based on that context and history. Your answer should be as precise as possible, and should only come from the context.\\nPlease add citation after each sentence when possible in a form \\\"(Source: citation)\\\".\\n\\n user: \\n Content: # Tutorial: Create resources you need to get started\\n\\n| [Upload, access and explore your data in Azure Machine Learning](tutorial-explore-data.md)     |  Store large data in the cloud and retrieve it from notebooks and scripts |\\n| [Model development on a cloud workstation](tutorial-cloud-workstation.md) | Start prototyping and developing machine learning models |\\n| [Train a model in Azure Machine Learning](tutorial-train-model.md) |    Dive in to the details of training a model     |\\n| [Deploy a model as an online endpoint](tutorial-deploy-model.md)  |   Dive in to the details of deploying a model      |\\n| [Create production machine learning pipelines](tutorial-pipeline-python-sdk.md) | Split a complete machine learning task into a multistep workflow. |\\nSource: quickstart-create-resources.md\\n\\nContent: # Configure a private endpoint for an Azure Machine Learning workspace\\n\\n* When using a workspace with multiple private endpoints, one of the private endpoints must be in the same VNet as the following dependency services:\\n\\n    * Azure Storage Account that provides the default storage for the workspace\\n    * Azure Key Vault for the workspace\\n    * Azure Container Registry for the workspace.\\n\\n    For example, one VNet ('services' VNet) would contain a private endpoint for the dependency services and the workspace. This configuration allows the workspace to communicate with the services. Another VNet ('clients') might only contain a private endpoint for the workspace, and be used only for communication between client development machines and the workspace.\\n\\n## Create a workspace that uses a private endpoint\\n\\nUse one of the following methods to create a workspace with a private endpoint. Each of these methods __requires an existing virtual network__:\\n\\n\u003e [!TIP]\\n\u003e If you'd like to create a workspace, private endpoint, and virtual network at the same time, see [Use an Azure Resource Manager template to create a workspace for Azure Machine Learning](how-to-create-workspace-template.md).\\n\\n# [Azure CLI](#tab\/cli)\\n[!INCLUDE [cli v2](includes\/machine-learning-cli-v2.md)]\\n\\nWhen using the Azure CLI [extension 2.0 CLI for machine learning](how-to-configure-cli.md), a YAML document is used to configure the workspace. The following example demonstrates creating a new workspace using a YAML configuration:\\n\\n\u003e [!TIP]\\n\u003e When using private link, your workspace cannot use Azure Container Registry tasks compute for image building. The `image_build_compute` property in this configuration specifies a CPU compute cluster name to use for Docker image environment building. You can also specify whether the private link workspace should be accessible over the internet using the `public_network_access` property.\\n\u003e\\n\u003e In this example, the compute referenced by `image_build_compute` will need to be created before building images.\\n\\n:::code language=\\\"YAML\\\" source=\\\"~\/azureml-examples-main\/cli\/resources\/workspace\/privatelink.yml\\\":::\\n\\n```azurecli-interactive\\naz ml workspace create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --file privatelink.yml\\n```\\n\\nAfter creating the workspace, use the [Azure networking CLI commands](\/cli\/azure\/network\/private-endpoint#az-network-private-endpoint-create) to create a private link endpoint for the workspace.\\n\\n```azurecli-interactive\\naz network private-endpoint create \\\\\\n    --name \u003cprivate-endpoint-name\u003e \\\\\\n    --vnet-name \u003cvnet-name\u003e \\\\\\n    --subnet \u003csubnet-name\u003e \\\\\\n    --private-connection-resource-id \\\"\/subscriptions\/\u003csubscription\u003e\/resourceGroups\/\u003cresource-group-name\u003e\/providers\/Microsoft.MachineLearningServices\/workspaces\/\u003cworkspace-name\u003e\\\" \\\\\\n    --group-id amlworkspace \\\\\\n    --connection-name workspace -l \u003clocation\u003e\\n```\\n\\nTo create the private DNS zone entries for the workspace, use the following commands:\\n\\n```azurecli-interactive\\n# Add privatelink.api.azureml.ms\\naz network private-dns zone create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --name privatelink.api.azureml.ms\\n\\naz network private-dns link vnet create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --zone-name privatelink.api.azureml.ms \\\\\\n    --name \u003clink-name\u003e \\\\\\n    --virtual-network \u003cvnet-name\u003e \\\\\\n    --registration-enabled false\\n\\naz network private-endpoint dns-zone-group create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --endpoint-name \u003cprivate-endpoint-name\u003e \\\\\\n    --name myzonegroup \\\\\\n    --private-dns-zone privatelink.api.azureml.ms \\\\\\n    --zone-name privatelink.api.azureml.ms\\n\\n# Add privatelink.notebooks.azure.net\\naz network private-dns zone create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --name privatelink.notebooks.azure.net\\n\\naz network private-dns link vnet create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --zone-name privatelink.notebooks.azure.net \\\\\\n    --name \u003clink-name\u003e \\\\\\n    --virtual-network \u003cvnet-name\u003e \\\\\\n    --registration-enabled false\\n\\naz network private-endpoint dns-zone-group add \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\nSource: how-to-configure-private-link.md\\n\\nContent: # Model performance and fairness\\n\\n- Learn how to use the components by checking out Fairlearn's [GitHub repository](https:\/\/github.com\/fairlearn\/fairlearn\/), [user guide](https:\/\/fairlearn.github.io\/main\/user_guide\/index.html), [examples](https:\/\/fairlearn.github.io\/main\/auto_examples\/index.html), and [sample notebooks](https:\/\/github.com\/fairlearn\/fairlearn\/blob\/main\/docs\/contributor_guide\/contributing_example_notebooks.rst).\\nSource: concept-fairness-ml.md \\n\\n chat history: \\n user: \\nwhat is aml? \\nassistant: \\n \\n user: \\nhow to create a spark job? \\nassistant: \\n \\n user: \\nthank you \\nassistant: \\n \\nuser: can you share a link to the examle? \\nassistant:\"\n}","inputs":"{\n  \"prompt\": \"{{prompt_text}}\",\n  \"deployment_name\": \"gpt-4-32k\",\n  \"temperature\": 1.0,\n  \"top_p\": 1.0,\n  \"presence_penalty\": 0.0,\n  \"frequency_penalty\": 0.0,\n  \"prompt_text\": \"system: \\nYou are an AI assistant that helps users answer questions given a specific context and conversation history. You will be given a context and chat history, and then asked a question based on that context and history. Your answer should be as precise as possible, and should only come from the context.\\nPlease add citation after each sentence when possible in a form \\\"(Source: citation)\\\".\\n\\n user: \\n Content: # Tutorial: Create resources you need to get started\\n\\n| [Upload, access and explore your data in Azure Machine Learning](tutorial-explore-data.md)     |  Store large data in the cloud and retrieve it from notebooks and scripts |\\n| [Model development on a cloud workstation](tutorial-cloud-workstation.md) | Start prototyping and developing machine learning models |\\n| [Train a model in Azure Machine Learning](tutorial-train-model.md) |    Dive in to the details of training a model     |\\n| [Deploy a model as an online endpoint](tutorial-deploy-model.md)  |   Dive in to the details of deploying a model      |\\n| [Create production machine learning pipelines](tutorial-pipeline-python-sdk.md) | Split a complete machine learning task into a multistep workflow. |\\nSource: quickstart-create-resources.md\\n\\nContent: # Configure a private endpoint for an Azure Machine Learning workspace\\n\\n* When using a workspace with multiple private endpoints, one of the private endpoints must be in the same VNet as the following dependency services:\\n\\n    * Azure Storage Account that provides the default storage for the workspace\\n    * Azure Key Vault for the workspace\\n    * Azure Container Registry for the workspace.\\n\\n    For example, one VNet ('services' VNet) would contain a private endpoint for the dependency services and the workspace. This configuration allows the workspace to communicate with the services. Another VNet ('clients') might only contain a private endpoint for the workspace, and be used only for communication between client development machines and the workspace.\\n\\n## Create a workspace that uses a private endpoint\\n\\nUse one of the following methods to create a workspace with a private endpoint. Each of these methods __requires an existing virtual network__:\\n\\n\u003e [!TIP]\\n\u003e If you'd like to create a workspace, private endpoint, and virtual network at the same time, see [Use an Azure Resource Manager template to create a workspace for Azure Machine Learning](how-to-create-workspace-template.md).\\n\\n# [Azure CLI](#tab\/cli)\\n[!INCLUDE [cli v2](includes\/machine-learning-cli-v2.md)]\\n\\nWhen using the Azure CLI [extension 2.0 CLI for machine learning](how-to-configure-cli.md), a YAML document is used to configure the workspace. The following example demonstrates creating a new workspace using a YAML configuration:\\n\\n\u003e [!TIP]\\n\u003e When using private link, your workspace cannot use Azure Container Registry tasks compute for image building. The `image_build_compute` property in this configuration specifies a CPU compute cluster name to use for Docker image environment building. You can also specify whether the private link workspace should be accessible over the internet using the `public_network_access` property.\\n\u003e\\n\u003e In this example, the compute referenced by `image_build_compute` will need to be created before building images.\\n\\n:::code language=\\\"YAML\\\" source=\\\"~\/azureml-examples-main\/cli\/resources\/workspace\/privatelink.yml\\\":::\\n\\n```azurecli-interactive\\naz ml workspace create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --file privatelink.yml\\n```\\n\\nAfter creating the workspace, use the [Azure networking CLI commands](\/cli\/azure\/network\/private-endpoint#az-network-private-endpoint-create) to create a private link endpoint for the workspace.\\n\\n```azurecli-interactive\\naz network private-endpoint create \\\\\\n    --name \u003cprivate-endpoint-name\u003e \\\\\\n    --vnet-name \u003cvnet-name\u003e \\\\\\n    --subnet \u003csubnet-name\u003e \\\\\\n    --private-connection-resource-id \\\"\/subscriptions\/\u003csubscription\u003e\/resourceGroups\/\u003cresource-group-name\u003e\/providers\/Microsoft.MachineLearningServices\/workspaces\/\u003cworkspace-name\u003e\\\" \\\\\\n    --group-id amlworkspace \\\\\\n    --connection-name workspace -l \u003clocation\u003e\\n```\\n\\nTo create the private DNS zone entries for the workspace, use the following commands:\\n\\n```azurecli-interactive\\n# Add privatelink.api.azureml.ms\\naz network private-dns zone create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --name privatelink.api.azureml.ms\\n\\naz network private-dns link vnet create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --zone-name privatelink.api.azureml.ms \\\\\\n    --name \u003clink-name\u003e \\\\\\n    --virtual-network \u003cvnet-name\u003e \\\\\\n    --registration-enabled false\\n\\naz network private-endpoint dns-zone-group create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --endpoint-name \u003cprivate-endpoint-name\u003e \\\\\\n    --name myzonegroup \\\\\\n    --private-dns-zone privatelink.api.azureml.ms \\\\\\n    --zone-name privatelink.api.azureml.ms\\n\\n# Add privatelink.notebooks.azure.net\\naz network private-dns zone create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --name privatelink.notebooks.azure.net\\n\\naz network private-dns link vnet create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --zone-name privatelink.notebooks.azure.net \\\\\\n    --name \u003clink-name\u003e \\\\\\n    --virtual-network \u003cvnet-name\u003e \\\\\\n    --registration-enabled false\\n\\naz network private-endpoint dns-zone-group add \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\nSource: how-to-configure-private-link.md\\n\\nContent: # Model performance and fairness\\n\\n- Learn how to use the components by checking out Fairlearn's [GitHub repository](https:\/\/github.com\/fairlearn\/fairlearn\/), [user guide](https:\/\/fairlearn.github.io\/main\/user_guide\/index.html), [examples](https:\/\/fairlearn.github.io\/main\/auto_examples\/index.html), and [sample notebooks](https:\/\/github.com\/fairlearn\/fairlearn\/blob\/main\/docs\/contributor_guide\/contributing_example_notebooks.rst).\\nSource: concept-fairness-ml.md \\n\\n chat history: \\n user: \\nwhat is aml? \\nassistant: \\n \\n user: \\nhow to create a spark job? \\nassistant: \\n \\n user: \\nthank you \\nassistant: \\n \\nuser: can you share a link to the examle? \\nassistant:\",\n  \"stream\": false\n}","__computed__.cumulative_token_count.completion":26,"__computed__.cumulative_token_count.prompt":1311,"__computed__.cumulative_token_count.total":1337,"output":"\"I'm sorry for any confusion, but the provided contexts don't include a direct link to an example for creating a spark job.\""},"events":[{"name":"promptflow.prompt.template","timestamp":"2024-04-11T18:08:57.752595Z","attributes":{"payload":"{\n  \"prompt.template\": \"{{prompt_text}}\",\n  \"prompt.variables\": \"{\\n  \\\"prompt_text\\\": \\\"system: \\\\nYou are an AI assistant that helps users answer questions given a specific context and conversation history. You will be given a context and chat history, and then asked a question based on that context and history. Your answer should be as precise as possible, and should only come from the context.\\\\nPlease add citation after each sentence when possible in a form \\\\\\\"(Source: citation)\\\\\\\".\\\\n\\\\n user: \\\\n Content: # Tutorial: Create resources you need to get started\\\\n\\\\n| [Upload, access and explore your data in Azure Machine Learning](tutorial-explore-data.md)     |  Store large data in the cloud and retrieve it from notebooks and scripts |\\\\n| [Model development on a cloud workstation](tutorial-cloud-workstation.md) | Start prototyping and developing machine learning models |\\\\n| [Train a model in Azure Machine Learning](tutorial-train-model.md) |    Dive in to the details of training a model     |\\\\n| [Deploy a model as an online endpoint](tutorial-deploy-model.md)  |   Dive in to the details of deploying a model      |\\\\n| [Create production machine learning pipelines](tutorial-pipeline-python-sdk.md) | Split a complete machine learning task into a multistep workflow. |\\\\nSource: quickstart-create-resources.md\\\\n\\\\nContent: # Configure a private endpoint for an Azure Machine Learning workspace\\\\n\\\\n* When using a workspace with multiple private endpoints, one of the private endpoints must be in the same VNet as the following dependency services:\\\\n\\\\n    * Azure Storage Account that provides the default storage for the workspace\\\\n    * Azure Key Vault for the workspace\\\\n    * Azure Container Registry for the workspace.\\\\n\\\\n    For example, one VNet ('services' VNet) would contain a private endpoint for the dependency services and the workspace. This configuration allows the workspace to communicate with the services. Another VNet ('clients') might only contain a private endpoint for the workspace, and be used only for communication between client development machines and the workspace.\\\\n\\\\n## Create a workspace that uses a private endpoint\\\\n\\\\nUse one of the following methods to create a workspace with a private endpoint. Each of these methods __requires an existing virtual network__:\\\\n\\\\n\u003e [!TIP]\\\\n\u003e If you'd like to create a workspace, private endpoint, and virtual network at the same time, see [Use an Azure Resource Manager template to create a workspace for Azure Machine Learning](how-to-create-workspace-template.md).\\\\n\\\\n# [Azure CLI](#tab\/cli)\\\\n[!INCLUDE [cli v2](includes\/machine-learning-cli-v2.md)]\\\\n\\\\nWhen using the Azure CLI [extension 2.0 CLI for machine learning](how-to-configure-cli.md), a YAML document is used to configure the workspace. The following example demonstrates creating a new workspace using a YAML configuration:\\\\n\\\\n\u003e [!TIP]\\\\n\u003e When using private link, your workspace cannot use Azure Container Registry tasks compute for image building. The `image_build_compute` property in this configuration specifies a CPU compute cluster name to use for Docker image environment building. You can also specify whether the private link workspace should be accessible over the internet using the `public_network_access` property.\\\\n\u003e\\\\n\u003e In this example, the compute referenced by `image_build_compute` will need to be created before building images.\\\\n\\\\n:::code language=\\\\\\\"YAML\\\\\\\" source=\\\\\\\"~\/azureml-examples-main\/cli\/resources\/workspace\/privatelink.yml\\\\\\\":::\\\\n\\\\n```azurecli-interactive\\\\naz ml workspace create \\\\\\\\\\\\n    -g \u003cresource-group-name\u003e \\\\\\\\\\\\n    --file privatelink.yml\\\\n```\\\\n\\\\nAfter creating the workspace, use the [Azure networking CLI commands](\/cli\/azure\/network\/private-endpoint#az-network-private-endpoint-create) to create a private link endpoint for the workspace.\\\\n\\\\n```azurecli-interactive\\\\naz network private-endpoint create \\\\\\\\\\\\n    --name \u003cprivate-endpoint-name\u003e \\\\\\\\\\\\n    --vnet-name \u003cvnet-name\u003e \\\\\\\\\\\\n    --subnet \u003csubnet-name\u003e \\\\\\\\\\\\n    --private-connection-resource-id \\\\\\\"\/subscriptions\/\u003csubscription\u003e\/resourceGroups\/\u003cresource-group-name\u003e\/providers\/Microsoft.MachineLearningServices\/workspaces\/\u003cworkspace-name\u003e\\\\\\\" \\\\\\\\\\\\n    --group-id amlworkspace \\\\\\\\\\\\n    --connection-name workspace -l \u003clocation\u003e\\\\n```\\\\n\\\\nTo create the private DNS zone entries for the workspace, use the following commands:\\\\n\\\\n```azurecli-interactive\\\\n# Add privatelink.api.azureml.ms\\\\naz network private-dns zone create \\\\\\\\\\\\n    -g \u003cresource-group-name\u003e \\\\\\\\\\\\n    --name privatelink.api.azureml.ms\\\\n\\\\naz network private-dns link vnet create \\\\\\\\\\\\n    -g \u003cresource-group-name\u003e \\\\\\\\\\\\n    --zone-name privatelink.api.azureml.ms \\\\\\\\\\\\n    --name \u003clink-name\u003e \\\\\\\\\\\\n    --virtual-network \u003cvnet-name\u003e \\\\\\\\\\\\n    --registration-enabled false\\\\n\\\\naz network private-endpoint dns-zone-group create \\\\\\\\\\\\n    -g \u003cresource-group-name\u003e \\\\\\\\\\\\n    --endpoint-name \u003cprivate-endpoint-name\u003e \\\\\\\\\\\\n    --name myzonegroup \\\\\\\\\\\\n    --private-dns-zone privatelink.api.azureml.ms \\\\\\\\\\\\n    --zone-name privatelink.api.azureml.ms\\\\n\\\\n# Add privatelink.notebooks.azure.net\\\\naz network private-dns zone create \\\\\\\\\\\\n    -g \u003cresource-group-name\u003e \\\\\\\\\\\\n    --name privatelink.notebooks.azure.net\\\\n\\\\naz network private-dns link vnet create \\\\\\\\\\\\n    -g \u003cresource-group-name\u003e \\\\\\\\\\\\n    --zone-name privatelink.notebooks.azure.net \\\\\\\\\\\\n    --name \u003clink-name\u003e \\\\\\\\\\\\n    --virtual-network \u003cvnet-name\u003e \\\\\\\\\\\\n    --registration-enabled false\\\\n\\\\naz network private-endpoint dns-zone-group add \\\\\\\\\\\\n    -g \u003cresource-group-name\u003e \\\\\\\\\\\\nSource: how-to-configure-private-link.md\\\\n\\\\nContent: # Model performance and fairness\\\\n\\\\n- Learn how to use the components by checking out Fairlearn's [GitHub repository](https:\/\/github.com\/fairlearn\/fairlearn\/), [user guide](https:\/\/fairlearn.github.io\/main\/user_guide\/index.html), [examples](https:\/\/fairlearn.github.io\/main\/auto_examples\/index.html), and [sample notebooks](https:\/\/github.com\/fairlearn\/fairlearn\/blob\/main\/docs\/contributor_guide\/contributing_example_notebooks.rst).\\\\nSource: concept-fairness-ml.md \\\\n\\\\n chat history: \\\\n user: \\\\nwhat is aml? \\\\nassistant: \\\\n \\\\n user: \\\\nhow to create a spark job? \\\\nassistant: \\\\n \\\\n user: \\\\nthank you \\\\nassistant: \\\\n \\\\nuser: can you share a link to the examle? \\\\nassistant:\\\"\\n}\"\n}"}},{"name":"promptflow.function.inputs","timestamp":"2024-04-11T18:08:57.754562Z","attributes":{"payload":"{\n  \"prompt\": \"{{prompt_text}}\",\n  \"deployment_name\": \"gpt-4-32k\",\n  \"temperature\": 1.0,\n  \"top_p\": 1.0,\n  \"presence_penalty\": 0.0,\n  \"frequency_penalty\": 0.0,\n  \"prompt_text\": \"system: \\nYou are an AI assistant that helps users answer questions given a specific context and conversation history. You will be given a context and chat history, and then asked a question based on that context and history. Your answer should be as precise as possible, and should only come from the context.\\nPlease add citation after each sentence when possible in a form \\\"(Source: citation)\\\".\\n\\n user: \\n Content: # Tutorial: Create resources you need to get started\\n\\n| [Upload, access and explore your data in Azure Machine Learning](tutorial-explore-data.md)     |  Store large data in the cloud and retrieve it from notebooks and scripts |\\n| [Model development on a cloud workstation](tutorial-cloud-workstation.md) | Start prototyping and developing machine learning models |\\n| [Train a model in Azure Machine Learning](tutorial-train-model.md) |    Dive in to the details of training a model     |\\n| [Deploy a model as an online endpoint](tutorial-deploy-model.md)  |   Dive in to the details of deploying a model      |\\n| [Create production machine learning pipelines](tutorial-pipeline-python-sdk.md) | Split a complete machine learning task into a multistep workflow. |\\nSource: quickstart-create-resources.md\\n\\nContent: # Configure a private endpoint for an Azure Machine Learning workspace\\n\\n* When using a workspace with multiple private endpoints, one of the private endpoints must be in the same VNet as the following dependency services:\\n\\n    * Azure Storage Account that provides the default storage for the workspace\\n    * Azure Key Vault for the workspace\\n    * Azure Container Registry for the workspace.\\n\\n    For example, one VNet ('services' VNet) would contain a private endpoint for the dependency services and the workspace. This configuration allows the workspace to communicate with the services. Another VNet ('clients') might only contain a private endpoint for the workspace, and be used only for communication between client development machines and the workspace.\\n\\n## Create a workspace that uses a private endpoint\\n\\nUse one of the following methods to create a workspace with a private endpoint. Each of these methods __requires an existing virtual network__:\\n\\n\u003e [!TIP]\\n\u003e If you'd like to create a workspace, private endpoint, and virtual network at the same time, see [Use an Azure Resource Manager template to create a workspace for Azure Machine Learning](how-to-create-workspace-template.md).\\n\\n# [Azure CLI](#tab\/cli)\\n[!INCLUDE [cli v2](includes\/machine-learning-cli-v2.md)]\\n\\nWhen using the Azure CLI [extension 2.0 CLI for machine learning](how-to-configure-cli.md), a YAML document is used to configure the workspace. The following example demonstrates creating a new workspace using a YAML configuration:\\n\\n\u003e [!TIP]\\n\u003e When using private link, your workspace cannot use Azure Container Registry tasks compute for image building. The `image_build_compute` property in this configuration specifies a CPU compute cluster name to use for Docker image environment building. You can also specify whether the private link workspace should be accessible over the internet using the `public_network_access` property.\\n\u003e\\n\u003e In this example, the compute referenced by `image_build_compute` will need to be created before building images.\\n\\n:::code language=\\\"YAML\\\" source=\\\"~\/azureml-examples-main\/cli\/resources\/workspace\/privatelink.yml\\\":::\\n\\n```azurecli-interactive\\naz ml workspace create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --file privatelink.yml\\n```\\n\\nAfter creating the workspace, use the [Azure networking CLI commands](\/cli\/azure\/network\/private-endpoint#az-network-private-endpoint-create) to create a private link endpoint for the workspace.\\n\\n```azurecli-interactive\\naz network private-endpoint create \\\\\\n    --name \u003cprivate-endpoint-name\u003e \\\\\\n    --vnet-name \u003cvnet-name\u003e \\\\\\n    --subnet \u003csubnet-name\u003e \\\\\\n    --private-connection-resource-id \\\"\/subscriptions\/\u003csubscription\u003e\/resourceGroups\/\u003cresource-group-name\u003e\/providers\/Microsoft.MachineLearningServices\/workspaces\/\u003cworkspace-name\u003e\\\" \\\\\\n    --group-id amlworkspace \\\\\\n    --connection-name workspace -l \u003clocation\u003e\\n```\\n\\nTo create the private DNS zone entries for the workspace, use the following commands:\\n\\n```azurecli-interactive\\n# Add privatelink.api.azureml.ms\\naz network private-dns zone create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --name privatelink.api.azureml.ms\\n\\naz network private-dns link vnet create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --zone-name privatelink.api.azureml.ms \\\\\\n    --name \u003clink-name\u003e \\\\\\n    --virtual-network \u003cvnet-name\u003e \\\\\\n    --registration-enabled false\\n\\naz network private-endpoint dns-zone-group create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --endpoint-name \u003cprivate-endpoint-name\u003e \\\\\\n    --name myzonegroup \\\\\\n    --private-dns-zone privatelink.api.azureml.ms \\\\\\n    --zone-name privatelink.api.azureml.ms\\n\\n# Add privatelink.notebooks.azure.net\\naz network private-dns zone create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --name privatelink.notebooks.azure.net\\n\\naz network private-dns link vnet create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --zone-name privatelink.notebooks.azure.net \\\\\\n    --name \u003clink-name\u003e \\\\\\n    --virtual-network \u003cvnet-name\u003e \\\\\\n    --registration-enabled false\\n\\naz network private-endpoint dns-zone-group add \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\nSource: how-to-configure-private-link.md\\n\\nContent: # Model performance and fairness\\n\\n- Learn how to use the components by checking out Fairlearn's [GitHub repository](https:\/\/github.com\/fairlearn\/fairlearn\/), [user guide](https:\/\/fairlearn.github.io\/main\/user_guide\/index.html), [examples](https:\/\/fairlearn.github.io\/main\/auto_examples\/index.html), and [sample notebooks](https:\/\/github.com\/fairlearn\/fairlearn\/blob\/main\/docs\/contributor_guide\/contributing_example_notebooks.rst).\\nSource: concept-fairness-ml.md \\n\\n chat history: \\n user: \\nwhat is aml? \\nassistant: \\n \\n user: \\nhow to create a spark job? \\nassistant: \\n \\n user: \\nthank you \\nassistant: \\n \\nuser: can you share a link to the examle? \\nassistant:\",\n  \"stream\": false\n}"}},{"name":"promptflow.function.output","timestamp":"2024-04-11T18:09:00.985487Z","attributes":{"payload":"\"I'm sorry for any confusion, but the provided contexts don't include a direct link to an example for creating a spark job.\""}}],"links":[],"resource":{"attributes":{"service.name":"promptflow"},"schema_url":""}}],"contentrange":"bytes 0-27837/27838","correlationid":"a2ec0d2a-97de-4858-99de-9b2b0054d038","xrequestid":"a2ec0d2a-97de-4858-99de-9b2b0054d038","modelversion":"default","collectdatatype":"pandas.core.frame.DataFrame","agent":"azureml-ai-monitoring/0.1.0b4"}
{"specversion":"1.0","id":"c898fcf4-974b-48a5-bb2e-6bddd93011bb","source":"/subscriptions/1aefdc5e-3a7c-4d71-a9f9-f5d3b03be19a/resourceGroups/yuachengtestrg/providers/Microsoft.MachineLearningServices/workspaces/ai-proj-eastus/onlineEndpoints/clone-vivi-log-test/deployments/clone-vivi-log-test-1","type":"azureml.inference.app_traces","datacontenttype":"application/json","time":"2024-04-11T18:09:01Z","data":[{"name":"generate_prompt_context","context":{"trace_id":"0xa2f3f4f8267a482fa3bb96ad3e1f7f35","span_id":"0xb377aaabae3522f8","trace_state":"[]"},"kind":"SpanKind.INTERNAL","parent_id":"0x38853fe3b7d18b15","start_time":"2024-04-11T18:08:57.712937Z","end_time":"2024-04-11T18:08:57.721057Z","status":{"status_code":"OK"},"attributes":{"framework":"promptflow","span_type":"Function","function":"generate_prompt_context","node_name":"generate_prompt_context","request_id":"de58ac2b-f07e-4e0a-89f1-509849ed2737","line_run_id":"de58ac2b-f07e-4e0a-89f1-509849ed2737","inputs":"{\n  \"search_result\": [\n    {\n      \"text\": \"# Tutorial: Create resources you need to get started\\n\\n| [Upload, access and explore your data in Azure Machine Learning](tutorial-explore-data.md)     |  Store large data in the cloud and retrieve it from notebooks and scripts |\\n| [Model development on a cloud workstation](tutorial-cloud-workstation.md) | Start prototyping and developing machine learning models |\\n| [Train a model in Azure Machine Learning](tutorial-train-model.md) |    Dive in to the details of training a model     |\\n| [Deploy a model as an online endpoint](tutorial-deploy-model.md)  |   Dive in to the details of deploying a model      |\\n| [Create production machine learning pipelines](tutorial-pipeline-python-sdk.md) | Split a complete machine learning task into a multistep workflow. |\",\n      \"metadata\": {\n        \"id\": \"cXVpY2tzdGFydC1jcmVhdGUtcmVzb3VyY2VzLm1kMg==\",\n        \"source\": {\n          \"title\": \"Tutorial: Create resources you need to get started\",\n          \"filename\": \"quickstart-create-resources.md\",\n          \"url\": \"quickstart-create-resources.md\",\n          \"mtime\": 1710206171.0\n        },\n        \"stats\": {\n          \"tiktokens\": 162,\n          \"chars\": 763,\n          \"lines\": 7\n        },\n        \"content_hash\": \"120bcf54a5162e37efb991db28b8fbdfa4718a161cb35be2d4baa921fefbf7eb\"\n      },\n      \"score\": 0.02364782989025116\n    },\n    {\n      \"text\": \"# Configure a private endpoint for an Azure Machine Learning workspace\\n\\n* When using a workspace with multiple private endpoints, one of the private endpoints must be in the same VNet as the following dependency services:\\n\\n    * Azure Storage Account that provides the default storage for the workspace\\n    * Azure Key Vault for the workspace\\n    * Azure Container Registry for the workspace.\\n\\n    For example, one VNet ('services' VNet) would contain a private endpoint for the dependency services and the workspace. This configuration allows the workspace to communicate with the services. Another VNet ('clients') might only contain a private endpoint for the workspace, and be used only for communication between client development machines and the workspace.\\n\\n## Create a workspace that uses a private endpoint\\n\\nUse one of the following methods to create a workspace with a private endpoint. Each of these methods __requires an existing virtual network__:\\n\\n\u003e [!TIP]\\n\u003e If you'd like to create a workspace, private endpoint, and virtual network at the same time, see [Use an Azure Resource Manager template to create a workspace for Azure Machine Learning](how-to-create-workspace-template.md).\\n\\n# [Azure CLI](#tab\/cli)\\n[!INCLUDE [cli v2](includes\/machine-learning-cli-v2.md)]\\n\\nWhen using the Azure CLI [extension 2.0 CLI for machine learning](how-to-configure-cli.md), a YAML document is used to configure the workspace. The following example demonstrates creating a new workspace using a YAML configuration:\\n\\n\u003e [!TIP]\\n\u003e When using private link, your workspace cannot use Azure Container Registry tasks compute for image building. The `image_build_compute` property in this configuration specifies a CPU compute cluster name to use for Docker image environment building. You can also specify whether the private link workspace should be accessible over the internet using the `public_network_access` property.\\n\u003e\\n\u003e In this example, the compute referenced by `image_build_compute` will need to be created before building images.\\n\\n:::code language=\\\"YAML\\\" source=\\\"~\/azureml-examples-main\/cli\/resources\/workspace\/privatelink.yml\\\":::\\n\\n```azurecli-interactive\\naz ml workspace create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --file privatelink.yml\\n```\\n\\nAfter creating the workspace, use the [Azure networking CLI commands](\/cli\/azure\/network\/private-endpoint#az-network-private-endpoint-create) to create a private link endpoint for the workspace.\\n\\n```azurecli-interactive\\naz network private-endpoint create \\\\\\n    --name \u003cprivate-endpoint-name\u003e \\\\\\n    --vnet-name \u003cvnet-name\u003e \\\\\\n    --subnet \u003csubnet-name\u003e \\\\\\n    --private-connection-resource-id \\\"\/subscriptions\/\u003csubscription\u003e\/resourceGroups\/\u003cresource-group-name\u003e\/providers\/Microsoft.MachineLearningServices\/workspaces\/\u003cworkspace-name\u003e\\\" \\\\\\n    --group-id amlworkspace \\\\\\n    --connection-name workspace -l \u003clocation\u003e\\n```\\n\\nTo create the private DNS zone entries for the workspace, use the following commands:\\n\\n```azurecli-interactive\\n# Add privatelink.api.azureml.ms\\naz network private-dns zone create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --name privatelink.api.azureml.ms\\n\\naz network private-dns link vnet create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --zone-name privatelink.api.azureml.ms \\\\\\n    --name \u003clink-name\u003e \\\\\\n    --virtual-network \u003cvnet-name\u003e \\\\\\n    --registration-enabled false\\n\\naz network private-endpoint dns-zone-group create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --endpoint-name \u003cprivate-endpoint-name\u003e \\\\\\n    --name myzonegroup \\\\\\n    --private-dns-zone privatelink.api.azureml.ms \\\\\\n    --zone-name privatelink.api.azureml.ms\\n\\n# Add privatelink.notebooks.azure.net\\naz network private-dns zone create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --name privatelink.notebooks.azure.net\\n\\naz network private-dns link vnet create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --zone-name privatelink.notebooks.azure.net \\\\\\n    --name \u003clink-name\u003e \\\\\\n    --virtual-network \u003cvnet-name\u003e \\\\\\n    --registration-enabled false\\n\\naz network private-endpoint dns-zone-group add \\\\\\n    -g \u003cresource-group-name\u003e \\\\\",\n      \"metadata\": {\n        \"id\": \"aG93LXRvLWNvbmZpZ3VyZS1wcml2YXRlLWxpbmsubWQx\",\n        \"source\": {\n          \"title\": \"Configure a private endpoint for an Azure Machine Learning workspace\",\n          \"filename\": \"how-to-configure-private-link.md\",\n          \"url\": \"how-to-configure-private-link.md\",\n          \"mtime\": 1710206126.0\n        },\n        \"stats\": {\n          \"tiktokens\": 878,\n          \"chars\": 4020,\n          \"lines\": 83\n        },\n        \"content_hash\": \"6defa15776349ba683025232d021517cd3cb8325d3ec94681700ec7bab908ce2\"\n      },\n      \"score\": 0.01666666753590107\n    },\n    {\n      \"text\": \"# Model performance and fairness\\n\\n- Learn how to use the components by checking out Fairlearn's [GitHub repository](https:\/\/github.com\/fairlearn\/fairlearn\/), [user guide](https:\/\/fairlearn.github.io\/main\/user_guide\/index.html), [examples](https:\/\/fairlearn.github.io\/main\/auto_examples\/index.html), and [sample notebooks](https:\/\/github.com\/fairlearn\/fairlearn\/blob\/main\/docs\/contributor_guide\/contributing_example_notebooks.rst).\",\n      \"metadata\": {\n        \"id\": \"Y29uY2VwdC1mYWlybmVzcy1tbC5tZDI=\",\n        \"source\": {\n          \"title\": \"Model performance and fairness\",\n          \"filename\": \"concept-fairness-ml.md\",\n          \"url\": \"concept-fairness-ml.md\",\n          \"mtime\": 1710206114.0\n        },\n        \"stats\": {\n          \"tiktokens\": 97,\n          \"chars\": 430,\n          \"lines\": 3\n        },\n        \"content_hash\": \"81513a84c2eb0f6235b7846f9612571b7cfbdd32f55af511cc1aad4f3f7111a3\"\n      },\n      \"score\": 0.01666666753590107\n    }\n  ]\n}","output":"\"Content: # Tutorial: Create resources you need to get started\\n\\n| [Upload, access and explore your data in Azure Machine Learning](tutorial-explore-data.md)     |  Store large data in the cloud and retrieve it from notebooks and scripts |\\n| [Model development on a cloud workstation](tutorial-cloud-workstation.md) | Start prototyping and developing machine learning models |\\n| [Train a model in Azure Machine Learning](tutorial-train-model.md) |    Dive in to the details of training a model     |\\n| [Deploy a model as an online endpoint](tutorial-deploy-model.md)  |   Dive in to the details of deploying a model      |\\n| [Create production machine learning pipelines](tutorial-pipeline-python-sdk.md) | Split a complete machine learning task into a multistep workflow. |\\nSource: quickstart-create-resources.md\\n\\nContent: # Configure a private endpoint for an Azure Machine Learning workspace\\n\\n* When using a workspace with multiple private endpoints, one of the private endpoints must be in the same VNet as the following dependency services:\\n\\n    * Azure Storage Account that provides the default storage for the workspace\\n    * Azure Key Vault for the workspace\\n    * Azure Container Registry for the workspace.\\n\\n    For example, one VNet ('services' VNet) would contain a private endpoint for the dependency services and the workspace. This configuration allows the workspace to communicate with the services. Another VNet ('clients') might only contain a private endpoint for the workspace, and be used only for communication between client development machines and the workspace.\\n\\n## Create a workspace that uses a private endpoint\\n\\nUse one of the following methods to create a workspace with a private endpoint. Each of these methods __requires an existing virtual network__:\\n\\n\u003e [!TIP]\\n\u003e If you'd like to create a workspace, private endpoint, and virtual network at the same time, see [Use an Azure Resource Manager template to create a workspace for Azure Machine Learning](how-to-create-workspace-template.md).\\n\\n# [Azure CLI](#tab\/cli)\\n[!INCLUDE [cli v2](includes\/machine-learning-cli-v2.md)]\\n\\nWhen using the Azure CLI [extension 2.0 CLI for machine learning](how-to-configure-cli.md), a YAML document is used to configure the workspace. The following example demonstrates creating a new workspace using a YAML configuration:\\n\\n\u003e [!TIP]\\n\u003e When using private link, your workspace cannot use Azure Container Registry tasks compute for image building. The `image_build_compute` property in this configuration specifies a CPU compute cluster name to use for Docker image environment building. You can also specify whether the private link workspace should be accessible over the internet using the `public_network_access` property.\\n\u003e\\n\u003e In this example, the compute referenced by `image_build_compute` will need to be created before building images.\\n\\n:::code language=\\\"YAML\\\" source=\\\"~\/azureml-examples-main\/cli\/resources\/workspace\/privatelink.yml\\\":::\\n\\n```azurecli-interactive\\naz ml workspace create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --file privatelink.yml\\n```\\n\\nAfter creating the workspace, use the [Azure networking CLI commands](\/cli\/azure\/network\/private-endpoint#az-network-private-endpoint-create) to create a private link endpoint for the workspace.\\n\\n```azurecli-interactive\\naz network private-endpoint create \\\\\\n    --name \u003cprivate-endpoint-name\u003e \\\\\\n    --vnet-name \u003cvnet-name\u003e \\\\\\n    --subnet \u003csubnet-name\u003e \\\\\\n    --private-connection-resource-id \\\"\/subscriptions\/\u003csubscription\u003e\/resourceGroups\/\u003cresource-group-name\u003e\/providers\/Microsoft.MachineLearningServices\/workspaces\/\u003cworkspace-name\u003e\\\" \\\\\\n    --group-id amlworkspace \\\\\\n    --connection-name workspace -l \u003clocation\u003e\\n```\\n\\nTo create the private DNS zone entries for the workspace, use the following commands:\\n\\n```azurecli-interactive\\n# Add privatelink.api.azureml.ms\\naz network private-dns zone create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --name privatelink.api.azureml.ms\\n\\naz network private-dns link vnet create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --zone-name privatelink.api.azureml.ms \\\\\\n    --name \u003clink-name\u003e \\\\\\n    --virtual-network \u003cvnet-name\u003e \\\\\\n    --registration-enabled false\\n\\naz network private-endpoint dns-zone-group create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --endpoint-name \u003cprivate-endpoint-name\u003e \\\\\\n    --name myzonegroup \\\\\\n    --private-dns-zone privatelink.api.azureml.ms \\\\\\n    --zone-name privatelink.api.azureml.ms\\n\\n# Add privatelink.notebooks.azure.net\\naz network private-dns zone create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --name privatelink.notebooks.azure.net\\n\\naz network private-dns link vnet create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --zone-name privatelink.notebooks.azure.net \\\\\\n    --name \u003clink-name\u003e \\\\\\n    --virtual-network \u003cvnet-name\u003e \\\\\\n    --registration-enabled false\\n\\naz network private-endpoint dns-zone-group add \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\nSource: how-to-configure-private-link.md\\n\\nContent: # Model performance and fairness\\n\\n- Learn how to use the components by checking out Fairlearn's [GitHub repository](https:\/\/github.com\/fairlearn\/fairlearn\/), [user guide](https:\/\/fairlearn.github.io\/main\/user_guide\/index.html), [examples](https:\/\/fairlearn.github.io\/main\/auto_examples\/index.html), and [sample notebooks](https:\/\/github.com\/fairlearn\/fairlearn\/blob\/main\/docs\/contributor_guide\/contributing_example_notebooks.rst).\\nSource: concept-fairness-ml.md\""},"events":[{"name":"promptflow.function.inputs","timestamp":"2024-04-11T18:08:57.720535Z","attributes":{"payload":"{\n  \"search_result\": [\n    {\n      \"text\": \"# Tutorial: Create resources you need to get started\\n\\n| [Upload, access and explore your data in Azure Machine Learning](tutorial-explore-data.md)     |  Store large data in the cloud and retrieve it from notebooks and scripts |\\n| [Model development on a cloud workstation](tutorial-cloud-workstation.md) | Start prototyping and developing machine learning models |\\n| [Train a model in Azure Machine Learning](tutorial-train-model.md) |    Dive in to the details of training a model     |\\n| [Deploy a model as an online endpoint](tutorial-deploy-model.md)  |   Dive in to the details of deploying a model      |\\n| [Create production machine learning pipelines](tutorial-pipeline-python-sdk.md) | Split a complete machine learning task into a multistep workflow. |\",\n      \"metadata\": {\n        \"id\": \"cXVpY2tzdGFydC1jcmVhdGUtcmVzb3VyY2VzLm1kMg==\",\n        \"source\": {\n          \"title\": \"Tutorial: Create resources you need to get started\",\n          \"filename\": \"quickstart-create-resources.md\",\n          \"url\": \"quickstart-create-resources.md\",\n          \"mtime\": 1710206171.0\n        },\n        \"stats\": {\n          \"tiktokens\": 162,\n          \"chars\": 763,\n          \"lines\": 7\n        },\n        \"content_hash\": \"120bcf54a5162e37efb991db28b8fbdfa4718a161cb35be2d4baa921fefbf7eb\"\n      },\n      \"score\": 0.02364782989025116\n    },\n    {\n      \"text\": \"# Configure a private endpoint for an Azure Machine Learning workspace\\n\\n* When using a workspace with multiple private endpoints, one of the private endpoints must be in the same VNet as the following dependency services:\\n\\n    * Azure Storage Account that provides the default storage for the workspace\\n    * Azure Key Vault for the workspace\\n    * Azure Container Registry for the workspace.\\n\\n    For example, one VNet ('services' VNet) would contain a private endpoint for the dependency services and the workspace. This configuration allows the workspace to communicate with the services. Another VNet ('clients') might only contain a private endpoint for the workspace, and be used only for communication between client development machines and the workspace.\\n\\n## Create a workspace that uses a private endpoint\\n\\nUse one of the following methods to create a workspace with a private endpoint. Each of these methods __requires an existing virtual network__:\\n\\n\u003e [!TIP]\\n\u003e If you'd like to create a workspace, private endpoint, and virtual network at the same time, see [Use an Azure Resource Manager template to create a workspace for Azure Machine Learning](how-to-create-workspace-template.md).\\n\\n# [Azure CLI](#tab\/cli)\\n[!INCLUDE [cli v2](includes\/machine-learning-cli-v2.md)]\\n\\nWhen using the Azure CLI [extension 2.0 CLI for machine learning](how-to-configure-cli.md), a YAML document is used to configure the workspace. The following example demonstrates creating a new workspace using a YAML configuration:\\n\\n\u003e [!TIP]\\n\u003e When using private link, your workspace cannot use Azure Container Registry tasks compute for image building. The `image_build_compute` property in this configuration specifies a CPU compute cluster name to use for Docker image environment building. You can also specify whether the private link workspace should be accessible over the internet using the `public_network_access` property.\\n\u003e\\n\u003e In this example, the compute referenced by `image_build_compute` will need to be created before building images.\\n\\n:::code language=\\\"YAML\\\" source=\\\"~\/azureml-examples-main\/cli\/resources\/workspace\/privatelink.yml\\\":::\\n\\n```azurecli-interactive\\naz ml workspace create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --file privatelink.yml\\n```\\n\\nAfter creating the workspace, use the [Azure networking CLI commands](\/cli\/azure\/network\/private-endpoint#az-network-private-endpoint-create) to create a private link endpoint for the workspace.\\n\\n```azurecli-interactive\\naz network private-endpoint create \\\\\\n    --name \u003cprivate-endpoint-name\u003e \\\\\\n    --vnet-name \u003cvnet-name\u003e \\\\\\n    --subnet \u003csubnet-name\u003e \\\\\\n    --private-connection-resource-id \\\"\/subscriptions\/\u003csubscription\u003e\/resourceGroups\/\u003cresource-group-name\u003e\/providers\/Microsoft.MachineLearningServices\/workspaces\/\u003cworkspace-name\u003e\\\" \\\\\\n    --group-id amlworkspace \\\\\\n    --connection-name workspace -l \u003clocation\u003e\\n```\\n\\nTo create the private DNS zone entries for the workspace, use the following commands:\\n\\n```azurecli-interactive\\n# Add privatelink.api.azureml.ms\\naz network private-dns zone create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --name privatelink.api.azureml.ms\\n\\naz network private-dns link vnet create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --zone-name privatelink.api.azureml.ms \\\\\\n    --name \u003clink-name\u003e \\\\\\n    --virtual-network \u003cvnet-name\u003e \\\\\\n    --registration-enabled false\\n\\naz network private-endpoint dns-zone-group create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --endpoint-name \u003cprivate-endpoint-name\u003e \\\\\\n    --name myzonegroup \\\\\\n    --private-dns-zone privatelink.api.azureml.ms \\\\\\n    --zone-name privatelink.api.azureml.ms\\n\\n# Add privatelink.notebooks.azure.net\\naz network private-dns zone create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --name privatelink.notebooks.azure.net\\n\\naz network private-dns link vnet create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --zone-name privatelink.notebooks.azure.net \\\\\\n    --name \u003clink-name\u003e \\\\\\n    --virtual-network \u003cvnet-name\u003e \\\\\\n    --registration-enabled false\\n\\naz network private-endpoint dns-zone-group add \\\\\\n    -g \u003cresource-group-name\u003e \\\\\",\n      \"metadata\": {\n        \"id\": \"aG93LXRvLWNvbmZpZ3VyZS1wcml2YXRlLWxpbmsubWQx\",\n        \"source\": {\n          \"title\": \"Configure a private endpoint for an Azure Machine Learning workspace\",\n          \"filename\": \"how-to-configure-private-link.md\",\n          \"url\": \"how-to-configure-private-link.md\",\n          \"mtime\": 1710206126.0\n        },\n        \"stats\": {\n          \"tiktokens\": 878,\n          \"chars\": 4020,\n          \"lines\": 83\n        },\n        \"content_hash\": \"6defa15776349ba683025232d021517cd3cb8325d3ec94681700ec7bab908ce2\"\n      },\n      \"score\": 0.01666666753590107\n    },\n    {\n      \"text\": \"# Model performance and fairness\\n\\n- Learn how to use the components by checking out Fairlearn's [GitHub repository](https:\/\/github.com\/fairlearn\/fairlearn\/), [user guide](https:\/\/fairlearn.github.io\/main\/user_guide\/index.html), [examples](https:\/\/fairlearn.github.io\/main\/auto_examples\/index.html), and [sample notebooks](https:\/\/github.com\/fairlearn\/fairlearn\/blob\/main\/docs\/contributor_guide\/contributing_example_notebooks.rst).\",\n      \"metadata\": {\n        \"id\": \"Y29uY2VwdC1mYWlybmVzcy1tbC5tZDI=\",\n        \"source\": {\n          \"title\": \"Model performance and fairness\",\n          \"filename\": \"concept-fairness-ml.md\",\n          \"url\": \"concept-fairness-ml.md\",\n          \"mtime\": 1710206114.0\n        },\n        \"stats\": {\n          \"tiktokens\": 97,\n          \"chars\": 430,\n          \"lines\": 3\n        },\n        \"content_hash\": \"81513a84c2eb0f6235b7846f9612571b7cfbdd32f55af511cc1aad4f3f7111a3\"\n      },\n      \"score\": 0.01666666753590107\n    }\n  ]\n}"}},{"name":"promptflow.function.output","timestamp":"2024-04-11T18:08:57.720874Z","attributes":{"payload":"\"Content: # Tutorial: Create resources you need to get started\\n\\n| [Upload, access and explore your data in Azure Machine Learning](tutorial-explore-data.md)     |  Store large data in the cloud and retrieve it from notebooks and scripts |\\n| [Model development on a cloud workstation](tutorial-cloud-workstation.md) | Start prototyping and developing machine learning models |\\n| [Train a model in Azure Machine Learning](tutorial-train-model.md) |    Dive in to the details of training a model     |\\n| [Deploy a model as an online endpoint](tutorial-deploy-model.md)  |   Dive in to the details of deploying a model      |\\n| [Create production machine learning pipelines](tutorial-pipeline-python-sdk.md) | Split a complete machine learning task into a multistep workflow. |\\nSource: quickstart-create-resources.md\\n\\nContent: # Configure a private endpoint for an Azure Machine Learning workspace\\n\\n* When using a workspace with multiple private endpoints, one of the private endpoints must be in the same VNet as the following dependency services:\\n\\n    * Azure Storage Account that provides the default storage for the workspace\\n    * Azure Key Vault for the workspace\\n    * Azure Container Registry for the workspace.\\n\\n    For example, one VNet ('services' VNet) would contain a private endpoint for the dependency services and the workspace. This configuration allows the workspace to communicate with the services. Another VNet ('clients') might only contain a private endpoint for the workspace, and be used only for communication between client development machines and the workspace.\\n\\n## Create a workspace that uses a private endpoint\\n\\nUse one of the following methods to create a workspace with a private endpoint. Each of these methods __requires an existing virtual network__:\\n\\n\u003e [!TIP]\\n\u003e If you'd like to create a workspace, private endpoint, and virtual network at the same time, see [Use an Azure Resource Manager template to create a workspace for Azure Machine Learning](how-to-create-workspace-template.md).\\n\\n# [Azure CLI](#tab\/cli)\\n[!INCLUDE [cli v2](includes\/machine-learning-cli-v2.md)]\\n\\nWhen using the Azure CLI [extension 2.0 CLI for machine learning](how-to-configure-cli.md), a YAML document is used to configure the workspace. The following example demonstrates creating a new workspace using a YAML configuration:\\n\\n\u003e [!TIP]\\n\u003e When using private link, your workspace cannot use Azure Container Registry tasks compute for image building. The `image_build_compute` property in this configuration specifies a CPU compute cluster name to use for Docker image environment building. You can also specify whether the private link workspace should be accessible over the internet using the `public_network_access` property.\\n\u003e\\n\u003e In this example, the compute referenced by `image_build_compute` will need to be created before building images.\\n\\n:::code language=\\\"YAML\\\" source=\\\"~\/azureml-examples-main\/cli\/resources\/workspace\/privatelink.yml\\\":::\\n\\n```azurecli-interactive\\naz ml workspace create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --file privatelink.yml\\n```\\n\\nAfter creating the workspace, use the [Azure networking CLI commands](\/cli\/azure\/network\/private-endpoint#az-network-private-endpoint-create) to create a private link endpoint for the workspace.\\n\\n```azurecli-interactive\\naz network private-endpoint create \\\\\\n    --name \u003cprivate-endpoint-name\u003e \\\\\\n    --vnet-name \u003cvnet-name\u003e \\\\\\n    --subnet \u003csubnet-name\u003e \\\\\\n    --private-connection-resource-id \\\"\/subscriptions\/\u003csubscription\u003e\/resourceGroups\/\u003cresource-group-name\u003e\/providers\/Microsoft.MachineLearningServices\/workspaces\/\u003cworkspace-name\u003e\\\" \\\\\\n    --group-id amlworkspace \\\\\\n    --connection-name workspace -l \u003clocation\u003e\\n```\\n\\nTo create the private DNS zone entries for the workspace, use the following commands:\\n\\n```azurecli-interactive\\n# Add privatelink.api.azureml.ms\\naz network private-dns zone create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --name privatelink.api.azureml.ms\\n\\naz network private-dns link vnet create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --zone-name privatelink.api.azureml.ms \\\\\\n    --name \u003clink-name\u003e \\\\\\n    --virtual-network \u003cvnet-name\u003e \\\\\\n    --registration-enabled false\\n\\naz network private-endpoint dns-zone-group create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --endpoint-name \u003cprivate-endpoint-name\u003e \\\\\\n    --name myzonegroup \\\\\\n    --private-dns-zone privatelink.api.azureml.ms \\\\\\n    --zone-name privatelink.api.azureml.ms\\n\\n# Add privatelink.notebooks.azure.net\\naz network private-dns zone create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --name privatelink.notebooks.azure.net\\n\\naz network private-dns link vnet create \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\n    --zone-name privatelink.notebooks.azure.net \\\\\\n    --name \u003clink-name\u003e \\\\\\n    --virtual-network \u003cvnet-name\u003e \\\\\\n    --registration-enabled false\\n\\naz network private-endpoint dns-zone-group add \\\\\\n    -g \u003cresource-group-name\u003e \\\\\\nSource: how-to-configure-private-link.md\\n\\nContent: # Model performance and fairness\\n\\n- Learn how to use the components by checking out Fairlearn's [GitHub repository](https:\/\/github.com\/fairlearn\/fairlearn\/), [user guide](https:\/\/fairlearn.github.io\/main\/user_guide\/index.html), [examples](https:\/\/fairlearn.github.io\/main\/auto_examples\/index.html), and [sample notebooks](https:\/\/github.com\/fairlearn\/fairlearn\/blob\/main\/docs\/contributor_guide\/contributing_example_notebooks.rst).\\nSource: concept-fairness-ml.md\""}}],"links":[],"resource":{"attributes":{"service.name":"promptflow"},"schema_url":""}}],"contentrange":"bytes 0-27312/27313","correlationid":"d9c5af03-c87e-470c-b141-62aaec6e2b44","xrequestid":"d9c5af03-c87e-470c-b141-62aaec6e2b44","modelversion":"default","collectdatatype":"pandas.core.frame.DataFrame","agent":"azureml-ai-monitoring/0.1.0b4"}
{"specversion":"1.0","id":"8296590d-19d5-43dd-aeaf-bb3bcedf304b","source":"/subscriptions/1aefdc5e-3a7c-4d71-a9f9-f5d3b03be19a/resourceGroups/yuachengtestrg/providers/Microsoft.MachineLearningServices/workspaces/ai-proj-eastus/onlineEndpoints/clone-vivi-log-test/deployments/clone-vivi-log-test-1","type":"azureml.inference.app_traces","datacontenttype":"application/json","time":"2024-04-11T18:09:01Z","data":[{"name":"model","context":{"trace_id":"0xa2f3f4f8267a482fa3bb96ad3e1f7f35","span_id":"0x38853fe3b7d18b15","trace_state":"[]"},"kind":"SpanKind.INTERNAL","parent_id":"0xde6f0ec6b2d86223","start_time":"2024-04-11T18:08:54.513149Z","end_time":"2024-04-11T18:09:00.991714Z","status":{"status_code":"OK"},"attributes":{"framework":"promptflow","span_type":"Flow","request_id":"de58ac2b-f07e-4e0a-89f1-509849ed2737","line_run_id":"de58ac2b-f07e-4e0a-89f1-509849ed2737","inputs":"{\n  \"question\": \"can you share a link to the examle?\",\n  \"chat_history\": [\n    {\n      \"inputs\": {\n        \"question\": \"what is aml?\"\n      },\n      \"outputs\": {\n        \"answer\": \"Azure Machine Learning (AML) is a cloud service used for accelerating and managing the machine learning project lifecycle. It is designed for ML professionals, data scientists, and engineers to facilitate their daily workflows in training and deploying models and managing machine learning operations (MLOps). You can create models in AML or use models built from open-source platforms like PyTorch, TensorFlow, or scikit-learn. Furthermore, Azure Machine Learning provides tools for monitoring, retraining, and redeploying models(Source: overview-what-is-azure-machine-learning.md).\"\n      }\n    },\n    {\n      \"inputs\": {\n        \"question\": \"how to create a spark job?\"\n      },\n      \"outputs\": {\n        \"answer\": \"To create a Spark job in Azure Machine Learning, you need to firstly provide a Name and optionally a Value under the **Add tags**. Then in the **Code** section, you need to choose the workspace's default blob storage for code location and select the path of the code file to upload. You then need to input the name of the `titanic.py` as the **Entry file**. \\n\\nNext, you add an input by selecting **+ Add input** under **Inputs** and filling up required fields such as **Input name**, **Input type**, and **Data type**. Similarly, you add an output by selecting **+ Add output** under **Outputs** and entering required information. \\n\\nThen you need to enter **Arguments** for the job. \\n\\nIn the **Spark configurations** section, you can configure parameters such as number of executor cores, memory, and instances. Similarly, configure the driver size. Then, you can add any additional optional configurations. \\n\\nOnce everything is set up, you can review the job specifications and select **Create** to submit the standalone Spark job (Source: quickstart-spark-jobs.md).\\n\\nBear in mind that you have the option to add any necessary Jar files, Py files or Archives for the job under the respective sections (Source: how-to-submit-spark-jobs.md). Also, please note that the job submitted defaults to user identity passthrough for data access (Source: quickstart-spark-jobs.md).\\n\"\n      }\n    },\n    {\n      \"inputs\": {\n        \"question\": \"thank you\"\n      },\n      \"outputs\": {\n        \"answer\": \"To create a Spark job in Azure Machine Learning, follow these steps:\\n\\n1. Provide a **Name** and optional **Tag** for your job.\\n2. In the **Code** section, you need to:\\n   1. Select **Azure Machine Learning workspace default blob storage** from **Choose code location** dropdown.\\n   2. Select **Browse** under **Path to code file to upload** and select the path to your file on the workspace default datastore.\\n   3. Input the name of your **Entry file** (e.g. `titanic.py`) for the standalone job.\\n3. To add an input, select **+ Add input** under **Inputs** and provide necessary details like **Input name**, **Input type**, **Data type**, **Data source**, and appropriate Azure Data Lake Storage (ADLS) Gen 2 data URI.\\n4. To add an output, select **+ Add output** under **Outputs** and provide necessary details like **Output name**, **Output type**, and an appropriate Azure Data Lake Storage (ADLS) Gen 2 folder URI.\\n5. Enter **Arguments** as `--titanic_data ${{inputs.titanic_data}} --wrangled_data ${{outputs.wrangled_data}}`.\\n6. For **Spark configurations**, adjust the **Executor size** and **Driver size** to fit your job's requirements.\\n7. Review the job specification in the **Review** screen, then select **Create** to submit the standalone Spark job (Source: quickstart-spark-jobs.md).\"\n      }\n    }\n  ]\n}","__computed__.cumulative_token_count.prompt":1431,"__computed__.cumulative_token_count.completion":35,"__computed__.cumulative_token_count.total":1466,"output":"{\n  \"answer\": \"I'm sorry for any confusion, but the provided contexts don't include a direct link to an example for creating a spark job.\"\n}"},"events":[{"name":"promptflow.function.inputs","timestamp":"2024-04-11T18:08:54.513976Z","attributes":{"payload":"{\n  \"question\": \"can you share a link to the examle?\",\n  \"chat_history\": [\n    {\n      \"inputs\": {\n        \"question\": \"what is aml?\"\n      },\n      \"outputs\": {\n        \"answer\": \"Azure Machine Learning (AML) is a cloud service used for accelerating and managing the machine learning project lifecycle. It is designed for ML professionals, data scientists, and engineers to facilitate their daily workflows in training and deploying models and managing machine learning operations (MLOps). You can create models in AML or use models built from open-source platforms like PyTorch, TensorFlow, or scikit-learn. Furthermore, Azure Machine Learning provides tools for monitoring, retraining, and redeploying models(Source: overview-what-is-azure-machine-learning.md).\"\n      }\n    },\n    {\n      \"inputs\": {\n        \"question\": \"how to create a spark job?\"\n      },\n      \"outputs\": {\n        \"answer\": \"To create a Spark job in Azure Machine Learning, you need to firstly provide a Name and optionally a Value under the **Add tags**. Then in the **Code** section, you need to choose the workspace's default blob storage for code location and select the path of the code file to upload. You then need to input the name of the `titanic.py` as the **Entry file**. \\n\\nNext, you add an input by selecting **+ Add input** under **Inputs** and filling up required fields such as **Input name**, **Input type**, and **Data type**. Similarly, you add an output by selecting **+ Add output** under **Outputs** and entering required information. \\n\\nThen you need to enter **Arguments** for the job. \\n\\nIn the **Spark configurations** section, you can configure parameters such as number of executor cores, memory, and instances. Similarly, configure the driver size. Then, you can add any additional optional configurations. \\n\\nOnce everything is set up, you can review the job specifications and select **Create** to submit the standalone Spark job (Source: quickstart-spark-jobs.md).\\n\\nBear in mind that you have the option to add any necessary Jar files, Py files or Archives for the job under the respective sections (Source: how-to-submit-spark-jobs.md). Also, please note that the job submitted defaults to user identity passthrough for data access (Source: quickstart-spark-jobs.md).\\n\"\n      }\n    },\n    {\n      \"inputs\": {\n        \"question\": \"thank you\"\n      },\n      \"outputs\": {\n        \"answer\": \"To create a Spark job in Azure Machine Learning, follow these steps:\\n\\n1. Provide a **Name** and optional **Tag** for your job.\\n2. In the **Code** section, you need to:\\n   1. Select **Azure Machine Learning workspace default blob storage** from **Choose code location** dropdown.\\n   2. Select **Browse** under **Path to code file to upload** and select the path to your file on the workspace default datastore.\\n   3. Input the name of your **Entry file** (e.g. `titanic.py`) for the standalone job.\\n3. To add an input, select **+ Add input** under **Inputs** and provide necessary details like **Input name**, **Input type**, **Data type**, **Data source**, and appropriate Azure Data Lake Storage (ADLS) Gen 2 data URI.\\n4. To add an output, select **+ Add output** under **Outputs** and provide necessary details like **Output name**, **Output type**, and an appropriate Azure Data Lake Storage (ADLS) Gen 2 folder URI.\\n5. Enter **Arguments** as `--titanic_data ${{inputs.titanic_data}} --wrangled_data ${{outputs.wrangled_data}}`.\\n6. For **Spark configurations**, adjust the **Executor size** and **Driver size** to fit your job's requirements.\\n7. Review the job specification in the **Review** screen, then select **Create** to submit the standalone Spark job (Source: quickstart-spark-jobs.md).\"\n      }\n    }\n  ]\n}"}},{"name":"promptflow.function.output","timestamp":"2024-04-11T18:09:00.991683Z","attributes":{"payload":"{\n  \"answer\": \"I'm sorry for any confusion, but the provided contexts don't include a direct link to an example for creating a spark job.\"\n}"}}],"links":[],"resource":{"attributes":{"service.name":"promptflow"},"schema_url":""}}],"modelversion":"default","collectdatatype":"pandas.core.frame.DataFrame","agent":"azureml-ai-monitoring/0.1.0b4","contentrange":"bytes 0-8892/8893","correlationid":"7c085421-9ba7-4d21-8c9c-b0e8966d605e","xrequestid":"7c085421-9ba7-4d21-8c9c-b0e8966d605e"}
