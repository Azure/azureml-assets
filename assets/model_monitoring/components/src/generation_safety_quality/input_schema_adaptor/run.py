# Copyright (c) Microsoft Corporation.
# Licensed under the MIT License.

"""Entry script for GSQ Input Schema Adaptor Spark Component."""

import argparse

from shared_utilities.io_utils import (
    save_spark_df_as_mltable,
    try_read_mltable_in_spark_with_error,
)


def run():
    """Adapt the production dataset schema to match GSQ input schema if necessary."""
    # Parse argument
    parser = argparse.ArgumentParser()
    parser.add_argument("--production_dataset", type=str, required=True)
    parser.add_argument("--adapted_production_data", type=str, required=True)

    args = parser.parse_args()

    production_data_df = try_read_mltable_in_spark_with_error(args.production_dataset, "production_dataset")

    # TODO: Add input schema adaptor logic. For now just pass data through.

    save_spark_df_as_mltable(production_data_df, args.adapted_production_data)


if __name__ == "__main__":
    run()
