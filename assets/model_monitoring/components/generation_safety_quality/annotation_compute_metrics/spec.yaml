$schema: http://azureml/sdk-2-0/SparkComponent.json
type: spark

name: gsq_annotation_compute_metrics
display_name: Annotation - Compute Metrics
description: Compute annotation metrics given a deployment's model data input.
version: 0.4.31
is_deterministic: True
inputs:
  annotation_histogram: 
    type: mltable
    mode: direct
  metric_names:
    type: string
    description: a comma-separated list of metric names to compute
    optional: false
  thresholds:
    type: string
    optional: true
    default: ""
    description: a comma-separated dictionary of threshold:value for each metric
  groundedness_passrate_threshold:
    type: number
    optional: true
    default: 0.7
  similarity_passrate_threshold:
    type: number
    optional: true
    default: 0.7
  relevance_passrate_threshold:
    type: number
    optional: true
    default: 0.7
  fluency_passrate_threshold:
    type: number
    optional: true
    default: 0.7
  coherence_passrate_threshold:
    type: number
    optional: true
    default: 0.7

outputs:
  signal_metrics:
    type: mltable
    mode: direct

conf:
  spark.driver.cores: 4
  spark.driver.memory: 28g
  spark.executor.cores: 4
  spark.executor.memory: 28g
  spark.executor.instances: 1
  spark.dynamicAllocation.enabled: True
  spark.dynamicAllocation.minExecutors: 1
  spark.dynamicAllocation.maxExecutors: 1 # avoid AOAI API limits by running only one executor at a time
  spark.jars.packages: com.microsoft.azure:synapseml_2.12:0.11.0-26-52919ce4-SNAPSHOT,org.apache.spark:spark-avro_2.12:3.3.1
  spark.jars.repositories: https://mmlspark.azureedge.net/maven
  spark.jars.excludes: org.scala-lang:scala-reflect,org.apache.spark:spark-tags_2.12,org.scalactic:scalactic_2.12,org.scalatest:scalatest_2.12,com.fasterxml.jackson.core:jackson-databind
  spark.yarn.user.classpath.first: true
  spark.sql.parquet.enableVectorizedReader: false
  spark.sql.legacy.replaceDatabricksSparkAvro.enabled: true
  spark.driver.userClassPathFirst: false
  spark.executor.userClassPathFirst: false
  spark.aml.internal.system.job: True
  spark.synapse.library.python.env: |
    channels:
      - defaults
    dependencies:
      - python=3.10
      - pip:
        - azure-cli-core~=2.66.0
        - azure-ai-evaluation~=1.0.1
        - azure-ai-ml~=1.30.0
        - openai~=1.56.2
        - json5==0.9.11
        - mltable~=1.6.3
        - keyrings.alt~=5.0.0
        - mlflow~=2.22.4
        - protobuf~=6.32.1
        - azureml-fsspec~=1.3.1
        - fsspec~=2023.4.0
        - tiktoken~=0.11.0
    name: momo-gsq-spark
code: ../../src

entry:
  file: ./generation_safety_quality/annotation_compute_metrics/run.py

args: >-
  --annotation_histogram ${{inputs.annotation_histogram}}
  --metric_names ${{inputs.metric_names}}
  $[[--thresholds ${{inputs.thresholds}}]]
  $[[--groundedness_passrate_threshold ${{inputs.groundedness_passrate_threshold}}]]
  $[[--relevance_passrate_threshold ${{inputs.relevance_passrate_threshold}}]]
  $[[--similarity_passrate_threshold ${{inputs.similarity_passrate_threshold}}]]
  $[[--fluency_passrate_threshold ${{inputs.fluency_passrate_threshold}}]]
  $[[--coherence_passrate_threshold ${{inputs.coherence_passrate_threshold}}]]
  --signal_metrics ${{outputs.signal_metrics}}
