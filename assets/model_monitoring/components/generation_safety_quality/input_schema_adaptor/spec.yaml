$schema: http://azureml/sdk-2-0/SparkComponent.json
type: spark

name: gsq_input_schema_adaptor
display_name: Input Schema Adaptor
description: Adapt data to fit into GSQ component.
version: 0.0.25
is_deterministic: True
inputs:
  production_dataset:
    type: mltable
    optional: False
    mode: direct
outputs:
  adapted_production_data:
    type: mltable
    mode: direct

conf:
  spark.hadoop.aml.enable_cache : "true"
  spark.aml.internal.system.job: True
  spark.driver.cores: 4
  spark.driver.memory: 28g
  spark.executor.cores: 4
  spark.executor.memory: 28g
  spark.executor.instances: 1
  spark.dynamicAllocation.enabled: True
  spark.dynamicAllocation.minExecutors: 1
  spark.dynamicAllocation.maxExecutors: 4
  spark.synapse.library.python.env: |
    channels:
      - defaults
    dependencies:
      - pip:
        - azure-storage-file-datalake~=12.8.0
        - azure-ai-ml~=1.26.3
        - azureml-mlflow~=1.49.0
        - mltable~=1.3.0
        - azureml-fsspec~=1.0.0
        - fsspec~=2023.4.0
        - numpy<2.0.0
        - cryptography==42.0.5
        - opentelemetry-sdk~=1.32.1
    name: momo-base-spark

code: ../../src

entry:
  file: ./generation_safety_quality/input_schema_adaptor/run.py

args: >-
  --production_dataset ${{inputs.production_dataset}}
  --adapted_production_data ${{outputs.adapted_production_data}}
