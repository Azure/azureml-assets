$schema: http://azureml/sdk-2-0/SparkComponent.json
type: spark

name: annotation_compute_histogram_spark
display_name: Annotation - Compute Histogram
description: Compute annotation histogram given a deployment's model data input.
version: 0.3.4
is_deterministic: false
inputs:
  production_dataset: 
    type: mltable
    mode: direct
  metric_names:
    type: string
    description: a comma-separated list of metric names to compute
    default: groundedness
  model_type:
    type: string
    optional: false
    description: type of model used for annotation
    enum:
      - gpt-35-turbo
      - gpt-4
      - gpt-4-32k
  model_deployment_name:
    type: string
    optional: false
    description: model name, e.g., name of the deployment for Azure OpenAI
  azure_endpoint_domain_name:
    type: string
    optional: false
    description: endpoint domain name, e.g., <instance>.openai.azure.com
  azure_openai_api_version:
    type: string
    optional: false
    description: API version, e.g., 2023-03-15-preview
  sample_rate:
    type: number
    optional: true
    description: sample rate for the input dataset, should be greater than 0 and at most 1
  user_assigned_managed_identity_client_id:
    type: string

outputs:
  histogram:
    type: mltable
    mode: direct

code: ../../src

entry:
  file: ./generation_safety_quality/annotation_compute_histogram/run.py

args: >-
  --production_dataset ${{inputs.production_dataset}}
  --metric_names ${{inputs.metric_names}}
  --model_type ${{inputs.model_type}}
  --model_deployment_name ${{inputs.model_deployment_name}}
  --azure_endpoint_domain_name ${{inputs.azure_endpoint_domain_name}}
  --azure_openai_api_version ${{inputs.azure_openai_api_version}}
  $[[--sample_rate ${{inputs.sample_rate}}]]
  --histogram ${{outputs.histogram}}


conf:
  spark.driver.cores: 1
  spark.driver.memory: 2g
  spark.executor.cores: 2
  spark.executor.memory: 2g
  spark.executor.instances: 1
  spark.dynamicAllocation.enabled: True
  spark.dynamicAllocation.minExecutors: 1
  spark.dynamicAllocation.maxExecutors: 1 # avoid AOAI API limits by running only one executor at a time
  spark.jars.packages: com.microsoft.azure:synapseml_2.12:0.11.0-26-52919ce4-SNAPSHOT,org.apache.spark:spark-avro_2.12:3.3.1
  spark.jars.repositories: https://mmlspark.azureedge.net/maven
  spark.jars.excludes: org.scala-lang:scala-reflect,org.apache.spark:spark-tags_2.12,org.scalactic:scalactic_2.12,org.scalatest:scalatest_2.12,com.fasterxml.jackson.core:jackson-databind
  spark.yarn.user.classpath.first: true
  spark.sql.parquet.enableVectorizedReader: false
  spark.sql.legacy.replaceDatabricksSparkAvro.enabled: true
  spark.driver.userClassPathFirst: false
  spark.executor.userClassPathFirst: false
  spark.synapse.library.python.env: |
    channels:
      - defaults
      - conda-forge
    dependencies:
      - python=3.10
      - pip:
          - azure-cli-core~=2.45.0
          - azure-identity~=1.12.0
          - azure-ai-ml~=1.4.0
          - azure-keyvault-secrets==4.7.0
          - tiktoken==0.3.3
          - json5==0.9.11
          - scipy~=1.10.0
          - numpy~=1.21.0
          - pandas~=1.4.3
          - azureml-mlflow~=1.49.0
          - mltable~=1.3.0

identity:
  type: managed
  client_id: ${{inputs.user_assigned_managed_identity_client_id}