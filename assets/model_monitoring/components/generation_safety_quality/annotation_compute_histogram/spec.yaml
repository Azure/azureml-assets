$schema: http://azureml/sdk-2-0/SparkComponent.json
type: spark

name: gsq_annotation_compute_histogram
display_name: Annotation - Compute Histogram
description: Compute annotation histogram given a deployment's model data input.
version: 0.4.2
is_deterministic: false
inputs:
  production_dataset: 
    type: mltable
    mode: direct
  metric_names:
    type: string
    description: a comma-separated list of metric names to compute
    optional: false
  model_deployment_name:
    type: string
    optional: false
    description: model name, e.g., name of the deployment for Azure OpenAI
  workspace_connection_arm_id:
    type: string
    optional: false
    description: path to the workspace connection
  prompt_column_name:
    type: string
    optional: true
    default: "prompt"
  completion_column_name:
    type: string
    optional: true
    default: "completion"
  ground_truth_column_name:
    type: string
    optional: true
    default: "ground_truth"
  context_column_name:
    type: string
    optional: true
    default: "context"
  groundedness_rating_threshold:
    type: integer
    optional: true
    default: 3
  similarity_rating_threshold:
    type: integer
    optional: true
    default: 3
  relevance_rating_threshold:
    type: integer
    optional: true
    default: 3
  fluency_rating_threshold:
    type: integer
    optional: true
    default: 3
  coherence_rating_threshold:
    type: integer
    optional: true
    default: 3
  sample_rate:
    type: number
    optional: true
    description: sample rate for the input dataset, should be greater than 0 and at most 1
outputs:
  histogram:
    type: mltable
    mode: direct
  samples_index:
    type: mltable
    mode: direct
  groundedness_violations:
    type: mltable
    mode: direct
  fluency_violations:
    type: mltable
    mode: direct
  coherence_violations:
    type: mltable
    mode: direct
  similarity_violations:
    type: mltable
    mode: direct
  relevance_violations:
    type: mltable
    mode: direct

conf:
  spark.driver.cores: 1
  spark.driver.memory: 2g
  spark.executor.cores: 2
  spark.executor.memory: 2g
  spark.executor.instances: 1
  spark.dynamicAllocation.enabled: True
  spark.dynamicAllocation.minExecutors: 1
  spark.dynamicAllocation.maxExecutors: 1 # avoid AOAI API limits by running only one executor at a time
  spark.jars.packages: com.microsoft.azure:synapseml_2.12:0.11.0-26-52919ce4-SNAPSHOT,org.apache.spark:spark-avro_2.12:3.3.1
  spark.jars.repositories: https://mmlspark.azureedge.net/maven
  spark.jars.excludes: org.scala-lang:scala-reflect,org.apache.spark:spark-tags_2.12,org.scalactic:scalactic_2.12,org.scalatest:scalatest_2.12,com.fasterxml.jackson.core:jackson-databind
  spark.yarn.user.classpath.first: true
  spark.sql.parquet.enableVectorizedReader: false
  spark.sql.legacy.replaceDatabricksSparkAvro.enabled: true
  spark.driver.userClassPathFirst: false
  spark.executor.userClassPathFirst: false
  spark.synapse.library.python.env: |
    channels:
      - defaults
      - conda-forge
    dependencies:
      - python=3.10
      - pip:
          - azure-cli-core~=2.45.0
          - azure-identity~=1.12.0
          - azure-ai-ml~=1.8.0
          - azure-keyvault-secrets==4.7.0
          - tiktoken==0.3.3
          - json5==0.9.11
          - scipy~=1.10.0
          - numpy~=1.21.0
          - pandas~=1.4.3
          - azureml-mlflow~=1.49.0
          - mltable~=1.3.0

code: ../../src

entry:
  file: ./generation_safety_quality/annotation_compute_histogram/run.py

args: >-
  --production_dataset ${{inputs.production_dataset}}
  --metric_names ${{inputs.metric_names}}
  --model_deployment_name ${{inputs.model_deployment_name}}
  --workspace_connection_arm_id ${{inputs.workspace_connection_arm_id}}
  $[[--prompt_column_name ${{inputs.prompt_column_name}}]]
  $[[--completion_column_name ${{inputs.completion_column_name}}]]
  $[[--context_column_name ${{inputs.context_column_name}}]]
  $[[--ground_truth_column_name ${{inputs.ground_truth_column_name}}]]
  $[[--sample_rate ${{inputs.sample_rate}}]]
  --histogram ${{outputs.histogram}}
  --samples_index ${{outputs.samples_index}}
  --groundedness_violations ${{outputs.groundedness_violations}}
  --fluency_violations ${{outputs.fluency_violations}}
  --similarity_violations ${{outputs.similarity_violations}}
  --coherence_violations ${{outputs.coherence_violations}}
  --relevance_violations ${{outputs.relevance_violations}}

identity:
  type: managed