$schema: https://azuremlschemas.azureedge.net/latest/pipelineComponent.schema.json
name: oss_distillation_pipeline
version: 0.0.9
type: pipeline


display_name: OSS Distillation Pipeline
description: Component to generate data from teacher model enpoint and finetune student model on generated dataset

inputs:
  # Compute parameters
  instance_type_pipeline_validation:
    type: string
    optional: True
    description: Instance type to be used for validation component. The parameter compute_pipeline_validation must be set to 'serverless' for instance_type to be used.
  instance_type_data_generation:
    type: string
    optional: true
    default: Standard_D4as_v4
    description: Instance type to be used for finetune component in case of virtual cluster compute, eg. Singularity.ND40_v2. The parameter compute_finetune must be set to 'serverless' for instance_type to be used
  instance_type_data_import:
    type: string
    optional: true
    default: Singularity.ND96amrs_A100_v4
    description: Instance type to be used for data_import component in case of virtual cluster compute, eg. Singularity.D8_v3. The parameter compute_data_import must be set to 'serverless' for instance_type to be used
  instance_type_finetune:
    type: string
    optional: true
    default: Singularity.ND96amrs_A100_v4
    description: Instance type to be used for finetune component in case of virtual cluster compute, eg. Singularity.ND40_v2. The parameter compute_finetune must be set to 'serverless' for instance_type to be used

  compute_pipeline_validation:
    type: string
    optional: True
    default: 'serverless'
    description: compute to be used for validation component

  compute_data_generation:
    type: string
    optional: true
    default: 'serverless'
    description: >-
      compute to be used for model_import eg. provide 'FT-Cluster' if
      your compute is named 'FT-Cluster'. Special characters like \ and ' are invalid in the parameter value.
      If compute cluster name is provided, instance_type field will be ignored and the respective cluster will be used
  compute_data_import:
    type: string
    optional: true
    default: 'serverless'
    description: >-
      compute to be used for model_import eg. provide 'FT-Cluster' if
      your compute is named 'FT-Cluster'. Special characters like \ and ' are invalid in the parameter value.
      If compute cluster name is provided, instance_type field will be ignored and the respective cluster will be used
  compute_finetune:
    type: string
    optional: true
    default: 'serverless'
    description: >-
      compute to be used for finetune eg. provide 'FT-Cluster' if your
      compute is named 'FT-Cluster'. Special characters like \ and ' are invalid in the parameter value.
      If compute cluster name is provided, instance_type field will be ignored and the respective cluster will be used

  # ########################### Data Generator Component ########################### #

  train_file_path:
    type: uri_file
    description: Path to the registered training data asset. The supported data formats are `jsonl`, `json`, `csv`, `tsv` and `parquet`.
    mode: rw_mount

  validation_file_path:
    type: uri_file
    optional: true
    description: Path to the registered validation data asset. The supported data formats are `jsonl`, `json`, `csv`, `tsv` and `parquet`.
    mode: rw_mount

  teacher_model_endpoint_name:
    type: string
    optional: true
    description: Teacher model endpoint name

  teacher_model_endpoint_url:
    type: string
    optional: true
    description: Teacher model endpoint URL

  teacher_model_endpoint_key: 
    type: string
    optional: true
    description: Teacher model endpoint key

  teacher_model_max_new_tokens:
    type: integer
    default: 128
    description: Teacher model max_new_tokens inference parameter

  teacher_model_temperature:
    type: number
    default: 0.2
    description: Teacher model temperature inference parameter

  teacher_model_top_p:
    type: number
    default: 0.1
    description: Teacher model top_p inference parameter

  teacher_model_frequency_penalty:
    type: number
    default: 0.0
    description: Teacher model frequency penalty inference parameter

  teacher_model_presence_penalty:
    type: number
    default: 0.0
    description: Teacher model presence penalty inference parameter

  teacher_model_stop:
    type: string
    optional: true
    description: Teacher model stop inference parameter

  request_batch_size:
    type: integer
    default: 10
    description: No of data records to hit teacher model endpoint in one go

  min_endpoint_success_ratio:
    type: number
    default: 0.7
    description: >
      The minimum value of (successful_requests / total_requests) required for classifying inference as successful.
      If (successful_requests / total_requests) < min_endpoint_success_ratio, the experiment will be marked as failed. 
      By default it is 0.7 (0 means all requests are allowed to fail while 1 means no request should fail.)

  enable_chain_of_thought:
    type: string
    optional: true
    default: "false"
    description: Enable Chain of thought for data generation

  enable_chain_of_density:
    type: string
    optional: true
    default: "false"
    description: Enable Chain of density for text summarization

  max_len_summary:
    type: integer
    optional: true
    default: 80
    description: Maximum Length Summary for text summarization 

  data_generation_task_type:
    type: string
    enum:
      - NLI
      - CONVERSATION
      - NLU_QA
      - MATH
      - SUMMARIZATION
    description: >
      Data generation task type. Supported values are:
      1. NLI: Generate Natural Language Inference data
      2. CONVERSATION: Generate conversational data (multi/single turn)
      3. NLU_QA: Generate Natural Language Understanding data for Question Answering data
      4. MATH: Generate Math data for numerical responses
      5. SUMMARIZATION: Generate Key Summary for an Article

  # ########################### Finetuning Component ########################### #

  number_of_gpu_to_use_finetuning:
    type: integer
    default: 1
    optional: true
    description: >-
      number of gpus to be used per node for finetuning, should be equal
      to number of gpu per node in the compute SKU used for finetune

  # Continual-Finetuning model path
  mlflow_model_path:
    type: mlflow_model
    optional: true
    description: MLflow model asset path. Special characters like \ and ' are invalid in the parameter value.
    mode: download
  pytorch_model_path:
    type: custom_model
    optional: true
    description: Pytorch model asset path. Special characters like \ and ' are invalid in the parameter value.
    mode: download

  # Training parameters
  num_train_epochs:
    type: integer
    default: 1
    optional: true
    description: training epochs

  per_device_train_batch_size:
    type: integer
    default: 1
    optional: true
    description: Train batch size

  learning_rate:
    type: number
    default: 3e-04
    optional: true
    description: Start learning rate.

  # Validation parameters
  system_properties:
    type: string
    optional: true
    description: Validation parameters propagated from pipeline.

  # Model parameters
  model_asset_id:
    type: string
    optional: false
    description: Asset id of model

  # Model registration
  registered_model_name:
    type: string
    optional: true
    description: Name of the registered model

outputs:
  output_model:
    type: uri_folder
    description: Output dir to save the finetuned lora weights
    mode: rw_mount

jobs:
  oss_distillation_validate_pipeline:
    type: command
    component: azureml:oss_distillation_validate_pipeline:0.0.3
    compute: '${{parent.inputs.compute_pipeline_validation}}'
    resources:
      instance_type: '${{parent.inputs.instance_type_pipeline_validation}}'
    identity:
      type: user_identity
    inputs:
      train_file_path: '${{parent.inputs.train_file_path}}'
      validation_file_path: '${{parent.inputs.validation_file_path}}'
      teacher_model_endpoint_name: '${{parent.inputs.teacher_model_endpoint_name}}'
      teacher_model_endpoint_url: '${{parent.inputs.teacher_model_endpoint_url}}'
      teacher_model_endpoint_key: '${{parent.inputs.teacher_model_endpoint_key}}'
      enable_chain_of_thought: '${{parent.inputs.enable_chain_of_thought}}'
      enable_chain_of_density: '${{parent.inputs.enable_chain_of_density}}'
      max_len_summary: '${{parent.inputs.max_len_summary}}'
      data_generation_task_type: '${{parent.inputs.data_generation_task_type}}'
      teacher_model_max_new_tokens: '${{parent.inputs.teacher_model_max_new_tokens}}'
      teacher_model_temperature: '${{parent.inputs.teacher_model_temperature}}'
      teacher_model_top_p: '${{parent.inputs.teacher_model_top_p}}'
      teacher_model_frequency_penalty: '${{parent.inputs.teacher_model_frequency_penalty}}'
      teacher_model_presence_penalty: '${{parent.inputs.teacher_model_presence_penalty}}'
      request_batch_size: '${{parent.inputs.request_batch_size}}'
      min_endpoint_success_ratio: '${{parent.inputs.min_endpoint_success_ratio}}'
      num_train_epochs: '${{parent.inputs.num_train_epochs}}'
      per_device_train_batch_size: '${{parent.inputs.per_device_train_batch_size}}'
      learning_rate: '${{parent.inputs.learning_rate}}'
    outputs:
      validation_info:
        type: uri_file
        path: azureml://datastores/${{default_datastore}}/paths/azureml/${{name}}/${{output_name}}.json

  oss_distillation_generate_data:
    type: command
    component: azureml:oss_distillation_generate_data:0.0.7
    compute: '${{parent.inputs.compute_data_generation}}'
    resources:
      instance_type: '${{parent.inputs.instance_type_data_generation}}'
    identity:
      type: user_identity
    inputs:  
      train_file_path: '${{parent.inputs.train_file_path}}'
      validation_file_path: '${{parent.inputs.validation_file_path}}'
      teacher_model_endpoint_name: '${{parent.inputs.teacher_model_endpoint_name}}'
      teacher_model_endpoint_url: '${{parent.inputs.teacher_model_endpoint_url}}'
      teacher_model_endpoint_key: '${{parent.inputs.teacher_model_endpoint_key}}'
      enable_chain_of_thought: '${{parent.inputs.enable_chain_of_thought}}'
      enable_chain_of_density: '${{parent.inputs.enable_chain_of_density}}'
      max_len_summary: '${{parent.inputs.max_len_summary}}'
      data_generation_task_type: '${{parent.inputs.data_generation_task_type}}'
      teacher_model_max_new_tokens: '${{parent.inputs.teacher_model_max_new_tokens}}'
      teacher_model_temperature: '${{parent.inputs.teacher_model_temperature}}'
      teacher_model_top_p: '${{parent.inputs.teacher_model_top_p}}'
      teacher_model_frequency_penalty: '${{parent.inputs.teacher_model_frequency_penalty}}'
      teacher_model_presence_penalty: '${{parent.inputs.teacher_model_presence_penalty}}'
      request_batch_size: '${{parent.inputs.request_batch_size}}'
      min_endpoint_success_ratio: '${{parent.inputs.min_endpoint_success_ratio}}'
      validation_output: '${{parent.jobs.oss_distillation_validate_pipeline.outputs.validation_info}}'
    outputs:
      generated_train_file_path: 
        type: uri_file
        path: azureml://datastores/${{default_datastore}}/paths/azureml/${{name}}/${{output_name}}.jsonl
      generated_validation_file_path: 
        type: uri_file
        path: azureml://datastores/${{default_datastore}}/paths/azureml/${{name}}/${{output_name}}.jsonl

  oss_text_generation_data_import:
    type: command
    component: azureml:oss_text_generation_data_import:0.0.21
    compute: '${{parent.inputs.compute_data_import}}'
    resources:
      instance_type: '${{parent.inputs.instance_type_data_import}}'
      properties:
        singularity:
          imageVersion: ''
          SLATier: 'Premium'
          priority: 'Medium'
    environment_variables:
      _AZUREML_CR_ENABLE_ITP_CAP: "false"
    inputs:
      train_file_path: '${{parent.jobs.oss_distillation_generate_data.outputs.generated_train_file_path}}'
      validation_file_path: '${{parent.jobs.oss_distillation_generate_data.outputs.generated_validation_file_path}}'
      system_properties: '${{parent.inputs.system_properties}}'

  oss_chat_completion_finetune:
    type: command
    component: azureml:oss_chat_completion_finetune:0.0.24
    compute: '${{parent.inputs.compute_finetune}}'
    resources:
      instance_type: '${{parent.inputs.instance_type_finetune}}'
      properties:
        singularity:
          imageVersion: ''
          SLATier: 'Premium'
          priority: 'Medium'
    environment_variables:
      _AZUREML_CR_ENABLE_ITP_CAP: "false"
    inputs:
      task_name: "ChatCompletion"
      mlflow_model_path: '${{parent.inputs.mlflow_model_path}}'
      model_asset_id: '${{parent.inputs.model_asset_id}}'
      pytorch_model_path: '${{parent.inputs.pytorch_model_path}}'
      dataset_input: '${{parent.jobs.oss_text_generation_data_import.outputs.output_dataset}}'
      batch_size: 1000
      pad_to_max_length: "false"
      max_seq_length: 8192
      number_of_gpu_to_use_finetuning: '${{parent.inputs.number_of_gpu_to_use_finetuning}}'
      apply_lora: "true"
      lora_alpha: 128
      lora_r: 8
      lora_dropout: 0
      num_train_epochs: '${{parent.inputs.num_train_epochs}}'
      max_steps: -1
      per_device_train_batch_size: '${{parent.inputs.per_device_train_batch_size}}'
      per_device_eval_batch_size: '${{parent.inputs.per_device_train_batch_size}}'
      auto_find_batch_size: "false"
      optim: adamw_hf
      learning_rate: '${{parent.inputs.learning_rate}}'
      warmup_steps: 0
      weight_decay: 0.1
      adam_beta1: 0.9
      adam_beta2: 0.95
      adam_epsilon: 1e-05
      gradient_accumulation_steps: 1
      eval_accumulation_steps: 1
      lr_scheduler_type: cosine
      precision: 16
      seed: 42
      enable_full_determinism: "false"
      dataloader_num_workers: 0
      ignore_mismatched_sizes: "false"
      max_grad_norm: 1.0
      evaluation_strategy: epoch
      evaluation_steps_interval: 0.0
      eval_steps: 500
      logging_strategy: steps
      logging_steps: 10
      metric_for_best_model: loss
      resume_from_checkpoint: "false"
      save_total_limit: 1
      apply_early_stopping: "false"
      early_stopping_patience: 0
      apply_deepspeed: "true"
      deepspeed_stage: 3
      apply_ort: "false"
      system_properties: '${{parent.inputs.system_properties}}'
      registered_model_name: '${{parent.inputs.registered_model_name}}'
      model_registration_tag: "isDistill:True"
    outputs:
      output_model: '${{parent.outputs.output_model}}'
