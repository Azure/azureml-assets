$schema: https://azuremlschemas.azureedge.net/latest/pipelineComponent.schema.json
name: oss_chat_completion_pipeline
version: 0.0.28
type: pipeline
display_name: OSS Chat Completion Pipeline
description: FTaaS Pipeline component for chat completion

inputs:
  # Compute parameters
  instance_type_data_import:
    type: string
    optional: true
    default: Singularity.D8_v3
    description: Instance type to be used for data_import component in case of virtual cluster compute, eg. Singularity.D8_v3. 
      The parameter compute_data_import must be set to 'virtual cluster' for instance_type to be used
  instance_type_finetune:
    type: string
    optional: true
    default: Singularity.ND40_v2
    description: Instance type to be used for finetune component in case of virtual cluster compute, eg. Singularity.ND40_v2. 
      The parameter compute_finetune must be set to 'virtual cluster' for instance_type to be used
  number_of_gpu_to_use_finetuning:
    type: integer
    default: 1
    optional: true
    description: >-
      number of gpus to be used per node for finetuning, should be equal
      to number of gpu per node in the compute SKU used for finetune

  # Continual-Finetuning model path
  mlflow_model_path:
    type: mlflow_model
    optional: true
    description: MLflow model asset path. Special characters like \ and ' are invalid in the parameter value.
    mode: download
  pytorch_model_path:
    type: custom_model
    optional: true
    description: Pytorch model asset path. Special characters like \ and ' are invalid in the parameter value.
    mode: download

  # Dataset path Parameters
  train_file_path:
    type: uri_file
    optional: false
    description: Path to the registered training data asset. The supported data formats are `jsonl`, `json`, `csv`, `tsv` and `parquet`. Special characters like \ and ' are invalid in the parameter value.
    mode: rw_mount

  validation_file_path:
    type: uri_file
    optional: true
    description: Path to the registered validation data asset. The supported data formats are `jsonl`, `json`, `csv`, `tsv` and `parquet`. Special characters like \ and ' are invalid in the parameter value.
    mode: rw_mount

  # Finetuning parameters
  # Training parameters
  max_seq_length:
    type: integer
    optional: true
    default: 8192
    description: Default is 8192.

  num_train_epochs:
    type: integer
    default: 1
    optional: true
    description: training epochs

  per_device_train_batch_size:
    type: integer
    default: 1
    optional: true
    description: Train batch size

  learning_rate:
    type: number
    default: 3e-04
    optional: true
    description: Start learning rate.

  # Validation parameters
  system_properties:
    type: string
    optional: true
    description: Validation parameters propagated from pipeline.

  # Compute parameters
  compute_data_import:
    type: string
    optional: true
    default: 'virtual cluster'
    description: >-
      compute to be used for model_import eg. provide 'FT-Cluster' if
      your compute is named 'FT-Cluster'. Special characters like \ and ' are invalid in the parameter value.
      If compute cluster name is provided, instance_type field will be ignored and the respective cluster will be used
  compute_finetune:
    type: string
    optional: true
    default: 'virtual cluster'
    description: >-
      compute to be used for finetune eg. provide 'FT-Cluster' if your
      compute is named 'FT-Cluster'. Special characters like \ and ' are invalid in the parameter value.
      If compute cluster name is provided, instance_type field will be ignored and the respective cluster will be used

  # Model parameters
  model_asset_id:
    type: string
    optional: false
    description: Asset id of model

  # Model registration
  registered_model_name:
    type: string
    optional: true
    description: Name of the registered model

outputs:
  output_model:
    type: uri_folder
    description: Output dir to save the finetuned lora weights
    mode: rw_mount

jobs:
  oss_text_generation_data_import:
    type: command
    component: azureml:oss_text_generation_data_import:0.0.28
    compute: '${{parent.inputs.compute_data_import}}'
    resources:
      instance_type: '${{parent.inputs.instance_type_data_import}}'
      properties:
        singularity:
          imageVersion: ''
          SLATier: 'Premium'
          priority: 'Medium'
    environment_variables:
      _AZUREML_CR_ENABLE_ITP_CAP: "false"
    inputs:
      task_name: "ChatCompletion"
      train_file_path: '${{parent.inputs.train_file_path}}'
      validation_file_path: '${{parent.inputs.validation_file_path}}'
      system_properties: '${{parent.inputs.system_properties}}'
      user_column_names: 'messages'
  oss_chat_completion_finetune:
    type: command
    component: azureml:oss_chat_completion_finetune:0.0.28
    compute: '${{parent.inputs.compute_finetune}}'
    resources:
      instance_type: '${{parent.inputs.instance_type_finetune}}'
      properties:
        singularity:
          imageVersion: ''
          SLATier: 'Premium'
          priority: 'Medium'
    environment_variables:
      _AZUREML_CR_ENABLE_ITP_CAP: "false"
    inputs:
      task_name: "ChatCompletion"
      mlflow_model_path: '${{parent.inputs.mlflow_model_path}}'
      model_asset_id: '${{parent.inputs.model_asset_id}}'
      pytorch_model_path: '${{parent.inputs.pytorch_model_path}}'
      dataset_input: '${{parent.jobs.oss_text_generation_data_import.outputs.output_dataset}}'
      batch_size: 1000
      pad_to_max_length: "false"
      max_seq_length: '${{parent.inputs.max_seq_length}}'
      number_of_gpu_to_use_finetuning: '${{parent.inputs.number_of_gpu_to_use_finetuning}}'
      apply_lora: "true"
      lora_alpha: 128
      lora_r: 8
      lora_dropout: 0
      num_train_epochs: '${{parent.inputs.num_train_epochs}}'
      max_steps: -1
      per_device_train_batch_size: '${{parent.inputs.per_device_train_batch_size}}'
      per_device_eval_batch_size: '${{parent.inputs.per_device_train_batch_size}}'
      auto_find_batch_size: "false"
      optim: adamw_hf
      learning_rate: '${{parent.inputs.learning_rate}}'
      warmup_steps: 0
      weight_decay: 0.1
      adam_beta1: 0.9
      adam_beta2: 0.95
      adam_epsilon: 1e-05
      gradient_accumulation_steps: 1
      eval_accumulation_steps: 1
      lr_scheduler_type: cosine
      precision: 16
      seed: 42
      enable_full_determinism: "false"
      dataloader_num_workers: 0
      ignore_mismatched_sizes: "false"
      max_grad_norm: 1.0
      evaluation_strategy: epoch
      evaluation_steps_interval: 0.0
      eval_steps: 500
      logging_strategy: steps
      logging_steps: 10
      metric_for_best_model: loss
      resume_from_checkpoint: "false"
      save_total_limit: 1
      apply_early_stopping: "false"
      early_stopping_patience: 0
      apply_deepspeed: "true"
      deepspeed_stage: 3
      apply_ort: "false"
      system_properties: '${{parent.inputs.system_properties}}'
      registered_model_name: '${{parent.inputs.registered_model_name}}'
    outputs:
      output_model: '${{parent.outputs.output_model}}'
