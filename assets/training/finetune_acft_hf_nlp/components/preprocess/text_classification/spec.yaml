$schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json
name: text_classification_datapreprocess
version: 0.0.76
type: command

is_deterministic: true

display_name: Text Classification DataPreProcess
description: Component to preprocess data for single label classification task. See [docs](https://aka.ms/azureml/components/text_classification_datapreprocess) to learn more.

environment: azureml://registries/azureml/environments/acft-hf-nlp-gpu/versions/95

code: ../../../src/preprocess

inputs:
  # Text Claasification task type
  task_name:
    type: string
    optional: false
    enum:
    - SingleLabelClassification
    default: SingleLabelClassification
    description: Text Classification task type

  # task arguments
  # sample input1
  # {"sentence":"Our friends won't buy this analysis, let alone the next one we propose.","label":true,"idx":0}
  # For this setting, `sentence1_key` is sentence, and `label_key` is label. The optional parameter `sentence2_key` can be ignored

  # sample input2
  # {"sentence1":"Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .","sentence2":"Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .","label":1,"idx":0}
  # If your dataset follows above pattern, `sentence1_key` should be set as sentence1 and `sentence2_key` as sentence2 `label_key` as label.

  sentence1_key:
    type: string
    optional: false
    description: Key for `sentence1_key` in each example line

  sentence2_key:
    type: string
    optional: true
    description: Key for `sentence2_key` in each example line

  label_key:
    type: string
    optional: false
    description: label key in each example line

  batch_size:
    type: integer
    min: 1
    optional: true
    default: 1000
    description: Number of examples to batch before calling the tokenization function

  # Tokenization params
  pad_to_max_length:
    type: string
    enum:
    - "true"
    - "false"
    default: "false"
    optional: true
    description: If set to True, the returned sequences will be padded according to the model's padding side and padding index, up to their `max_seq_length`. If no `max_seq_length` is specified, the padding is done up to the model's max length.

  max_seq_length:
    type: integer
    optional: true
    default: -1
    description: Controls the maximum length to use when pad_to_max_length parameter is set to `true`. Default is -1 which means the padding is done up to the model's max length. Else will be padded to `max_seq_length`.

  # Data inputs
  # Please note that either `train_file_path` or `train_mltable_path` needs to be passed. In case both are passed, `mltable path` will take precedence. The validation and test paths are optional and an automatic split from train data happens if they are not passed.
  # If both validation and test files are missing, 10% of train data will be assigned to each of them and the remaining 80% will be used for training
  # If anyone of the file is missing, 20% of the train data will be assigned to it and the remaining 80% will be used for training
  train_file_path:
    type: uri_file
    optional: true
    description: Path to the registered training data asset. The supported data formats are `jsonl`, `json`, `csv`, `tsv` and `parquet`.
    mode: rw_mount

  validation_file_path:
    type: uri_file
    optional: true
    description: Path to the registered validation data asset. The supported data formats are `jsonl`, `json`, `csv`, `tsv` and `parquet`.
    mode: rw_mount

  test_file_path:
    type: uri_file
    optional: true
    description: Path to the registered test data asset. The supported data formats are `jsonl`, `json`, `csv`, `tsv` and `parquet`.
    mode: rw_mount

  train_mltable_path:
    type: mltable
    optional: true
    description: Path to the registered training data asset in `mltable` format.

  validation_mltable_path:
    type: mltable
    optional: true
    description: Path to the registered validation data asset in `mltable` format.

  test_mltable_path:
    type: mltable
    optional: true
    description: Path to the registered test data asset in `mltable` format.

  # Dataset parameters
  model_selector_output:
    type: uri_folder
    optional: false
    description: output folder of model selector containing model metadata like config, checkpoints, tokenizer config
    mode: rw_mount

outputs:
  output_dir:
    type: uri_folder
    description: The folder contains the tokenized output of the train, validation and test data along with the tokenizer files used to tokenize the data
    mode: rw_mount

command: >-
  python preprocess.py --task_name SingleLabelClassification --sentence1_key '${{inputs.sentence1_key}}' $[[--sentence2_key '${{inputs.sentence2_key}}']] --label_key '${{inputs.label_key}}' $[[--batch_size '${{inputs.batch_size}}']] $[[--pad_to_max_length '${{inputs.pad_to_max_length}}']] $[[--max_seq_length '${{inputs.max_seq_length}}']] $[[--train_file_path '${{inputs.train_file_path}}']] $[[--validation_file_path '${{inputs.validation_file_path}}']] $[[--test_file_path '${{inputs.test_file_path}}']] $[[--train_mltable_path '${{inputs.train_mltable_path}}']] $[[--validation_mltable_path '${{inputs.validation_mltable_path}}']] $[[--test_mltable_path '${{inputs.test_mltable_path}}']] --model_selector_output '${{inputs.model_selector_output}}' --output_dir '${{outputs.output_dir}}'
