$schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json
name: vllm_evaluation_component
version: 0.0.5
type: command
is_deterministic: true
display_name: vLLM Evaluation Component
description: Component for evaluating model responses using vLLM on financial reasoning tasks
environment: azureml://registries/test_centralus/environments/verl_trainer_rl/versions/1
code: ./

distribution:
  type: pytorch

inputs:
  model_path:
    type: uri_folder
    optional: false
    description: "Path to the model to evaluate"
    mode: ro_mount
  validation_file:
    type: uri_file
    optional: false
    description: "Path to the validation JSONL file"
  max_prompt_length:
    type: integer
    default: 2048
    optional: true
    description: "Maximum prompt length"
  max_response_length:
    type: integer
    default: 1024
    optional: true
    description: "Maximum response length for generation"
  batch_size:
    type: integer
    default: 16
    optional: true
    description: "Batch size for evaluation"
  temperature:
    type: number
    default: 0.7
    optional: true
    description: "Sampling temperature for generation"
  top_p:
    type: number
    default: 0.9
    optional: true
    description: "Top-p sampling parameter"
  tensor_parallel_size:
    type: integer
    default: 1
    optional: true
    description: "Tensor parallel size for vLLM"
  gpu_memory_utilization:
    type: number
    default: 0.8
    optional: true
    description: "GPU memory utilization for vLLM"
  dtype:
    type: string
    enum:
    - "float16"
    - "bfloat16"
    - "float32"
    default: "bfloat16"
    optional: true
    description: "Data type for model inference"
  extraction_method:
    type: string
    enum:
    - "strict"
    - "flexible"
    default: "strict"
    optional: true
    description: "Method for extracting solutions from responses (strict: looks for #### pattern, flexible: extracts last number)"
  n_gpus_per_node:
    type: integer
    default: 1
    optional: true
    description: "Number of GPUs per node"

outputs:
  evaluation_results:
    type: uri_folder
    description: "Directory containing evaluation results and metrics"

command: >-
  python vllm_evaluation.py
  --model_path '${{inputs.model_path}}'
  --validation_file '${{inputs.validation_file}}'
  $[[--max_prompt_length '${{inputs.max_prompt_length}}']]
  $[[--max_response_length '${{inputs.max_response_length}}']]
  $[[--batch_size '${{inputs.batch_size}}']]
  $[[--temperature '${{inputs.temperature}}']]
  $[[--top_p '${{inputs.top_p}}']]
  $[[--tensor_parallel_size '${{inputs.tensor_parallel_size}}']]
  $[[--gpu_memory_utilization '${{inputs.gpu_memory_utilization}}']]
  $[[--dtype '${{inputs.dtype}}']]
  $[[--extraction_method '${{inputs.extraction_method}}']]
  $[[--n_gpus_per_node '${{inputs.n_gpus_per_node}}']]
  --output_dir '${{outputs.evaluation_results}}'
