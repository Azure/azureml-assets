$schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json
name: compute_metrics
display_name: Compute Metrics
description: Calculate model performance metrics, given ground truth and prediction data.

version: 0.0.36
type: command
tags:
  type: evaluation
  sub_type: compute_metrics

inputs:
  task:
    type: string
    optional: false
    default: tabular-classification
    enum: [
      tabular-classification,
      tabular-classification-multilabel,
      tabular-regression,
      tabular-forecasting,
      text-classification,
      text-classification-multilabel,
      text-named-entity-recognition,
      text-summarization,
      question-answering,
      text-translation,
      text-generation,
      fill-mask,
      image-classification,
      image-classification-multilabel,
      chat-completion,
      image-object-detection,
      image-instance-segmentation,
    ]
    description: "Task type"
  ground_truth:
    type: uri_folder
    optional: true
    mode: ro_mount
    description: "Ground Truths of Test Data as a 1-column JSON Lines file"
  ground_truth_column_name:
    type: string
    optional: true
    description: "Column name which contains ground truths in provided uri file for ground_truth. (Optional if we have one column name.)"
  prediction:
    type: uri_folder
    optional: false
    mode: ro_mount
    description: "Model Predictions as a 1-column JSON Lines file"
  prediction_column_name:
    type: string
    optional: true
    description: "Column name which contains ground truths in provided uri file for prediction. (Optional if we have one column name.)"
  prediction_probabilities:
    type: uri_folder
    optional: true
    mode: ro_mount
    description: "Predictions Probabilities as 1-column JSON Lines file"
  evaluation_config:
    type: uri_file
    optional: true
    mode: ro_mount
    description: "Additional parameters required for evaluation."
  evaluation_config_params:
    type: string
    optional: true
    description: "JSON Serialized string of evaluation_config"
  openai_config_params:
    type: string
    optional: true
    description: "Required OpenAI Params for calculating GPT Based metrics for QnA task"

outputs:
  evaluation_result:
    type: uri_folder

is_deterministic: True
code: ../../src
environment: azureml://registries/azureml/environments/model-evaluation/labels/latest

command: >-
  python download_metrics_dependencies.py && 
  python compute_metrics.py
  --task '${{inputs.task}}'
  $[[--ground_truths '${{inputs.ground_truth}}']]
  --predictions '${{inputs.prediction}}'
  --output '${{outputs.evaluation_result}}'
  $[[--prediction_probabilities '${{inputs.prediction_probabilities}}']]
  $[[--config-file-name '${{inputs.evaluation_config}}']]
  $[[--ground_truths_column_name '${{inputs.ground_truth_column_name}}']]
  $[[--predictions_column_name '${{inputs.prediction_column_name}}']]
  $[[--config_str '${{inputs.evaluation_config_params}}']]
  $[[--openai-config-params '${{inputs.openai_config_params}}']]
