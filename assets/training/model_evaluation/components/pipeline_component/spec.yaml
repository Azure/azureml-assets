$schema: https://azuremlschemas.azureedge.net/latest/pipelineComponent.schema.json
name: model_evaluation_pipeline
version: 0.0.36
type: pipeline
display_name: Model Evaluation Pipeline
description: Pipeline component for model evaluation for supported tasks. \
    Generates predictions on a given model, followed by computing model performance metrics to score the model quality for supported tasks.

tags:
  type: evaluation
  sub_type: subgraph

inputs:
  compute_name:
    type: string
    default: serverless
  instance_type:
    type: string
    default: STANDARD_NC24S_V3
  # model prediction
  task:
    type: string
    default: tabular-classification
    enum: [
      tabular-classification,
      tabular-classification-multilabel,
      tabular-regression,
      text-classification,
      text-classification-multilabel,
      text-named-entity-recognition,
      text-summarization,
      question-answering,
      text-translation,
      text-generation,
      fill-mask,
      image-classification,
      image-classification-multilabel,
      chat-completion,
      image-object-detection,
      image-instance-segmentation,
    ]
    description: "Task type"
  test_data: 
    type: uri_folder
    optional: false
    description: "Test Data"
  mlflow_model:
    type: mlflow_model 
    optional: false
    description: "Mlflow Model (could be a registered model or part of another pipeline"
  label_column_name:
    type: string
    optional: true
    description: "Label column name in provided test dataset (Ex: label)"
  input_column_names:
    type: string
    optional: true
    description: "Input column names in provided test dataset (Ex : column1). Add comma delimited values in case of multiple input columns (Ex : column1,column2)"
  device:
    type: string
    optional: false
    default: auto
    enum: [auto, cpu, gpu]
  batch_size:
    type: integer
    optional: true

  # compute metrics
  evaluation_config:
    type: uri_file 
    optional: true
    description: "Additional parameters required for evaluation. See How to create a config [here](https://microsoft.sharepoint.com/:f:/t/SDAutoML/EhDl9iADAR5MlCnlG4sy1NkBi5SfbdaZwKSFnUQD6ckeRg?e=cI7kaB)"
  evaluation_config_params:
    type: string
    optional: true
    description: "JSON Serialized string of evaluation_config"
  openai_config_params:
    type: string
    optional: true
    description: "Required OpenAI Params for calculating GPT Based metrics for QnA task"

outputs:
  evaluation_result:
    type: uri_folder
    description: Output dir to save the evaluation result
  
jobs:
  validation_trigger_model_evaluation:
    type: command
    component: azureml:validation_trigger_model_evaluation:0.0.36
    compute: '${{parent.inputs.compute_name}}'
    resources:
      instance_type: '${{parent.inputs.instance_type}}'
    inputs:
      compute_name: '${{parent.inputs.compute_name}}'
      compute_instance_type: '${{parent.inputs.instance_type}}'
      task: '${{parent.inputs.task}}'
      test_data: '${{parent.inputs.test_data}}'
      mlflow_model_path: '${{parent.inputs.mlflow_model}}'
      label_column_name: '${{parent.inputs.label_column_name}}'
      input_column_names: '${{parent.inputs.input_column_names}}'
      device: '${{parent.inputs.device}}'
      batch_size: '${{parent.inputs.batch_size}}'
      evaluation_config: '${{parent.inputs.evaluation_config}}'
      evaluation_config_params: '${{parent.inputs.evaluation_config_params}}'

  validation_succeeded:
    type: if_else
    condition: ${{parent.jobs.validation_trigger_model_evaluation.outputs.output}}
    true_block: ${{parent.jobs.model_prediction}}

  model_prediction:
    type: command
    component: azureml:model_prediction:0.0.36
    compute: '${{parent.inputs.compute_name}}'
    resources:
      instance_type: '${{parent.inputs.instance_type}}'
    inputs:
      task: '${{parent.inputs.task}}'
      test_data: '${{parent.inputs.test_data}}'
      mlflow_model: '${{parent.inputs.mlflow_model}}'
      label_column_name: '${{parent.inputs.label_column_name}}'
      input_column_names: '${{parent.inputs.input_column_names}}'
      device: '${{parent.inputs.device}}'
      batch_size: '${{parent.inputs.batch_size}}'
      evaluation_config: '${{parent.inputs.evaluation_config}}'
      evaluation_config_params: '${{parent.inputs.evaluation_config_params}}'
  
  compute_metrics:
    type: command
    component: azureml:compute_metrics:0.0.36
    compute: '${{parent.inputs.compute_name}}'
    resources:
      instance_type: '${{parent.inputs.instance_type}}'
    inputs:
      task: '${{parent.inputs.task}}'
      ground_truth: '${{parent.jobs.model_prediction.outputs.ground_truth}}'
      ground_truth_column_name: '${{parent.inputs.label_column_name}}'
      prediction: '${{parent.jobs.model_prediction.outputs.predictions}}'
      prediction_column_name: predictions
      prediction_probabilities: '${{parent.jobs.model_prediction.outputs.prediction_probabilities}}'
      evaluation_config: '${{parent.inputs.evaluation_config}}'
      evaluation_config_params: '${{parent.inputs.evaluation_config_params}}'
      openai_config_params: '${{parent.inputs.openai_config_params}}'
    outputs:
      evaluation_result: '${{parent.outputs.evaluation_result}}'
