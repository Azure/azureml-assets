$schema: https://azuremlschemas.azureedge.net/latest/pipelineComponent.schema.json
type: pipeline

version: 0.0.13
name: image_object_detection_pipeline
display_name: Image Object Detection Pipeline
description: Pipeline component for image object detection.

is_deterministic: false

inputs:
  # ------------------- Computes -------------------
  compute_model_import:
    type: string
    optional: false
    description: Compute to be used for framework_selector eg. provide 'gpu-cluster' if your compute is named 'gpu-cluster'.

  compute_finetune:
    type: string
    optional: false
    description: Compute to be used for running the selected framework eg. provide 'gpu-cluster' if your compute is named 'gpu-cluster'.

  instance_count:
    type: integer
    default: 1
    optional: true
    description: Number of nodes to be used for finetuning (used for distributed training).

  process_count_per_instance:
    type: integer
    default: 1
    optional: true
    description: Number of gpus to be used per node for finetuning, should be equal to number of gpu per node in the compute SKU used for finetune.

  # ------------------- Model Framework Selector -------------------
  model_name:
    type: string
    optional: true
    description: Name of the model. Based on this model name, a framework will be selected (Hugging Face, MM Detection).

  download_from_source:
      type: boolean
      optional: true
      default: false
      description: Download model directly from MMDetection instead of system registry

  # ------------------- Data Inputs ------------------
  training_data:
    type: mltable
    optional: false
    description: Path to MLTable for training data.

  validation_data:
    type: mltable
    optional: true
    description: Path to MLTable for validation data.

  # ------------------- Task Type ------------------
  task_type:
    description: Type of the task
    type: string
    optional: false
    default: 'image-object-detection'
    enum: ['image-object-detection']

  # ------------------- Primary Metric ----------------
  primary_metric:
    description: Primary metric for the task
    type: string
    optional: true
    default: 'mean_average_precision'
    enum: ['mean_average_precision']

  # ------------------- Hyperparamters ------------------
  ams_gradient:
    description: Enable ams_gradient when optimizer is adam or adamw.
    type: boolean
    optional: true

  beta1:
    description: Value of beta1 when optimizer is adam or adamw. Must be a float in the range [0, 1].
    type: number
    optional: true
    min: 0
    max: 1

  beta2:
    description: Value of beta2 when optimizer is adam or adamw. Must be a float in the range [0, 1].
    type: number
    optional: true
    min: 0
    max: 1

  box_detections_per_image:
    description: Maximum number of detections per image, for all classes. Must be a positive integer.
    type: integer
    optional: true
    min: 1

  box_score_threshold:
    description: During inference, only return proposals with a classification score greater than box_score_threshold. Must be a float in the range [0, 1].
    type: number
    optional: true
    min: 0
    max: 1

  checkpoint_frequency:
    description: Frequency to store model checkpoints. Must be a positive integer.
    type: integer
    optional: true
    min: 0

  checkpoint_run_id:
    description: The run ID of the experiment that has a pretrained checkpoint for incremental training.
    type: string
    optional: true

  early_stopping:
    description: Enable early stopping logic during training.
    type: boolean
    optional: true

  early_stopping_patience:
    description: Minimum number of epochs or validation evaluations with no primary metric improvement before the run is stopped. Must be a positive integer.
    type: integer
    optional: true
    min: 1

  early_stopping_delay:
    description: Minimum number of epochs or validation evaluations to wait before primary metric improvement is tracked for early stopping. Must be a positive integer.
    type: integer
    optional: true
    min: 1

  evaluation_frequency:
    description: Frequency to evaluate validation dataset to get metric scores. Must be a positive integer.
    type: integer
    optional: true
    min: 1

  gradient_accumulation_step:
    description: Number of forward passes without updating the model weights while accumulating the gradients of those steps, and then using the accumulated gradients to compute the weight updates. Must be a positive integer.
    type: integer
    optional: true
    min: 1

  layers_to_freeze:
    description: How many layers to freeze for your model. For instance, passing 2 as value for seresnext means freezing layer0 and layer1 referring to the below supported model layer info. Must be a positive integer.
    type: integer
    optional: true
    min: 1

  learning_rate:
    description: Initial learning rate
    type: number
    optional: true
    min: 0
    max: 1

  learning_rate_scheduler:
    description: Type of learning rate scheduler. Must be warmup_cosine or step.
    type: string
    optional: true
    enum: ['warmup_cosine', 'step']

  max_size:
    description: Maximum size of the image to be rescaled before feeding it to the backbone.
    type: integer
    optional: true
    min: 1

  min_size:
    description: Minimum size of the image to be rescaled before feeding it to the backbone. Must be a positive integer.
    type: integer
    optional: true
    min: 1

  momentum:
    description: Value of momentum when optimizer is sgd. Must be a float in the range [0, 1].
    type: number
    optional: true
    min: 0
    max: 1

  nesterov:
    description: Enable nesterov when optimizer is sgd.
    type: boolean
    optional: true

  nms_iou_threshold:
    description: IOU threshold used during inference in non-maximum suppression post processing. Must be a float in the range [0, 1].
    type: number
    optional: true
    min: 0
    max: 1

  number_of_epochs:
    description: Number of training epochs
    type: integer
    optional: true
    min: 1

  number_of_workers:
    description: Number of subprocesses to use for data loading (PyTorch only). 0 means that the data will be loaded in the main process.
    type: integer
    optional: true

  optimizer:
    description: Type of optimizer
    type: string
    optional: true
    enum: ['sgd', 'adam', 'adamw']

  random_seed:
    description: Random seed that will be set at the beginning of training.
    type: integer
    optional: true

  step_lr_gamma:
    description: Value of gamma when learning rate scheduler is step. Must be a float in the range [0, 1].
    type: number
    optional: true
    min: 0
    max: 1

  step_lr_step_size:
    description: Value of step size when learning rate scheduler is step. Must be a positive integer.
    type: integer
    optional: true
    min: 0

  tile_grid_size:
    description: The grid size to use for tiling each image. Should be passed as a string in '3x2' format. Example --tile_grid_size '3x2'. For more information please visit https://learn.microsoft.com/en-us/azure/machine-learning/how-to-use-automl-small-object-detect?tabs=CLI-v2.
    type: string
    optional: true

  tile_overlap_ratio:
    description: Overlap ratio between adjacent tiles in each dimension. Must be float in the range of [0, 1).
    type: number
    optional: true
    min: 0
    max: 1

  tile_predictions_nms_threshold:
    description: The IOU threshold to use to perform NMS while merging predictions from tiles and image. Used in validation/ inference. Must be float in the range of [0, 1].
    type: number
    optional: true
    min: 0
    max: 1

  training_batch_size:
    description: Training batch size.
    type: integer
    optional: true
    min: 1

  validation_batch_size:
    description: Validation batch size.
    type: integer
    optional: true
    min: 1

  validation_iou_threshold:
    description: IOU threshold for box matching when computing validation metrics. Must be a float in the range [0.1, 1].
    type: number
    optional: true
    min: 0.1
    max: 1

  validation_metric_type:
    description: Metric computation method to use for validation metrics. Must be none, coco, voc, or coco_voc.
    type: string
    optional: true
    default: 'voc'
    enum: ['none', 'coco', 'voc', 'coco_voc']

  warmup_cosine_lr_cycles:
    description: Value of cosine cycle when learning rate scheduler is warmup_cosine. Must be a float in the range [0, 1].
    type: number
    optional: true
    min: 0
    max: 1

  warmup_cosine_lr_warmup_epochs:
    description: Value of warmup epochs when learning rate scheduler is warmup_cosine. Must be a positive integer.
    type: integer
    optional: true
    min: 0

  weight_decay:
    description: Value of weight decay used by the optimizer.
    type: number
    optional: true
    min: 0
    max: 1

  # ------------------- Yolov5 Model Specific Hyperparamters ------------------
  model_size:
    description: Model size for yolov5.
    type: string
    optional: true
    default: medium
    enum: ['small', 'medium', 'large', 'xlarge']

  multi_scale:
    description: Enable multi-scale image by varying image size by +/- 50%.
    type: boolean
    optional: true

  image_size:
    description: Image size for train and validation for yolov5 model.
    type: integer
    optional: true
    min: 1

outputs:
  pytorch_model_folder:
    type: custom_model
    description: Trained pytorch model.
  mlflow_model_folder:
    type: mlflow_model
    description: The trained MLFlow model.

jobs:

  finetune_common_validation:
    type: command
    component: azureml:finetune_common_validation:0.0.2
    compute: ${{parent.inputs.compute_model_import}}
    inputs:
      train_mltable_path: ${{parent.inputs.training_data}}
      validation_mltable_path: ${{parent.inputs.validation_data}}
      compute_model_import: ${{parent.inputs.compute_model_import}}
      compute_finetune: ${{parent.inputs.compute_finetune}}
      task_name: ${{parent.inputs.task_type}}
      user_column_names: image_url, label
      task_specific_extra_params: '"model_family=MmDetectionImage;model_name=${{parent.inputs.model_name}};metric_for_best_model=${{parent.inputs.primary_metric}};number_of_epochs=${{parent.inputs.number_of_epochs}}"'

  framework_selector:
    type: command
    component: azureml:image_framework_selector:0.0.12
    compute: ${{parent.inputs.compute_model_import}}
    inputs:
      task_type: ${{parent.inputs.task_type}}
      model_name: ${{parent.inputs.model_name}}
      validation_output: ${{parent.jobs.finetune_common_validation.outputs.validation_info}}

  image_object_detection_runtime_component:
    type: command
    component:  azureml:train_object_detection_model:0.0.7
    compute: ${{parent.inputs.compute_finetune}}
    resources:
      shm_size: '16g'
    inputs:
      training_data: ${{parent.inputs.training_data}}
      validation_data: ${{parent.inputs.validation_data}}
      ams_gradient: ${{parent.inputs.ams_gradient}}
      beta1: ${{parent.inputs.beta1}}
      beta2: ${{parent.inputs.beta2}}
      box_detections_per_image: ${{parent.inputs.box_detections_per_image}}
      box_score_threshold: ${{parent.inputs.box_score_threshold}}
      checkpoint_frequency: ${{parent.inputs.checkpoint_frequency}}
      checkpoint_run_id: ${{parent.inputs.checkpoint_run_id}}
      early_stopping: ${{parent.inputs.early_stopping}}
      early_stopping_patience: ${{parent.inputs.early_stopping_patience}}
      early_stopping_delay: ${{parent.inputs.early_stopping_delay}}
      evaluation_frequency: ${{parent.inputs.evaluation_frequency}}
      gradient_accumulation_step:  ${{parent.inputs.gradient_accumulation_step}}
      layers_to_freeze: ${{parent.inputs.layers_to_freeze}}
      learning_rate: ${{parent.inputs.learning_rate}}
      learning_rate_scheduler:  ${{parent.inputs.learning_rate_scheduler}}
      max_size: ${{parent.inputs.max_size}}
      min_size: ${{parent.inputs.min_size}}
      model_name: ${{parent.inputs.model_name}}
      model_size: ${{parent.inputs.model_size}}
      momentum: ${{parent.inputs.momentum}}
      multi_scale: ${{parent.inputs.multi_scale}}
      nesterov: ${{parent.inputs.nesterov}}
      nms_iou_threshold: ${{parent.inputs.nms_iou_threshold}}
      number_of_epochs: ${{parent.inputs.number_of_epochs}}
      number_of_workers: ${{parent.inputs.number_of_workers}}
      optimizer: ${{parent.inputs.optimizer}}
      random_seed: ${{parent.inputs.random_seed}}
      step_lr_gamma: ${{parent.inputs.step_lr_gamma}}
      step_lr_step_size: ${{parent.inputs.step_lr_step_size}}
      tile_grid_size: ${{parent.inputs.tile_grid_size}}
      tile_overlap_ratio: ${{parent.inputs.tile_overlap_ratio}}
      tile_predictions_nms_threshold: ${{parent.inputs.tile_predictions_nms_threshold}}
      training_batch_size: ${{parent.inputs.training_batch_size}}
      validation_batch_size: ${{parent.inputs.validation_batch_size}}
      validation_iou_threshold:  ${{parent.inputs.validation_iou_threshold}}
      validation_metric_type: ${{parent.inputs.validation_metric_type}}
      warmup_cosine_lr_cycles: ${{parent.inputs.warmup_cosine_lr_cycles}}
      warmup_cosine_lr_warmup_epochs: ${{parent.inputs.warmup_cosine_lr_warmup_epochs}}
      weight_decay: ${{parent.inputs.weight_decay}}

  mm_detection_model_import:
    type: command
    component: azureml:mmdetection_image_objectdetection_instancesegmentation_model_import:0.0.12
    compute: ${{parent.inputs.compute_model_import}}
    inputs:
      model_family: 'MmDetectionImage'
      model_name: ${{parent.inputs.model_name}}
      download_from_source: ${{parent.inputs.download_from_source}}
      validation_output: ${{parent.jobs.finetune_common_validation.outputs.validation_info}}

  mm_detection_finetune:
    type: command
    component: azureml:mmdetection_image_objectdetection_instancesegmentation_finetune:0.0.12
    compute: ${{parent.inputs.compute_finetune}}
    distribution:
      type: pytorch
      process_count_per_instance: ${{parent.inputs.process_count_per_instance}}
    resources:
      instance_count: ${{parent.inputs.instance_count}}
      shm_size: '16g'
    inputs:
      # Model path is same as what is output of model selector
      model_path: ${{parent.jobs.mm_detection_model_import.outputs.output_dir}}
      training_data: ${{parent.inputs.training_data}}
      validation_data: ${{parent.inputs.validation_data}}
      image_min_size: ${{parent.inputs.min_size}}
      image_max_size: ${{parent.inputs.max_size}}
      iou_threshold: ${{parent.inputs.nms_iou_threshold}}
      box_score_threshold: ${{parent.inputs.box_score_threshold}}
      early_stopping: ${{parent.inputs.early_stopping}}
      early_stopping_patience: ${{parent.inputs.early_stopping_patience}}
      evaluation_steps: ${{parent.inputs.evaluation_frequency}}
      gradient_accumulation_step: ${{parent.inputs.gradient_accumulation_step}}
      learning_rate: ${{parent.inputs.learning_rate}}
      learning_rate_scheduler: ${{parent.inputs.learning_rate_scheduler}}
      number_of_epochs: ${{parent.inputs.number_of_epochs}}
      number_of_workers: ${{parent.inputs.number_of_workers}}
      optimizer: ${{parent.inputs.optimizer}}
      random_seed: ${{parent.inputs.random_seed}}
      save_as_mlflow_model: true
      save_steps: ${{parent.inputs.checkpoint_frequency}}
      task_name: ${{parent.inputs.task_type}}
      metric_for_best_model: ${{parent.inputs.primary_metric}}
      training_batch_size: ${{parent.inputs.training_batch_size}}
      validation_batch_size: ${{parent.inputs.validation_batch_size}}
      weight_decay: ${{parent.inputs.weight_decay}}
      extra_optim_args: '"momentum=${{parent.inputs.momentum}};nesterov=${{parent.inputs.nesterov}}"'

  condition_node:
    type: if_else
    true_block: ${{parent.jobs.image_object_detection_runtime_component}}
    condition: ${{parent.jobs.framework_selector.outputs.output}}
    false_block: ${{parent.jobs.mm_detection_model_import}}

  output_selector:
    type: command
    component: azureml:image_model_output_selector:0.0.11
    compute: ${{parent.inputs.compute_model_import}}
    inputs:
      mlflow_model_t: ${{parent.jobs.image_object_detection_runtime_component.outputs.mlflow_model_folder}}
      pytorch_model_t: ${{parent.jobs.image_object_detection_runtime_component.outputs.pytorch_model_folder}}
      condition: ${{parent.jobs.framework_selector.outputs.output}}
      mlflow_model_f: ${{parent.jobs.mm_detection_finetune.outputs.mlflow_model_folder}}
      pytorch_model_f: ${{parent.jobs.mm_detection_finetune.outputs.pytorch_model_folder}}
    outputs:
      mlflow_model_folder: ${{parent.outputs.mlflow_model_folder}}
      pytorch_model_folder: ${{parent.outputs.pytorch_model_folder}}
