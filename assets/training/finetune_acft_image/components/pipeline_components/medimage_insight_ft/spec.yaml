$schema: https://azuremlschemas.azureedge.net/latest/pipelineComponent.schema.json
name: medimage_insight_ft_pipeline
version: 0.0.20
type: pipeline
display_name: Medical Image Insight Embedding Generator and Classification Adapter Pipeline
description: Pipeline Component to finetune Hugging Face pretrained models for chat completion task. The component supports optimizations such as LoRA, Deepspeed and ONNXRuntime for performance enhancement. See [docs](https://aka.ms/azureml/components/chat_completion_pipeline) to learn more.

distribution:
  type: mpi

inputs:

  mlflow_embedding_model_path:
    type: uri_folder
    optional: false
    description: Path to the MLflow model to be imported.
    mode: ro_mount

  eval_image_tsv:
    type: uri_file
    optional: false
    description: Path to the evaluation image TSV file.
    mode: ro_mount

  eval_text_tsv:
    type: uri_file
    optional: false
    description: Path to the evaluation text TSV file.
    mode: ro_mount

  image_tsv:
    type: uri_file
    optional: false
    description: Path to the image TSV file.
    mode: ro_mount

  text_tsv:
    type: uri_file
    optional: false
    description: Path to the text TSV file.
    mode: ro_mount

  label_file:
    type: uri_file
    optional: false
    description: Path to the label file.
    mode: ro_mount

  conf_files:
    type: uri_file
    optional: false
    description: Path to the configuration files.
    mode: ro_mount

  log_every:
    type: integer
    min: 1
    default: 10
    optional: true
    description: Log every n steps.

  resume:
    type: boolean
    default: false
    optional: true
    description: Resume training from checkpoint.

  reset_data_loader:
    type: boolean
    default: false
    optional: true
    description: Reset data loader.

  fp16:
    type: boolean
    default: false
    optional: true
    description: Use mixed precision training.

  zero_stage:
    type: integer
    min: 0
    default: 0
    optional: true
    description: Zero optimization stage.

  deepspeed:
    type: boolean
    default: false
    optional: true
    description: Use DeepSpeed for distributed training.

  save_per_optim_steps:
    type: integer
    min: 1
    default: 100
    optional: true
    description: Save model every n optimization steps.

  eval_per_optim_steps:
    type: integer
    min: 1
    default: 100
    optional: true
    description: Evaluate model every n optimization steps.

  grad_clipping:
    type: number
    default: 1.0
    optional: true
    description: Gradient clipping value.

  world_size:
    type: integer
    min: 1
    default: 8
    optional: true
    description: Number of GPUs on which to finetune.

  set_sampler_epoch:
    type: boolean
    default: False
    optional: true
    description: Set sampler epoch.

  verbose:
    type: boolean
    default: false
    optional: true
    description: Verbose logging.

  workers:
    type: integer
    min: 0
    default: 6
    optional: true
    description: Number of workers.

  pin_memory:
    type: boolean
    default: false
    optional: true
    description: Pin memory.

  knn:
    type: integer
    min: 0
    default: 200
    optional: true
    description: Number of nearest neighbors.

  batch_size_per_gpu:
    type: integer
    min: 1
    default: 2
    optional: true
    description: Batch size per GPU.

  max_num_epochs:
    type: integer
    min: 1
    default: 10000
    optional: true
    description: Maximum number of epochs.

  gradient_accumulate_step:
    type: integer
    min: 1
    default: 1
    optional: true
    description: Gradient accumulation steps.

  drop_path_rate:
    type: number
    default: 0.2
    optional: true
    description: Drop path rate.

  context_length:
    type: integer
    default: 77
    optional: true
    description: Context length.

  scale:
    type: number
    default: 0.8
    optional: true
    description: Scale range.

  ratio:
    type: number
    default: 0.75
    optional: true
    description: Aspect ratio range.

  re_prob:
    type: number
    default: 0.25
    optional: true
    description: Random erasing probability.

  hflip:
    type: number
    default: 0.0
    optional: true
    description: Horizontal flip probability.

  vflip:
    type: number
    default: 0.0
    optional: true
    description: Vertical flip probability.

  text_augmentation:
    type: integer
    default: 1
    optional: true
    description: Text augmentation flag.

  batch_size_total:
    type: integer
    default: 1024
    optional: true
    description: Total batch size.

  decay:
    type: number
    default: 0.999
    optional: true
    description: Decay rate.

  start_learning_rate:
    type: number
    default: 0.00001
    optional: true
    description: Start learning rate.
#start of adapter pipeline inputs 
  instance_type_preprocess:
      type: string
      optional: true
      default: Standard_d12_v2
      description: Instance type to be used for preprocess component in case of serverless compute, eg. standard_d12_v2. 
        The parameter compute_preprocess must be set to 'serverless' for instance_type to be used

  instance_type_finetune:
    type: string
    optional: true
    default: Standard_nc24rs_v3
    description: Instance type to be used for finetune component in case of serverless compute, eg. standard_nc24rs_v3. 
      The parameter compute_finetune must be set to 'serverless' for instance_type to be used

  compute_preprocess:
    type: string
    optional: true
    default: serverless
    description: compute to be used for preprocess eg. provide 'FT-Cluster' if your
      compute is named 'FT-Cluster'. Special characters like \ and ' are invalid in the parameter value.
      If compute cluster name is provided, instance_type field will be ignored and the respective cluster will be used

  compute_finetune:
    type: string
    optional: true
    default: serverless
    description: compute to be used for finetune eg. provide 'FT-Cluster' if your
      compute is named 'FT-Cluster'. Special characters like \ and ' are invalid in the parameter value.
      If compute cluster name is provided, instance_type field will be ignored and the respective cluster will be used

  train_dataloader_batch_size:
    type: integer
    min: 1
    default: 8
    optional: true
    description: Batch size for the training dataloader.

  validation_dataloader_batch_size:
    type: integer
    min: 1
    default: 1
    optional: true
    description: Batch size for the validation dataloader.

  train_dataloader_workers:
    type: integer
    min: 0
    default: 2
    optional: true
    description: Number of workers for the training dataloader.

  validation_dataloader_workers:
    type: integer
    min: 0
    default: 2
    optional: true
    description: Number of workers for the validation dataloader.

  hidden_dimensions:
    type: integer
    min: 1
    default: 512
    optional: true
    description: Number of hidden dimensions.

  input_channels:
    type: integer
    min: 1
    default: 1024
    optional: true
    description: Number of input channels.

  learning_rate:
    type: number
    default: 0.0003
    optional: true
    description: Learning rate for training.

  max_epochs:
    type: integer
    min: 1
    default: 10
    optional: true
    description: Maximum number of epochs for training.

outputs:
  save_dir:
    type: uri_folder
    description: Directory to save the model.
    mode: rw_mount
  
  mlflow_model_folder:
    type: mlflow_model
    description: Directory to save the MLflow model.
    mode: rw_mount
  
  merged_mlfow_model:
    type: mlflow_model
    description: Path to save the output model.
    mode: rw_mount


jobs:
  medical_image_embedding_model_finetune:
    type: command
    component: azureml://registries/mablonde-registry-101/components/medimgage_embedding_finetune/versions/0.0.23
    compute: '${{parent.inputs.compute_finetune}}'
    resources:
      instance_type: '${{parent.inputs.instance_type_finetune}}'
    inputs:
      mlflow_model_path: '${{parent.inputs.mlflow_embedding_model_path}}'
      log_every: ${{parent.inputs.log_every}}
      resume: ${{parent.inputs.resume}}
      reset_data_loader: ${{parent.inputs.reset_data_loader}}
      fp16: ${{parent.inputs.fp16}}
      zero_stage: ${{parent.inputs.zero_stage}}
      deepspeed: ${{parent.inputs.deepspeed}}
      save_per_optim_steps: ${{parent.inputs.save_per_optim_steps}}
      eval_per_optim_steps: ${{parent.inputs.eval_per_optim_steps}}
      grad_clipping: ${{parent.inputs.grad_clipping}}
      set_sampler_epoch: ${{parent.inputs.set_sampler_epoch}}
      verbose: ${{parent.inputs.verbose}}
      workers: ${{parent.inputs.workers}}
      world_size: ${{parent.inputs.world_size}}
      pin_memory: ${{parent.inputs.pin_memory}}
      eval_image_tsv: '${{parent.inputs.eval_image_tsv}}'
      eval_text_tsv: '${{parent.inputs.eval_text_tsv}}'
      image_tsv: '${{parent.inputs.image_tsv}}'
      text_tsv: '${{parent.inputs.text_tsv}}'
      label_file: '${{parent.inputs.label_file}}'
      knn: ${{parent.inputs.knn}}
      batch_size_per_gpu: ${{parent.inputs.batch_size_per_gpu}}
      max_num_epochs: ${{parent.inputs.max_num_epochs}}
      gradient_accumulate_step: ${{parent.inputs.gradient_accumulate_step}}
      conf_files: '${{parent.inputs.conf_files}}'
    outputs:
      save_dir: '${{parent.outputs.save_dir}}'
      mlflow_model_folder: '${{parent.outputs.mlflow_model_folder}}'
  medical_image_embedding_datapreprocessing_train:
    type: command
    component: azureml://registries/mablonde-registry-101/components/medical_image_embedding_datapreprocessing/versions/0.0.11
    compute: '${{parent.inputs.compute_preprocess}}'
    resources:
      instance_type: '${{parent.inputs.instance_type_preprocess}}'
    inputs:
      mlflow_model_path: '${{parent.jobs.medical_image_embedding_model_finetune.outputs.mlflow_model_folder}}'
      image_tsv: '${{parent.inputs.image_tsv}}'
  medical_image_embedding_datapreprocessing_validation:
    type: command
    component: azureml://registries/mablonde-registry-101/components/medical_image_embedding_datapreprocessing/versions/0.0.11
    compute: '${{parent.inputs.compute_preprocess}}'
    resources:
      instance_type: '${{parent.inputs.instance_type_preprocess}}'
    inputs:
      mlflow_model_path: '${{parent.jobs.medical_image_embedding_model_finetune.outputs.mlflow_model_folder}}'
      image_tsv: '${{parent.inputs.eval_image_tsv}}'  
  medimgage_adapter_finetune:
    type: command
    component: azureml://registries/mablonde-registry-101/components/medimgage_adapter_finetune/versions/0.0.7
    compute: '${{parent.inputs.compute_finetune}}'
    resources:
      instance_type: '${{parent.inputs.instance_type_finetune}}'
    inputs:
      train_data_path: '${{parent.jobs.medical_image_embedding_datapreprocessing_train.outputs.output_pkl}}'
      validation_data_path: '${{parent.jobs.medical_image_embedding_datapreprocessing_validation.outputs.output_pkl}}'
      train_text_tsv: '${{parent.inputs.text_tsv}}'
      validation_text_tsv: '${{parent.inputs.eval_text_tsv}}'
      train_dataloader_batch_size: '${{parent.inputs.train_dataloader_batch_size}}'
      validation_dataloader_batch_size: '${{parent.inputs.validation_dataloader_batch_size}}'
      train_dataloader_workers: '${{parent.inputs.train_dataloader_workers}}'
      validation_dataloader_workers: '${{parent.inputs.validation_dataloader_workers}}'
      label_file: '${{parent.inputs.label_file}}'
      hidden_dimensions: '${{parent.inputs.hidden_dimensions}}'
      input_channels: '${{parent.inputs.input_channels}}'
      learning_rate: '${{parent.inputs.learning_rate}}'
      max_epochs: '${{parent.inputs.max_epochs}}'
  medimage_embedding_adapter_merge:
    type: command
    component: azureml://registries/mablonde-registry-101/components/medimage_embedding_adapter_merge/versions/0.0.13
    compute: '${{parent.inputs.compute_finetune}}'
    resources:
      instance_type: '${{parent.inputs.instance_type_finetune}}'
    inputs:
      adapter_model: '${{parent.jobs.medimgage_adapter_finetune.outputs.output_model_path}}'
      mlflow_model: '${{parent.jobs.medical_image_embedding_model_finetune.outputs.mlflow_model_folder}}'
      label_file: '${{parent.inputs.label_file}}'
      hidden_dimensions: '${{parent.inputs.hidden_dimensions}}'
      input_channels: '${{parent.inputs.input_channels}}'
    outputs:
      output_dir: '${{parent.outputs.merged_mlfow_model}}'