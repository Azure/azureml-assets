$schema: https://azuremlschemas.azureedge.net/latest/pipelineComponent.schema.json
type: pipeline

version: 0.0.24
name: image_classification_pipeline
display_name: Image Classification Pipeline
description: Pipeline component for image classification.

is_deterministic: false

inputs:
  # ------------------- Computes -------------------
  compute_model_import:
    type: string
    optional: false
    description: Compute to be used for framework_selector eg. provide 'cpu-cluster' if your compute is named 'cpu-cluster'.

  compute_finetune:
    type: string
    optional: false
    description: Compute to be used for running the selected framework eg. provide 'gpu-cluster' if your compute is named 'gpu-cluster'.

  instance_count:
    type: integer
    default: 1
    optional: true
    description: Number of nodes to be used for finetuning (used for distributed training)

  process_count_per_instance:
    type: integer
    default: 1
    optional: true
    description: Number of gpus to be used per node for finetuning, should be equal to number of gpu per node in the compute SKU used for finetune.

  # ------------------- Model Framework Selector -------------------
  model_name:
    description: Name of the model. Based on this model name, a framework will be selected (Hugging Face, MM Detection).
    type: string
    optional: true

  download_from_source:
    type: boolean
    optional: true
    default: false
    description: Download model directly from HuggingFace instead of system registry

  # ------------------- Data Inputs ------------------
  training_data:
    type: mltable
    optional: false
    description: Path to MLTable for training data.

  validation_data:
    type: mltable
    optional: true
    description: Path to MLTable for validation data.

  # ------------------- Classification Type ------------------
  task_type:
    description: Whether a single image can have multiple labels.
    type: string
    enum: ['image-classification', 'image-classification-multilabel']

  # ------------------- Primary Metric ----------------
  primary_metric:
    description: Primary metric for the task
    type: string
    optional: true
    enum: ['accuracy', 'iou']

  # ------------------- Hyperparamters ------------------
  ams_gradient:
    description: Enable ams_gradient when optimizer is adam or adamw.
    type: boolean
    optional: true

  beta1:
    description: Value of beta1 when optimizer is adam or adamw. Must be a float in the range [0, 1].
    type: number
    optional: true
    min: 0
    max: 1

  beta2:
    description: Value of beta2 when optimizer is adam or adamw. Must be a float in the range [0, 1].
    type: number
    optional: true
    min: 0
    max: 1

  checkpoint_frequency:
    description: Frequency to store model checkpoints. Must be a positive integer.
    type: integer
    optional: true
    min: 0

  checkpoint_run_id:
    description: The run ID of the experiment that has a pretrained checkpoint for incremental training.
    type: string
    optional: true

  early_stopping:
    description: Enable early stopping logic during training.
    type: boolean
    optional: true

  early_stopping_patience:
    description: Minimum number of epochs or validation evaluations with no primary metric improvement before the run is stopped. Must be a positive integer.
    type: integer
    optional: true
    min: 1

  early_stopping_delay:
    description: Minimum number of epochs or validation evaluations to wait before primary metric improvement is tracked for early stopping. Must be a positive integer.
    type: integer
    optional: true
    min: 1

  evaluation_frequency:
    description: Frequency to evaluate validation dataset to get metric scores. Must be a positive integer.
    type: integer
    optional: true
    min: 1

  gradient_accumulation_step:
    description: Number of forward passes without updating the model weights while accumulating the gradients of those steps, and then using the accumulated gradients to compute the weight updates. Must be a positive integer.
    type: integer
    optional: true
    min: 1

  layers_to_freeze:
    description: How many layers to freeze for your model. For instance, passing 2 as value for seresnext means freezing layer0 and layer1 referring to the below supported model layer info. Must be a positive integer.
    type: integer
    optional: true
    min: 1

  learning_rate:
    description: Initial learning rate.
    type: number
    optional: true
    min: 0
    max: 1

  learning_rate_scheduler:
    description: Type of learning rate scheduler. Must be warmup_cosine or step.
    type: string
    optional: true
    enum: ['warmup_cosine', 'step']

  momentum:
    description: Value of momentum when optimizer is sgd. Must be a float in the range [0, 1].
    type: number
    optional: true
    min: 0
    max: 1

  nesterov:
    description: Enable nesterov when optimizer is sgd.
    type: boolean
    optional: true

  number_of_epochs:
    description: Number of training epochs
    type: integer
    optional: true
    min: 1

  number_of_workers:
    description: Number of subprocesses to use for data loading (PyTorch only). 0 means that the data will be loaded in the main process.
    type: integer
    optional: true

  optimizer:
    description: Type of optimizer
    type: string
    optional: true
    enum: ['sgd', 'adam', 'adamw']

  random_seed:
    description: Random seed that will be set at the beginning of training.
    type: integer
    optional: true

  step_lr_gamma:
    description: Value of gamma when learning rate scheduler is step. Please check for https://learn.microsoft.com/azure/machine-learning/reference-automl-images-hyperparameters more information.
    type: number
    optional: true

  step_lr_step_size:
    description: Value of step size when learning rate scheduler is step. Please check for https://learn.microsoft.com/azure/machine-learning/reference-automl-images-hyperparameters more information.
    type: integer
    optional: true

  training_batch_size:
    description: Training batch size.
    type: integer
    optional: true
    min: 1

  training_crop_size:
    description: Image crop size that's input to your neural network for training dataset. Notes - seresnext doesn't take an arbitrary size. ViT-variants should have the same validation_crop_size and training_crop_size.
    type: integer
    optional: true
    min: 1

  validation_batch_size:
    description: Validation batch size.
    type: integer
    optional: true
    min: 1

  validation_crop_size:
    description: Image crop size that's input to your neural network for validation dataset. Note - seresnext doesn't take an arbitrary size. ViT-variants should have the same validation_crop_size and training_crop_size.
    type: integer
    optional: true
    min: 1

  validation_resize_size:
    description: Image size to which to resize before cropping for validation dataset. Note - seresnext doesn't take an arbitrary size.
    type: integer
    optional: true
    min: 1

  warmup_cosine_lr_cycles:
    description: Value of cosine cycle when learning rate scheduler is warmup_cosine. Please check for https://learn.microsoft.com/azure/machine-learning/reference-automl-images-hyperparameters more information.
    type: number
    optional: true

  warmup_cosine_lr_warmup_epochs:
    description: Value of warmup epochs when learning rate scheduler is warmup_cosine. Please check for https://learn.microsoft.com/azure/machine-learning/reference-automl-images-hyperparameters more information.
    type: integer
    optional: true

  weight_decay:
    description: Value of weight decay used by the optimizer.
    type: number
    optional: true
    min: 0
    max: 1

  weighted_loss:
    description: Value of weighted loss.
    type: integer
    optional: true

outputs:
  pytorch_model_folder:
    type: custom_model
    description: The trained pytorch model.
  mlflow_model_folder:
    type: mlflow_model
    description: The trained MLFlow model.

jobs:

  finetune_common_validation:
    type: command
    component: azureml:finetune_common_validation:0.0.9
    compute: ${{parent.inputs.compute_model_import}}
    inputs:
      train_mltable_path: ${{parent.inputs.training_data}}
      validation_mltable_path: ${{parent.inputs.validation_data}}
      compute_model_import: ${{parent.inputs.compute_model_import}}
      compute_finetune: ${{parent.inputs.compute_finetune}}
      task_name: ${{parent.inputs.task_type}}
      label_column_name: label
      user_column_names: image_url,label
      task_specific_extra_params: '"model_family=HuggingFaceImage;model_name=${{parent.inputs.model_name}};metric_for_best_model=${{parent.inputs.primary_metric}};number_of_epochs=${{parent.inputs.number_of_epochs}}"'

  framework_selector:
    type: command
    component: azureml:image_framework_selector:0.0.21
    compute: ${{parent.inputs.compute_model_import}}
    inputs:
      task_type: 'image-classification'
      model_name: ${{parent.inputs.model_name}}
      validation_output: ${{parent.jobs.finetune_common_validation.outputs.validation_info}}

  image_classification_runtime_component:
    type: command
    component: azureml:train_image_classification_model:0.0.14
    compute: ${{parent.inputs.compute_finetune}}
    resources:
      shm_size: '16g'
    inputs:
      training_data: ${{parent.inputs.training_data}}
      validation_data: ${{parent.inputs.validation_data}}
      ams_gradient: ${{parent.inputs.ams_gradient}}
      beta1: ${{parent.inputs.beta1}}
      beta2: ${{parent.inputs.beta2}}
      checkpoint_frequency: ${{parent.inputs.checkpoint_frequency}}
      checkpoint_run_id: ${{parent.inputs.checkpoint_run_id}}
      early_stopping: ${{parent.inputs.early_stopping}}
      early_stopping_patience: ${{parent.inputs.early_stopping_patience}}
      early_stopping_delay: ${{parent.inputs.early_stopping_delay}}
      evaluation_frequency: ${{parent.inputs.evaluation_frequency}}
      gradient_accumulation_step:  ${{parent.inputs.gradient_accumulation_step}}
      layers_to_freeze: ${{parent.inputs.layers_to_freeze}}
      learning_rate: ${{parent.inputs.learning_rate}}
      learning_rate_scheduler:  ${{parent.inputs.learning_rate_scheduler}}
      model_name: ${{parent.inputs.model_name}}
      momentum: ${{parent.inputs.momentum}}
      nesterov: ${{parent.inputs.nesterov}}
      number_of_epochs: ${{parent.inputs.number_of_epochs}}
      number_of_workers: ${{parent.inputs.number_of_workers}}
      optimizer: ${{parent.inputs.optimizer}}
      random_seed: ${{parent.inputs.random_seed}}
      step_lr_gamma: ${{parent.inputs.step_lr_gamma}}
      step_lr_step_size: ${{parent.inputs.step_lr_step_size}}
      task_type: ${{parent.inputs.task_type}}
      training_batch_size: ${{parent.inputs.training_batch_size}}
      training_crop_size: ${{parent.inputs.training_crop_size}}
      validation_batch_size: ${{parent.inputs.validation_batch_size}}
      validation_crop_size: ${{parent.inputs.validation_crop_size}}
      validation_resize_size: ${{parent.inputs.validation_resize_size}}
      warmup_cosine_lr_cycles: ${{parent.inputs.warmup_cosine_lr_cycles}}
      warmup_cosine_lr_warmup_epochs: ${{parent.inputs.warmup_cosine_lr_warmup_epochs}}
      weight_decay: ${{parent.inputs.weight_decay}}
      weighted_loss: ${{parent.inputs.weighted_loss}}

  hugging_face_model_import:
    type: command
    component: azureml:transformers_image_classification_model_import:0.0.21
    compute: ${{parent.inputs.compute_model_import}}
    inputs:
      model_family: 'HuggingFaceImage'
      model_name: ${{parent.inputs.model_name}}
      download_from_source: ${{parent.inputs.download_from_source}}
      validation_output: ${{parent.jobs.finetune_common_validation.outputs.validation_info}}

  hugging_face_finetune:
    type: command
    component: azureml:transformers_image_classification_finetune:0.0.22
    compute: ${{parent.inputs.compute_finetune}}
    distribution:
      type: pytorch
      process_count_per_instance: ${{parent.inputs.process_count_per_instance}}
    resources:
      instance_count: ${{parent.inputs.instance_count}}
      shm_size: '16g'
    inputs:
      # Model path is same as what is output of model selector
      model_path: ${{parent.jobs.hugging_face_model_import.outputs.output_dir}}
      training_data: ${{parent.inputs.training_data}}
      validation_data: ${{parent.inputs.validation_data}}
      early_stopping: ${{parent.inputs.early_stopping}}
      early_stopping_patience: ${{parent.inputs.early_stopping_patience}}
      evaluation_steps: ${{parent.inputs.evaluation_frequency}}
      gradient_accumulation_step: ${{parent.inputs.gradient_accumulation_step}}
      image_height: ${{parent.inputs.training_crop_size}}
      image_width: ${{parent.inputs.training_crop_size}}
      learning_rate: ${{parent.inputs.learning_rate}}
      learning_rate_scheduler: ${{parent.inputs.learning_rate_scheduler}}
      number_of_epochs: ${{parent.inputs.number_of_epochs}}
      number_of_workers: ${{parent.inputs.number_of_workers}}
      optimizer: ${{parent.inputs.optimizer}}
      random_seed: ${{parent.inputs.random_seed}}
      save_as_mlflow_model: true
      save_steps: ${{parent.inputs.checkpoint_frequency}}
      task_name: ${{parent.inputs.task_type}}
      metric_for_best_model: ${{parent.inputs.primary_metric}}
      training_batch_size: ${{parent.inputs.training_batch_size}}
      validation_batch_size: ${{parent.inputs.validation_batch_size}}
      weight_decay: ${{parent.inputs.weight_decay}}
      extra_optim_args: '"momentum=${{parent.inputs.momentum}};nesterov=${{parent.inputs.nesterov}}"'

  condition_node:
    type: if_else
    true_block: ${{parent.jobs.image_classification_runtime_component}}
    condition: ${{parent.jobs.framework_selector.outputs.output}}
    false_block: ${{parent.jobs.hugging_face_model_import}}

  output_selector:
    type: command
    component: azureml:image_model_output_selector:0.0.20
    compute: ${{parent.inputs.compute_model_import}}
    inputs:
      mlflow_model_t: ${{parent.jobs.image_classification_runtime_component.outputs.mlflow_model_folder}}
      pytorch_model_t: ${{parent.jobs.image_classification_runtime_component.outputs.pytorch_model_folder}}
      condition: ${{parent.jobs.framework_selector.outputs.output}}
      mlflow_model_f: ${{parent.jobs.hugging_face_finetune.outputs.mlflow_model_folder}}
      pytorch_model_f: ${{parent.jobs.hugging_face_finetune.outputs.pytorch_model_folder}}
    outputs:
      mlflow_model_folder: ${{parent.outputs.mlflow_model_folder}}
      pytorch_model_folder: ${{parent.outputs.pytorch_model_folder}}
