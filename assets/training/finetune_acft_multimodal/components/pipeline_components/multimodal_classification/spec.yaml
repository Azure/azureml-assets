$schema: https://azuremlschemas.azureedge.net/latest/pipelineComponent.schema.json
type: pipeline

version: 0.0.1
name: multimodal_classification_pipeline
display_name: Multimodal Classification Pipeline
description: Pipeline component for multimodal classification models.

is_deterministic: false

inputs:
  # Compute parameters
  compute_model_import:
    type: string
    optional: false
    description: compute to be used for model_selector eg. provide 'FT-Cluster' if your compute is named 'FT-Cluster'.

  compute_preprocess:
    type: string
    optional: false
    description: compute to be   used for preprocess eg. provide 'FT-Cluster' if your compute is named 'FT-Cluster'.

  compute_finetune:
    type: string
    optional: false
    description: compute to be used for finetune eg. provide 'FT-Cluster' if your compute is named 'FT-Cluster'.

  instance_count:
    type: integer
    default: 1
    optional: true
    description: Number of nodes to be used for finetuning (used for distributed training).

  process_count_per_instance:
    type: integer
    default: 1
    optional: true
    description: Number of gpus to be used per node for finetuning, should be equal to number of gpu per node in the compute SKU used for finetune.

  # ########################### Model Selector Component ########################### #
  data_modalities:
    type: string
    enum:
      - "text-image"
      - "text-image-tabular"
    default: "text-image-tabular"
    description: Modalities to be supported.

  # pytorch_model_path:
  #   type: custom_model
  #   optional: true
  #   description: Input folder path containing pytorch model in azureml registry.

  mlflow_model_path:
    type: mlflow_model
    optional: false
    description: Path to multimodal model in azureml registry.

  # ########################### Data Preprocessing Component ########################### #
  problem_type:
    type: string
    default: multimodal-classification-singlelabel
    optional: false
    enum:
      - multimodal-classification-singlelabel
      - multimodal-classification-multilabel
    description: Specify whether its single-label or multi-label classification task.

  label_column:
    type: string
    optional: false
    description: label column name.

  image_column:
    type: string
    optional: false
    description: Image column name.

  drop_columns:
    type: string
    default: ""
    optional: true
    description: Columns to ignore.

  numerical_columns_overrides:
    type: string
    default: ""
    optional: true
    description: Columns to treat as numerical. Overrides automatic column purpose detection.

  categorical_columns_overrides:
    type: string
    default: ""
    optional: true
    description: Columns to treat as categorical. Overrides automatic column purpose detection.

  text_columns_overrides:
    type: string
    default: ""
    optional: true
    description: Columns to treat as text. Overrides automatic column purpose detection.

  # Inputs
  training_data:
    type: mltable
    optional: false
    description: Enter the train mltable path.

  validation_data:
    type: mltable
    optional: false
    description: Enter the validation mltable path.

  # ########################### Finetuning Component ########################### #

  # Training parameters
  number_of_epochs:
    type: integer
    default: 1
    optional: true
    description: training epochs

  max_steps:
    type: integer
    default: -1
    optional: true
    description: If set to a positive number, the total number of training steps to perform. Overrides 'number_of_epochs'. In case of using a finite iterable dataset the training may stop before reaching the set number of steps when all data is exhausted.

  training_batch_size:
    type: integer
    default: 1
    optional: true
    description: Train batch size.

  validation_batch_size:
    type: integer
    default: 1
    optional: true
    description: Validation batch size.

  auto_find_batch_size:
    type: string
    enum:
      - "true"
      - "false"
    default: "false"
    optional: true
    description: Flag to enable auto finding of batch size. If the provided 'training_batch_size' goes into Out Of Memory (OOM) enabling auto_find_batch_size will find the correct batch size by iteratively reducing 'training_batch_size' by a factor of 2 till the OOM is fixed.

  optimizer:
    type: string
    default: adamw_hf
    optional: true
    enum:
      - adamw_hf
      - adamw_torch
      # - adamw_apex_fused
      - adafactor
    description: Optimizer to be used while training.

  learning_rate:
    type: number
    default: 0.00002
    optional: true
    description: Start learning rate. Defaults to linear scheduler.

  warmup_steps:
    type: integer
    default: 0
    optional: true
    description: Number of steps used for a linear warmup from 0 to learning_rate.

  weight_decay:
    type: number
    default: 0.0
    optional: true
    description: The weight decay to apply (if not zero) to all layers except all bias and LayerNorm weights in AdamW optimizer.

  adam_beta1:
    type: number
    default: 0.9
    optional: true
    description: The beta1 hyperparameter for the AdamW optimizer.

  adam_beta2:
    type: number
    default: 0.999
    optional: true
    description: The beta2 hyperparameter for the AdamW optimizer.

  adam_epsilon:
    type: number
    default: 1e-8
    optional: true
    description: The epsilon hyperparameter for the AdamW optimizer.

  gradient_accumulation_steps:
    type: integer
    default: 64
    optional: true
    description: Number of updates steps to accumulate the gradients for, before performing a backward/update pass.

  learning_rate_scheduler:
    type: string
    default: linear
    optional: true
    enum:
      - linear
      - cosine
      - cosine_with_restarts
      - polynomial
      - constant
      - constant_with_warmup
    description: The scheduler type to use.

  precision:
    type: string
    enum:
      - "32"
      - "16"
    default: "32"
    optional: true
    description: Apply mixed precision training. This can reduce memory footprint by performing operations in half-precision.

  random_seed:
    type: integer
    default: 42
    optional: true
    description: Random seed that will be set at the beginning of training.

  evaluation_strategy:
    type: string
    default: epoch
    optional: true
    enum:
      - epoch
      - steps
    description: The evaluation strategy to adopt during training.

  evaluation_steps_interval:
    type: number
    default: 0.0
    optional: true
    description: The evaluation steps in fraction of an epoch steps to adopt during training. Overwrites evaluation_steps if not 0.

  evaluation_steps:
    type: integer
    default: 500
    optional: true
    description: Number of update steps between two evals if evaluation_strategy='steps'.

  logging_strategy:
    type: string
    default: epoch
    optional: true
    enum:
      - epoch
      - steps
    description: The logging strategy to adopt during training.

  logging_steps:
    type: integer
    default: 500
    optional: true
    description: Number of update steps between two logs if logging_strategy='steps'.

  primary_metric:
    type: string
    default: loss
    optional: true
    enum:
      - loss
      - f1_macro
      - mcc
      - accuracy
      - precision_macro
      - recall_macro
    description: Specify the metric to use to compare two different models.

  resume_from_checkpoint:
    type: string
    default: "false"
    optional: true
    enum:
      - "true"
      - "false"
    description: Loads Optimizer, Scheduler and Trainer state for finetuning if true.

  save_total_limit:
    type: integer
    default: -1
    optional: true
    description: If a value is passed, will limit the total amount of checkpoints. Deletes the older checkpoints in output_dir. If the value is -1 saves all checkpoints".

  # Early Stopping Parameters
  apply_early_stopping:
    type: string
    default: "false"
    optional: true
    enum:
      - "true"
      - "false"
    description: Enable early stopping.

  early_stopping_patience:
    type: integer
    default: 1
    optional: true
    description: Stop training when the specified metric worsens for early_stopping_patience evaluation calls.

  early_stopping_threshold:
    type: number
    default: 0.0
    optional: true
    description: Denotes how much the specified metric must improve to satisfy early stopping conditions.

  # Deepspeed Parameters
  apply_deepspeed:
    type: string
    enum:
      - "true"
      - "false"
    default: "false"
    optional: true
    description: If set to true, will enable deepspeed for training.

  deepspeed_config:
    type: uri_file
    optional: true
    description: Deepspeed config to be used for finetuning.

  # ORT Parameters
  apply_ort:
    type: string
    enum:
      - "true"
      - "false"
    default: "false"
    optional: true
    description: If set to true, will use the ONNXRunTime training.

  # MLFlow Parameters
  save_as_mlflow_model:
    type: string
    enum:
      - "true"
      - "false"
    default: "true"
    optional: true
    description: If set to true, will save as mlflow model with pyfunc as flavour.


outputs:
  # ########################### Finetuning Component ########################### #
  mlflow_model_folder:
    type: mlflow_model
    description: Output dir to save the finetune model as mlflow model.
  pytorch_model_folder:
    type: custom_model
    description: Output dir to save the finetune model as torch model.

jobs:
  multimodal_classification_model_import:
    type: command
    component: azureml:multimodal_classification_model_import:0.0.1
    compute: ${{parent.inputs.compute_model_import}}
    inputs:
      data_modalities: ${{parent.inputs.data_modalities}}
      # pytorch_model_path: ${{parent.inputs.pytorch_model_path}}
      mlflow_model_path: ${{parent.inputs.mlflow_model_path}}

  multimodal_classification_data_preprocess:
    type: command
    component: azureml:multimodal_classification_datapreprocessing:0.0.1
    compute: ${{parent.inputs.compute_preprocess}}
    inputs:
      problem_type: ${{parent.inputs.problem_type}}
      label_column: ${{parent.inputs.label_column}}
      image_column: ${{parent.inputs.image_column}}
      drop_columns: ${{parent.inputs.drop_columns}}
      numerical_columns_overrides: ${{parent.inputs.numerical_columns_overrides}}
      categorical_columns_overrides: ${{parent.inputs.categorical_columns_overrides}}
      text_columns_overrides: ${{parent.inputs.text_columns_overrides}}
      training_data: ${{parent.inputs.training_data}}
      validation_data: ${{parent.inputs.validation_data}}
      model_selector_output: ${{parent.jobs.multimodal_classification_model_import.outputs.output_dir}}

  multimodal_classification_finetune:
    type: command
    component: azureml:multimodal_classification_finetune:0.0.1
    compute: ${{parent.inputs.compute_finetune}}
    distribution:
      type: pytorch
      process_count_per_instance: ${{parent.inputs.process_count_per_instance}}
    resources:
      instance_count: ${{parent.inputs.instance_count}}
    inputs:
      number_of_epochs: ${{parent.inputs.number_of_epochs}}
      max_steps: ${{parent.inputs.max_steps}}
      training_batch_size: ${{parent.inputs.training_batch_size}}
      validation_batch_size: ${{parent.inputs.validation_batch_size}}
      auto_find_batch_size: ${{parent.inputs.auto_find_batch_size}}
      optimizer: ${{parent.inputs.optimizer}}
      learning_rate: ${{parent.inputs.learning_rate}}
      warmup_steps: ${{parent.inputs.warmup_steps}}
      weight_decay: ${{parent.inputs.weight_decay}}
      adam_beta1: ${{parent.inputs.adam_beta1}}
      adam_beta2: ${{parent.inputs.adam_beta2}}
      adam_epsilon: ${{parent.inputs.adam_epsilon}}
      gradient_accumulation_steps: ${{parent.inputs.gradient_accumulation_steps}}
      learning_rate_scheduler: ${{parent.inputs.learning_rate_scheduler}}
      precision: ${{parent.inputs.precision}}
      random_seed: ${{parent.inputs.random_seed}}
      evaluation_strategy: ${{parent.inputs.evaluation_strategy}}
      evaluation_steps_interval: ${{parent.inputs.evaluation_steps_interval}}
      evaluation_steps: ${{parent.inputs.evaluation_steps}}
      logging_strategy: ${{parent.inputs.logging_strategy}}
      logging_steps: ${{parent.inputs.logging_steps}}
      primary_metric: ${{parent.inputs.primary_metric}}
      resume_from_checkpoint: ${{parent.inputs.resume_from_checkpoint}}
      save_total_limit: ${{parent.inputs.save_total_limit}}
      apply_early_stopping: ${{parent.inputs.apply_early_stopping}}
      early_stopping_patience: ${{parent.inputs.early_stopping_patience}}
      early_stopping_threshold: ${{parent.inputs.early_stopping_threshold}}
      apply_deepspeed: ${{parent.inputs.apply_deepspeed}}
      deepspeed: ${{parent.inputs.deepspeed_config}}
      apply_ort: ${{parent.inputs.apply_ort}}
      save_as_mlflow_model: ${{parent.inputs.save_as_mlflow_model}}
      preprocess_output: ${{parent.jobs.multimodal_classification_data_preprocess.outputs.output_dir}}
      model_selector_output: ${{parent.jobs.multimodal_classification_model_import.outputs.output_dir}}
    outputs:
      pytorch_model_folder: ${{parent.outputs.pytorch_model_folder}}
      mlflow_model_folder: ${{parent.outputs.mlflow_model_folder}}
