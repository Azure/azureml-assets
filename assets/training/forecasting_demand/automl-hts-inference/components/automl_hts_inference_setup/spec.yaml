$schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json
name: automl_hts_inference_setup_step
version: 0.0.2
display_name: AutoML HTS - Inference Setup
type: command

inputs:
  raw_data:
    type: uri_folder
    description: 'Folder URI with inference data.'
  instance_count:
    type: integer
    description: 'Number of nodes in a compute cluster we will run the inference step on.'
  max_concurrency_per_instance:
    type: integer
    description: 'Number of processes that will be run concurrently on any given node. This number should not be larger than 1/2 of the number of cores in an individual node in the specified cluster'
  parallel_step_timeout_in_seconds:
    type: integer
    description: 'The PRS step time out setting in seconds.'
    default: 3600
  train_run_id:
    optional: true
    type: string
    description: 'The train run id used for training models that will be used to generate forecasts.'
  train_experiment_name:
    optional: true
    type: string
    description: 'The train experiment used for inference'
  forecast_mode:
    optional: true
    type: string
    default: 'recursive'
    enum: ['recursive', 'rolling']
    description: 'The forecast mode used for inference. The possible values are `recursive` and `rolling`.'
  forecast_step:
    optional: true
    type: integer
    description: 'The forecast step used for rolling forecast. See more details here: https://learn.microsoft.com/en-us/azure/machine-learning/how-to-auto-train-forecast?view=azureml-api-2#evaluating-model-accuracy-with-a-rolling-forecast'
  allocation_method:
    type: string
    description: 'Method that allocates forecasts within a hierarchy. Possible values are average_historical_proportions and proportions_of_historical_average'
    default: 'average_historical_proportions'
    enum: ['average_historical_proportions', 'proportions_of_historical_average']
  forecast_level:
    type: string
    description: 'Specify the level of the hierarchy for which you are interested in obtaining the forecast for.'
  forecast_quantiles:
    type: string
    optional: true
    description: 'Space separated list of quantiles for forecasting jobs. It is applicable only when the forecast_mode is recursive.'
  optional_train_metadata:
    type: uri_folder
    optional: true
    description: 'Metadata from training run.'
  enable_event_logger:
    optional: true
    type: boolean
    description: 'Enable event logger.'

outputs:
  metadata:
    type: uri_folder
    description: "Metadata calculated."
  processed_data:
    type: uri_folder
    description: "Processed input data."


code: ../../src/setup
environment: azureml://registries/azureml/environments/automl-gpu/versions/2

command: >-
  python setup.py 
  --raw-data ${{inputs.raw_data}}
  --processed-data ${{outputs.processed_data}}
  --output-metadata ${{outputs.metadata}}
  --forecast-level ${{inputs.forecast_level}}
  --nodes-count ${{inputs.instance_count}}
  --allocation-method  ${{inputs.allocation_method}}
  --node-process-count ${{inputs.max_concurrency_per_instance}}
  --prs-step-timeout ${{inputs.parallel_step_timeout_in_seconds}}
  $[[--train-run-id ${{inputs.train_run_id}}]]
  $[[--train-experiment-name ${{inputs.train_experiment_name}}]]
  $[[--forecast-quantiles ${{inputs.forecast_quantiles}}]]
  $[[--forecast-mode ${{inputs.forecast_mode}}]]
  $[[--forecast-step ${{inputs.forecast_step}}]]
  $[[--enable-event-logger ${{inputs.enable_event_logger}}]]
  $[[--optional-train-metadata ${{inputs.optional_train_metadata}}]]
  