$schema: https://azuremlschemas.azureedge.net/latest/pipelineJob.schema.json
type: pipeline

display_name: test_endpoint_preparer
description: Pipeline to test endpoint preparer.
settings:
  default_compute: azureml:serverless

inputs:
  input_dataset:
    type: uri_folder
    path: ../data/
  batch_input_pattern: >-
    '{"input_data": 
      {
        "input_string": ["###<prompt>"],
        "parameters":
        {
          "temperature": 0.6,
          "max_new_tokens": 100,
          "do_sample": true
        }
      },
    "_batch_request_metadata": ###<_batch_request_metadata>
    }'
  is_performance_test: False
  endpoint_url: test-endpoint

outputs:
  formatted_data:
    type: uri_folder
    path: azureml://datastores/${{default_datastore}}/paths/${{name}}/formatted_data/
  ground_truth_metadata:
    type: uri_folder
    path: azureml://datastores/${{default_datastore}}/paths/${{name}}/ground_truth_metadata/

jobs:
  run_batch_inference_preparer:
    type: command
    component: ../../components/batch-inference-preparer/spec.yaml
    limits: 
      timeout: 900
    inputs:
      input_dataset: ${{parent.inputs.input_dataset}}
      batch_input_pattern: ${{parent.inputs.batch_input_pattern}}
      online_endpoint_url: ${{parent.inputs.endpoint_url}}
      is_performance_test: ${{parent.inputs.is_performance_test}}
    outputs:
      formatted_data: ${{parent.outputs.formatted_data}}
      ground_truth_metadata: ${{parent.outputs.ground_truth_metadata}}
