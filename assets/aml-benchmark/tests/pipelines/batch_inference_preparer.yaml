$schema: https://azuremlschemas.azureedge.net/latest/pipelineJob.schema.json
type: pipeline

display_name: test_endpoint_preparer
description: Pipeline to test endpoint preparer.
settings:
  default_compute: azureml:yuzhua-e4s

inputs:
  input_dataset:
    type: uri_folder
    path: ../data/
  batch_input_pattern: >-
    '{"input_data": 
      {
        "input_string": ["###<prompt>"],
        "parameters":
        {
          "temperature": 0.6,
          "max_new_tokens": 100,
          "do_sample": true
        }
      },
    "_batch_request_metadata": ###<_batch_request_metadata>
    }'
  model: gpt-35-turbo-16k
  model_type: oai
  deployment_sku: 120
  endpoint: test-oai-yuzhua

outputs:
  formatted_data:
    type: uri_folder
    path: azureml://datastores/${{default_datastore}}/paths/${{name}}/formatted_data/
  output_metadata:
    type: uri_folder
    path: azureml://datastores/${{default_datastore}}/paths/${{name}}/output_metadata/

jobs:
  run_batch_inference_preparer:
    type: command
    component: ../../components/batch-inference-preparer/spec.yaml
    limits: 
      timeout: 900
    inputs:
      input_dataset: ${{parent.inputs.input_dataset}}
      batch_input_pattern: ${{parent.inputs.batch_input_pattern}}
      model_type: ${{parent.inputs.model_type}}
      model: ${{parent.inputs.model}}
      deployment_sku: ${{parent.inputs.deployment_sku}}
      endpoint: ${{parent.inputs.endpoint}}
    outputs:
      formatted_data: ${{parent.outputs.formatted_data}}
      output_metadata: ${{parent.outputs.output_metadata}}
