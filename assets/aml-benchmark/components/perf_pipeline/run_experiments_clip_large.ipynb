{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import load_component\n",
    "# Import required libraries\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml import MLClient\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "ml_client = None\n",
    "try:\n",
    "    ml_client = MLClient.from_config(credential)\n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "    # Enter details of your AML workspace\n",
    "    subscription_id = \"<SUBSCRIPTION_ID>\"\n",
    "    resource_group = \"<RESOURCE_GROUP>\"\n",
    "    workspace = \"<AML_WORKSPACE_NAME>\"\n",
    "    ml_client = MLClient(credential, subscription_id, resource_group, workspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "tmp_yml_path = \"./temp_perf_pipeline_clip_large.yml\"\n",
    "src_yml_path = \"./perf_pipeline_clip_large.yml\"\n",
    "\n",
    "input_params_list = [\n",
    "    {\n",
    "    \"concurrent_requests\" : 1,\n",
    "    },\n",
    "    {\n",
    "    \"concurrent_requests\" : 2,\n",
    "    },\n",
    "    {\n",
    "    \"concurrent_requests\" : 4,\n",
    "    },\n",
    "    {\n",
    "    \"concurrent_requests\" : 8,\n",
    "    },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completed_jobs = []\n",
    "for input_params in input_params_list:\n",
    "    with open(src_yml_path, \"r\") as yaml_file:\n",
    "        yaml_obj = yaml.safe_load(yaml_file)\n",
    "\n",
    "    # set dataset\n",
    "    # yaml_obj['jobs']['endpoint']['inputs']['input_dataset']['path'] = input_params['input_dataset_path']\n",
    "    # set concurrent requests\n",
    "    yaml_obj['jobs']['endpoint']['inputs']['initial_worker_count'] = input_params['concurrent_requests']\n",
    "    yaml_obj['jobs']['endpoint']['inputs']['max_worker_count'] = input_params['concurrent_requests']\n",
    "\n",
    "    with open(tmp_yml_path, \"w\") as yaml_file:\n",
    "        yaml_obj = yaml.dump(yaml_obj, yaml_file)\n",
    "\n",
    "    pipeline_job = load_component(source=tmp_yml_path)\n",
    "    returned_job = ml_client.jobs.create_or_update(pipeline_job())\n",
    "    ml_client.jobs.stream(returned_job.name)\n",
    "    completed_jobs.append(returned_job.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completed_jobs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rc_133",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
