$schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json
type: command

name: batch_endpoint_preparer
display_name: Batch Input Formatter
description: Prepare the jsonl file and endpoint for batch inference component.
version: 0.0.1

inputs:
  input_dataset: 
    type: uri_folder
    description: Input jsonl dataset that contains prompt. For the performance test, this one will be neglected.
    optional: True
  batch_input_pattern:
    type: string
    description: >- 
      The string for the batch input pattern. The input should be the payload format with substitution
      for the key for the value put in the `###<key>`. For example, one can use the following format for
      a llama text-gen model with a input dataset has `prompt` for the payload
      and `_batch_request_metadata` storing the corresponding ground truth.
      {"input_data": 
        {
          "input_string": ["###<prompt>"],
          "parameters":
          {
            "temperature": 0.6,
            "max_new_tokens": 100,
            "do_sample": true
          }
        },
        "_batch_request_metadata": ###<_batch_request_metadata>
      }
    optional: False
  model_type:
    type: string
    optional: False
    description: The endpoint model type.
    enum:
      - oss
      - oai
    default: oss
  is_performance_test:
    type: boolean
    default: False
    description: If true, the performance test will be run.
  endpoint:
    type: string
    optional: True
    description: The endpoint name or url. If not provided, the endpoint will be created.
  deployment_name:
    type: string
    optional: True
    description: The deployment name. If not provided, the deployment will be created.
  model:
    type: string
    optional: True
    description: Model name or model asset path. Only needed for managed deployment.
  model_version:
    type: string
    optional: True
    description: Model version. If model asset path provided, this one can be optional.
  deployment_sku:
    type: string
    optional: True
    description: The sku for the deployment. Only needed for managed deployment.
  endpoint_workspace:
    type: string
    optional: True
    description: The workspace name for the endpoint. If not provided, the same workspace of the run will be used.
  endpoint_resource_group:
    type: string
    optional: True
    description: The resource group name for the endpoint. If not provided, the same resource group of the run will be used.
  endpoint_subscription_id:
    type: string
    optional: True
    description: The subscription id for the endpoint. If not provided, the same subscription id of the run will be used.
  endpoint_location:
    type: string
    optional: True
    description: The location for the endpoint. Only required for the AOAI endpoint. If not provided, the same location of the run will be used.
  n_samples:
    type: integer
    description: The number of top samples send to endpoint.
    optional: True
outputs:
  formatted_data:
    type: mltable
    description: Path to the folder where the payload will be stored.
  output_metadata:
    type: uri_folder
    description: Path to the folder where the deployment metadata will be stored.

code: ../src
environment: azureml://registries/azureml/environments/model-evaluation/labels/latest
command: >-
  python -m batch_inference_preparer.main
  --model_type ${{inputs.model_type}}
  --batch_input_pattern '${{inputs.batch_input_pattern}}'
  --formatted_data ${{outputs.formatted_data}}
  --output_metadata ${{outputs.output_metadata}}
  --is_performance_test ${{inputs.is_performance_test}}
  $[[--input_dataset ${{inputs.input_dataset}}]]
  $[[--n_samples ${{inputs.n_samples}}]]
  $[[--endpoint ${{inputs.endpoint}}]]
  $[[--deployment_name ${{inputs.deployment_name}}]]
  $[[--model ${{inputs.model}}]]
  $[[--model_version ${{inputs.model_version}}]]
  $[[--deployment_sku ${{inputs.deployment_sku}}]]
  $[[--endpoint_workspace ${{inputs.endpoint_workspace}}]]
  $[[--endpoint_resource_group ${{inputs.endpoint_resource_group}}]]
  $[[--endpoint_subscription_id ${{inputs.endpoint_subscription_id}}]]
  $[[--endpoint_location ${{inputs.endpoint_location}}]]
