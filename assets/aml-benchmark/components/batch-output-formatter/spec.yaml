name: batch_output_formatter
version: 0.0.1
display_name: Batch Output Formatter
is_deterministic: True
type: command
description: Output Formatter for batch inference output
inputs:
  batch_inference_output:
    type: uri_folder
    description: The raw batch inference output.
    optional: False
  label_column_name:
    type: string
    optional: True
    description: The label column name.
  endpoint_url:
    type: string
    optional: False
  ground_truth_input:
    type: uri_folder
    description: The raw batch inference output.
    optional: True
  handle_response_failure:
    type: string
    optional: False
    description: The way that the formatter handles the failed response.
    enum:
      - use_fallback
      - neglect
    default: use_fallback
  fallback_value:
    description: The fallback value that can be used when request payload failed.
    type: string
    optional: True
  is_performance_test:
    type: boolean
    default: False
    description: If true, the performance test will be run.
    optional: False
outputs:
  predictions:
    type: uri_file
  performance_metadata:
    type: uri_file
  ground_truth:
    type: uri_file
code: ../src
environment: azureml://registries/azureml/environments/model-evaluation/labels/latest

resources:
  instance_count: 1

command: >-
  python -m aml_benchmark.batch_output_formatter.main
  --batch_inference_output ${{inputs.batch_inference_output}}
  --prediction_data ${{outputs.predictions}}
  --perf_data ${{outputs.performance_metadata}}
  --predict_ground_truth_data ${{outputs.ground_truth}}
  --endpoint_url ${{inputs.endpoint_url}}
  $[[--label_key ${{inputs.label_column_name}}]]
  --handle_response_failure ${{inputs.handle_response_failure}}
  --is_performance_test ${{inputs.is_performance_test}}
  $[[--fallback_value ${{inputs.fallback_value}}]]
  $[[--ground_truth_input ${{inputs.ground_truth_input}}]]
