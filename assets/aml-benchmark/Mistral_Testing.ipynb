{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d3a297e-0248-40a4-a84f-31f8b5ec0a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing c:\\users\\shiprajain\\azureml-assets\\assets\\aml-benchmark\\azure_ai_ml-1.12.0a20231215001-py3-none-any.whl\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.1.0 in c:\\users\\shiprajain\\appdata\\local\\miniconda3\\lib\\site-packages (from azure-ai-ml==1.12.0a20231215001) (6.0.1)\n",
      "Requirement already satisfied: msrest>=0.6.18 in c:\\users\\shiprajain\\appdata\\local\\miniconda3\\lib\\site-packages (from azure-ai-ml==1.12.0a20231215001) (0.7.1)\n",
      "Requirement already satisfied: azure-core<2.0.0,>=1.23.0 in c:\\users\\shiprajain\\appdata\\local\\miniconda3\\lib\\site-packages (from azure-ai-ml==1.12.0a20231215001) (1.29.7)\n",
      "Requirement already satisfied: azure-mgmt-core<2.0.0,>=1.3.0 in c:\\users\\shiprajain\\appdata\\local\\miniconda3\\lib\\site-packages (from azure-ai-ml==1.12.0a20231215001) (1.4.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.5 in c:\\users\\shiprajain\\appdata\\local\\miniconda3\\lib\\site-packages (from azure-ai-ml==1.12.0a20231215001) (3.20.2)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in c:\\users\\shiprajain\\appdata\\local\\miniconda3\\lib\\site-packages (from azure-ai-ml==1.12.0a20231215001) (4.21.1)\n",
      "Requirement already satisfied: tqdm<5.0.0 in c:\\users\\shiprajain\\appdata\\local\\miniconda3\\lib\\site-packages (from azure-ai-ml==1.12.0a20231215001) (4.65.0)\n",
      "Requirement already satisfied: strictyaml<2.0.0 in c:\\users\\shiprajain\\appdata\\local\\miniconda3\\lib\\site-packages (from azure-ai-ml==1.12.0a20231215001) (1.7.3)\n",
      "Requirement already satisfied: colorama<0.5.0 in c:\\users\\shiprajain\\appdata\\local\\miniconda3\\lib\\site-packages (from azure-ai-ml==1.12.0a20231215001) (0.4.6)\n",
      "Requirement already satisfied: pyjwt<3.0.0 in c:\\users\\shiprajain\\appdata\\local\\miniconda3\\lib\\site-packages (from azure-ai-ml==1.12.0a20231215001) (2.8.0)\n",
      "Requirement already satisfied: azure-storage-blob<13.0.0,>=12.10.0 in c:\\users\\shiprajain\\appdata\\local\\miniconda3\\lib\\site-packages (from azure-ai-ml==1.12.0a20231215001) (12.19.0)\n",
      "Requirement already satisfied: azure-storage-file-share<13.0.0 in c:\\users\\shiprajain\\appdata\\local\\miniconda3\\lib\\site-packages (from azure-ai-ml==1.12.0a20231215001) (12.15.0)\n",
      "Requirement already satisfied: azure-storage-file-datalake<13.0.0 in c:\\users\\shiprajain\\appdata\\local\\miniconda3\\lib\\site-packages (from azure-ai-ml==1.12.0a20231215001) (12.14.0)\n",
      "Requirement already satisfied: pydash<7.0.6,>=6.0.0 in c:\\users\\shiprajain\\appdata\\local\\miniconda3\\lib\\site-packages (from azure-ai-ml==1.12.0a20231215001) (7.0.5)\n",
      "Requirement already satisfied: isodate in c:\\users\\shiprajain\\appdata\\local\\miniconda3\\lib\\site-packages (from azure-ai-ml==1.12.0a20231215001) (0.6.1)\n",
      "Requirement already satisfied: azure-common<2.0.0,>=1.1 in c:\\users\\shiprajain\\appdata\\local\\miniconda3\\lib\\site-packages (from azure-ai-ml==1.12.0a20231215001) (1.1.28)\n",
      "Requirement already satisfied: typing-extensions<5.0.0 in c:\\users\\shiprajain\\appdata\\local\\miniconda3\\lib\\site-packages (from azure-ai-ml==1.12.0a20231215001) (4.9.0)\n",
      "Requirement already satisfied: opencensus-ext-azure<2.0.0 in c:\\users\\shiprajain\\appdata\\local\\miniconda3\\lib\\site-packages (from azure-ai-ml==1.12.0a20231215001) (1.1.13)\n",
      "Requirement already satisfied: requests>=2.21.0 in c:\\users\\shiprajain\\appdata\\local\\miniconda3\\lib\\site-packages (from azure-core<2.0.0,>=1.23.0->azure-ai-ml==1.12.0a20231215001) (2.31.0)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\shiprajain\\appdata\\local\\miniconda3\\lib\\site-packages (from azure-core<2.0.0,>=1.23.0->azure-ai-ml==1.12.0a20231215001) (1.16.0)\n",
      "Requirement already satisfied: cryptography>=2.1.4 in c:\\users\\shiprajain\\appdata\\local\\miniconda3\\lib\\site-packages (from azure-storage-blob<13.0.0,>=12.10.0->azure-ai-ml==1.12.0a20231215001) (41.0.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\shiprajain\\appdata\\local\\miniconda3\\lib\\site-packages (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml==1.12.0a20231215001) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\shiprajain\\appdata\\local\\miniconda3\\lib\\site-packages (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml==1.12.0a20231215001) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\shiprajain\\appdata\\local\\miniconda3\\lib\\site-packages (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml==1.12.0a20231215001) (0.32.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\shiprajain\\appdata\\local\\miniconda3\\lib\\site-packages (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml==1.12.0a20231215001) (0.17.1)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\shiprajain\\appdata\\local\\miniconda3\\lib\\site-packages (from marshmallow<4.0.0,>=3.5->azure-ai-ml==1.12.0a20231215001) (23.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shiprajain\\appdata\\local\\miniconda3\\lib\\site-packages (from msrest>=0.6.18->azure-ai-ml==1.12.0a20231215001) (2023.7.22)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in c:\\users\\shiprajain\\appdata\\local\\miniconda3\\lib\\site-packages (from msrest>=0.6.18->azure-ai-ml==1.12.0a20231215001) (1.3.1)\n",
      "Requirement already satisfied: azure-identity<2.0.0,>=1.5.0 in c:\\users\\shiprajain\\appdata\\local\\miniconda3\\lib\\site-packages (from opencensus-ext-azure<2.0.0->azure-ai-ml==1.12.0a20231215001) (1.15.0)\n",
      "Requirement already satisfied: opencensus<1.0.0,>=0.11.4 in c:\\users\\shiprajain\\appdata\\local\\miniconda3\\lib\\site-packages (from opencensus-ext-azure<2.0.0->azure-ai-ml==1.12.0a20231215001) (0.11.4)\n",
      "Requirement already satisfied: psutil>=5.6.3 in c:\\users\\shiprajain\\appdata\\local\\miniconda3\\lib\\site-packages (from opencensus-ext-azure<2.0.0->azure-ai-ml==1.12.0a20231215001) (5.9.8)\n",
      "Requirement already satisfied: python-dateutil>=2.6.0 in c:\\users\\shiprajain\\appdata\\local\\miniconda3\\lib\\site-packages (from strictyaml<2.0.0->azure-ai-ml==1.12.0a20231215001) (2.8.2)\n",
      "Requirement already satisfied: msal<2.0.0,>=1.24.0 in c:\\users\\shiprajain\\appdata\\local\\miniconda3\\lib\\site-packages (from azure-identity<2.0.0,>=1.5.0->opencensus-ext-azure<2.0.0->azure-ai-ml==1.12.0a20231215001) (1.26.0)\n",
      "Requirement already satisfied: msal-extensions<2.0.0,>=0.3.0 in c:\\users\\shiprajain\\appdata\\local\\miniconda3\\lib\\site-packages (from azure-identity<2.0.0,>=1.5.0->opencensus-ext-azure<2.0.0->azure-ai-ml==1.12.0a20231215001) (1.1.0)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\shiprajain\\appdata\\local\\miniconda3\\lib\\site-packages (from cryptography>=2.1.4->azure-storage-blob<13.0.0,>=12.10.0->azure-ai-ml==1.12.0a20231215001) (1.15.1)\n",
      "Requirement already satisfied: opencensus-context>=0.1.3 in c:\\users\\shiprajain\\appdata\\local\\miniconda3\\lib\\site-packages (from opencensus<1.0.0,>=0.11.4->opencensus-ext-azure<2.0.0->azure-ai-ml==1.12.0a20231215001) (0.1.3)\n",
      "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in c:\\users\\shiprajain\\appdata\\local\\miniconda3\\lib\\site-packages (from opencensus<1.0.0,>=0.11.4->opencensus-ext-azure<2.0.0->azure-ai-ml==1.12.0a20231215001) (2.15.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shiprajain\\appdata\\local\\miniconda3\\lib\\site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.23.0->azure-ai-ml==1.12.0a20231215001) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shiprajain\\appdata\\local\\miniconda3\\lib\\site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.23.0->azure-ai-ml==1.12.0a20231215001) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\shiprajain\\appdata\\local\\miniconda3\\lib\\site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.23.0->azure-ai-ml==1.12.0a20231215001) (1.26.18)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\shiprajain\\appdata\\local\\miniconda3\\lib\\site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.18->azure-ai-ml==1.12.0a20231215001) (3.2.2)\n",
      "Requirement already satisfied: pycparser in c:\\users\\shiprajain\\appdata\\local\\miniconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob<13.0.0,>=12.10.0->azure-ai-ml==1.12.0a20231215001) (2.21)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\shiprajain\\appdata\\local\\miniconda3\\lib\\site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure<2.0.0->azure-ai-ml==1.12.0a20231215001) (1.62.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in c:\\users\\shiprajain\\appdata\\local\\miniconda3\\lib\\site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure<2.0.0->azure-ai-ml==1.12.0a20231215001) (4.25.2)\n",
      "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in c:\\users\\shiprajain\\appdata\\local\\miniconda3\\lib\\site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure<2.0.0->azure-ai-ml==1.12.0a20231215001) (2.27.0)\n",
      "Requirement already satisfied: portalocker<3,>=1.6 in c:\\users\\shiprajain\\appdata\\local\\miniconda3\\lib\\site-packages (from msal-extensions<2.0.0,>=0.3.0->azure-identity<2.0.0,>=1.5.0->opencensus-ext-azure<2.0.0->azure-ai-ml==1.12.0a20231215001) (2.8.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\shiprajain\\appdata\\local\\miniconda3\\lib\\site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure<2.0.0->azure-ai-ml==1.12.0a20231215001) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\shiprajain\\appdata\\local\\miniconda3\\lib\\site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure<2.0.0->azure-ai-ml==1.12.0a20231215001) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\shiprajain\\appdata\\local\\miniconda3\\lib\\site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure<2.0.0->azure-ai-ml==1.12.0a20231215001) (4.9)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\shiprajain\\appdata\\local\\miniconda3\\lib\\site-packages (from portalocker<3,>=1.6->msal-extensions<2.0.0,>=0.3.0->azure-identity<2.0.0,>=1.5.0->opencensus-ext-azure<2.0.0->azure-ai-ml==1.12.0a20231215001) (306)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\shiprajain\\appdata\\local\\miniconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure<2.0.0->azure-ai-ml==1.12.0a20231215001) (0.5.1)\n",
      "azure-ai-ml is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install azure_ai_ml-1.12.0a20231215001-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41305517-36cb-4f96-8260-8acbf51a69b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de26ac01-36b7-4633-b76d-ebc98547dfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client = MLClient(\n",
    "    DefaultAzureCredential(),\n",
    "    \"72c03bf3-4e69-41af-9532-dfcdc3eefef4\",\n",
    "    \"aml-benchmarking\",\n",
    "    \"aml-benchmarking-rd\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2426076b-2e29-4197-8b50-7c68237a2945",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "\u001b[32mUploading src (0.44 MBs): 100%|#######################################################| 435014/435014 [00:21<00:00, 19805.13it/s]\u001b[0m\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PipelineComponent({'intellectual_property': None, 'auto_increment_version': False, 'source': 'REMOTE.WORKSPACE.COMPONENT', 'is_anonymous': False, 'auto_delete_setting': None, 'name': 'batch_benchmark_inference', 'description': 'Components for batch endpoint inference', 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': '/subscriptions/72c03bf3-4e69-41af-9532-dfcdc3eefef4/resourceGroups/aml-benchmarking/providers/Microsoft.MachineLearningServices/workspaces/aml-benchmarking-rd/components/batch_benchmark_inference/versions/0.0.1', 'Resource__source_path': None, 'base_path': 'C:\\\\Users\\\\shiprajain\\\\azureml-assets\\\\assets\\\\aml-benchmark', 'creation_context': <azure.ai.ml._restclient.v2022_10_01.models._models_py3.SystemData object at 0x00000166E7228E10>, 'serialize': <msrest.serialization.Serializer object at 0x00000166E6D79A90>, 'version': '0.0.1', 'latest_version': None, 'schema': 'https://azuremlschemas.azureedge.net/latest/pipelineComponent.schema.json', 'type': 'pipeline', 'display_name': 'Batch Benchmark Inference', 'is_deterministic': False, 'inputs': {'input_dataset': {'type': 'uri_folder', 'description': 'Input jsonl dataset that contains prompt.  For the performance test, this one will be neglected.', 'optional': True}, 'endpoint_config_file': {'type': 'uri_file', 'description': 'The endpoint config file.', 'optional': True}, 'model_type': {'type': 'string', 'description': \"Type of model's input and output contract. Can be one of ('oai', 'oss', 'vision_oss')\", 'optional': False, 'enum': ['oai', 'oss', 'vision_oss']}, 'batch_input_pattern': {'type': 'string', 'description': 'The string for the batch input pattern. The input should be the payload format with substitution for the key for the value put in the `###<key>`. For example, one can use the following format for a llama text-gen model with a input dataset has `prompt` for the payload and `_batch_request_metadata` storing the corresponding ground truth. {\\n  \"input_data\":\\n  {\\n    \"input_string\": [\"###<prompt>\"],\\n    \"parameters\":\\n    {\\n      \"temperature\": 0.6,\\n      \"max_new_tokens\": 100,\\n      \"do_sample\": true\\n    }\\n  },\\n  \"_batch_request_metadata\": ###<_batch_request_metadata>\\n}\\nFor AOAI model, the following pattern can be used, {\\n    \"messages\": ###<prompt>,\\n      \"temperature\": 0.7,\\n      \"top_p\": 0.95,\\n      \"frequency_penalty\": 0,\\n      \"presence_penalty\": 0,\\n      \"max_tokens\": 800,\\n      \"stop\": null\\n}', 'optional': False}, 'endpoint_url': {'type': 'string', 'description': 'The URL of the endpoint.', 'optional': False}, 'is_performance_test': {'type': 'boolean', 'description': 'If true, the performance test will be run and the input dataset will be neglected.', 'default': False, 'optional': False}, 'authentication_type': {'type': 'string', 'description': 'Authentication type for endpoint- azureml_workspace_connection or managed_identity.', 'default': 'azureml_workspace_connection', 'optional': False, 'enum': ['azureml_workspace_connection', 'managed_identity']}, 'deployment_name': {'type': 'string', 'description': 'The deployment name. Only needed for managed OSS deployment.', 'optional': True}, 'connections_name': {'type': 'string', 'description': 'Connections name for the endpoint. Only required if authentication_type is \"azureml_workspace_connection\".', 'optional': True}, 'label_column_name': {'type': 'string', 'description': 'The label column name.', 'optional': True}, 'additional_columns': {'type': 'string', 'description': 'The name(s) for additional columns that could be helpful to calculate some metrics, separated by comma (\",\").', 'optional': True}, 'n_samples': {'type': 'integer', 'description': 'The number of top samples send to endpoint. When performance test is enabled, this will be the number of repeated samples send to the endpoint.', 'optional': True}, 'handle_response_failure': {'type': 'string', 'description': \"The way that the formatter handles the failed response. 'use_fallback' will replace them with fallback_value, 'neglect' will drop those rows and 'raise_error' will throw an error.\", 'default': 'use_fallback', 'optional': False, 'enum': ['use_fallback', 'neglect', 'raise_error']}, 'fallback_value': {'type': 'string', 'description': 'The fallback value that can be used when request payload failed. If not provided, the fallback value will be an empty string.', 'optional': True}, 'additional_headers': {'type': 'string', 'description': 'A stringified json expressing additional headers to be added to each request.', 'optional': True}, 'ensure_ascii': {'type': 'boolean', 'description': 'If ensure_ascii is true, the output is guaranteed to have all incoming non-ASCII characters escaped. If ensure_ascii is false, these characters will be output as-is. More detailed information can be found at https://docs.python.org/3/library/json.html', 'default': False, 'optional': False}, 'max_retry_time_interval': {'type': 'integer', 'description': 'The maximum time (in seconds) spent retrying a payload. If unspecified, payloads are retried unlimited times.', 'optional': True}, 'mini_batch_size': {'type': 'string', 'description': 'The mini batch size for parallel run.', 'default': '100KB', 'optional': True}, 'initial_worker_count': {'type': 'integer', 'description': 'The initial number of workers to use for scoring.', 'default': 5, 'optional': False}, 'max_worker_count': {'type': 'integer', 'description': 'Overrides initial_worker_count if necessary', 'default': 200, 'optional': False}, 'instance_count': {'type': 'integer', 'description': 'Number of nodes in a compute cluster we will run the train step on.', 'default': 1, 'optional': False}, 'max_concurrency_per_instance': {'type': 'integer', 'description': 'Number of processes that will be run concurrently on any given node. This number should not be larger than 1/2 of the number of cores in an individual node in the specified cluster.', 'default': 1, 'optional': False}, 'debug_mode': {'type': 'boolean', 'description': 'Enable debug mode will print all the debug logs in the score step.', 'default': False, 'optional': False}, 'response_segment_size': {'type': 'integer', 'description': 'Set to 0 by default- The maximum number of tokens to generate at a time. If set to 0, the full response is generated all at once. If greater than 0, tokens are generated incrementally in segments. During each increment, the request and the previous partial response are sent to the model to generate the next segment. Segments are stitched together to form the full response.', 'default': 0, 'optional': False, 'min': 0}}, 'outputs': {'predictions': {'type': 'uri_file', 'description': 'The prediction data.'}, 'performance_metadata': {'type': 'uri_file', 'description': 'The performance data.'}, 'ground_truth': {'type': 'uri_file', 'description': 'The ground truth data that has a one-to-one mapping with the prediction data.'}}, 'yaml_str': None, 'other_parameter': {}, 'jobs': {}, 'job_types': {}, 'job_sources': {}, 'source_job_id': None})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Component create\n",
    "from azure.ai.ml import load_component\n",
    " \n",
    "component = load_component(\"./components/batch-benchmark-inference/spec.yaml\")\n",
    " \n",
    "ml_client.components.create_or_update(component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c430eb-a264-4624-aaea-b1f1dc415a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an API key connection\n",
    "from azure.ai.ml.entities import WorkspaceConnection, ApiKeyConfiguration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83ebd14-eec6-491d-92eb-6eb8320c3be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client.connections.create_or_update(workspace_connection=wps_connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8801c6-c1b1-4221-81b1-cbc4ce3ecba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading YAML and submitting it.\n",
    "from azure.ai.ml import load_job\n",
    "job = load_job(\"pipeline_path.yaml\")\n",
    "ml_client.create_or_update(job, experiment_name=\"experiment_name\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
