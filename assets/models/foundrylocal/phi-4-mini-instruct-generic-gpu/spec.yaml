$schema: https://azuremlschemas.azureedge.net/latest/model.schema.json
name: Phi-4-mini-instruct-generic-gpu
version: 4
path: ./
tags:
  foundryLocal: ""
  license: "MIT"
  licenseDescription: "This model is provided under the License Terms available at <https://huggingface.co/microsoft/Phi-4-mini-instruct/blob/main/LICENSE>."
  author: Microsoft
  inputModalities: "text"
  outputModalities: "text"
  task: chat-completion
  maxOutputTokens: 2048
  alias: phi-4-mini
  directoryPath: v3
  promptTemplate: "{\"system\": \"<|system|>{Content}<|end|>\", \"user\": \"<|user|>{Content}<|end|>\", \"assistant\": \"<|assistant|>{Content}<|end|>\", \"prompt\": \"<|user|>{Content}<|end|><|assistant|>\"}"
  supportsToolCalling: "true"
  toolCallStart: "<|tool_call|>"
  toolCallEnd: "<|/tool_call|>"
  toolRegisterStart: "<|tool|>"
  toolRegisterEnd: "<|/tool|>"
  toolResponseStart: "<|tool_response|>"
  toolResponseEnd: "<|/tool_response|>"
type: custom_model
variantInfo:
  parents:
  - assetId: azureml://registries/azureml/models/Phi-4-mini-instruct/versions/1
  variantMetadata:
    modelType: 'ONNX'
    quantization: ['RTN']
    device: 'gpu'
    executionProvider: 'WebGPUExecutionProvider'
    fileSizeBytes: 3994319585
    vRamFootprintBytes: 4020946899
