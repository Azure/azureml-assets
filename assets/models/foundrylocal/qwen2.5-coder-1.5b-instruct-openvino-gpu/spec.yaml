$schema: https://azuremlschemas.azureedge.net/latest/model.schema.json
name: qwen2.5-coder-1.5b-instruct-openvino-gpu
version: 1
path: ./
tags:
  foundryLocal: "hide"
  license: "apache-2.0"
  licenseDescription: "This model is provided under the License Terms available at <https://huggingface.co/Qwen/Qwen2.5-Coder-0.5B-Instruct/blob/main/LICENSE>."
  author: Microsoft
  inputModalities: "text"
  outputModalities: "text"
  task: chat-completion
  maxOutputTokens: 2048
  alias: qwen2.5-coder-1.5b
  directoryPath: model
  promptTemplate: "{\"system\": \"<|im_start|>system\\n{Content}<|im_end|>\", \"user\": \"<|im_start|>user\\n{Content}<|im_end|>\", \"assistant\": \"<|im_start|>assistant\\n{Content}<|im_end|>\", \"prompt\": \"<|im_start|>user\\n{Content}<|im_end|>\\n<|im_start|>assistant\"}"
  parameterSchema: "{\"enabled\": [{\"name\": \"temperature\", \"default\": 1.0}, {\"name\": \"top_p\", \"default\": 0.9}, {\"name\": \"top_k\", \"default\": 40}, {\"name\": \"presence_penalty\", \"default\": 1.1}]}"
  supportsToolCalling: "true"
  toolCallStart: "<tool_call>"
  toolCallEnd: "</tool_call>"
  toolRegisterStart: "<tools>"
  toolRegisterEnd: "</tools>"
  toolResponseStart: "<tool_response>"
  toolResponseEnd: "</tool_response>"
type: custom_model
variantInfo:
  parents:
  - assetId: azureml://registries/azureml/models/qwen2.5-coder-1.5b-instruct/versions/1
  variantMetadata:
    modelType: 'ONNX'
    quantization: ['RTN']
    device: 'gpu'
    executionProvider: 'OpenVINOExecutionProvider'
    fileSizeBytes: 1067945948
    vRamFootprintBytes: 1067945948