The RoBERTa base OpenAI Detector functions as a model designed to detect outputs generated by the GPT-2 model. It was created by refining a RoBERTa base model using the outputs of the 1.5B-parameter GPT-2 model. This detector is utilized to determine whether text was generated by a GPT-2 model. OpenAI introduced this model concurrently with the release of the weights for the largest GPT-2 model, known as the 1.5B parameter version.


> The above summary was generated using ChatGPT. Review the <a href="https://huggingface.co/roberta-base-openai-detector" target="_blank">original model card</a> to understand the data used to train the model, evaluation metrics, license, intended uses, limitations and bias before using the model.


### Inference samples

Inference type|Python sample (Notebook)|CLI with YAML
|--|--|--|
Real time|<a href="https://aka.ms/azureml-infer-online-sdk-text-classification" target="_blank">text-classification-online-endpoint.ipynb</a>|<a href="https://aka.ms/azureml-infer-online-cli-text-classification" target="_blank">text-classification-online-endpoint.sh</a>
Batch |<a href="https://aka.ms/azureml-infer-batch-sdk-text-classification" target="_blank">entailment-contradiction-batch.ipynb</a>| coming soon

**Training**
**Training Data**
The model serves as a sequence classifier based on RoBERTa base, initially trained with the RoBERTa base training data. Subsequently, it undergoes fine-tuning using the outputs of the 1.5B GPT-2 model.

**Training Procedure**
According to the model developers, they constructed a sequence classifier leveraging RoBERTaBASE (125 million parameters) and fine-tuned it to differentiate between outputs from the 1.5B GPT-2 model and WebText, the dataset utilized for training the GPT-2 model. To ensure the detector model's robustness in accurately classifying generated texts across various sampling methods, they conducted an in-depth analysis of the model's transfer performance. Further details on the training procedure are available in the associated paper.

**Evaluation**
Evaluation details extracted from the associated paper are as follows:

**Testing Data, Factors, and Metrics**
The model's primary purpose is to detect text generated by GPT-2 models. To assess its performance, the model developers test it on text datasets, measuring accuracy by evaluating:

510-token test examples, comprising 5,000 samples from the WebText dataset and 5,000 samples generated by a GPT-2 model. These examples were not utilized during the training phase.


### Sample inputs and outputs (for real-time inference)

#### Sample input
```json
{ 

  "input_data": [ 

           "I like you. I love you",  

       "Today was a horrible day" 

  ], 

  "params": { 

    "return_all_scores": true 

  } 

} 
```

#### Sample output
```json
[
  {
    "label": "Fake",
    "score": 0.881293773651123
  },
  {
    "label": "Fake",
    "score": 0.9996414184570312
  }
]
```
