flavors:
  python_function:
    env:
      conda: conda.yaml
      virtualenv: python_env.yaml
    loader_module: mlflow.transformers
    model_binary: model
    python_version: 3.8.18
  transformers:
    code: null
    components:
    - tokenizer
    framework: pt
    instance_type: TextGenerationPipeline
    model_binary: model
    pipeline_model_type: GPT2LMHeadModel
    task: text-generation
    tokenizer_type: GPT2TokenizerFast
    transformers_version: 4.35.2
metadata:
  base_model_name: gpt2-large
  base_model_task: text-generation
  is_acft_model: true
  is_finetuned_model: false
  azureml.base_image: mcr.microsoft.com/azureml/curated/mlflow-model-inference:1
mlflow_version: 2.8.1
model_size_bytes: 3099561926
model_uuid: 916fcb500dd44c7c84eb43ec02107e05
signature:
  inputs: '[{"type": "string"}]'
  outputs: '[{"type": "string"}]'
  params: '[{"name": "top_p", "type": "float", "default": 1.0, "shape": null}, {"name": "temperature", "type": "float", "default": 0.8, "shape": null}, {"name": "max_new_tokens", "type": "integer", "default": 50, "shape": null}, {"name": "do_sample", "type": "boolean", "default": true, "shape": null}, {"name": "return_full_text", "type": "boolean", "default": true, "shape": null}]'
utc_time_created: '2023-12-06 09:18:29.934345'
