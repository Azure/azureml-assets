flavors:
  python_function:
    env:
      conda: conda.yaml
      virtualenv: python_env.yaml
    loader_module: mlflow.transformers
    model_binary: model
    python_version: 3.8.18
  transformers:
    code: null
    components:
    - tokenizer
    framework: pt
    instance_type: TextGenerationPipeline
    model_binary: model
    pipeline_model_type: GPT2LMHeadModel
    task: text-generation
    tokenizer_type: GPT2TokenizerFast
    transformers_version: 4.35.2
metadata:
  base_model_name: gpt2-medium
  base_model_task: text-generation
  is_acft_model: true
  is_finetuned_model: false
mlflow_version: 2.8.1
model_size_bytes: 1422708538
model_uuid: 798d0a704f874098b395bbe1fdcaa86c
signature:
  inputs: '[{"type": "string"}]'
  outputs: '[{"type": "string"}]'
  params: '[{"name": "top_p", "type": "float", "default": 1.0, "shape": null}, {"name": "temperature", "type": "float", "default": 0.8, "shape": null}, {"name": "max_new_tokens", "type": "integer", "default": 50, "shape": null}, {"name": "do_sample", "type": "boolean", "default": true, "shape": null}, {"name": "return_full_text", "type": "boolean", "default": true, "shape": null}]'
utc_time_created: '2023-12-06 09:45:45.494930'
