# **Model Details**

Name: cognitivecomputations/WizardLM-33B-V1.0-Uncensored
This is a retraining of the WizardLM/WizardLM-30B-V1.0 model with a filtered dataset, aimed at reducing refusals, avoidance, and bias. The intention is to create a more compliant model compared to the original WizardLM/WizardLM-7B-V1.0.

The model, named ehartford/WizardLM-33B-V1.0-Uncensored, acknowledges that there is no such thing as a "truly uncensored" model, as LLaMA itself holds inherent ethical beliefs. However, this version is expected to be more compliant than its predecessor.

The dataset used for evaluation was automatically created during the model's evaluation run on the Open LLM Leaderboard. It consists of 64 configurations, each corresponding to an evaluated task. The dataset is generated from two runs, with each run represented as a specific split in the configurations. The "train" split points to the latest results.

A disclaimer emphasizes that an uncensored model has no guardrails, and users are responsible for the content generated by the model. The responsibility is compared to handling dangerous objects like knives, guns, lighters, or cars. Publishing content generated by the model holds the same accountability as if it were published by the user, and the model cannot be blamed for the content. The acknowledgment appreciates the open-source AI/ML community and everyone who contributed to the project.

# **Inference samples**

Inference type|Python sample (Notebook)|CLI with YAML
|--|--|--|
Real time|<a href="https://aka.ms/azureml-infer-online-sdk-text-generation-dolly" target="_blank">text-generation-online-endpoint.ipynb</a>|<a href="https://aka.ms/azureml-infer-online-cli-text-generation-dolly" target="_blank">text-generation-online-endpoint.sh</a>
Batch |<a href="https://aka.ms/azureml-infer-batch-sdk-text-generation" target="_blank">text-generation-batch-endpoint.ipynb</a>| coming soon

