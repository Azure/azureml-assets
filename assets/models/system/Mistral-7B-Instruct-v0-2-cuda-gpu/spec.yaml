$schema: https://azuremlschemas.azureedge.net/latest/model.schema.json
name: mistralai-Mistral-7B-Instruct-v0-2-cuda-gpu
version: 1
path: ./
tags:
  foundryLocal: ""
  license: "apache-2.0"
  licenseDescription: "This model is provided under the License Terms available at <https://www.apache.org/licenses/LICENSE-2.0.html>."
  author: Microsoft
  inputModalities: "text"
  outputModalities: "text"
  task: chat-completion
  maxOutputTokens: 2048
  alias: mistral-7b-v0.2
  directoryPath: mistral-7b-instruct-v0.2-cuda-int4-rtn-block-32
  promptTemplate: "{\"system\": \"<s>\", \"user\": \"[INST]\\n{Content}\\n[/INST]\", \"assistant\": \"{Content}</s>\", \"prompt\": \"[INST]\\n{Content}\\n[/INST]\"}"
  parameterSchema: "{\"enabled\": [{\"name\": \"max_tokens\", \"default\": 256}, {\"name\": \"temperature\"}, {\"name\": \"top_p\"}, {\"name\": \"top_k\"}, {\"name\": \"presence_penalty\"}, {\"name\": \"frequency_penalty\", \"default\": 1}]}"
type: custom_model
variantInfo:
  parents:
  - assetId: azureml://registries/azureml/models/mistralai-Mistral-7B-Instruct-v0-2/versions/6
  variantMetadata:
    modelType: 'ONNX'
    quantization: ['RTN']
    device: 'gpu'
    executionProvider: 'CUDAExecutionProvider'
    fileSizeBytes: 4273492459
    vRamFootprintBytes: 4273717196