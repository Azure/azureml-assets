$schema: https://azuremlschemas.azureedge.net/latest/model.schema.json

name: MedImageInsight-onnx
path: ./

properties:
  inference-min-sku-spec: 4|1|28|64
  inference-recommended-sku: Standard_NC4as_T4_v3, Standard_NC8as_T4_v3, Standard_NC16as_T4_v3, Standard_NC64as_T4_v3, Standard_NC24ads_A100_v4, Standard_NC48ads_A100_v4, Standard_NC96ads_A100_v4, Standard_ND96asr_v4, Standard_ND96amsr_A100_v4, Standard_ND40rs_v2, Standard_NC40ads_H100_v5, Standard_NC80adis_H100_v5, Standard_ND96isr_H100_v5
  SharedComputeCapacityEnabled: true

tags:
  task: embeddings
  industry: health-and-life-sciences
  Preview: ""
  inference_supported_envs:
    - hf
  license: mit
  author: Microsoft
  displayName: "MedImageInsight ONNX"
  languages: "en"
  evaluation: "evaluation.md"
  notes: "notes.md"
  inputModalities: "image, text"
  outputModalities: "embeddings"
  keywords: "Multimodal,Low latency"
  hiddenlayerscanned: ""
  SharedComputeCapacityEnabled: ""
  inference_compute_allow_list:
    [
      Standard_NC4as_T4_v3,
      Standard_NC8as_T4_v3,
      Standard_NC16as_T4_v3,
      Standard_NC64as_T4_v3,
      Standard_NC24ads_A100_v4,
      Standard_NC48ads_A100_v4,
      Standard_NC96ads_A100_v4,
      Standard_ND96asr_v4,
      Standard_ND96amsr_A100_v4,
      Standard_ND40rs_v2,
      Standard_NC40ads_H100_v5,
      Standard_NC80adis_H100_v5,
      Standard_ND96isr_H100_v5
    ]
version: 2
