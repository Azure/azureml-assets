$schema: https://azuremlschemas.azureedge.net/latest/model.schema.json
name: llama-3.2-1b-instruct-cuda-gpu
version: 1
path: ./
tags:
  foundryLocal: ""
  license: "llama3.2"
  licenseDescription: "This model is provided under the License Terms available at <https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct/blob/main/LICENSE>."
  author: Microsoft
  inputModalities: "text"
  outputModalities: "text"
  task: chat-completion
  maxOutputTokens: 2048
type: custom_model
variantInfo:
  parents:
  - assetId: azureml://registries/azureml/models/llama-3.2-1b-instruct/versions/1
  variantMetadata:
    modelType: 'ONNX'
    quantization: ['RTN']
    device: 'gpu'
    executionProvider: 'CUDAExecutionProvider'
    fileSizeBytes: 1234803097
    vRamFootprintBytes: 1234908252