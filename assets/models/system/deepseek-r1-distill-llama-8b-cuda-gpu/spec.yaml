$schema: https://azuremlschemas.azureedge.net/latest/model.schema.json
name: deepseek-r1-distill-llama-8b-cuda-gpu
version: 1
path: ./
tags:
  foundryLocal: ""
  license: "MIT"
  licenseDescription: "This model is provided under the License Terms available at <https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B/blob/main/LICENSE>."
  author: Microsoft
  inputModalities: "text"
  outputModalities: "text"
  task: chat-completion
  maxOutputTokens: 2048
  alias: deepseek-r1-8b
  directoryPath: cuda-int4-rtn-block-32
  promptTemplate: "{\"assistant\": \"{Content}\", \"prompt\": \"\\\\u003C\\\\uFF5CUser\\\\uFF5C\\\\u003E{Content}\\\\u003C\\\\uFF5CAssistant\\\\uFF5C\\\\u003E\"}"
type: custom_model
variantInfo:
  parents:
  - assetId: azureml://registries/azureml/models/deepseek-r1-distill-llama-8b/versions/1
  variantMetadata:
    modelType: 'ONNX'
    quantization: ['RTN']
    device: 'gpu'
    executionProvider: 'CUDAExecutionProvider'
    fileSizeBytes: 5304284610
    vRamFootprintBytes: 5304515348