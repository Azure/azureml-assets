The Model Card for DeciCoder 1B provides details about a 1 billion parameter decoder-only code completion model developed by Deci. The model was trained on Python, Java, and JavaScript subsets of Starcoder Training Dataset and uses Grouped Query Attention with a context window of 2048 tokens. It was trained using a Fill-in-the-Middle training objective and generated by Deci's proprietary Neural Architecture Search-based technology, AutoNAC. The model is intended for single/multiline code completion from a context window of up to 2048 tokens. The model has limitations as it has undergone training with source code from Python, Java, and JavaScript, and there is no assurance that the resulting code will function as expected. The Model Card provides details on how to use the model, training details, and evaluation results. The model's checkpoints are licensed under the Apache 2.0 license.


# Model Evaluation Sample

Task| Use case| Dataset| Python sample (Notebook)| CLI with YAML
|--|--|--|--|--|
Text generation | Text generation | <a href="https://huggingface.co/datasets/cnn_dailymail" target="_blank"> cnn_dailymail </a> | <a href="https://aka.ms/azureml-eval-sdk-text-generation/" target="_blank">evaluate-model-text-generation.ipynb</a> | <a href="https://aka.ms/azureml-eval-cli-text-generation/" target="_blank">evaluate-model-text-generation.yml</a>

# Inference samples

Inference type|Python sample (Notebook)|CLI with YAML
|--|--|--|
Real time|<a href="https://aka.ms/azureml-infer-online-sdk-text-generation-dolly" target="_blank">text-generation-online-endpoint.ipynb</a>|<a href="https://aka.ms/azureml-infer-online-cli-text-generation-dolly" target="_blank">text-generation-online-endpoint.sh</a>
Batch |<a href="https://aka.ms/azureml-infer-batch-sdk-text-generation" target="_blank">text-generation-batch-endpoint.ipynb</a>| coming soon

# Sample inputs and outputs (for real-time inference)

### Sample input
```json
{
  "input_data": {
    "input_string": [
      "def print_hello_world():"
    ],
    "parameters": {
      "top_p": 0.95,
      "temperature": 0.1,
      "max_new_tokens": 10,
      "do_sample": true
    }
  }
}
```

### Sample output
```json
[
  {
    "0": "def print_hello_world():\n    print(\"Hello World!\")\n\n\ndef print"
  }
]
```