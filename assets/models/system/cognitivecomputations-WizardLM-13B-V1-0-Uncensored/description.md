LLaMA is a retrained version of WizardLM/WizardLM-13B-V1.0, undertaken with the intention of mitigating issues related to refusals, avoidance, and bias in generated responses

## Ethical Framework
LLaMA inherently carries ethical beliefs and is designed to be more compliant than its predecessor, WizardLM/WizardLM-7B-V1.0.

## Uncensored Model Warning
LLaMA does not claim to be a "truly uncensored" model. It acknowledges the presence of ethical boundaries and emphasizes the absence of absolute guardrails

## Responsibility and Accountability
Users are explicitly reminded of their responsibility when using the model. It draws an analogy between handling the model and dealing with potentially dangerous objects like knives, guns, lighters, or cars.
Content generated by the model is considered the user's responsibility, and users cannot shift blame to the model for published content.

## Training Source and Style
The model is retrained from WizardLM/WizardLM-13B-V1.0, adopting a specific prompt style known as Vicuna-1.1.

## Sponsorship Acknowledgment
LLaMA extends gratitude to chirper.ai for contributing to the sponsorship of its compute resources.

## Usage Guidelines
Users are instructed to interact with the model using a defined prompt structure: USER: <prompt>\nASSISTANT:

## Filtered Dataset and Objective
The retraining process involved the use of a filtered dataset to address specific issues, namely refusals, avoidance, and bias in generated responses.

## Acknowledgments
The model card expresses appreciation for the open-source AI/ML community and individuals who played a role in the development of LLaMA.

## Comparative Information
LLaMA is positioned as an improvement compared to WizardLM/WizardLM-7B-V1.0, with a focus on addressing and reducing specific issues present in the original model.

## Important Note on Publishing
Users are cautioned about the responsibility associated with content publication, underscoring that the model is a tool, and the user ultimately determines the use and consequences of generated content.

> Review the <a href="https://huggingface.co/cognitivecomputations/WizardLM-13B-V1.0-Uncensored" target="_blank">original model card</a> to understand the data used to train the model, evaluation metrics, license, intended uses, limitations and bias before using the model.

### Model Evaluation

Task| Use case| Dataset| Python sample (Notebook)| CLI with YAML
|--|--|--|--|--|
Token Classification | Token Classification | <a href="https://huggingface.co/datasets/conll2003" target="_blank">CoNLL 2003</a> | <a href="https://aka.ms/azureml-eval-sdk-token-classification" target="_blank">evaluate-model-token-classification.ipynb</a> | <a href="https://aka.ms/azureml-eval-cli-token-classification" target="_blank">evaluate-model-token-classification.yml</a>

### Inference samples

Inference type|Python sample (Notebook)|CLI with YAML
|--|--|--|
Real time|<a href="https://aka.ms/azureml-infer-online-sdk-token-classification" target="_blank">token-classification-online-endpoint.ipynb</a>|<a href="https://aka.ms/azureml-infer-online-cli-token-classification" target="_blank">token-classification-online-endpoint.sh</a>
Batch |<a href="https://aka.ms/azureml-infer-batch-sdk-token-classification" target="_blank">token-classification-batch-endpoint.ipynb</a>| coming soon

## Sample input (for real-time inference)

```json
{
  "input_data": {
    "input_string": [
      "The meaning of the life is"
    ],
    "parameters": {
      "top_p": 0.95,
      "temperature": 0.6,
      "max_new_tokens": 10,
      "do_sample": true
    }
  }
}
```

## Sample output
```json
[
  {
    "0": "The meaning of the life is to be happy, and itâ€™s not a"
  }
]
```