type: "evaluator"
name: "builtin.rouge_score"
version: 1
displayName: "Rouge-Score-Evaluator"
description: "Compares the overlap of words or phrases between model output and reference text. Higher scores indicate closer alignment. Reccomended use cases include text summarization and document comparison, especially when focusing on recall and the ability to capture relevant information from the reference text."
evaluatorType: "builtin"
evaluatorSubType: "code"
categories: ["quality"]
tags:
  provider: "Microsoft"
initParameterSchema:
  type: "object"
  properties:
    rouge_type:
      type: "string"
      enum: ["rouge1", "rouge2", "rouge3", "rouge4", "rouge5", "rougeL"]
    f1_score_threshold:
      type: "number"
      minimum: 0
      maximum: 1
      multipleOf: 0.1
    precision_threshold:
      type: "number"
      minimum: 0
      maximum: 1
      multipleOf: 0.1
    recall_threshold:
      type: "number"
      minimum: 0
      maximum: 1
      multipleOf: 0.1
  required: ["rouge_type", "f1_score_threshold", "precision_threshold", "recall_threshold"]
dataMappingSchema:
  type: "object"
  properties:
    ground_truth:
      type: "string"
    response:
      type: "string"
  required: ["ground_truth", "response"]
outputSchema:
  rouge_precision:
    type: "continuous"
    desirable_direction: "increase"
    min_value: 0
    max_value: 1
  rouge_recall:
    type: "continuous"
    desirable_direction: "increase"
    min_value: 0
    max_value: 1
  rouge_f1_score:
    type: "continuous"
    desirable_direction: "increase"
    min_value: 0
    max_value: 1
path: ./evaluator