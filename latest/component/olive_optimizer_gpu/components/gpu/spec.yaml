$schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json
type: command

version: 0.0.10
name: olive_optimizer_gpu
display_name: Olive Optimizer - GPU
is_deterministic: false

code: ../../src

description: An GPU version optimizer based on "Olive". "Olive" is an easy-to-use
  hardware-aware model optimization tool that composes industry-leading techniques
  across model compression, optimization, and compilation. For detailed info please
  refer to https://github.com/microsoft/Olive

inputs:
  config:
    type: uri_file
    optional: false
    description: "A JSON file that provides detailed Olive configurations."
  code_path:
    type: uri_folder
    optional: true
    description: "A code folder that contains all the files that is needed for Olive."
  data:
    type: uri_folder
    optional: true
    description: "A folder that contains the data directory that is needed for Olive."
  model:
    type: uri_folder
    optional: true
    description: "A folder that contains the model that is needed for Olive."

outputs:
  optimized_parameters:
    type: uri_folder
    description: "A folder that contains the inference parameters file(s) for corresponding\
      \ optimized model(s)."
  optimized_model:
    type: uri_folder
    description: "A folder that contains the optimized model(s)."

environment: azureml:olive-optimizer-gpu@latest

command: >-
  python -m olive_optimizer.run
  --config_path ${{inputs.config}}
  $[[--code ${{inputs.code_path}}]]
  $[[--data_path ${{inputs.data}}]]
  $[[--model_path ${{inputs.model}}]]
  --optimized_parameters_path ${{outputs.optimized_parameters}}
  --optimized_model_path ${{outputs.optimized_model}}
