$schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json
name: aoai_finetuning
version: 0.0.12
type: command

is_deterministic: true

display_name: AOAI Finetuning Job
description: Upload data to Azure OpenAI resource, finetune model and delete data

environment: azureml://registries/azureml-1p-preview/environments/aoai-data-upload-finetune/versions/5

code: ../../src

inputs:
  endpoint_name:
    type: string
    optional: false
    description: The endpoint name or AOAI resource name.

  endpoint_resource_group:
    type: string
    optional: true
    description: Resource group for the AOAI resource.

  endpoint_subscription:
    type: string
    optional: true
    description: Subscription for the AOAI resource.

  training_file_path:
    type: uri_file
    optional: true
    description: jsonl source file/folder for training dataset.

  validation_file_path:
    type: uri_file
    optional: true
    description: source file/folder for validation dataset.

  training_import_path:
    type: uri_file
    optional: true
    description: json file containing training data uri or key for stored uri in keyvault.

  validation_import_path:
    type: uri_file
    optional: true
    description: json file containing validation data uri or key for stored uri in
      keyvault.

  model:
    type: string
    optional: false
    default: gpt-35-turbo-0613
    description: GPT model engine

  task_type:
    type: string
    optional: false
    description: Dataset type - chat or completion
    enum:
    - chat
    - completion

  n_epochs:
    type: integer
    optional: true
    description: Number of training epochs. If not provided, it will be determined
      dynamically based on the input data.

  batch_size:
    type: integer
    optional: true
    description: Global batch size. If not provided, it will be determined dynamically
      based on the input data.

  learning_rate_multiplier:
    type: number
    optional: true
    description: The learning rate multiplier to use for training. If not provided,
      it will be determined dynamically based on the input data.

  suffix:
    type: string
    optional: true
    description: A string of up to 18 characters that will be added to your fine-tuned
      model name

  lora_dim:
    type: integer
    optional: true
    description: The size of LoRA dimensions in self attention layer. If not provided,
      it will be determined dynamically.

  n_ctx:
    type: integer
    optional: true
    description: Context length of the model. If not provided, context window will
      be determined dynamically.

  weight_decay_multiplier:
    type: number
    optional: true
    description: Weight Decay Multiplier for training. Not applicable for embedding
      finetuning

  completion_override:
    type: boolean
    optional: true


outputs:
  aoai_finetuning_output:
    type: uri_file
    description: Contains finetuned model id in output file in JSON/custom class format

command: >-
  python finetuning.py
  --endpoint_name ${{inputs.endpoint_name}}
  $[[--endpoint_resource_group ${{inputs.endpoint_resource_group}}]]
  $[[--endpoint_subscription ${{inputs.endpoint_subscription}}]]
  $[[--training_file_path ${{inputs.training_file_path}}]]
  $[[--validation_file_path ${{inputs.validation_file_path}}]]
  $[[--training_import_path ${{inputs.training_import_path}}]]
  $[[--validation_import_path ${{inputs.validation_import_path}}]]
  --model ${{inputs.model}}
  --task_type ${{inputs.task_type}}
  $[[--n_epochs ${{inputs.n_epochs}}]]
  $[[--batch_size ${{inputs.batch_size}}]]
  $[[--learning_rate_multiplier ${{inputs.learning_rate_multiplier}}]]
  $[[--suffix ${{inputs.suffix}}]]
  $[[--lora_dim ${{inputs.lora_dim}}]]
  $[[--n_ctx ${{inputs.n_ctx}}]]
  $[[--weight_decay_multiplier ${{inputs.weight_decay_multiplier}}]]
  --aoai_finetuning_output ${{outputs.aoai_finetuning_output}}
  $[[--completion_override ${{inputs.completion_override}}]]
