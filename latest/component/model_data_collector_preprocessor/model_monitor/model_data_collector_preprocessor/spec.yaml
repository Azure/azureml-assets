$schema: http://azureml/sdk-2-0/SparkComponent.json
type: spark

name: model_data_collector_preprocessor
display_name: Model Data Collector - Preprocessor
description: Filters the data based on the window provided.
version: 0.4.28
is_deterministic: true

code: ../../src
entry:
  file: ./model_data_collector_preprocessor/spark_run.py

inputs:
  data_window_end:
    type: string
  data_window_start:
    type: string
  input_data:
    type: uri_folder
    mode: direct
  extract_correlation_id:
    type: string
    default: "False"
outputs:
  preprocessed_input_data:
    type: mltable
    mode: direct
conf:
  spark.hadoop.aml.enable_cache: "true"
  spark.driver.cores: 4
  spark.driver.memory: 28g
  spark.executor.cores: 4
  spark.executor.memory: 28g
  spark.executor.instances: 1
  spark.dynamicAllocation.enabled: true
  spark.dynamicAllocation.minExecutors: 1
  spark.dynamicAllocation.maxExecutors: 4
  spark.aml.internal.system.job: true
  spark.synapse.library.python.env: |
    channels:
      - defaults
    dependencies:
      - pip:
        - azure-storage-file-datalake~=12.11.0
        - azure-ai-ml~=1.23.1
        - azureml-mlflow~=1.59.0
        - mltable~=1.6.1
        - azureml-fsspec~=1.3.1
        - fsspec~=2023.4.0
        - numpy<2.0.0
    name: momo-base-spark
args: >-
  --data_window_end ${{inputs.data_window_end}}
  --data_window_start ${{inputs.data_window_start}}
  --input_data ${{inputs.input_data}}
  --extract_correlation_id ${{inputs.extract_correlation_id}}
  --preprocessed_input_data ${{outputs.preprocessed_input_data}}
