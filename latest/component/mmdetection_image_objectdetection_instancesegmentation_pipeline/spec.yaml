$schema: 
  https://azuremlschemas.azureedge.net/latest/pipelineComponent.schema.json
type: pipeline

version: 0.0.27
name: mmdetection_image_objectdetection_instancesegmentation_pipeline
display_name: Image Object Detection and Instance Segmentation MMDetection 
  Pipeline
description: Pipeline component for image object detection and instance 
  segmentation using MMDetection models.

is_deterministic: false

inputs:
  compute_model_import:
    type: string
    optional: false
    description: Compute to be used for model_import eg. provide 'FT-Cluster' if
      your compute is named 'FT-Cluster'

  compute_finetune:
    type: string
    optional: false
    description: Compute to be used for finetune eg. provide 'FT-Cluster' if 
      your compute is named 'FT-Cluster'

  instance_count:
    type: integer
    default: 1
    optional: true
    description: Number of nodes to be used for finetuning (used for distributed
      training)

  process_count_per_instance:
    type: integer
    default: 1
    optional: true
    description: Number of gpus to be used per node for finetuning, should be 
      equal to number of gpu per node in the compute SKU used for finetune

  compute_model_evaluation:
    type: string
    optional: true
    description: Compute to be used for model evaluation eg. provide 
      'FT-Cluster' if your compute is named 'FT-Cluster'

  # ########################### Model Selector Component ########################### #
  # Model family
  model_family:
    type: string
    optional: true
    default: MmDetectionImage
    enum:
    - MmDetectionImage
    description: Which framework the model belongs to.

  model_name:
    type: string
    optional: true
    description: Please select models from AzureML Model Assets for all 
      supported models. For MMDetection, provide the model's config name here, 
      same as its specified in MMDetection Model Zoo. To find the correct model 
      name, go to https://github.com/open-mmlab/mmdetection/tree/v3.1.0/configs 
      click on the model type and you will find the model name in the 
      metafile.yml file which is present at configs/<MODEL_TYPE>/metafile.yml 
      location. It is the user responsibility to comply with the model's license
      terms.

  pytorch_model:
    type: custom_model
    optional: true
    description: Pytorch Model registered in AzureML Asset.

  mlflow_model:
    type: mlflow_model
    optional: true
    description: Mlflow Model registered in AzureML Asset.

  download_from_source:
    type: boolean
    optional: true
    default: false
    description: Download model directly from MMDetection instead of system 
      registry

  # ########################### Finetuning Component ########################### #

  # component input: training mltable
  training_data:
    type: mltable
    optional: false
    description: Path to the mltable of the training dataset.

  # optional component input: validation mltable
  validation_data:
    type: mltable
    optional: true
    description: Path to the mltable of the validation dataset.

  image_min_size:
    type: integer
    optional: true
    description: Minimum image size after augmentation that is input to the 
      network. If left empty, it would either be overwritten by image_scale in 
      model config or would be chosen based on the task type and model selected.
      The image will be rescaled as large as possible within the range 
      [image_min_size, image_max_size]. The image size will be constraint so 
      that the max edge is no longer than image_max_size and short edge is no 
      longer than image_min_size.

  image_max_size:
    type: integer
    optional: true
    description: Maximum image size after augmentation that is input to the 
      network. If left empty, it would either be overwritten by image_scale in 
      model config or would be chosen based on the task type and model selected.
      The image will be rescaled as large as possible within the range 
      [image_min_size, image_max_size]. The image size will be constraint so 
      that the max edge is no longer than image_max_size and short edge is no 
      longer than image_min_size.

  task_name:
    type: string
    enum:
    - image-object-detection
    - image-instance-segmentation
    description: Which task the model is solving.

  # primary metric
  metric_for_best_model:
    type: string
    optional: true
    enum:
    - mean_average_precision
    - precision
    - recall
    description: Specify the metric to use to compare two different models. If 
      left empty, will be chosen automatically based on the task type and model 
      selected.

  # Augmentation parameters
  apply_augmentations:
    type: boolean
    default: true
    optional: true
    description: If set to true, will enable data augmentations for training.

  number_of_workers:
    type: integer
    default: 8
    optional: true
    description: Number of subprocesses to use for data loading (PyTorch only). 
      0 means that the data will be loaded in the main process.

  # Deepspeed Parameters
  apply_deepspeed:
    type: boolean
    default: false
    optional: true
    description: If set to true, will enable deepspeed for training. Please note
      deepspeed is not yet supported for MMDetection, will be enabled in future.

  # optional component input: deepspeed config
  deepspeed_config:
    type: uri_file
    optional: true
    description: Deepspeed config to be used for finetuning. Please note 
      deepspeed is not yet supported for MMDetection, will be enabled in future.

  apply_ort:
    type: boolean
    default: false
    optional: true
    description: If set to true, will use the ONNXRunTime training. Please note 
      ONNXRunTime is not yet supported for MMDetection, will be enabled in 
      future.

  # Training parameters
  number_of_epochs:
    type: integer
    optional: true
    description: Number of training epochs. If left empty, will be chosen 
      automatically based on the task type and model selected.

  max_steps:
    type: integer
    optional: true
    description: If set to a positive number, the total number of training steps
      to perform. Overrides 'number_of_epochs'. In case of using a finite 
      iterable dataset the training may stop before reaching the set number of 
      steps when all data is exhausted. If left empty, will be chosen 
      automatically based on the task type and model selected.

  training_batch_size:
    type: integer
    optional: true
    description: Train batch size. If left empty, will be chosen automatically 
      based on the task type and model selected.

  validation_batch_size:
    type: integer
    optional: true
    description: Validation batch size. If left empty, will be chosen 
      automatically based on the task type and model selected.

  auto_find_batch_size:
    type: boolean
    default: false
    optional: true
    description: Flag to enable auto finding of batch size. If the provided 
      'per_device_train_batch_size' goes into Out Of Memory (OOM) enabling 
      auto_find_batch_size will find the correct batch size by iteratively 
      reducing 'per_device_train_batch_size' by a factor of 2 till the OOM is 
      fixed.

  # learning rate and learning rate scheduler 
  learning_rate:
    type: number
    optional: true
    description: Start learning rate. Defaults to linear scheduler. If left 
      empty, will be chosen automatically based on the task type and model 
      selected.

  learning_rate_scheduler:
    type: string
    optional: true
    enum:
    - warmup_linear
    - warmup_cosine
    - warmup_cosine_with_restarts
    - warmup_polynomial
    - constant
    - warmup_constant
    description: The scheduler type to use. If left empty, will be chosen 
      automatically based on the task type and model selected.

  warmup_steps:
    type: integer
    optional: true
    description: Number of steps used for a linear warmup from 0 to 
      learning_rate. If left empty, will be chosen automatically based on the 
      task type and model selected.

  # optimizer
  optimizer:
    type: string
    optional: true
    enum:
    - adamw_hf
    - adamw
      # - adamw_torch_xla
      # - adamw_apex_fused
      # - adamw_bnb_8bit
      # - adamw_anyprecision
    - sgd
    - adafactor
    - adagrad
    description: optimizer to be used while training. If left empty, will be 
      chosen automatically based on the task type and model selected.

  weight_decay:
    type: number
    optional: true
    description: The weight decay to apply (if not zero) to all layers except 
      all bias and LayerNorm weights in Adam, AdamW & SGD optimizer. If left 
      empty, will be chosen automatically based on the task type and model 
      selected.

  extra_optim_args:
    type: string
    default: ""
    optional: true
    description: Optional additional arguments that are supplied to SGD 
      Optimizer. The arguments should be semi-colon separated key value pairs 
      and should be enclosed in double quotes. For example, "momentum=0.5; 
      nesterov=True" for sgd. Please make sure to use a valid parameter names 
      for the chosen optimizer. For exact parameter names, please refer 
      https://pytorch.org/docs/1.13/generated/torch.optim.SGD.html#torch.optim.SGD
      for SGD. Parameters supplied in extra_optim_args will take precedence over
      the parameter supplied via other arguments such as weight_decay. If 
      weight_decay is provided via "weight_decay" parameter and via 
      extra_optim_args both, values specified in extra_optim_args will be used.

  # gradient accumulation
  gradient_accumulation_step:
    type: integer
    optional: true
    description: Number of update steps to accumulate the gradients for, before 
      performing a backward/update pass. If left empty, will be chosen 
      automatically based on the task type and model selected.

  # mixed precision training
  precision:
    type: string
    enum:
    - "32"
    - "16"
    default: "32"
    optional: true
    description: Apply mixed precision training. This can reduce memory 
      footprint by performing operations in half-precision.

  # metric thresholds
  iou_threshold:
    type: number
    optional: true
    description: IOU threshold used during inference in non-maximum suppression 
      post processing.

  box_score_threshold:
    type: number
    optional: true
    description: During inference, only return proposals with a score greater 
      than `box_score_threshold`. The score is the multiplication of the 
      objectness score and classification probability.

  # random seed
  random_seed:
    type: integer
    default: 42
    optional: true
    description: Random seed that will be set at the beginning of training.

  # evaluation strategy parameters
  evaluation_strategy:
    type: string
    default: epoch
    optional: true
    enum:
    - epoch
    - steps
    description: The evaluation strategy to adopt during training. Please note 
      that the save_strategy and evaluation_strategy should match.

  evaluation_steps:
    type: integer
    default: 500
    optional: true
    description: Number of update steps between two evals if 
      evaluation_strategy='steps'. Please note that the saving steps should be a
      multiple of the evaluation steps.

  # logging strategy parameters
  logging_strategy:
    type: string
    default: epoch
    optional: true
    enum:
    - epoch
    - steps
    description: The logging strategy to adopt during training.

  logging_steps:
    type: integer
    default: 500
    optional: true
    description: Number of update steps between two logs if 
      logging_strategy='steps'.

  # Save strategy
  save_strategy:
    type: string
    default: epoch
    optional: true
    enum:
    - epoch
    - steps
    description: The checkpoint save strategy to adopt during training. Please 
      note that the save_strategy and evaluation_strategy should match.

  save_steps:
    type: integer
    default: 500
    optional: true
    description: Number of updates steps before two checkpoint saves if 
      save_strategy="steps". Please note that the saving steps should be a 
      multiple of the evaluation steps.

  # model checkpointing limit
  save_total_limit:
    type: integer
    default: 5
    optional: true
    description: If a value is passed, will limit the total amount of 
      checkpoints. Deletes the older checkpoints in output_dir. If the value is 
      -1 saves all checkpoints".

  # Early Stopping Parameters
  early_stopping:
    type: boolean
    default: false
    optional: true
    description: Enable early stopping.

  early_stopping_patience:
    type: integer
    default: 1
    optional: true
    description: Stop training when the specified metric worsens for 
      early_stopping_patience evaluation calls.

  # Grad Norm
  max_grad_norm:
    type: number
    optional: true
    description: Maximum gradient norm (for gradient clipping). If left empty, 
      will be chosen automatically based on the task type and model selected.

  # resume from the input model
  resume_from_checkpoint:
    type: boolean
    default: false
    optional: true
    description: Loads optimizer, Scheduler and Trainer state for finetuning if 
      true.

  save_as_mlflow_model:
    type: boolean
    default: true
    optional: true
    description: Save as mlflow model with pyfunc as flavour.

  # ########################### Model prediction Component ########################### #

  # component input: test mltable
  test_data:
    type: mltable
    optional: false
    description: Path to the mltable of the test dataset.

  test_batch_size:
    type: integer
    default: 4
    optional: true
    description: Test batch size.

  label_column_name:
    type: string
    default: label
    optional: true
    description: Label column name to be ignored by model for prediction 
      purposes, for example "label".

  input_column_names:
    type: string
    default: image,image_meta_info,text_prompt
    optional: true
    description: Input column names provided to model for prediction, for 
      example column1. Add comma delimited values in case of multiple input 
      columns, for example column1,column2.

  evaluation_config:
    type: uri_file
    optional: true
    description: Additional parameters for Computing Metrics.

  evaluation_config_params:
    type: string
    optional: true
    description: Additional parameters as JSON serialized string.

outputs:
  # ########################### Finetuning Component ########################### #
  mlflow_model_folder:
    type: mlflow_model
    description: Output dir to save the finetune model as mlflow model.
  pytorch_model_folder:
    type: custom_model
    description: Output dir to save the finetune model as torch model.
  # ######################### Compute metrics Component ######################### #
  evaluation_result:
    type: uri_folder
    description: Test Data Evaluation Results

jobs:
  finetune_common_validation:
    type: command
    component: azureml:finetune_common_validation:0.0.8
    compute: ${{parent.inputs.compute_model_import}}
    inputs:
      mlflow_model_path: ${{parent.inputs.mlflow_model}}
      train_mltable_path: ${{parent.inputs.training_data}}
      validation_mltable_path: ${{parent.inputs.validation_data}}
      test_mltable_path: ${{parent.inputs.test_data}}
      compute_model_import: ${{parent.inputs.compute_model_import}}
      compute_finetune: ${{parent.inputs.compute_finetune}}
      instance_count: ${{parent.inputs.instance_count}}
      process_count_per_instance: ${{parent.inputs.process_count_per_instance}}
      compute_model_evaluation: ${{parent.inputs.compute_model_evaluation}}
      task_name: ${{parent.inputs.task_name}}
      label_column_name: label
      user_column_names: image_url,label
      test_batch_size: ${{parent.inputs.test_batch_size}}
      device: auto
      evaluation_config: ${{parent.inputs.evaluation_config}}
      evaluation_config_params: '${{parent.inputs.evaluation_config_params}}'
      task_specific_extra_params: '"model_family=${{parent.inputs.model_family}};model_name=${{parent.inputs.model_name}};metric_for_best_model=${{parent.inputs.metric_for_best_model}};number_of_epochs=${{parent.inputs.number_of_epochs}}"'

  image_od_is_model_import:
    type: command
    component: 
      azureml:mmdetection_image_objectdetection_instancesegmentation_model_import:0.0.20
    compute: ${{parent.inputs.compute_model_import}}
    inputs:
      model_family: ${{parent.inputs.model_family}}
      model_name: ${{parent.inputs.model_name}}
      pytorch_model: ${{parent.inputs.pytorch_model}}
      mlflow_model: ${{parent.inputs.mlflow_model}}
      download_from_source: ${{parent.inputs.download_from_source}}
      validation_output: 
        ${{parent.jobs.finetune_common_validation.outputs.validation_info}}

  image_od_is_finetune:
    type: command
    component: 
      azureml:mmdetection_image_objectdetection_instancesegmentation_finetune:0.0.22
    compute: ${{parent.inputs.compute_finetune}}
    distribution:
      type: pytorch
      process_count_per_instance: ${{parent.inputs.process_count_per_instance}}
    resources:
      instance_count: ${{parent.inputs.instance_count}}
      shm_size: '16g'
    inputs:
      # Model path is same as what is output of model selector
      model_path: ${{parent.jobs.image_od_is_model_import.outputs.output_dir}}
      training_data: ${{parent.inputs.training_data}}
      validation_data: ${{parent.inputs.validation_data}}
      image_min_size: ${{parent.inputs.image_min_size}}
      image_max_size: ${{parent.inputs.image_max_size}}
      task_name: ${{parent.inputs.task_name}}
      metric_for_best_model: ${{parent.inputs.metric_for_best_model}}
      apply_augmentations: ${{parent.inputs.apply_augmentations}}
      number_of_workers: ${{parent.inputs.number_of_workers}}
      apply_deepspeed: ${{parent.inputs.apply_deepspeed}}
      deepspeed_config: ${{parent.inputs.deepspeed_config}}
      apply_ort: ${{parent.inputs.apply_ort}}
      number_of_epochs: ${{parent.inputs.number_of_epochs}}
      max_steps: ${{parent.inputs.max_steps}}
      training_batch_size: ${{parent.inputs.training_batch_size}}
      validation_batch_size: ${{parent.inputs.validation_batch_size}}
      auto_find_batch_size: ${{parent.inputs.auto_find_batch_size}}
      learning_rate: ${{parent.inputs.learning_rate}}
      learning_rate_scheduler: ${{parent.inputs.learning_rate_scheduler}}
      warmup_steps: ${{parent.inputs.warmup_steps}}
      optimizer: ${{parent.inputs.optimizer}}
      weight_decay: ${{parent.inputs.weight_decay}}
      extra_optim_args: ${{parent.inputs.extra_optim_args}}
      gradient_accumulation_step: ${{parent.inputs.gradient_accumulation_step}}
      precision: ${{parent.inputs.precision}}
      iou_threshold: ${{parent.inputs.iou_threshold}}
      box_score_threshold: ${{parent.inputs.box_score_threshold}}
      random_seed: ${{parent.inputs.random_seed}}
      evaluation_strategy: ${{parent.inputs.evaluation_strategy}}
      evaluation_steps: ${{parent.inputs.evaluation_steps}}
      logging_strategy: ${{parent.inputs.logging_strategy}}
      logging_steps: ${{parent.inputs.logging_steps}}
      save_strategy: ${{parent.inputs.save_strategy}}
      save_steps: ${{parent.inputs.save_steps}}
      save_total_limit: ${{parent.inputs.save_total_limit}}
      early_stopping: ${{parent.inputs.early_stopping}}
      early_stopping_patience: ${{parent.inputs.early_stopping_patience}}
      max_grad_norm: ${{parent.inputs.max_grad_norm}}
      resume_from_checkpoint: ${{parent.inputs.resume_from_checkpoint}}
      save_as_mlflow_model: ${{parent.inputs.save_as_mlflow_model}}
    outputs:
      mlflow_model_folder: ${{parent.outputs.mlflow_model_folder}}
      pytorch_model_folder: ${{parent.outputs.pytorch_model_folder}}

  model_prediction:
    type: command
    component: azureml:model_prediction:0.0.37
    compute: '${{parent.inputs.compute_model_evaluation}}'
    inputs:
      task: '${{parent.inputs.task_name}}'
      label_column_name: '${{parent.inputs.label_column_name}}'
      input_column_names: '${{parent.inputs.input_column_names}}'
      batch_size: '${{parent.inputs.test_batch_size}}'
      device: auto
      evaluation_config: '${{parent.inputs.evaluation_config}}'
      evaluation_config_params: '${{parent.inputs.evaluation_config_params}}'
      test_data: '${{parent.inputs.test_data}}'
      mlflow_model: '${{parent.jobs.image_od_is_finetune.outputs.mlflow_model_folder}}'

  compute_metrics:
    type: command
    component: azureml:compute_metrics:0.0.35
    compute: '${{parent.inputs.compute_model_evaluation}}'
    inputs:
      task: '${{parent.inputs.task_name}}'
      ground_truth: '${{parent.jobs.model_prediction.outputs.ground_truth}}'
      ground_truth_column_name: '${{parent.inputs.label_column_name}}'
      prediction: '${{parent.jobs.model_prediction.outputs.predictions}}'
      prediction_column_name: predictions
      prediction_probabilities: '${{parent.jobs.model_prediction.outputs.prediction_probabilities}}'
      evaluation_config: '${{parent.inputs.evaluation_config}}'
      evaluation_config_params: '${{parent.inputs.evaluation_config_params}}'
    outputs:
      evaluation_result: '${{parent.outputs.evaluation_result}}'
