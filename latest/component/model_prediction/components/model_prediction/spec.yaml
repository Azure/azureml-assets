$schema: 
  https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json
name: model_prediction
display_name: Model Prediction
description: Generate predictions on a given mlflow model for supported tasks.

version: 0.0.37
type: command
tags:
  type: evaluation
  sub_type: inference
inputs:
  task:
    type: string
    optional: false
    default: tabular-classification
    enum: [tabular-classification, tabular-classification-multilabel, 
        tabular-regression, text-classification, text-classification-multilabel, 
        text-named-entity-recognition, text-summarization, question-answering, 
        text-translation, text-generation, fill-mask, image-classification, 
        image-classification-multilabel, chat-completion, image-object-detection,
      image-instance-segmentation, image-generation]
    description: "Task type"
  test_data:
    type: uri_folder
    optional: false
    mode: ro_mount
    description: "Test Data"
  mlflow_model:
    type: mlflow_model
    optional: false
    mode: ro_mount
    description: "Mlflow Model - registered model or output of a job with type mlflow_model
      in a pipeline"
  label_column_name:
    type: string
    optional: true
    description: "Label column name in provided test dataset (Ex: label)"
  input_column_names:
    type: string
    optional: true
    description: "Input column names in provided test dataset (Ex : column1). Add
      comma delimited values in case of multiple input columns (Ex : column1,column2)"
  evaluation_config:
    type: uri_file
    optional: true
    mode: ro_mount
    description: "Additional parameters required for evaluation."
  evaluation_config_params:
    type: string
    optional: true
    description: "JSON Serialized string of evaluation_config"
  device:
    type: string
    optional: false
    default: auto
    enum: [auto, cpu, gpu]
  batch_size:
    type: integer
    optional: true

outputs:
  predictions:
    type: uri_file
  prediction_probabilities:
    type: uri_file
  ground_truth:
    type: uri_file
  performance_metadata:
    type: uri_file

is_deterministic: true
code: ../../src
environment: 
  azureml://registries/azureml/environments/model-evaluation/labels/latest

command: >-
  python download_dependencies.py
  --mlflow-model '${{inputs.mlflow_model}}' &&
  python model_prediction.py
  --data '${{inputs.test_data}}'
  --task '${{inputs.task}}'
  --predictions '${{outputs.predictions}}'
  --prediction-probabilities '${{outputs.prediction_probabilities}}'
  --ground-truth '${{outputs.ground_truth}}'
  --performance-metadata '${{outputs.performance_metadata}}'
  --mlflow-model '${{inputs.mlflow_model}}'
  --device '${{inputs.device}}'
  $[[--input-column-names '${{inputs.input_column_names}}']]
  $[[--label-column-name '${{inputs.label_column_name}}']]
  $[[--config-file-name '${{inputs.evaluation_config}}']]
  $[[--batch-size '${{inputs.batch_size}}']]
  $[[--config_str '${{inputs.evaluation_config_params}}']]

