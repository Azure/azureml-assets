$schema: 
  https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json
type: command

description: Component to finetune AutoML legacy models for object detection.

name: train_object_detection_model
display_name: Image Object Detection AutoML Legacy Model Finetune
version: 0.0.15

is_deterministic: false

inputs:
  training_data:
    description: Path to MLTable for training data.
    type: mltable
  validation_data:
    description: Path to MLTable for validation data.
    type: mltable
    optional: true
  ams_gradient:
    description: Enable ams_gradient when optimizer is adam or adamw.
    type: boolean
    optional: true
  beta1:
    description: Value of beta1 when optimizer is adam or adamw. Must be a float
      in the range [0, 1].
    type: number
    optional: true
    min: 0
    max: 1
  beta2:
    description: Value of beta2 when optimizer is adam or adamw. Must be a float
      in the range [0, 1].
    type: number
    optional: true
    min: 0
    max: 1
  box_detections_per_image:
    description: Maximum number of detections per image, for all classes. Must 
      be a positive integer.
    type: integer
    optional: true
    min: 1
  box_score_threshold:
    description: During inference, only return proposals with a classification 
      score greater than box_score_threshold. Must be a float in the range [0, 
      1].
    type: number
    optional: true
    min: 0
    max: 1
  checkpoint_frequency:
    description: Frequency to store model checkpoints. Must be a positive 
      integer.
    type: integer
    optional: true
    min: 0
  checkpoint_run_id:
    description: The run ID of the experiment that has a pretrained checkpoint 
      for incremental training.
    type: string
    optional: true
  early_stopping:
    description: Enable early stopping logic during training.
    type: boolean
    optional: true
  early_stopping_patience:
    description: Minimum number of epochs or validation evaluations with no 
      primary metric improvement before the run is stopped. Must be a positive 
      integer.
    type: integer
    optional: true
    min: 1
  early_stopping_delay:
    description: Minimum number of epochs or validation evaluations to wait 
      before primary metric improvement is tracked for early stopping. Must be a
      positive integer.
    type: integer
    optional: true
    min: 1
  evaluation_frequency:
    description: Frequency to evaluate validation dataset to get metric scores. 
      Must be a positive integer.
    type: integer
    optional: true
    min: 1
  gradient_accumulation_step:
    description: Number of forward passes without updating the model weights 
      while accumulating the gradients of those steps, and then using the 
      accumulated gradients to compute the weight updates. Must be a positive 
      integer.
    type: integer
    optional: true
    min: 1
  layers_to_freeze:
    description: How many layers to freeze for your model. For instance, passing
      2 as value for seresnext means freezing layer0 and layer1 referring to the
      below supported model layer info. Must be a positive integer.
    type: integer
    optional: true
    min: 1
  learning_rate:
    description: Initial learning rate
    type: number
    optional: true
    min: 0
    max: 1
  learning_rate_scheduler:
    description: Type of learning rate scheduler. Must be warmup_cosine or step.
    type: string
    optional: true
    default: warmup_cosine
    enum: ['warmup_cosine', 'step']
  max_size:
    description: Maximum size of the image to be rescaled before feeding it to 
      the backbone.
    type: integer
    optional: true
    min: 1
  min_size:
    description: Minimum size of the image to be rescaled before feeding it to 
      the backbone. Must be a positive integer.
    type: integer
    optional: true
    min: 1
  model_name:
    description: Model name
    type: string
    optional: true
  momentum:
    description: Value of momentum when optimizer is sgd. Must be a float in the
      range [0, 1].
    type: number
    optional: true
    min: 0
    max: 1
  model_size:
    description: Model size for yolov5.
    type: string
    optional: true
    default: medium
    enum: ['small', 'medium', 'large', 'xlarge']
  multi_scale:
    description: Enable multi-scale image by varying image size by +/- 50%.
    type: boolean
    optional: true
  nesterov:
    description: Enable nesterov when optimizer is sgd.
    type: boolean
    optional: true
  nms_iou_threshold:
    description: IOU threshold used during inference in non-maximum suppression 
      post processing. Must be a float in the range [0, 1].
    type: number
    optional: true
    min: 0
    max: 1
  number_of_epochs:
    description: Number of training epochs
    type: integer
    optional: true
    min: 1
  number_of_workers:
    description: Number of subprocesses to use for data loading (PyTorch only). 
      0 means that the data will be loaded in the main process.
    type: integer
    optional: true
  optimizer:
    description: Type of optimizer
    type: string
    optional: true
    default: sgd
    enum: ['sgd', 'adam', 'adamw']
  random_seed:
    description: Random seed that will be set at the beginning of training.
    type: integer
    optional: true
  step_lr_gamma:
    description: Value of gamma when learning rate scheduler is step. Must be a 
      float in the range [0, 1].
    type: number
    optional: true
    min: 0
    max: 1
  step_lr_step_size:
    description: Value of step size when learning rate scheduler is step. Must 
      be a positive integer.
    type: integer
    optional: true
    min: 0
  tile_grid_size:
    description: The grid size to use for tiling each image. Should be passed as
      a string in '3x2' format. Example --tile_grid_size '3x2'. For more 
      information please visit 
      https://learn.microsoft.com/en-us/azure/machine-learning/how-to-use-automl-small-object-detect?tabs=CLI-v2.
    type: string
    optional: true
  tile_overlap_ratio:
    description: Overlap ratio between adjacent tiles in each dimension. Must be
      float in the range of [0, 1).
    type: number
    optional: true
    min: 0
    max: 1
  tile_predictions_nms_threshold:
    description: The IOU threshold to use to perform NMS while merging 
      predictions from tiles and image. Used in validation/ inference. Must be 
      float in the range of [0, 1].
    type: number
    optional: true
    min: 0
    max: 1
  training_batch_size:
    description: Training batch size.
    type: integer
    optional: true
    min: 1
  validation_batch_size:
    description: Validation batch size.
    type: integer
    optional: true
    min: 1
  validation_iou_threshold:
    description: IOU threshold for box matching when computing validation 
      metrics. Must be a float in the range [0.1, 1].
    type: number
    optional: true
    min: 0.1
    max: 1
  validation_metric_type:
    description: Metric computation method to use for validation metrics. Must 
      be none, coco, voc, or coco_voc.
    type: string
    optional: true
    default: 'voc'
    enum: ['none', 'coco', 'voc', 'coco_voc']
  warmup_cosine_lr_cycles:
    description: Value of cosine cycle when learning rate scheduler is 
      warmup_cosine. Must be a float in the range [0, 1].
    type: number
    optional: true
    min: 0
    max: 1
  warmup_cosine_lr_warmup_epochs:
    description: Value of warmup epochs when learning rate scheduler is 
      warmup_cosine. Must be a positive integer.
    type: integer
    optional: true
    min: 0
  weight_decay:
    description: Value of weight decay used by the optimizer.
    type: number
    optional: true
    min: 0
    max: 1

outputs:
  mlflow_model_folder:
    description: Trained MLFlow model.
    type: mlflow_model
  pytorch_model_folder:
    description: Trained Pytorch model.
    type: custom_model

code: ../src

environment: 
  azureml://registries/azureml/environments/automl-dnn-vision-gpu/versions/74

command: >-
  python -m object_detection.run
  --training_data ${{inputs.training_data}}
  $[[--validation_data ${{inputs.validation_data}}]]
  $[[--amsgrad ${{inputs.ams_gradient}}]]
  $[[--beta1 ${{inputs.beta1}}]]
  $[[--beta2 ${{inputs.beta2}}]]
  $[[--box_detections_per_img ${{inputs.box_detections_per_image}}]]
  $[[--box_score_thresh ${{inputs.box_score_threshold}}]]
  $[[--checkpoint_frequency ${{inputs.checkpoint_frequency}}]]
  $[[--checkpoint_run_id ${{inputs.checkpoint_run_id}}]]
  $[[--early_stopping ${{inputs.early_stopping}}]]
  $[[--early_stopping_patience ${{inputs.early_stopping_patience}}]]
  $[[--early_stopping_delay ${{inputs.early_stopping_delay}}]]
  $[[--evaluation_frequency ${{inputs.evaluation_frequency}}]]
  $[[--grad_accumulation_step ${{inputs.gradient_accumulation_step}}]]
  $[[--layers_to_freeze ${{inputs.layers_to_freeze}}]]
  $[[--learning_rate ${{inputs.learning_rate}}]]
  $[[--lr_scheduler ${{inputs.learning_rate_scheduler}}]]
  $[[--max_size ${{inputs.max_size}}]]
  $[[--min_size ${{inputs.min_size}}]]
  $[[--model_name  ${{inputs.model_name}}]]
  $[[--model_size ${{inputs.model_size}}]]
  $[[--momentum ${{inputs.momentum}}]]
  $[[--multi_scale ${{inputs.multi_scale}}]]
  $[[--nesterov ${{inputs.nesterov}}]]
  $[[--nms_iou_thresh ${{inputs.nms_iou_threshold}}]]
  $[[--number_of_epochs ${{inputs.number_of_epochs}}]]
  $[[--number_of_workers ${{inputs.number_of_workers}}]]
  $[[--optimizer ${{inputs.optimizer}}]]
  $[[--random_seed ${{inputs.random_seed}}]]
  $[[--step_lr_gamma ${{inputs.step_lr_gamma}}]]
  $[[--step_lr_step_size ${{inputs.step_lr_step_size}}]]
  $[[--tile_grid_size ${{inputs.tile_grid_size}}]]
  $[[--tile_overlap_ratio ${{inputs.tile_overlap_ratio}}]]
  $[[--tile_predictions_nms_thresh ${{inputs.tile_predictions_nms_threshold}}]]
  $[[--training_batch_size ${{inputs.training_batch_size}}]]
  $[[--validation_batch_size ${{inputs.validation_batch_size}}]]
  $[[--validation_iou_threshold ${{inputs.validation_iou_threshold}}]]
  $[[--validation_metric_type ${{inputs.validation_metric_type}}]]
  $[[--warmup_cosine_lr_cycles ${{inputs.warmup_cosine_lr_cycles}}]]
  $[[--warmup_cosine_lr_warmup_epochs ${{inputs.warmup_cosine_lr_warmup_epochs}}]]
  $[[--weight_decay ${{inputs.weight_decay}}]]
  --mlflow_model_output ${{outputs.mlflow_model_folder}}
  --pytorch_model_output ${{outputs.pytorch_model_folder}}

distribution:
  type: pytorch
