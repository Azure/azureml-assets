$schema: http://azureml/sdk-2-0/SparkComponent.json
type: spark

name: model_monitor_feature_selector
display_name: Model Monitor - Feature Selector
description: Selects features to compute signal metrics on.
version: 0.3.28
is_deterministic: true

code: ../../src
entry:
  file: ./model_monitor_feature_selector/run.py

inputs:
  input_data_1:
    type: mltable
    mode: direct
  input_data_2:
    type: mltable
    mode: direct
    optional: true
  filter_type:
    type: string
  filter_value:
    type: string
  feature_importance:
    type: mltable
    mode: direct
    optional: true
outputs:
  feature_names:
    type: mltable
    mode: direct
conf:
  spark.hadoop.aml.enable_cache: "true"
  spark.driver.cores: 4
  spark.driver.memory: 28g
  spark.executor.cores: 4
  spark.executor.memory: 28g
  spark.executor.instances: 1
  spark.dynamicAllocation.enabled: true
  spark.dynamicAllocation.minExecutors: 1
  spark.dynamicAllocation.maxExecutors: 4
  spark.aml.internal.system.job: true
  spark.synapse.library.python.env: |
    channels:
      - defaults
    dependencies:
      - pip:
        - azure-storage-file-datalake~=12.11.0
        - azure-ai-ml~=1.23.1
        - azureml-mlflow~=1.59.0
        - mltable~=1.6.1
        - azureml-fsspec~=1.3.1
        - fsspec~=2023.4.0
        - numpy<2.0.0
    name: momo-base-spark
args: >-
  --input_data_1 ${{inputs.input_data_1}}
  $[[--input_data_2 ${{inputs.input_data_2}}]]
  --filter_type ${{inputs.filter_type}}
  --filter_value ${{inputs.filter_value}}
  $[[--feature_importance ${{inputs.feature_importance}}]]
  --feature_names ${{outputs.feature_names}}
