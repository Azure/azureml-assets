$schema: 
  https://azuremlschemas.azureedge.net/latest/pipelineComponent.schema.json
type: pipeline

name: automl_many_models_inference
display_name: AutoML Many Models - Inference
description: Inference components for AutoML many model.
version: 0.0.12
is_deterministic: false

inputs:
  raw_data:
    type: uri_folder
    description: 'Folder URI with inference data.'
  compute_name:
    type: string
    description: 'Compute name for inference pipeline.'
  max_nodes:
    type: integer
    description: 'Number of nodes in a compute cluster we will run the inference step
      on.'
  max_concurrency_per_node:
    type: integer
    description: 'Number of processes that will be run concurrently on any given node.
      This number should not be larger than 1/2 of the number of cores in an individual
      node in the specified cluster'
  parallel_step_timeout_in_seconds:
    type: integer
    description: 'The PRS step time out setting in seconds.'
    default: 3600
  train_run_id:
    type: string
    description: 'The train run id used for training models that will be used to generate
      forecasts.'
    optional: true
  training_experiment_name:
    type: string
    description: 'The training experiment that used for inference.'
    optional: true
  partition_column_names:
    type: string
    description: 'The partition column names for inference.'
    optional: true
  forecast_quantiles:
    type: string
    description: 'Space separated list of quantiles for forecasting jobs. It is applicable
      only when the forecast_mode is recursive.'
    optional: true
  inference_type:
    type: string
    description: 'The inference type of the inference, possible values are `forecast`,
      `predict` and `predict_proba`. `predict_proba`` should be used on the classification
      tasks, `predict` should be used on the regression tasks and `forecast` should
      be used on the forecasting tasks.'
    enum: ['forecast', 'predict', 'predict_proba']
    optional: true
  forecast_mode:
    type: string
    description: 'The forecast mode used for inference. The possible values are `recursive`
      and `rolling`.'
    enum: ['recursive', 'rolling']
    optional: true
  forecast_step:
    type: integer
    description: 'The forecast step used for rolling forecast. See more details here:
      https://learn.microsoft.com/en-us/azure/machine-learning/how-to-auto-train-forecast?view=azureml-api-2#evaluating-model-accuracy-with-a-rolling-forecast'
    default: 1
    optional: true
  allow_multi_partitions:
    type: boolean
    description: 'Allow multi paritions in one partitioned file'
    optional: true
  skip_concat_results:
    type: boolean
    description: 'Flag on skip concat inferece results'
    optional: true
  early_validation_failure:
    type: boolean
    description: 'Enable early failure validations'
    optional: true
  optional_train_metadata:
    type: uri_folder
    optional: true
    description: 'Metadata from training run.'
  label_column_name:
    type: string
    optional: true
    description: 'Label column name for the data.'

outputs:
  run_output:
    type: uri_folder
    description: 'Folder URI representing the location of the output data'
  raw_predictions:
    type: uri_folder
    description: 'The raw forecast results from each inferece run'
  evaluation_configs:
    type: uri_file
    description: 'The evaluation configs.'
  evaluation_data:
    type: uri_file
    description: 'The evaluation data.'

jobs:
  automl_many_models_inference_setup_step:
    type: command
    component: azureml:automl_many_models_inference_setup_step:0.0.12
    inputs:
      raw_Data: ${{parent.inputs.raw_data}}
      enable_event_logger: true
      instance_count: ${{parent.inputs.max_nodes}}
      max_concurrency_per_instance: ${{parent.inputs.max_concurrency_per_node}}
      parallel_step_timeout_in_seconds: 
        ${{parent.inputs.parallel_step_timeout_in_seconds}}
      train_run_id: ${{parent.inputs.train_run_id}}
      training_experiment_name: ${{parent.inputs.training_experiment_name}}
      partition_column_names: ${{parent.inputs.partition_column_names}}
      forecast_quantiles: ${{parent.inputs.forecast_quantiles}}
      inference_type: ${{parent.inputs.inference_type}}
      forecast_mode: ${{parent.inputs.forecast_mode}}
      forecast_step: ${{parent.inputs.forecast_step}}
      allow_multi_partitions: ${{parent.inputs.allow_multi_partitions}}
      skip_concat_results: ${{parent.inputs.skip_concat_results}}
      early_validation_failure: ${{parent.inputs.early_validation_failure}}
      optional_train_metadata: ${{parent.inputs.optional_train_metadata}}
      label_column_name: ${{parent.inputs.label_column_name}}
    outputs:
      processed_data:
        type: uri_folder
      metadata:
        type: uri_folder
    compute: ${{parent.inputs.compute_name}}
  automl_many_models_inferencing_step:
    type: parallel
    component: azureml:automl_many_models_inference_step:0.0.12
    inputs:
      partitioned_data: 
        ${{parent.jobs.automl_many_models_inference_setup_step.outputs.processed_data}}
      metadata: 
        ${{parent.jobs.automl_many_models_inference_setup_step.outputs.metadata}}
      enable_event_logger: true
      instance_count: ${{parent.inputs.max_nodes}}
      max_concurrency_per_instance: ${{parent.inputs.max_concurrency_per_node}}
      parallel_step_timeout_in_seconds: 
        ${{parent.inputs.parallel_step_timeout_in_seconds}}
    outputs:
      output_metadata:
        type: uri_folder
      prediction:
        type: uri_folder
        path: ${{parent.outputs.raw_predictions}}
      prs_output:
        type: uri_folder
    resources:
      instance_count: ${{parent.inputs.max_nodes}}
    max_concurrency_per_instance: ${{parent.inputs.max_concurrency_per_node}}
    mini_batch_size: "1"
    retry_settings:
      timeout: ${{parent.inputs.parallel_step_timeout_in_seconds}}
    compute: ${{parent.inputs.compute_name}}
  automl_many_models_inference_collect_step:
    type: command
    component: azureml:automl_many_models_inference_collect_step:0.0.12
    inputs:
      setup_metadata: 
        ${{parent.jobs.automl_many_models_inference_setup_step.outputs.metadata}}
      input_metadata: 
        ${{parent.jobs.automl_many_models_inferencing_step.outputs.output_metadata}}
      input_prediction: 
        ${{parent.jobs.automl_many_models_inferencing_step.outputs.prediction}}
      enable_event_logger: true
    outputs:
      metadata:
        type: uri_folder
        path: ${{parent.outputs.run_output}}
      evaluation_configs:
        type: uri_file
        path: ${{parent.outputs.evaluation_configs}}
      evaluation_data:
        type: uri_folder
        path: ${{parent.outputs.evaluation_data}}
    compute: ${{parent.inputs.compute_name}}
