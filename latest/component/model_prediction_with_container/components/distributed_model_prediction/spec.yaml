$schema: https://azuremlschemas.azureedge.net/latest/pipelineComponent.schema.json
name: model_prediction_with_container
version: 0.0.5
type: command
display_name: Distributed Model Prediction
description: "Optimized Distributed inference component for LLMs."

tags:
  type: evaluation
  sub_type: subgraph
  Preview: ""
distribution:
  type: pytorch

inputs:
  # model prediction
  task:
    type: string
    default: text-classification
    enum: [text-classification, text-classification-multilabel, text-named-entity-recognition,
      text-summarization, question-answering, text-translation, text-generation, fill-mask,
      chat-completion]
    description: "Task type"
  test_data:
    type: uri_folder
    optional: false
    description: "Test Data"
  mlflow_model:
    type: mlflow_model
    optional: false
    description: "Mlflow model"
  label_column_name:
    type: string
    description: "Label column name in provided test dataset (Ex: label)"
  input_column_names:
    type: string
    optional: true
    description: "Input column names in provided test dataset (Ex : column1). Add\
      \ comma delimited values in case of multiple input columns (Ex : column1,column2)"
  mini_batch_size:
    type: integer
    optional: true
    default: 100
  evaluation_config_params:
    type: string
    optional: true
    description: "JSON Serialized string of evaluation_config"
outputs:
  predictions:
    type: uri_file
  ground_truth:
    type: uri_file
  prediction_probabilities:
    type: uri_file  # TODO: Not implemented yet in this component
  performance_metadata:
    type: uri_file
    description: "Json File containing metadata for perf output"



code: ../../src_distributed
environment: azureml://registries/azureml/environments/foundation-model-inference/labels/latest
command: >-
  python download_extra_dependency.py
  --mlflow-model '${{inputs.mlflow_model}}' ;
  python model_prediction.py
  --data '${{inputs.test_data}}'
  --task ${{inputs.task}}
  --predictions '${{outputs.predictions}}'
  --ground-truth '${{outputs.ground_truth}}'
  --mlflow_model '${{inputs.mlflow_model}}'
  --label-column-name ${{inputs.label_column_name}}
  --performance-metadata '${{outputs.performance_metadata}}'
  --prediction-probabilities '${{outputs.prediction_probabilities}}'
  $[[--input-column-names '${{inputs.input_column_names}}']]
  $[[--batch-size ${{inputs.mini_batch_size}}]]
  $[[--parameters '${{inputs.evaluation_config_params}}']]
