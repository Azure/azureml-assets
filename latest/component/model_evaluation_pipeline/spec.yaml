$schema: https://azuremlschemas.azureedge.net/latest/pipelineComponent.schema.json
name: model_evaluation_pipeline
version: 0.0.20
type: pipeline
display_name: Model Evaluation Pipeline
description: Pipeline component for model evaluation for supported tasks. \ Generates
  predictions on a given model, followed by computing model performance metrics to
  score the model quality for supported tasks.

tags:
  type: evaluation
  sub_type: subgraph
  Preview: ""

inputs:
  compute_name:
    type: string
    default: serverless
  instance_type:
    type: string
    default: STANDARD_NC24S_V3
  # model prediction
  task:
    type: string
    default: tabular-classification
    enum: [tabular-classification, tabular-classification-multilabel, tabular-regression,
      text-classification, text-classification-multilabel, text-named-entity-recognition,
      text-summarization, question-answering, text-translation, text-generation, fill-mask,
      image-classification, image-classification-multilabel, chat-completion, image-object-detection,
      image-instance-segmentation]
    description: "Task type"
  test_data:
    type: uri_folder
    optional: false
    description: "Test Data"
  mlflow_model:
    type: mlflow_model
    optional: false
    description: "Mlflow Model (could be a registered model or part of another pipeline"
  label_column_name:
    type: string
    optional: true
    description: "Label column name in provided test dataset (Ex: label)"
  input_column_names:
    type: string
    optional: true
    description: "Input column names in provided test dataset (Ex : column1). Add\
      \ comma delimited values in case of multiple input columns (Ex : column1,column2)"
  device:
    type: string
    optional: false
    default: auto
    enum: [auto, cpu, gpu]
  batch_size:
    type: integer
    optional: true

  # compute metrics
  evaluation_config:
    type: uri_file
    optional: true
    description: "Additional parameters required for evaluation. See How to create\
      \ a config [here](https://microsoft.sharepoint.com/:f:/t/SDAutoML/EhDl9iADAR5MlCnlG4sy1NkBi5SfbdaZwKSFnUQD6ckeRg?e=cI7kaB)"
  evaluation_config_params:
    type: string
    optional: true
    description: "JSON Serialized string of evaluation_config"
  openai_config_params:
    type: string
    optional: true
    description: "Required OpenAI Params for calculating GPT Based metrics for QnA\
      \ task"

outputs:
  evaluation_result:
    type: uri_folder
    description: Output dir to save the evaluation result

jobs:
  validation_trigger_model_evaluation:
    type: command
    component: azureml:validation_trigger_model_evaluation:0.0.19
    compute: '${{parent.inputs.compute_name}}'
    resources:
      instance_type: '${{parent.inputs.instance_type}}'
    inputs:
      compute_name: '${{parent.inputs.compute_name}}'
      compute_instance_type: '${{parent.inputs.instance_type}}'
      task: '${{parent.inputs.task}}'
      test_data: '${{parent.inputs.test_data}}'
      mlflow_model_path: '${{parent.inputs.mlflow_model}}'
      label_column_name: '${{parent.inputs.label_column_name}}'
      input_column_names: '${{parent.inputs.input_column_names}}'
      device: '${{parent.inputs.device}}'
      batch_size: '${{parent.inputs.batch_size}}'
      evaluation_config: '${{parent.inputs.evaluation_config}}'
      evaluation_config_params: '${{parent.inputs.evaluation_config_params}}'

  validation_succeeded:
    type: if_else
    condition: ${{parent.jobs.validation_trigger_model_evaluation.outputs.output}}
    true_block: ${{parent.jobs.model_prediction}}

  model_prediction:
    type: command
    component: azureml:model_prediction:0.0.19
    compute: '${{parent.inputs.compute_name}}'
    resources:
      instance_type: '${{parent.inputs.instance_type}}'
    inputs:
      task: '${{parent.inputs.task}}'
      test_data: '${{parent.inputs.test_data}}'
      mlflow_model: '${{parent.inputs.mlflow_model}}'
      label_column_name: '${{parent.inputs.label_column_name}}'
      input_column_names: '${{parent.inputs.input_column_names}}'
      device: '${{parent.inputs.device}}'
      batch_size: '${{parent.inputs.batch_size}}'
      evaluation_config: '${{parent.inputs.evaluation_config}}'
      evaluation_config_params: '${{parent.inputs.evaluation_config_params}}'
  compute_metrics:
    type: command
    component: azureml:compute_metrics:0.0.19
    compute: '${{parent.inputs.compute_name}}'
    resources:
      instance_type: '${{parent.inputs.instance_type}}'
    inputs:
      task: '${{parent.inputs.task}}'
      ground_truth: '${{parent.jobs.model_prediction.outputs.ground_truth}}'
      ground_truth_column_name: '${{parent.inputs.label_column_name}}'
      prediction: '${{parent.jobs.model_prediction.outputs.predictions}}'
      prediction_column_name: predictions
      prediction_probabilities: '${{parent.jobs.model_prediction.outputs.prediction_probabilities}}'
      evaluation_config: '${{parent.inputs.evaluation_config}}'
      evaluation_config_params: '${{parent.inputs.evaluation_config_params}}'
      openai_config_params: '${{parent.inputs.openai_config_params}}'
    outputs:
      evaluation_result: '${{parent.outputs.evaluation_result}}'
