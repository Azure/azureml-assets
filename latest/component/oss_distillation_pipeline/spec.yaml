$schema: https://azuremlschemas.azureedge.net/latest/pipelineComponent.schema.json
name: oss_distillation_pipeline
version: 0.0.10
type: pipeline


display_name: OSS Distillation Pipeline
description: Component to generate data from teacher model enpoint and finetune student
  model on generated dataset

inputs:
  # Compute parameters
  instance_type_pipeline_validation:
    type: string
    optional: true
    description: Instance type to be used for validation component. The parameter
      compute_pipeline_validation must be set to 'serverless' for instance_type to
      be used.
  instance_type_data_generation:
    type: string
    optional: true
    default: Standard_D4as_v4
    description: Instance type to be used for finetune component in case of virtual
      cluster compute, eg. Singularity.ND40_v2. The parameter compute_finetune must
      be set to 'serverless' for instance_type to be used
  instance_type_data_import:
    type: string
    optional: true
    default: Singularity.ND96amrs_A100_v4
    description: Instance type to be used for data_import component in case of virtual
      cluster compute, eg. Singularity.D8_v3. The parameter compute_data_import must
      be set to 'serverless' for instance_type to be used
  instance_type_finetune:
    type: string
    optional: true
    default: Singularity.ND96amrs_A100_v4
    description: Instance type to be used for finetune component in case of virtual
      cluster compute, eg. Singularity.ND40_v2. The parameter compute_finetune must
      be set to 'serverless' for instance_type to be used

  compute_pipeline_validation:
    type: string
    optional: true
    default: 'serverless'
    description: compute to be used for validation component

  compute_data_generation:
    type: string
    optional: true
    default: 'serverless'
    description: >-
      compute to be used for model_import eg. provide 'FT-Cluster' if
      your compute is named 'FT-Cluster'. Special characters like \ and ' are invalid
      in the parameter value.
      If compute cluster name is provided, instance_type field will be ignored and
      the respective cluster will be used
  compute_data_import:
    type: string
    optional: true
    default: 'serverless'
    description: >-
      compute to be used for model_import eg. provide 'FT-Cluster' if
      your compute is named 'FT-Cluster'. Special characters like \ and ' are invalid
      in the parameter value.
      If compute cluster name is provided, instance_type field will be ignored and
      the respective cluster will be used
  compute_finetune:
    type: string
    optional: true
    default: 'serverless'
    description: >-
      compute to be used for finetune eg. provide 'FT-Cluster' if your
      compute is named 'FT-Cluster'. Special characters like \ and ' are invalid in
      the parameter value.
      If compute cluster name is provided, instance_type field will be ignored and
      the respective cluster will be used

  # ########################### Data Generator Component ########################### #

  train_file_path:
    type: uri_file
    description: Path to the registered training data asset. The supported data formats
      are `jsonl`, `json`, `csv`, `tsv` and `parquet`.
    mode: rw_mount

  validation_file_path:
    type: uri_file
    optional: true
    description: Path to the registered validation data asset. The supported data
      formats are `jsonl`, `json`, `csv`, `tsv` and `parquet`.
    mode: rw_mount

  teacher_model_endpoint_name:
    type: string
    optional: true
    description: Teacher model endpoint name

  teacher_model_endpoint_url:
    type: string
    optional: true
    description: Teacher model endpoint URL

  teacher_model_endpoint_key:
    type: string
    optional: true
    description: Teacher model endpoint key

  teacher_model_max_new_tokens:
    type: integer
    default: 128
    description: Teacher model max_new_tokens inference parameter

  teacher_model_temperature:
    type: number
    default: 0.2
    description: Teacher model temperature inference parameter

  teacher_model_top_p:
    type: number
    default: 0.1
    description: Teacher model top_p inference parameter

  teacher_model_frequency_penalty:
    type: number
    default: 0.0
    description: Teacher model frequency penalty inference parameter

  teacher_model_presence_penalty:
    type: number
    default: 0.0
    description: Teacher model presence penalty inference parameter

  teacher_model_stop:
    type: string
    optional: true
    description: Teacher model stop inference parameter

  request_batch_size:
    type: integer
    default: 10
    description: No of data records to hit teacher model endpoint in one go

  min_endpoint_success_ratio:
    type: number
    default: 0.7
    description: >
      The minimum value of (successful_requests / total_requests) required for classifying
      inference as successful.
      If (successful_requests / total_requests) < min_endpoint_success_ratio, the
      experiment will be marked as failed.  By default it is 0.7 (0 means all requests
      are allowed to fail while 1 means no request should fail.)

  enable_chain_of_thought:
    type: string
    optional: true
    default: "false"
    description: Enable Chain of thought for data generation
    enum:
    - "true"
    - "false"

  enable_chain_of_density:
    type: string
    optional: true
    default: "false"
    description: Enable Chain of density for text summarization
    enum:
    - "true"
    - "false"

  max_len_summary:
    type: integer
    optional: true
    default: 80
    description: Maximum Length Summary for text summarization

  data_generation_task_type:
    type: string
    enum:
    - NLI
    - CONVERSATION
    - NLU_QA
    - MATH
    - SUMMARIZATION
    description: >
      Data generation task type. Supported values are:
      1. NLI: Generate Natural Language Inference data
      2. CONVERSATION: Generate conversational data (multi/single turn)
      3. NLU_QA: Generate Natural Language Understanding data for Question Answering
      data
      4. MATH: Generate Math data for numerical responses
      5. SUMMARIZATION: Generate Key Summary for an Article


  # ########################### Batch Score Component ########################### #
  authentication_type:
    type: string
    optional: false
    description: Authentication type for endpoint. Either `azureml_workspace_connection`
      or `managed_identity`.
    default: azureml_workspace_connection
    enum:
    - azureml_workspace_connection
    - managed_identity
  additional_headers:
    type: string
    optional: true
    description: JSON serialized string expressing additional headers to be added
      to each request.
  debug_mode:
    type: boolean
    optional: false
    default: false
    description: Enable debug mode to print all the debug logs in the score step.
  ensure_ascii:
    type: boolean
    optional: false
    default: false
    description: If set to true, the output is guaranteed to have all incoming non-ASCII
      characters escaped. If set to false, these characters will be output as-is.
      More detailed information can be found at https://docs.python.org/3/library/json.html
  max_retry_time_interval:
    type: integer
    optional: true
    description: The maximum time (in seconds) spent retrying a payload. If unspecified,
      payloads are retried for unlimited time.
  initial_worker_count:
    type: integer
    optional: false
    default: 5
    description: The initial number of workers to use for scoring.
  max_worker_count:
    type: integer
    optional: false
    default: 200
    description: Overrides `initial_worker_count` if necessary.
  instance_count:
    type: integer
    default: 1
    description: Number of nodes in a compute cluster we will run the batch score
      step on.
  max_concurrency_per_instance:
    type: integer
    default: 1
    description: Number of processes that will be run concurrently on any given node.
      This number should not be larger than 1/2 of the number of cores in an individual
      node in the specified cluster.
  mini_batch_size:
    type: string
    optional: true
    default: 100KB
    description: The mini batch size for parallel run.

  # ########################### Finetuning Component ########################### #

  number_of_gpu_to_use_finetuning:
    type: integer
    default: 1
    optional: true
    description: >-
      number of gpus to be used per node for finetuning, should be equal
      to number of gpu per node in the compute SKU used for finetune

  # Continual-Finetuning model path
  mlflow_model_path:
    type: mlflow_model
    optional: true
    description: MLflow model asset path. Special characters like \ and ' are invalid
      in the parameter value.
    mode: download
  pytorch_model_path:
    type: custom_model
    optional: true
    description: Pytorch model asset path. Special characters like \ and ' are invalid
      in the parameter value.
    mode: download

  # Training parameters
  num_train_epochs:
    type: integer
    default: 1
    optional: true
    description: training epochs

  per_device_train_batch_size:
    type: integer
    default: 1
    optional: true
    description: Train batch size

  learning_rate:
    type: number
    default: 3e-04
    optional: true
    description: Start learning rate.

  # Validation parameters
  system_properties:
    type: string
    optional: true
    description: Validation parameters propagated from pipeline.

  # Model parameters
  model_asset_id:
    type: string
    optional: false
    description: Asset id of model

  # Model registration
  registered_model_name:
    type: string
    optional: true
    description: Name of the registered model

  validation_info:
    type: uri_file
    optional: true
    description: Validation status.
    mode: rw_mount

outputs:
  output_model:
    type: uri_folder
    description: Output dir to save the finetuned lora weights
    mode: rw_mount

jobs:
  oss_distillation_validate_pipeline:
    type: command
    component: azureml:oss_distillation_validate_pipeline:0.0.5
    compute: '${{parent.inputs.compute_pipeline_validation}}'
    resources:
      instance_type: '${{parent.inputs.instance_type_pipeline_validation}}'
    identity:
      type: user_identity
    inputs:
      train_file_path: '${{parent.inputs.train_file_path}}'
      validation_file_path: '${{parent.inputs.validation_file_path}}'
      teacher_model_endpoint_name: '${{parent.inputs.teacher_model_endpoint_name}}'
      teacher_model_endpoint_url: '${{parent.inputs.teacher_model_endpoint_url}}'
      teacher_model_endpoint_key: '${{parent.inputs.teacher_model_endpoint_key}}'
      enable_chain_of_thought: '${{parent.inputs.enable_chain_of_thought}}'
      enable_chain_of_density: '${{parent.inputs.enable_chain_of_density}}'
      max_len_summary: '${{parent.inputs.max_len_summary}}'
      data_generation_task_type: '${{parent.inputs.data_generation_task_type}}'
      teacher_model_max_new_tokens: '${{parent.inputs.teacher_model_max_new_tokens}}'
      teacher_model_temperature: '${{parent.inputs.teacher_model_temperature}}'
      teacher_model_top_p: '${{parent.inputs.teacher_model_top_p}}'
      teacher_model_frequency_penalty: '${{parent.inputs.teacher_model_frequency_penalty}}'
      teacher_model_presence_penalty: '${{parent.inputs.teacher_model_presence_penalty}}'
      request_batch_size: '${{parent.inputs.request_batch_size}}'
      min_endpoint_success_ratio: '${{parent.inputs.min_endpoint_success_ratio}}'
      num_train_epochs: '${{parent.inputs.num_train_epochs}}'
      per_device_train_batch_size: '${{parent.inputs.per_device_train_batch_size}}'
      learning_rate: '${{parent.inputs.learning_rate}}'
    outputs:
      validation_info:
        type: uri_file
        path: azureml://datastores/${{default_datastore}}/paths/azureml/${{name}}/${{output_name}}.json

  data_generation_batch_scoring_selector:
    type: command
    component: azureml:oss_distillation_data_generation_batch_scoring_selector:0.0.1
    compute: '${{parent.inputs.compute_pipeline_validation}}'
    resources:
      instance_type: '${{parent.inputs.instance_type_pipeline_validation}}'
    identity:
      type: user_identity
    inputs:
      data_generation_task_type: '${{parent.inputs.data_generation_task_type}}'

  validation_succeeded:
    type: if_else
    condition: ${{parent.jobs.data_generation_batch_scoring_selector.outputs.output}}
    true_block: ${{parent.jobs.oss_distillation_batchscoring_datagen_pipeline}}
    false_block: ${{parent.jobs.oss_distillation_seq_scoring_pipeline}}

  oss_distillation_batchscoring_datagen_pipeline:
    type: pipeline
    component: azureml:oss_distillation_batchscoring_datagen_pipeline:0.0.1
    inputs:
      instance_type_pipeline_validation: '${{parent.inputs.instance_type_pipeline_validation}}'
      instance_type_data_generation: '${{parent.inputs.instance_type_data_generation}}'
      instance_type_data_import: '${{parent.inputs.instance_type_data_import}}'
      instance_type_finetune: '${{parent.inputs.instance_type_finetune}}'
      compute_pipeline_validation: '${{parent.inputs.compute_pipeline_validation}}'
      compute_data_generation: '${{parent.inputs.compute_data_generation}}'
      compute_data_import: '${{parent.inputs.compute_data_import}}'
      compute_finetune: '${{parent.inputs.compute_finetune}}'
      train_file_path: '${{parent.inputs.train_file_path}}'
      validation_file_path: '${{parent.inputs.validation_file_path}}'
      teacher_model_endpoint_url: '${{parent.inputs.teacher_model_endpoint_url}}'
      teacher_model_endpoint_name: '${{parent.inputs.teacher_model_endpoint_name}}'
      teacher_model_endpoint_key: '${{parent.inputs.teacher_model_endpoint_key}}'
      teacher_model_max_new_tokens: '${{parent.inputs.teacher_model_max_new_tokens}}'
      teacher_model_temperature: '${{parent.inputs.teacher_model_temperature}}'
      teacher_model_top_p: '${{parent.inputs.teacher_model_top_p}}'
      teacher_model_frequency_penalty: '${{parent.inputs.teacher_model_frequency_penalty}}'
      teacher_model_presence_penalty: '${{parent.inputs.teacher_model_presence_penalty}}'
      teacher_model_stop: '${{parent.inputs.teacher_model_stop}}'
      min_endpoint_success_ratio: '${{parent.inputs.min_endpoint_success_ratio}}'
      enable_chain_of_thought: '${{parent.inputs.enable_chain_of_thought}}'
      enable_chain_of_density: '${{parent.inputs.enable_chain_of_density}}'
      max_len_summary: '${{parent.inputs.max_len_summary}}'
      data_generation_task_type: '${{parent.inputs.data_generation_task_type}}'
      num_train_epochs: '${{parent.inputs.num_train_epochs}}'
      per_device_train_batch_size: '${{parent.inputs.per_device_train_batch_size}}'
      learning_rate: '${{parent.inputs.learning_rate}}'
      authentication_type: '${{parent.inputs.authentication_type}}'
      additional_headers: '${{parent.inputs.additional_headers}}'
      debug_mode: '${{parent.inputs.debug_mode}}'
      ensure_ascii: '${{parent.inputs.ensure_ascii}}'
      max_retry_time_interval: '${{parent.inputs.max_retry_time_interval}}'
      initial_worker_count: '${{parent.inputs.initial_worker_count}}'
      max_worker_count: '${{parent.inputs.max_worker_count}}'
      instance_count: '${{parent.inputs.instance_count}}'
      max_concurrency_per_instance: '${{parent.inputs.max_concurrency_per_instance}}'
      mini_batch_size: '${{parent.inputs.mini_batch_size}}'
      validation_info: '${{parent.jobs.oss_distillation_validate_pipeline.outputs.validation_info}}'

    outputs:
      generated_batch_train_file_path:
        type: uri_file
        path: azureml://datastores/${{default_datastore}}/paths/azureml/${{name}}/${{output_name}}.jsonl
      generated_batch_validation_file_path:
        type: uri_file
        path: azureml://datastores/${{default_datastore}}/paths/azureml/${{name}}/${{output_name}}.jsonl

  oss_distillation_seq_scoring_pipeline:
    type: pipeline
    component: azureml:oss_distillation_seq_scoring_pipeline:0.0.1
    inputs:
      instance_type_pipeline_validation: '${{parent.inputs.instance_type_pipeline_validation}}'
      instance_type_data_generation: '${{parent.inputs.instance_type_data_generation}}'
      instance_type_data_import: '${{parent.inputs.instance_type_data_import}}'
      instance_type_finetune: '${{parent.inputs.instance_type_finetune}}'
      compute_pipeline_validation: '${{parent.inputs.compute_pipeline_validation}}'
      compute_data_generation: '${{parent.inputs.compute_data_generation}}'
      compute_data_import: '${{parent.inputs.compute_data_import}}'
      compute_finetune: '${{parent.inputs.compute_finetune}}'
      train_file_path: '${{parent.inputs.train_file_path}}'
      validation_file_path: '${{parent.inputs.validation_file_path}}'
      teacher_model_endpoint_name: '${{parent.inputs.teacher_model_endpoint_name}}'
      teacher_model_endpoint_url: '${{parent.inputs.teacher_model_endpoint_url}}'
      teacher_model_endpoint_key: '${{parent.inputs.teacher_model_endpoint_key}}'
      teacher_model_max_new_tokens: '${{parent.inputs.teacher_model_max_new_tokens}}'
      teacher_model_temperature: '${{parent.inputs.teacher_model_temperature}}'
      teacher_model_top_p: '${{parent.inputs.teacher_model_top_p}}'
      teacher_model_frequency_penalty: '${{parent.inputs.teacher_model_frequency_penalty}}'
      teacher_model_presence_penalty: '${{parent.inputs.teacher_model_presence_penalty}}'
      teacher_model_stop: '${{parent.inputs.teacher_model_stop}}'
      request_batch_size: '${{parent.inputs.request_batch_size}}'
      min_endpoint_success_ratio: '${{parent.inputs.min_endpoint_success_ratio}}'
      enable_chain_of_thought: '${{parent.inputs.enable_chain_of_thought}}'
      enable_chain_of_density: '${{parent.inputs.enable_chain_of_density}}'
      max_len_summary: '${{parent.inputs.max_len_summary}}'
      data_generation_task_type: '${{parent.inputs.data_generation_task_type}}'
      validation_output: '${{parent.jobs.oss_distillation_validate_pipeline.outputs.validation_info}}'
    outputs:
      generated_train_file_path:
        type: uri_file
        path: azureml://datastores/${{default_datastore}}/paths/azureml/${{name}}/${{output_name}}.jsonl
      generated_validation_file_path:
        type: uri_file
        path: azureml://datastores/${{default_datastore}}/paths/azureml/${{name}}/${{output_name}}.jsonl


  oss_distillation_train_data_generation_file_selector:
    type: command
    component: azureml:oss_distillation_data_generation_file_selector:0.0.1
    compute: '${{parent.inputs.compute_pipeline_validation}}'
    resources:
      instance_type: '${{parent.inputs.instance_type_pipeline_validation}}'
    identity:
      type: user_identity
    inputs:
      generated_batch_train_file_path: '${{parent.jobs.oss_distillation_batchscoring_datagen_pipeline.outputs.generated_batch_train_file_path}}'
      generated_batch_validation_file_path: '${{parent.jobs.oss_distillation_batchscoring_datagen_pipeline.outputs.generated_batch_validation_file_path}}'
      generated_train_file_path: '${{parent.jobs.oss_distillation_seq_scoring_pipeline.outputs.generated_train_file_path}}'
      generated_validation_file_path: '${{parent.jobs.oss_distillation_seq_scoring_pipeline.outputs.generated_validation_file_path}}'
      condition: '${{parent.jobs.data_generation_batch_scoring_selector.outputs.output}}'
    outputs:
      ft_input_train_file_path:
        type: uri_file
        path: azureml://datastores/${{default_datastore}}/paths/azureml/${{name}}/${{output_name}}.jsonl
      ft_input_validation_file_path:
        type: uri_file
        path: azureml://datastores/${{default_datastore}}/paths/azureml/${{name}}/${{output_name}}.jsonl


  oss_text_generation_data_import:
    type: command
    component: azureml:oss_text_generation_data_import:0.0.25
    compute: '${{parent.inputs.compute_data_import}}'
    resources:
      instance_type: '${{parent.inputs.instance_type_data_import}}'
      properties:
        singularity:
          imageVersion: ''
          SLATier: 'Premium'
          priority: 'Medium'
    environment_variables:
      _AZUREML_CR_ENABLE_ITP_CAP: "false"
    inputs:
      train_file_path: '${{parent.jobs.oss_distillation_train_data_generation_file_selector.outputs.ft_input_train_file_path}}'
      validation_file_path: '${{parent.jobs.oss_distillation_train_data_generation_file_selector.outputs.ft_input_validation_file_path}}'
      system_properties: '${{parent.inputs.system_properties}}'

  oss_chat_completion_finetune:
    type: command
    component: azureml:oss_chat_completion_finetune:0.0.25
    compute: '${{parent.inputs.compute_finetune}}'
    resources:
      instance_type: '${{parent.inputs.instance_type_finetune}}'
      properties:
        singularity:
          imageVersion: ''
          SLATier: 'Premium'
          priority: 'Medium'
    environment_variables:
      _AZUREML_CR_ENABLE_ITP_CAP: "false"
    inputs:
      task_name: "ChatCompletion"
      mlflow_model_path: '${{parent.inputs.mlflow_model_path}}'
      model_asset_id: '${{parent.inputs.model_asset_id}}'
      pytorch_model_path: '${{parent.inputs.pytorch_model_path}}'
      dataset_input: '${{parent.jobs.oss_text_generation_data_import.outputs.output_dataset}}'
      batch_size: 1000
      pad_to_max_length: "false"
      max_seq_length: 8192
      number_of_gpu_to_use_finetuning: '${{parent.inputs.number_of_gpu_to_use_finetuning}}'
      apply_lora: "true"
      lora_alpha: 128
      lora_r: 8
      lora_dropout: 0
      num_train_epochs: '${{parent.inputs.num_train_epochs}}'
      max_steps: -1
      per_device_train_batch_size: '${{parent.inputs.per_device_train_batch_size}}'
      per_device_eval_batch_size: '${{parent.inputs.per_device_train_batch_size}}'
      auto_find_batch_size: "false"
      optim: adamw_hf
      learning_rate: '${{parent.inputs.learning_rate}}'
      warmup_steps: 0
      weight_decay: 0.1
      adam_beta1: 0.9
      adam_beta2: 0.95
      adam_epsilon: 1e-05
      gradient_accumulation_steps: 1
      eval_accumulation_steps: 1
      lr_scheduler_type: cosine
      precision: 16
      seed: 42
      enable_full_determinism: "false"
      dataloader_num_workers: 0
      ignore_mismatched_sizes: "false"
      max_grad_norm: 1.0
      evaluation_strategy: epoch
      evaluation_steps_interval: 0.0
      eval_steps: 500
      logging_strategy: steps
      logging_steps: 10
      metric_for_best_model: loss
      resume_from_checkpoint: "false"
      save_total_limit: 1
      apply_early_stopping: "false"
      early_stopping_patience: 0
      apply_deepspeed: "true"
      deepspeed_stage: 3
      apply_ort: "false"
      system_properties: '${{parent.inputs.system_properties}}'
      registered_model_name: '${{parent.inputs.registered_model_name}}'
      model_registration_tag: "isDistill:True"
    outputs:
      output_model: '${{parent.outputs.output_model}}'
