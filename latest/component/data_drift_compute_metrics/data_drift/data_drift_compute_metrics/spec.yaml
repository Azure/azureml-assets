$schema: http://azureml/sdk-2-0/SparkComponent.json
type: spark

name: data_drift_compute_metrics
display_name: Data Drift - Compute Metrics
description: Compute data drift metrics given a baseline and a deployment's model
  data input.
version: 0.3.34
is_deterministic: true

code: ../../src
entry:
  file: ./data_drift_compute_metrics/run.py

inputs:
  baseline_dataset:
    mode: direct
    type: mltable
  production_dataset:
    mode: direct
    type: mltable
  feature_names:
    mode: direct
    type: mltable
  numerical_metric:
    type: string
  categorical_metric:
    type: string
  categorical_threshold:
    type: number
  numerical_threshold:
    type: number
  override_numerical_features:
    type: string
    optional: true
  override_categorical_features:
    type: string
    optional: true
outputs:
  signal_metrics:
    mode: direct
    type: mltable
conf:
  spark.hadoop.aml.enable_cache: "true"
  spark.driver.cores: 4
  spark.driver.memory: 28g
  spark.executor.cores: 4
  spark.executor.memory: 28g
  spark.executor.instances: 1
  spark.dynamicAllocation.enabled: true
  spark.dynamicAllocation.minExecutors: 1
  spark.dynamicAllocation.maxExecutors: 4
  spark.jars.packages: com.microsoft.azure:synapseml_2.12:0.11.0-26-52919ce4-SNAPSHOT,org.apache.spark:spark-avro_2.12:3.3.1
  spark.jars.repositories: https://mmlspark.azureedge.net/maven
  spark.jars.excludes: org.scala-lang:scala-reflect,org.apache.spark:spark-tags_2.12,org.scalactic:scalactic_2.12,org.scalatest:scalatest_2.12,com.fasterxml.jackson.core:jackson-databind
  spark.yarn.user.classpath.first: true
  spark.sql.parquet.enableVectorizedReader: false
  spark.sql.legacy.replaceDatabricksSparkAvro.enabled: true
  spark.driver.userClassPathFirst: false
  spark.executor.userClassPathFirst: false
  spark.aml.internal.system.job: true
  spark.synapse.library.python.env: |
    channels:
      - defaults
    dependencies:
      - pip:
        - azure-storage-file-datalake~=12.11.0
        - azure-ai-ml~=1.26.3
        - azureml-mlflow~=1.59.0
        - mltable~=1.6.1
        - azureml-fsspec~=1.3.1
        - fsspec~=2023.4.0
        - numpy<2.0.0
    name: momo-base-spark
args: >-
  --production_dataset ${{inputs.production_dataset}}
  --baseline_dataset ${{inputs.baseline_dataset}}
  --numerical_metric ${{inputs.numerical_metric}}
  --categorical_metric ${{inputs.categorical_metric}}
  --numerical_threshold ${{inputs.numerical_threshold}}
  --categorical_threshold ${{inputs.categorical_threshold}}
  --feature_names ${{inputs.feature_names}}
  $[[--override_numerical_features ${{inputs.override_numerical_features}}]]
  $[[--override_categorical_features ${{inputs.override_categorical_features}}]]
  --signal_metrics ${{outputs.signal_metrics}}
