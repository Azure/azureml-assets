$schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json
name: batch_deploy_model
version: 0.0.6
type: command

is_deterministic: true

display_name: Batch deploy model
description: Batch deploy a model to a workspace. The component works on compute with
  [MSI](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-create-manage-compute-instance?tabs=python)
  attached.

environment: azureml://registries/azureml/environments/python-sdk-v2/versions/31

code: ../../src
command: >-
  python batch_deploy.py
  $[[--registration_details_folder ${{inputs.registration_details_folder}}]]
  $[[--model_id ${{inputs.model_id}}]]
  $[[--inference_payload_file ${{inputs.inference_payload_file}}]]
  $[[--inference_payload_folder ${{inputs.inference_payload_folder}}]]
  $[[--endpoint_name ${{inputs.endpoint_name}}]]
  $[[--deployment_name ${{inputs.deployment_name}}]]
  $[[--compute_name ${{inputs.compute_name}}]]
  $[[--size ${{inputs.size}}]]
  $[[--min_instances ${{inputs.min_instances}}]]
  $[[--max_instances ${{inputs.max_instances}}]]
  $[[--idle_time_before_scale_down ${{inputs.idle_time_before_scale_down}}]]
  $[[--output_file_name ${{inputs.output_file_name}}]]
  $[[--max_concurrency_per_instance ${{inputs.max_concurrency_per_instance}}]]
  $[[--error_threshold ${{inputs.error_threshold}}]]
  $[[--max_retries ${{inputs.max_retries}}]]
  $[[--timeout ${{inputs.timeout}}]]
  $[[--logging_level ${{inputs.logging_level}}]]
  $[[--mini_batch_size ${{inputs.mini_batch_size}}]]
  $[[--instance_count ${{inputs.instance_count}}]]
  --batch_job_output_folder ${{outputs.batch_job_output_folder}}

inputs:
  # Output of registering component
  registration_details_folder:
    type: uri_folder
    optional: true
    description: Folder containing model registration details in a JSON file named
      model_registration_details.json

  model_id:
    type: string
    optional: true
    description: |
      Asset ID of the model registered in workspace/registry.
      Registry - azureml://registries/<registry-name>/models/<model-name>/versions/<version>
      Workspace - azureml:<model-name>:<version>

  inference_payload_file:
    type: uri_file
    optional: true
    description: File containing data used to validate deployment

  inference_payload_folder:
    type: uri_folder
    optional: true
    description: Folder containing files used to validate deployment

  endpoint_name:
    type: string
    optional: true
    description: Name of the endpoint

  deployment_name:
    type: string
    optional: true
    default: default
    description: Name of the deployment

  compute_name:
    type: string
    optional: true
    default: cpu-cluster
    description: Name of the compute cluster to execute the batch scoring jobs on.
      New compute will be created if the compute cluster is not present.

  size:
    type: string
    optional: true
    enum:
    - Standard_DS1_v2
    - Standard_DS2_v2
    - Standard_DS3_v2
    - Standard_DS4_v2
    - Standard_DS5_v2
    - Standard_F2s_v2
    - Standard_F4s_v2
    - Standard_F8s_v2
    - Standard_F16s_v2
    - Standard_F32s_v2
    - Standard_F48s_v2
    - Standard_F64s_v2
    - Standard_F72s_v2
    - Standard_FX24mds
    - Standard_FX36mds
    - Standard_FX48mds
    - Standard_E2s_v3
    - Standard_E4s_v3
    - Standard_E8s_v3
    - Standard_E16s_v3
    - Standard_E32s_v3
    - Standard_E48s_v3
    - Standard_E64s_v3
    - Standard_NC4as_T4_v3
    - Standard_NC6s_v2
    - Standard_NC6s_v3
    - Standard_NC8as_T4_v3
    - Standard_NC12s_v2
    - Standard_NC12s_v3
    - Standard_NC16as_T4_v3
    - Standard_NC24s_v2
    - Standard_NC24s_v3
    - Standard_NC24rs_v3
    - Standard_NC64as_T4_v3
    - Standard_ND40rs_v2
    - Standard_ND96asr_v4
    - Standard_ND96amsr_A100_v4
    default: Standard_NC24s_v3
    description: Compute instance size to deploy model. Make sure that instance type
      is available and have enough quota available.

  min_instances:
    type: integer
    optional: true
    default: 0
    description: Minimum number of instances of the compute cluster to be created.

  max_instances:
    type: integer
    optional: true
    default: 1
    description: Maximum number of instances of the compute cluster to be created.

  idle_time_before_scale_down:
    type: integer
    optional: true
    default: 120
    description: Node Idle Time before scaling down the compute cluster to be created.

  output_file_name:
    type: string
    optional: true
    default: predictions.csv
    description: Name of the batch scoring output file.

  max_concurrency_per_instance:
    type: integer
    optional: true
    default: 1
    description: The maximum number of parallel scoring_script runs per instance.

  error_threshold:
    type: integer
    optional: true
    default: -1
    description: The number of file failures that should be ignored.

  max_retries:
    type: integer
    optional: true
    default: 3
    description: The maximum number of retries for a failed or timed-out mini batch.

  timeout:
    type: integer
    optional: true
    default: 500
    description: The timeout in seconds for scoring a single mini batch.

  logging_level:
    type: string
    optional: true
    default: info
    description: The log verbosity level.

  mini_batch_size:
    type: integer
    optional: true
    default: 10
    description: The number of files the code_configuration.scoring_script can process
      in one run() call.

  instance_count:
    type: integer
    optional: true
    default: 1
    description: The number of nodes to use for each batch scoring job.

outputs:
  batch_job_output_folder:
    type: uri_folder
    description: Folder to which batch job outputs will be saved.

tags:
  Preview: ""
  Internal: ""
