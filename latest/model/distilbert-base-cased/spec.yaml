$schema: https://azuremlschemas.azureedge.net/latest/model.schema.json
name: distilbert-base-cased
path: ./
properties:
  SHA: 4dc145c5bd4fdb672dcded7fdc1efd6c2bc55992
  datasets: bookcorpus, wikipedia
  finetuning-tasks: text-classification, token-classification, question-answering
  languages: en
  inference-recommended-sku: Standard_DS2_v2
  inference-min-sku-spec: 2|0|7|14
  evaluation-recommended-sku: Standard_DS2_v2
  evaluation-min-sku-spec: 2|0|7|14
  finetune-recommended-sku: Standard_ND40RS_v2
  finetune-min-sku-spec: 4|1|28|176     # num_cpu_cores|num_gpu|ram_gb|memory_gb (this min sku spec is used to filter the computes shown to the user submitting a job from Model Catalog page)
tags:
  Preview: ''
  license: apache-2.0
  task: fill-mask
version: 3
description: |
  The DistilBERT model is a smaller, faster version of the BERT model for Transformer-based language modeling with 40% fewer parameters and 60% faster run time while retaining 95% of BERT's performance on the GLUE language understanding benchmark. This English language question answering model has a F1 score of 87.1 on SQuAD v1.1 and was developed by Hugging Face under the Apache 2.0 license. Training the model requires significant computational power, such as 8 16GB V100 GPUs and 90 hours. Intended uses include fine-tuning on downstream tasks, but it should not be used to create hostile or alienating environments and limitations and biases should be taken into account.
  <br>Please Note: This model accepts masks in `[mask]` format. See Sample input for reference.Â 
  > The above summary was generated using ChatGPT. Review the <a href="https://huggingface.co/distilbert-base-cased" target="_blank">original model card</a> to understand the data used to train the model, evaluation metrics, license, intended uses, limitations and bias before using the model.

  ### Inference samples

  Inference type|Python sample (Notebook)|CLI with YAML
  |--|--|--|
  Real time|<a href="https://aka.ms/azureml-infer-online-sdk-fill-mask" target="_blank">fill-mask-online-endpoint.ipynb</a>|<a href="https://aka.ms/azureml-infer-online-cli-fill-mask" target="_blank">fill-mask-online-endpoint.sh</a>
  Batch | coming soon


  ### Finetuning samples

  Task|Use case|Dataset|Python sample (Notebook)|CLI with YAML
  |--|--|--|--|--|
  Text Classification|Emotion Detection|<a href="https://huggingface.co/datasets/dair-ai/emotion" target="_blank">Emotion</a>|<a href="https://aka.ms/azureml-ft-sdk-emotion-detection" target="_blank">emotion-detection.ipynb</a>|<a href="https://aka.ms/azureml-ft-cli-emotion-detection" target="_blank">emotion-detection.sh</a>
  Token Classification|Named Entity Recognition|<a href="https://huggingface.co/datasets/conll2003" target="_blank">Conll2003</a>|<a href="https://aka.ms/azureml-ft-sdk-token-classification" target="_blank">named-entity-recognition.ipynb</a>|<a href="https://aka.ms/azureml-ft-cli-token-classification" target="_blank">named-entity-recognition.sh</a>
  Question Answering|Extractive Q&A|<a href="https://huggingface.co/datasets/squad" target="_blank">SQUAD (Wikipedia)</a>|<a href="https://aka.ms/azureml-ft-sdk-extractive-qa" target="_blank">extractive-qa.ipynb</a>|<a href="https://aka.ms/azureml-ft-cli-extractive-qa" target="_blank">extractive-qa.sh</a>


  ### Model Evaluation

  Task| Use case| Python sample (Notebook)| CLI with YAML
  |--|--|--|--|
  Fill Mask | Fill Mask | <a href="https://huggingface.co/datasets/imdb" target="_blank">imdb</a> | <a href="https://aka.ms/azureml-eval-sdk-fill-mask/" target="_blank">evaluate-model-fill-mask.ipynb</a> | <a href="https://aka.ms/azureml-eval-cli-fill-mask/" target="_blank">evaluate-model-fill-mask.yml</a>


  ### Sample inputs and outputs (for real-time inference)

  #### Sample input
  ```json
  {
      "inputs": {
          "input_string": ["Paris is the [MASK] of France.", "Today is a [MASK] day!"]
      }
  }
  ```

  #### Sample output
  ```json
  [
      {
          "0": "capital"
      },
      {
          "0": "beautiful"
      }
  ]
  ```
