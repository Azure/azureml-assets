$schema: https://azuremlschemas.azureedge.net/latest/model.schema.json
name: roberta-base-openai-detector
path: ./
properties:
  SHA: 8bdaf8823e2e58aaa3716eabc607f05b631b7273
  datasets: bookcorpus, wikipedia
  finetuning-tasks: text-classification, token-classification, question-answering
  languages: en
tags:
  Preview: ''
  license: mit
  min_inference_sku: Standard_DS2_v2
  task: text-classification
version: 1
description: |
  RoBERTa Base OpenAI Detector is a language model developed by OpenAI that is fine-tuned using outputs from the 1.5B GPT-2 model. It is designed to detect text generated by GPT-2 and is not meant to be used for malicious purposes or to evade detection. The main focus of the model is to aid in synthetic text generation research, but users should be aware of its limitations, risks and potential biases, including accuracy and robustness limitations and the possibility of bias and stereotypes. The associated paper provides information on the training procedure and results from testing, which showed that the model achieved approximately 95% accuracy in detecting text generated by GPT-2, with a higher accuracy when trained using nucleus sampling. Further improvement to the model's effectiveness is said to require methods such as metadata-based approaches, human judgment, and public education.


  > The above summary was generated using ChatGPT. Review the [original model card](https://huggingface.co/roberta-base-openai-detector) to understand the data used to train the model, evaluation metrics, license, intended uses, limitations and bias before using the model.


  ### Inference samples

  Inference type|Python sample (Notebook)|CLI with YAML
  |--|--|--|
  Real time|[entailment-contradiction-online.ipynb](https://aka.ms/azureml-infer-online-sdk-text-classification)|[text-classification-online-endpoint.sh](https://aka.ms/azureml-infer-online-cli-text-classification)
  Batch | coming soon


  ### Finetuning samples

  Task|Use case|Dataset|Python sample (Notebook)|CLI with YAML
  |---|--|--|--|--|
  Text Classification|Emotion Detection|[Emotion](https://huggingface.co/datasets/dair-ai/emotion)|[emotion-detection.ipynb](https://aka.ms/azureml-ft-sdk-emotion-detection)|[emotion-detection.sh](https://aka.ms/azureml-ft-cli-emotion-detection)
  Token Classification|Token Classification|[Conll2003](https://huggingface.co/datasets/conll2003)|[token-classification.ipynb](https://aka.ms/azureml-ft-sdk-token-classification)|[token-classification.sh](https://aka.ms/azureml-ft-cli-token-classification)
  Question Answering|Extractive Q&A|[SQUAD (Wikipedia)](https://huggingface.co/datasets/squad)|[extractive-qa.ipynb](https://aka.ms/azureml-ft-sdk-extractive-qa)|[extractive-qa.sh](https://aka.ms/azureml-ft-cli-extractive-qa)


  ### Model Evaluation

  | Task                | Use case          | Dataset                                                   | Python sample (Notebook)                                                                        | CLI with YAML                                                                                 |
  |---------------------|-------------------|-----------------------------------------------------------|-------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------|
  | Text Classification | Emotion Detection | [GoEmotions](https://huggingface.co/datasets/go_emotions) | [evaluate-model-text-classification.ipynb](https://aka.ms/azureml-eval-sdk-text-classification) | [evaluate-model-text-classification.yml](https://aka.ms/azureml-eval-cli-text-classification) |


  ### Sample inputs and outputs (for real-time inference)

  #### Sample input
  ```json
  {
      "inputs": {
          "input_string": ["Today was an amazing day!", "It was an unfortunate series of events."]
      }
  }
  ```

  #### Sample output
  ```json
  [
      {
          "label": "Fake",
          "score": 0.9851952195167542
      },
      {
          "label": "Fake",
          "score": 0.6486035585403442
      }
  ]
  ```
