$schema: https://azuremlschemas.azureedge.net/latest/model.schema.json
name: Coherence-Evaluator
path: ./
properties:
  is-promptflow: true
  is-evaluator: true
  show-artifact: true
  _default-display-file: ./evaluator/prompt.jinja2
tags:
  Preview: ""
  hiddenlayerscanned: ""
version: 2
description: |
  | 	| |
  | -- | -- |
  | Score range |	Integer [1-5]: where 1 is bad and 5 is good |
  | What is this metric? | Measures how well the language model can produce output that flows smoothly, reads naturally, and resembles human-like language. |
  | How does it work? | The coherence measure assesses the ability of the language model to generate text that reads naturally, flows smoothly, and resembles human-like language in its responses. |
  | When to use it? |	Use it when assessing the readability and user-friendliness of your model's generated responses in real-world applications. |
  | What does it need as input? |	Query, Generated Response |
