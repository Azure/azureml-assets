$schema: https://azuremlschemas.azureedge.net/latest/model.schema.json
name: t5-large
path: ./
properties:
  SHA: 150ebc2c4b72291e770f58e6057481c8d2ed331a
  datasets: c4
  evaluation-min-sku-spec: 8|0|28|56
  evaluation-recommended-sku: Standard_DS4_v2
  finetune-min-sku-spec: 4|1|28|176
  finetune-recommended-sku: Standard_NC24rs_v3
  finetuning-tasks: summarization, translation
  inference-min-sku-spec: 8|0|28|56
  inference-recommended-sku: Standard_DS4_v2, Standard_D8a_v4, Standard_D8as_v4, Standard_DS5_v2,
    Standard_D16a_v4, Standard_D16as_v4, Standard_D32a_v4, Standard_D32as_v4, Standard_D48a_v4,
    Standard_D48as_v4, Standard_D64a_v4, Standard_D64as_v4, Standard_D96a_v4, Standard_D96as_v4,
    Standard_FX12mds, Standard_F16s_v2, Standard_F32s_v2, Standard_F48s_v2, Standard_F64s_v2,
    Standard_F72s_v2, Standard_FX24mds, Standard_FX36mds, Standard_FX48mds, Standard_E8s_v3,
    Standard_E16s_v3, Standard_E32s_v3, Standard_E48s_v3, Standard_E64s_v3, Standard_NC4as_T4_v3,
    Standard_NC6s_v3, Standard_NC8as_T4_v3, Standard_NC12s_v3, Standard_NC16as_T4_v3,
    Standard_NC24s_v3, Standard_NC64as_T4_v3, Standard_NC24ads_A100_v4, Standard_NC48ads_A100_v4,
    Standard_NC96ads_A100_v4, Standard_ND96asr_v4, Standard_ND96amsr_A100_v4, Standard_ND40rs_v2
  languages: en, fr, ro, de
tags:
  Preview: ''
  computes_allow_list:
  - Standard_NC6s_v3
  - Standard_NC12s_v3
  - Standard_NC24s_v3
  - Standard_NC24rs_v3
  - Standard_NC6s_v2
  - Standard_NC12s_v2
  - Standard_NC24s_v2
  - Standard_NC24rs_v2
  - Standard_NC4as_T4_v3
  - Standard_NC8as_T4_v3
  - Standard_NC16as_T4_v3
  - Standard_NC64as_T4_v3
  - Standard_ND6s
  - Standard_ND12s
  - Standard_ND24s
  - Standard_ND24rs
  - Standard_ND40rs_v2
  - Standard_ND96asr_v4
  license: apache-2.0
  model_specific_defaults:
    apply_deepspeed: 'true'
    apply_lora: 'true'
    apply_ort: 'true'
  task: text-translation
version: 12
description: |
  The T5-Large is a text-to-text transfer transformer (T5) model with 770 million parameters. It has been developed by Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J. Liu. The T5 model is a language model that is pre-trained on a multi-task mixture of unsupervised and supervised tasks. The model is versatile and can be used for many NLP tasks such as translation, summarization, question answering, and classification. The license of T5-Large is Apache 2.0. The model is made available on GitHub and is well-documented on Hugging Face.  A code sample is provided to get started with this model. The input and output are always text strings. The T5 framework was introduced to bring together transfer learning techniques for NLP and convert all language problems into the text to text format. The T5 model was pre-trained on the Colossal Clean Crawled Corpus (C4). The full details of the training procedure can be found in the research paper. The evaluation of T5-Large is not provided. The information regarding bias, risks, limitations, and recommendations is not available. The authors of the Model Card for T5-Large are not specified.

  > The above summary was generated using ChatGPT. Review the <a href="https://huggingface.co/t5-large" target="_blank">original-model-card</a> to understand the data used to train the model, evaluation metrics, license, intended uses, limitations and bias before using the model.

  ### Inference samples

  Inference type|Python sample (Notebook)|CLI with YAML
  |--|--|--|
  Real time|<a href="https://aka.ms/azureml-infer-online-sdk-translation" target="_blank">translation-online-endpoint.ipynb</a>|<a href="https://aka.ms/azureml-infer-online-cli-translation" target="_blank">translation-online-endpoint.sh</a>
  Batch |<a href="https://aka.ms/azureml-infer-batch-sdk-translation" target="_blank">translation-batch-endpoint.ipynb</a>| coming soon


  ### Finetuning samples

  Task|Use case|Dataset|Python sample (Notebook)|CLI with YAML
  |--|--|--|--|--|
  Summarization|News Summary|<a href="https://huggingface.co/datasets/cnn_dailymail" target="_blank">CNN DailyMail</a>|<a href="https://aka.ms/azureml-ft-sdk-news-summary" target="_blank">news-summary.ipynb</a>|<a href="https://aka.ms/azureml-ft-cli-news-summary" target="_blank">news-summary.sh</a>
  Translation|Translate English to Romanian|<a href="https://huggingface.co/datasets/cnn_dailymail" target="_blank">WMT16</a>|<a href="https://aka.ms/azureml-ft-sdk-translation" target="_blank">translate-english-to-romanian.ipynb</a>|<a href="https://aka.ms/azureml-ft-cli-translation" target="_blank">translate-english-to-romanian.sh</a>


  ### Model Evaluation

  Task| Use case| Dataset| Python sample (Notebook)| CLI with YAML
  |--|--|--|--|--|
  Translation | Translation | <a href="https://huggingface.co/datasets/wmt16/viewer/ro-en/train" target="_blank">wmt16/ro-en</a> | <a href="https://aka.ms/azureml-eval-sdk-translation" target="_blank">evaluate-model-translation.ipynb</a> | <a href="https://aka.ms/azureml-eval-cli-translation" target="_blank">evaluate-model-translation.yml</a>


  ### Sample inputs and outputs (for real-time inference)

  #### Sample input
  ```json
  {
      "input_data": {
          "input_string": ["My name is John and I live in Seattle", "Berlin is the capital of Germany."]
      },
      "parameters": {
          "task_type": "translation_en_to_fr"
      }
  }
  ```

  #### Sample output
  ```json
  [
      {
          "0": "Mon nom est John et je vivais Ã  Seattle."
      },
      {
          "0": "Berlin est la capitale de l'Allemagne."
      }
  ]
  ```
