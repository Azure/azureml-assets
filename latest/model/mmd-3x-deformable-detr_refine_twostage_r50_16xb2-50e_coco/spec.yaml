$schema: https://azuremlschemas.azureedge.net/latest/model.schema.json
name: mmd-3x-deformable-detr_refine_twostage_r50_16xb2-50e_coco
path: ./
properties:
  SharedComputeCapacityEnabled: true
  SHA: 4c111175692fb607b153282bf15c81c8e7f8edcc
  finetuning-tasks: image-object-detection
  finetune-min-sku-spec: 4|1|28|176
  finetune-recommended-sku: Standard_NC4as_T4_v3, Standard_NC6s_v3, 
    Standard_NC8as_T4_v3, Standard_NC12s_v3, Standard_NC16as_T4_v3, 
    Standard_NC24s_v3, Standard_NC64as_T4_v3, Standard_NC96ads_A100_v4, 
    Standard_ND96asr_v4, Standard_ND96amsr_A100_v4, Standard_ND40rs_v2
  evaluation-min-sku-spec: 4|1|28|176
  evaluation-recommended-sku: Standard_NC4as_T4_v3, Standard_NC6s_v3, 
    Standard_NC8as_T4_v3, Standard_NC12s_v3, Standard_NC16as_T4_v3, 
    Standard_NC24s_v3, Standard_NC64as_T4_v3, Standard_NC96ads_A100_v4, 
    Standard_ND96asr_v4, Standard_ND96amsr_A100_v4, Standard_ND40rs_v2
  inference-min-sku-spec: 4|0|14|28
  inference-recommended-sku: Standard_DS3_v2, Standard_D4a_v4, Standard_D4as_v4,
    Standard_DS4_v2, Standard_D8a_v4, Standard_D8as_v4, Standard_DS5_v2, 
    Standard_D16a_v4, Standard_D16as_v4, Standard_D32a_v4, Standard_D32as_v4, 
    Standard_D48a_v4, Standard_D48as_v4, Standard_D64a_v4, Standard_D64as_v4, 
    Standard_D96a_v4, Standard_D96as_v4, Standard_FX4mds, Standard_F8s_v2, 
    Standard_FX12mds, Standard_F16s_v2, Standard_F32s_v2, Standard_F48s_v2, 
    Standard_F64s_v2, Standard_F72s_v2, Standard_FX24mds, Standard_FX36mds, 
    Standard_FX48mds, Standard_E4s_v3, Standard_E8s_v3, Standard_E16s_v3, 
    Standard_E32s_v3, Standard_E48s_v3, Standard_E64s_v3, Standard_NC4as_T4_v3, 
    Standard_NC6s_v3, Standard_NC8as_T4_v3, Standard_NC12s_v3, 
    Standard_NC16as_T4_v3, Standard_NC24s_v3, Standard_NC64as_T4_v3, 
    Standard_NC24ads_A100_v4, Standard_NC48ads_A100_v4, 
    Standard_NC96ads_A100_v4, Standard_ND96asr_v4, Standard_ND96amsr_A100_v4, 
    Standard_ND40rs_v2
tags:
  SharedComputeCapacityEnabled: ''
  openmmlab_model_id: mmd-3x-deformable-detr_refine_twostage_r50_16xb2-50e_coco
  training_dataset: COCO
  hiddenlayerscanned: ""
  license: apache-2.0
  model_specific_defaults:
    apply_deepspeed: 'false'
    apply_ort: 'false'
  task: object-detection
  inference_compute_allow_list: [Standard_DS3_v2, Standard_D4a_v4, 
      Standard_D4as_v4, Standard_DS4_v2, Standard_D8a_v4, Standard_D8as_v4, 
      Standard_DS5_v2, Standard_D16a_v4, Standard_D16as_v4, Standard_D32a_v4, 
      Standard_D32as_v4, Standard_D48a_v4, Standard_D48as_v4, Standard_D64a_v4, 
      Standard_D64as_v4, Standard_D96a_v4, Standard_D96as_v4, Standard_FX4mds, 
      Standard_F8s_v2, Standard_FX12mds, Standard_F16s_v2, Standard_F32s_v2, 
      Standard_F48s_v2, Standard_F64s_v2, Standard_F72s_v2, Standard_FX24mds, 
      Standard_FX36mds, Standard_FX48mds, Standard_E4s_v3, Standard_E8s_v3, 
      Standard_E16s_v3, Standard_E32s_v3, Standard_E48s_v3, Standard_E64s_v3, 
      Standard_NC4as_T4_v3, Standard_NC6s_v3, Standard_NC8as_T4_v3, 
      Standard_NC12s_v3, Standard_NC16as_T4_v3, Standard_NC24s_v3, 
      Standard_NC64as_T4_v3, Standard_NC24ads_A100_v4, Standard_NC48ads_A100_v4, 
      Standard_NC96ads_A100_v4, Standard_ND96asr_v4, Standard_ND96amsr_A100_v4, 
      Standard_ND40rs_v2]
  evaluation_compute_allow_list: [Standard_NC4as_T4_v3, Standard_NC6s_v3, 
      Standard_NC8as_T4_v3, Standard_NC12s_v3, Standard_NC16as_T4_v3, 
      Standard_NC24s_v3, Standard_NC64as_T4_v3, Standard_NC96ads_A100_v4, 
      Standard_ND96asr_v4, Standard_ND96amsr_A100_v4, Standard_ND40rs_v2]
  finetune_compute_allow_list: [Standard_NC4as_T4_v3, Standard_NC6s_v3, 
      Standard_NC8as_T4_v3, Standard_NC12s_v3, Standard_NC16as_T4_v3, 
      Standard_NC24s_v3, Standard_NC64as_T4_v3, Standard_NC96ads_A100_v4, 
      Standard_ND96asr_v4, Standard_ND96amsr_A100_v4, Standard_ND40rs_v2]
version: 16
description: |
  `deformable-detr_refine_twostage_r50_16xb2-50e_coco` model is from <a href="https://github.com/open-mmlab/mmdetection/tree/v3.1.0" target="_blank">OpenMMLab's MMDetection library</a>. DETR has been recently proposed to eliminate the need for many hand-designed components in object detection while demonstrating good performance. However, it suffers from slow convergence and limited feature spatial resolution, due to the limitation of Transformer attention modules in processing image feature maps. To mitigate these issues, we proposed Deformable DETR, whose attention modules only attend to a small set of key sampling points around a reference. Deformable DETR can achieve better performance than DETR (especially on small objects) with 10 times less training epochs. Extensive experiments on the COCO benchmark demonstrate the effectiveness of our approach.

  # Training Details

  ## Training Data

  The model developers used COCO dataset for training the model.

  ## Training Procedure

  Training Techniques:

  - AdamW
  - Multi Scale Train
  - Gradient Clip

  Epochs: 50

  Training Resources: 8 x V100 GPUs

  # Evaluation Results

  box AP: 47.0

  # License

  apache-2.0

  # Inference Samples

  Inference type|Python sample (Notebook)|CLI with YAML
  |--|--|--|
  Real time|<a href="https://aka.ms/azureml-infer-sdk-image-object-detection" target="_blank">image-object-detection-online-endpoint.ipynb</a>|<a href="https://aka.ms/azureml-infer-cli-image-object-detection" target="_blank">image-object-detection-online-endpoint.sh</a>
  Batch |<a href="https://aka.ms/azureml-infer-batch-sdk-image-object-detection" target="_blank">image-object-detection-batch-endpoint.ipynb</a>|<a href="https://aka.ms/azureml-infer-batch-cli-image-object-detection" target="_blank">image-object-detection-batch-endpoint.sh</a>

  # Finetuning Samples

  Task|Use case|Dataset|Python sample (Notebook)|CLI with YAML
  |---|--|--|--|--|
  Image object detection|Image object detection|[fridgeObjects](https://cvbp-secondary.z19.web.core.windows.net/datasets/object_detection/odFridgeObjects.zip)|<a href="https://aka.ms/azureml-ft-sdk-image-object-detection" target="_blank">fridgeobjects-object-detection.ipynb</a>|<a href="https://aka.ms/azureml-ft-cli-image-object-detection" target="_blank">fridgeobjects-object-detection.sh</a>

  # Evaluation Samples

  |Task|Use case|Dataset|Python sample (Notebook)|
  |---|--|--|--|
  Image object detection|Image object detection|[fridgeObjects](https://cvbp-secondary.z19.web.core.windows.net/datasets/object_detection/odFridgeObjects.zip)|<a href="https://aka.ms/azureml-evaluation-sdk-image-object-detection" target="_blank">image-object-detection.ipynb</a>|

  # Sample input and output

  ### Sample input

  ```json
  {
    "input_data": {
      "columns": [
        "image"
      ],
      "index": [0, 1],
      "data": ["image1", "image2"]
    }
  }
  ```

  Note: "image1" and "image2" string should be in base64 format or publicly accessible urls.

  ### Sample output

  ```json
  [
      {
          "boxes": [
              {
                  "box": {
                      "topX": 0.1,
                      "topY": 0.2,
                      "bottomX": 0.8,
                      "bottomY": 0.7
                  },
                  "label": "carton",
                  "score": 0.98
              }
          ]
      },
      {
          "boxes": [
              {
                  "box": {
                      "topX": 0.2,
                      "topY": 0.3,
                      "bottomX": 0.6,
                      "bottomY": 0.5
                  },
                  "label": "can",
                  "score": 0.97
              }
          ]
      }
  ]
  ```

  Note: Please refer to object detection output <a href="https://learn.microsoft.com/en-us/azure/machine-learning/reference-automl-images-schema?view=azureml-api-2#object-detection-1" target="_blank">data schema</a> for more detail.

  #### Visualization of inference result for a sample image

  <img src="https://automlcesdkdataresources.blob.core.windows.net/finetuning-image-models/images/Model_Result_Visualizations(Do_not_delete)/plot_deformable_detr_twostage_refine_r50_16x2_50e_coco_OD.png" alt="od visualization">
