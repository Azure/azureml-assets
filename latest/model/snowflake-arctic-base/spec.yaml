$schema: https://azuremlschemas.azureedge.net/latest/model.schema.json
name: snowflake-arctic-base
path: ./
properties:
  SharedComputeCapacityEnabled: true
  SHA: 76fa59362cd95eb633a4e419c24364c90674966c
  inference-min-sku-spec: 96|12|1900|1024
  inference-recommended-sku: Standard_ND96isr_H100_v5
  languages: moe, fr, it, de, es, en
tags:
  Featured: ''
  huggingface_model_id: Snowflake/snowflake-arctic-base
  license: apache2.0
  disable-batch: 'true'
  task: text-generation
  SharedComputeCapacityEnabled: ''
  author: Snowflake
  inference_compute_allow_list: [Standard_ND96isr_H100_v5]
  inference_supported_envs:
  - vllm
version: 1
description: |-
  # Model Overview

  Arctic is a dense-MoE Hybrid transformer architecture pre-trained from scratch by the Snowflake AI Research Team. We are releasing model checkpoints for both the base and instruct-tuned versions of Arctic under an Apache-2.0 license. This means you can use them freely in your own research, prototypes, and products. Please see our blog [Snowflake Arctic: The Best LLM for Enterprise AI â€” Efficiently Intelligent, Truly Open](https://www.snowflake.com/blog/arctic-open-efficient-foundation-language-models-snowflake) for more information on Arctic and links to other relevant resources such as our series of cookbooks covering topics around training your own custom MoE models, how to produce high-quality training data, and much more.

  - **Inputs:** Models input text only.
  - **Output:** Models generate text and code only.
  - **Model Architecture:** Arctic combines a 10B dense transformer model with a residual 128x3.66B MoE MLP resulting in 480B total and 17B active parameters chosen using a top-2 gating. For more details about Arctic's model Architecture, training process, data, etc. [see our series of cookbooks](https://www.snowflake.com/en/data-cloud/arctic/cookbook/).
  - **License:** Apache-2.0.
  - **Model developers:** Snowflake AI Research Team.

  ## Training Data
  Snowflake Arctic was pretrained on 3.5 trillion tokens of data from publicly available sources. The fine-tuning data includes publicly available  datasets.

  ## Evaluation Results

  | Metric                                   | Value  |
  |------------------------------------------|--------|
  | MMLU                                     | 67.3   |
  | GSM8k                                    | 74.2   |
  | Spider                                   | 78.9   |
  | IFEval                                   | 52.4   |
  | Coding - HumanEval+ & MBPP+ -            | 64.3   |

  # Inference samples
  Inference type|Python sample (Notebook)|CLI with YAML
  |--|--|--|
  Real time|<a href="https://aka.ms/azureml-infer-online-sdk-text-generation-dolly" target="_blank">text-generation-online-endpoint.ipynb</a>|<a href="https://aka.ms/azureml-infer-online-cli-text-generation-dolly" target="_blank">text-generation-online-endpoint.sh</a>
  Batch |<a href="https://aka.ms/azureml-infer-batch-sdk-text-generation" target="_blank">text-generation-batch-endpoint.ipynb</a>| coming soon


  # Sample Inputs and Outputs (for real-time inference)
  ### **Sample input**
  ```json
  {
    "input_data": {
        "input_string": ["I believe the meaning of life is"],
        "parameters":{   
                "top_p": 0.9,
                "temperature": 0.6,
                "max_new_tokens": 96,
                "do_sample": true
        }
    }
  }
  ```
  ### **Sample output**
  ```json
  [
      {
          "0": "I believe the meaning of life is to learn to love.\\nI believe in a world of compassion, a world where love rules.\\nI believe in a world where people care for one another.\\nI believe in a world where people help each other.\\nI believe in a world where people are kind to each other.\\nI believe in a world where people are happy.\\nI believe in a world where people are peaceful.\\nI believe in a world where people are loving."
      }
  ]
  ```
