$schema: https://azuremlschemas.azureedge.net/latest/model.schema.json
name: how-to-use-functions-with-GPT-chat-API
path: ./
properties:
  is-promptflow: true
  azureml.promptflow.section: gallery
  azureml.promptflow.type: chat
  azureml.promptflow.name: Use GPT Function Calling
  azureml.promptflow.description: Learn how to use GPT function calling to extend
    the capabilities of GPT models with external data sources.
  inference-min-sku-spec: 2|0|14|28
  inference-recommended-sku: Standard_DS3_v2
version: 7
description: |-
  The "Use Functions with Chat Models" is a chat model illustrates how to employ the LLM tool's Chat API with external functions, thereby expanding the capabilities of GPT models. The Chat Completion API includes an optional 'functions' parameter, which can be used to stipulate function specifications. This allows models to generate arguments that comply with the given specifications. However, it's important to note that the API will not directly execute any function calls. The responsibility of executing function calls using the model outputs lies with the developers.


  ### Inference samples

  Inference type|CLI|VS Code Extension
  |--|--|--|
  Real time|<a href="https://microsoft.github.io/promptflow/how-to-guides/deploy-a-flow/index.html" target="_blank">deploy-promptflow-model-cli-example</a>|<a href="https://microsoft.github.io/promptflow/how-to-guides/deploy-a-flow/index.html" target="_blank">deploy-promptflow-model-vscode-extension-example</a>
  Batch | N/A | N/A

  ### Sample inputs and outputs (for real-time inference)

  #### Sample input
  ```json
  {
      "inputs": {
          "question": "How about London next week?"
      }
  }
  ```

  #### Sample output
  ```json
  {
      "outputs": {
          "answer": "Function generation requested, function = get_n_day_weather_forecast, args = { 'location': 'London', 'num_days': 7, 'format': 'celsius' }"
      }
  }
  ```
