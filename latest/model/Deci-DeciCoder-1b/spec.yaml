$schema: https://azuremlschemas.azureedge.net/latest/model.schema.json
name: Deci-DeciCoder-1b
path: ./
properties:
  SharedComputeCapacityEnabled: true
  SHA: 59cead352e3b213c9a77097d3d08e89bf467ef7b
  inference-recommended-sku: Standard_NC12s_v3, Standard_NC24s_v3, Standard_ND40rs_v2,
    Standard_ND96asr_v4, Standard_ND96amsr_A100_v4
  inference-min-sku-spec: 12|2|224|672
  evaluation-recommended-sku: Standard_NC12s_v3, Standard_NC24s_v3, Standard_ND40rs_v2,
    Standard_ND96asr_v4, Standard_ND96amsr_A100_v4
  evaluation-min-sku-spec: 12|2|224|672
  languages: EN
tags:
  Featured: ''
  Preview: ''
  inference_compute_allow_list:
  - Standard_NC12s_v3
  - Standard_NC24s_v3
  - Standard_ND40rs_v2
  - Standard_ND96asr_v4
  - Standard_ND96amsr_A100_v4
  evaluation_compute_allow_list:
  - Standard_NC12s_v3
  - Standard_NC24s_v3
  - Standard_ND40rs_v2
  - Standard_ND96asr_v4
  - Standard_ND96amsr_A100_v4
  SharedComputeCapacityEnabled: ''
  task: text-generation
  license: apache-2.0
  author: deci-ai
  huggingface_model_id: Deci/DeciCoder-1b
  datasets: bigcode/starcoderdata
version: 3
description: |-
  The Model Card for DeciCoder 1B provides details about a 1 billion parameter decoder-only code completion model developed by Deci. The model was trained on Python, Java, and JavaScript subsets of Starcoder Training Dataset and uses Grouped Query Attention with a context window of 2048 tokens. It was trained using a Fill-in-the-Middle training objective and generated by Deci's proprietary Neural Architecture Search-based technology, AutoNAC. The model is intended for single/multiline code completion from a context window of up to 2048 tokens. The model has limitations as it has undergone training with source code from Python, Java, and JavaScript, and there is no assurance that the resulting code will function as expected. The Model Card provides details on how to use the model, training details, and evaluation results. The model's checkpoints are licensed under the Apache 2.0 license.


  # Model Evaluation Sample

  Task| Use case| Dataset| Python sample (Notebook)| CLI with YAML
  |--|--|--|--|--|
  Text generation | Text generation | <a href="https://huggingface.co/datasets/cnn_dailymail" target="_blank"> cnn_dailymail </a> | <a href="https://aka.ms/azureml-eval-sdk-text-generation/" target="_blank">evaluate-model-text-generation.ipynb</a> | <a href="https://aka.ms/azureml-eval-cli-text-generation/" target="_blank">evaluate-model-text-generation.yml</a>

  # Inference samples

  Inference type|Python sample (Notebook)|CLI with YAML
  |--|--|--|
  Real time|<a href="https://aka.ms/azureml-infer-online-sdk-text-generation-dolly" target="_blank">text-generation-online-endpoint.ipynb</a>|<a href="https://aka.ms/azureml-infer-online-cli-text-generation-dolly" target="_blank">text-generation-online-endpoint.sh</a>
  Batch |<a href="https://aka.ms/azureml-infer-batch-sdk-text-generation" target="_blank">text-generation-batch-endpoint.ipynb</a>| coming soon

  # Sample inputs and outputs (for real-time inference)

  ### Sample input
  ```json
  {
    "input_data": {
      "input_string": [
        "def print_hello_world():"
      ],
      "parameters": {
        "top_p": 0.95,
        "temperature": 0.1,
        "max_new_tokens": 10,
        "do_sample": true
      }
    }
  }
  ```

  ### Sample output
  ```json
  [
    {
      "0": "def print_hello_world():\n    print(\"Hello World!\")\n\n\ndef print"
    }
  ]
  ```
