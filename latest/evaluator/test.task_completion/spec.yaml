type: "evaluator"
name: "test.task_completion"
version: 1
displayName: "Task-Completion-Evaluator"
description: "| | |\n| -- | -- |\n| Score range | Boolean [True/False]: True means
  task was successfully completed, False means task failed or not completed. |\n|
  What is this metric? | Task Completion evaluates whether an AI agent successfully
  completed the requested task based on the final outcome and deliverable quality.
  |\n| How does it work? | This metric analyzes the conversation history and agent
  response to determine if all task requirements were met and a usable deliverable
  was provided. It focuses solely on completion status, not adherence or intent understanding.
  |\n| When to use it? | Use this metric to assess agent effectiveness in task-oriented
  scenarios, workflow automation, and goal-oriented AI interactions. |\n| What does
  it need as input? | Query, Response, Tool Definitions (optional) |\n"
evaluatorType: "builtin"
evaluatorSubType: "code"
categories: ["agents"]
initParameterSchema:
  type: "object"
  properties:
    deployment_name:
      type: "string"
    credential:
      type: "object"
  required: ["deployment_name"]
dataMappingSchema:
  type: "object"
  properties:
    query:
      anyOf:
      - type: "string"
      - type: "array"
        items:
          type: "object"
    response:
      anyOf:
      - type: "string"
      - type: "array"
        items:
          type: "object"
    tool_definitions:
      anyOf:
      - type: "object"
      - type: "array"
        items:
          type: "object"
  required: ["query", "response"]
outputSchema:
  task_completion:
    type: "binary"
    desirable_direction: "increase"
    min_value: 0
    max_value: 1
path: ./evaluator
