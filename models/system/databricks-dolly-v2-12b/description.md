The dolly-v2-12b model is a large, instruction-following language model created by Databricks, Inc. and is licensed for commercial use. It is based on EleutherAIâ€™s Pythia-12b and was trained on a 15,000-record instruction corpus generated by Databricks employees, which was released under a CC-BY-SA license. It is not a state-of-the-art model, but it does exhibit high-quality instruction-following behavior that is not characteristic of the foundation model on which it is based. The model is available in three sizes: dolly-v2-12b, dolly-v2-7b, and dolly-v2-3b.

> The above summary was generated using ChatGPT. Review the <a href="https://huggingface.co/databricks/dolly-v2-12b" target="_blank">original model card</a> to understand the data used to train the model, evaluation metrics, license, intended uses, limitations and bias before using the model.

### Sample inputs and outputs (for real-time inference)

```json
{
    "inputs": {
        "input_string": ["My name is John and I am", "Once upon a time,"]
    }
}
```

#### Sample output
```json
[
    {
        "0": "My name is John and I am a student at UC Berkeley. It is my main interest to do research in the humanities. I am going to share"
    },
    {
        "0": "Once upon a time, they were just another small family, only three. She says one day that her father was getting a new license"
    }
]
```
