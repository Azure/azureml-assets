$schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json
name: azureml_tokenclassification_deploy
version: 0.0.1
type: command

is_deterministic: True

display_name: Deploy for TokenClassification
description: Component to deploy finetuned model for name entity recognition task

environment: azureml:azml-train-finetune-deploy-curated-acpt-pytorch-111-py38-cuda113-gpu:0.0.1

code: ../scripts/deploy

inputs:
  # Output of finetuning component
  model_checkpoint_dir:
    type: uri_folder
    optional: false
    description: The input path that contains the model files

  registry_name:
    type: string
    optional: true
    description: The name of the registry

  deployment_env_name:
    type: string
    optional: true
    description: The name of the environment to be deployed at online endpoint

  name_for_registered_model:
    type: string
    default: inferencemodel
    description: The name you want to give to the registered model

  endpoint_name:
    type: string
    default: inference-end-point
    description: The name of the endpoint to deploy the model to

  # TODO Add list of computes in enum
  instance_type:
    type: string
    default: Standard_F8s_v2
    description: The instance type to use for the deployment

  instance_count:
    type: integer
    default: 1
    description: Number of vms for the deployment

  max_concurrent_requests_per_instance:
    type: integer
    default: 1
    optional: true
    description: Maximum concurrent requests to be handled per instance

  request_timeout_ms:
    type: integer
    default: 5000
    optional: true
    description: Request timeout in ms. Max limit is 90000.

  max_queue_wait_ms:
    type: integer
    default: 500
    optional: true
    description: Maximum queue wait time of a request in ms

  # Token Classification task arguments
  token_key:
    type: string
    optional: true
    description: Token key name

  tag_key:
    type: string
    optional: true
    description: Tag key name

  label_all_tokens:
    type: string
    enum:
      - "true"
      - "false"
    default: "true"
    optional: true
    description: If all the tokens of an entity are labelled

  # Inference Parameters
  batch_size:
    type: integer
    default: 4
    optional: true
    description: Validation batch size

  precision:
    type: string
    enum:
      - "32"
      - "16"
    default: "32"
    optional: true
    description: Apply mixed precision training. This can reduce memory footprint by performing operations in half-precision.

  # Lora, Deepspeed and ORT Params
  apply_ort:
    type: string
    enum:
      - "true"
      - "false"
    default: "false"
    optional: true
    description: If set to true, will use the ONNXRunTime training

  apply_deepspeed:
    type: string
    enum:
      - "true"
      - "false"
    default: "false"
    optional: true
    description: If set to true, will enable deepspeed for training

  deepspeed_config:
    type: uri_file
    optional: true
    description: If apply_deepspeed is set to True, this file will be used as deepspeed config

command: >-
  python deploy.py --model_checkpoint_dir ${{inputs.model_checkpoint_dir}} $[[--registry_name ${{inputs.registry_name}}]] $[[--deployment_env_name ${{inputs.deployment_env_name}}]] --endpoint_name ${{inputs.endpoint_name}} --name_for_registered_model ${{inputs.name_for_registered_model}}  --instance_type ${{inputs.instance_type}} --instance_count ${{inputs.instance_count}} $[[--max_concurrent_requests_per_instance ${{inputs.max_concurrent_requests_per_instance}}]] $[[--request_timeout_ms ${{inputs.request_timeout_ms}}]] $[[--max_queue_wait_ms ${{inputs.max_queue_wait_ms}}]] $[[--token_key ${{inputs.token_key}}]] $[[--tag_key ${{inputs.tag_key}}]] $[[--label_all_tokens ${{inputs.label_all_tokens}}]] $[[--batch_size ${{inputs.batch_size}}]] $[[--precision ${{inputs.precision}}]] $[[--apply_ort ${{inputs.apply_ort}}]] $[[--apply_deepspeed ${{inputs.apply_deepspeed}}]] $[[--deepspeed_config ${{inputs.deepspeed_config}}]]

